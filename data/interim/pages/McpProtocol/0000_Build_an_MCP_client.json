{
  "title": "Build an MCP client",
  "source_url": "https://modelcontextprotocol.io/docs/develop/build-client",
  "content": "Get started building your own client that can integrate with all MCP servers.\n\nIn this tutorial, you'll learn how to build an LLM-powered chatbot client that connects to MCP servers.\n\nBefore you begin, it helps to have gone through our [Build an MCP Server](/docs/develop/build-server) tutorial so you can understand how clients and servers communicate.\n\n<Tabs>\n  <Tab title=\"Python\">\n    [You can find the complete code for this tutorial here.](https://github.com/modelcontextprotocol/quickstart-resources/tree/main/mcp-client-python)\n\n    ## System Requirements\n\n    Before starting, ensure your system meets these requirements:\n\n    * Mac or Windows computer\n    * Latest Python version installed\n    * Latest version of `uv` installed\n\n    ## Setting Up Your Environment\n\n    First, create a new Python project with `uv`:\n\n    <CodeGroup>\n      ```bash macOS/Linux theme={null}\n      # Create project directory\n      uv init mcp-client\n      cd mcp-client\n\n      # Create virtual environment\n      uv venv\n\n      # Activate virtual environment\n      source .venv/bin/activate\n\n      # Install required packages\n      uv add mcp anthropic python-dotenv\n\n      # Remove boilerplate files\n      rm main.py\n\n      # Create our main file\n      touch client.py\n      ```\n\n      ```powershell Windows theme={null}\n      # Create project directory\n      uv init mcp-client\n      cd mcp-client\n\n      # Create virtual environment\n      uv venv\n\n      # Activate virtual environment\n      .venv\\Scripts\\activate\n\n      # Install required packages\n      uv add mcp anthropic python-dotenv\n\n      # Remove boilerplate files\n      del main.py\n\n      # Create our main file\n      new-item client.py\n      ```\n    </CodeGroup>\n\n    ## Setting Up Your API Key\n\n    You'll need an Anthropic API key from the [Anthropic Console](https://console.anthropic.com/settings/keys).\n\n    Create a `.env` file to store it:\n\n    ```bash  theme={null}\n    echo \"ANTHROPIC_API_KEY=your-api-key-goes-here\" > .env\n    ```\n\n    Add `.env` to your `.gitignore`:\n\n    ```bash  theme={null}\n    echo \".env\" >> .gitignore\n    ```\n\n    <Warning>\n      Make sure you keep your `ANTHROPIC_API_KEY` secure!\n    </Warning>\n\n    ## Creating the Client\n\n    ### Basic Client Structure\n\n    First, let's set up our imports and create the basic client class:\n\n    ```python  theme={null}\n    import asyncio\n    from typing import Optional\n    from contextlib import AsyncExitStack\n\n    from mcp import ClientSession, StdioServerParameters\n    from mcp.client.stdio import stdio_client\n\n    from anthropic import Anthropic\n    from dotenv import load_dotenv\n\n    load_dotenv()  # load environment variables from .env\n\n    class MCPClient:\n        def __init__(self):\n            # Initialize session and client objects\n            self.session: Optional[ClientSession] = None\n            self.exit_stack = AsyncExitStack()\n            self.anthropic = Anthropic()\n        # methods will go here\n    ```\n\n    ### Server Connection Management\n\n    Next, we'll implement the method to connect to an MCP server:\n\n    ```python  theme={null}\n    async def connect_to_server(self, server_script_path: str):\n        \"\"\"Connect to an MCP server\n\n        Args:\n            server_script_path: Path to the server script (.py or .js)\n        \"\"\"\n        is_python = server_script_path.endswith('.py')\n        is_js = server_script_path.endswith('.js')\n        if not (is_python or is_js):\n            raise ValueError(\"Server script must be a .py or .js file\")\n\n        command = \"python\" if is_python else \"node\"\n        server_params = StdioServerParameters(\n            command=command,\n            args=[server_script_path],\n            env=None\n        )\n\n        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))\n        self.stdio, self.write = stdio_transport\n        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))\n\n        await self.session.initialize()\n\n        # List available tools\n        response = await self.session.list_tools()\n        tools = response.tools\n        print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])\n    ```\n\n    ### Query Processing Logic\n\n    Now let's add the core functionality for processing queries and handling tool calls:\n\n    ```python  theme={null}\n    async def process_query(self, query: str) -> str:\n        \"\"\"Process a query using Claude and available tools\"\"\"\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": query\n            }\n        ]\n\n        response = await self.session.list_tools()\n        available_tools = [{\n            \"name\": tool.name,\n            \"description\": tool.description,\n            \"input_schema\": tool.inputSchema\n        } for tool in response.tools]\n\n        # Initial Claude API call\n        response = self.anthropic.messages.create(\n            model=\"claude-sonnet-4-20250514\",\n            max_tokens=1000,\n            messages=messages,\n            tools=available_tools\n        )\n\n        # Process response and handle tool calls\n        final_text = []\n\n        assistant_message_content = []\n        for content in response.content:\n            if content.type == 'text':\n                final_text.append(content.text)\n                assistant_message_content.append(content)\n            elif content.type == 'tool_use':\n                tool_name = content.name\n                tool_args = content.input\n\n                # Execute tool call\n                result = await self.session.call_tool(tool_name, tool_args)\n                final_text.append(f\"[Calling tool {tool_name} with args {tool_args}]\")\n\n                assistant_message_content.append(content)\n                messages.append({\n                    \"role\": \"assistant\",\n                    \"content\": assistant_message_content\n                })\n                messages.append({\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"tool_result\",\n                            \"tool_use_id\": content.id,\n                            \"content\": result.content\n                        }\n                    ]\n                })\n\n                # Get next response from Claude\n                response = self.anthropic.messages.create(\n                    model=\"claude-sonnet-4-20250514\",\n                    max_tokens=1000,\n                    messages=messages,\n                    tools=available_tools\n                )\n\n                final_text.append(response.content[0].text)\n\n        return \"\\n\".join(final_text)\n    ```\n\n    ### Interactive Chat Interface\n\n    Now we'll add the chat loop and cleanup functionality:\n\n    ```python  theme={null}\n    async def chat_loop(self):\n        \"\"\"Run an interactive chat loop\"\"\"\n        print(\"\\nMCP Client Started!\")\n        print(\"Type your queries or 'quit' to exit.\")\n\n        while True:\n            try:\n                query = input(\"\\nQuery: \").strip()\n\n                if query.lower() == 'quit':\n                    break\n\n                response = await self.process_query(query)\n                print(\"\\n\" + response)\n\n            except Exception as e:\n                print(f\"\\nError: {str(e)}\")\n\n    async def cleanup(self):\n        \"\"\"Clean up resources\"\"\"\n        await self.exit_stack.aclose()\n    ```\n\n    ### Main Entry Point\n\n    Finally, we'll add the main execution logic:\n\n    ```python  theme={null}\n    async def main():\n        if len(sys.argv) < 2:\n            print(\"Usage: python client.py <path_to_server_script>\")\n            sys.exit(1)\n\n        client = MCPClient()\n        try:\n            await client.connect_to_server(sys.argv[1])\n            await client.chat_loop()\n        finally:\n            await client.cleanup()\n\n    if __name__ == \"__main__\":\n        import sys\n        asyncio.run(main())\n    ```\n\n    You can find the complete `client.py` file [here](https://github.com/modelcontextprotocol/quickstart-resources/blob/main/mcp-client-python/client.py).\n\n    ## Key Components Explained\n\n    ### 1. Client Initialization\n\n    * The `MCPClient` class initializes with session management and API clients\n    * Uses `AsyncExitStack` for proper resource management\n    * Configures the Anthropic client for Claude interactions\n\n    ### 2. Server Connection\n\n    * Supports both Python and Node.js servers\n    * Validates server script type\n    * Sets up proper communication channels\n    * Initializes the session and lists available tools\n\n    ### 3. Query Processing\n\n    * Maintains conversation context\n    * Handles Claude's responses and tool calls\n    * Manages the message flow between Claude and tools\n    * Combines results into a coherent response\n\n    ### 4. Interactive Interface\n\n    * Provides a simple command-line interface\n    * Handles user input and displays responses\n    * Includes basic error handling\n    * Allows graceful exit\n\n    ### 5. Resource Management\n\n    * Proper cleanup of resources\n    * Error handling for connection issues\n    * Graceful shutdown procedures\n\n    ## Common Customization Points\n\n    1. **Tool Handling**\n       * Modify `process_query()` to handle specific tool types\n       * Add custom error handling for tool calls\n       * Implement tool-specific response formatting\n\n    2. **Response Processing**\n       * Customize how tool results are formatted\n       * Add response filtering or transformation\n       * Implement custom logging\n\n    3. **User Interface**\n       * Add a GUI or web interface\n       * Implement rich console output\n       * Add command history or auto-completion\n\n    ## Running the Client\n\n    To run your client with any MCP server:\n\n    ```bash  theme={null}\n    uv run client.py path/to/server.py # python server\n    uv run client.py path/to/build/index.js # node server\n    ```\n\n    <Note>\n      If you're continuing [the weather tutorial from the server quickstart](https://github.com/modelcontextprotocol/quickstart-resources/tree/main/weather-server-python), your command might look something like this: `python client.py .../quickstart-resources/weather-server-python/weather.py`\n    </Note>\n\n    The client will:\n\n    1. Connect to the specified server\n    2. List available tools\n    3. Start an interactive chat session where you can:\n       * Enter queries\n       * See tool executions\n       * Get responses from Claude\n\n    Here's an example of what it should look like if connected to the weather server from the server quickstart:\n\n    <Frame>\n      <img src=\"https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=686d6e0ae7c54f807827db111eaed7d4\" data-og-width=\"1932\" width=\"1932\" data-og-height=\"1739\" height=\"1739\" data-path=\"images/client-claude-cli-python.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?w=280&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=48ff45c4ca51501589d9f20f060daa56 280w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?w=560&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=b35ca5d8a67c2f08efec9c6519efcfe2 560w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?w=840&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=51b8f5c7fa48db6ccd30aa9988a8c917 840w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?w=1100&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=9e1b01bc4c324a7e5100674f63f36b13 1100w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?w=1650&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=e3e961bd5b5506fed6c860f70df9bf9d 1650w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/client-claude-cli-python.png?w=2500&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=da01c2527db68cb0c99d29d20751a868 2500w\" />\n    </Frame>\n\n    ## How It Works\n\n    When you submit a query:\n\n    1. The client gets the list of available tools from the server\n    2. Your query is sent to Claude along with tool descriptions\n    3. Claude decides which tools (if any) to use\n    4. The client executes any requested tool calls through the server\n    5. Results are sent back to Claude\n    6. Claude provides a natural language response\n    7. The response is displayed to you\n\n    ## Best practices\n\n    1. **Error Handling**\n       * Always wrap tool calls in try-catch blocks\n       * Provide meaningful error messages\n       * Gracefully handle connection issues\n\n    2. **Resource Management**\n       * Use `AsyncExitStack` for proper cleanup\n       * Close connections when done\n       * Handle server disconnections\n\n    3. **Security**\n       * Store API keys securely in `.env`\n       * Validate server responses\n       * Be cautious with tool permissions\n\n    4. **Tool Names**\n       * Tool names can be validated according to the format specified [here](/specification/draft/server/tools#tool-names)\n       * If a tool name conforms to the specified format, it should not fail validation by an MCP client\n\n    ## Troubleshooting\n\n    ### Server Path Issues\n\n    * Double-check the path to your server script is correct\n    * Use the absolute path if the relative path isn't working\n    * For Windows users, make sure to use forward slashes (/) or escaped backslashes (\\\\) in the path\n    * Verify the server file has the correct extension (.py for Python or .js for Node.js)\n\n    Example of correct path usage:\n\n    ```bash  theme={null}\n    # Relative path\n    uv run client.py ./server/weather.py\n\n    # Absolute path\n    uv run client.py /Users/username/projects/mcp-server/weather.py\n\n    # Windows path (either format works)\n    uv run client.py C:/projects/mcp-server/weather.py\n    uv run client.py C:\\\\projects\\\\mcp-server\\\\weather.py\n    ```\n\n    ### Response Timing\n\n    * The first response might take up to 30 seconds to return\n    * This is normal and happens while:\n      * The server initializes\n      * Claude processes the query\n      * Tools are being executed\n    * Subsequent responses are typically faster\n    * Don't interrupt the process during this initial waiting period\n\n    ### Common Error Messages\n\n    If you see:\n\n    * `FileNotFoundError`: Check your server path\n    * `Connection refused`: Ensure the server is running and the path is correct\n    * `Tool execution failed`: Verify the tool's required environment variables are set\n    * `Timeout error`: Consider increasing the timeout in your client configuration\n  </Tab>\n\n  <Tab title=\"TypeScript\">\n    [You can find the complete code for this tutorial here.](https://github.com/modelcontextprotocol/quickstart-resources/tree/main/mcp-client-typescript)\n\n    ## System Requirements\n\n    Before starting, ensure your system meets these requirements:\n\n    * Mac or Windows computer\n    * Node.js 17 or higher installed\n    * Latest version of `npm` installed\n    * Anthropic API key (Claude)\n\n    ## Setting Up Your Environment\n\n    First, let's create and set up our project:\n\n    <CodeGroup>\n      ```bash macOS/Linux theme={null}\n      # Create project directory\n      mkdir mcp-client-typescript\n      cd mcp-client-typescript\n\n      # Initialize npm project\n      npm init -y\n\n      # Install dependencies\n      npm install @anthropic-ai/sdk @modelcontextprotocol/sdk dotenv\n\n      # Install dev dependencies\n      npm install -D @types/node typescript\n\n      # Create source file\n      touch index.ts\n      ```\n\n      ```powershell Windows theme={null}\n      # Create project directory\n      md mcp-client-typescript\n      cd mcp-client-typescript\n\n      # Initialize npm project\n      npm init -y\n\n      # Install dependencies\n      npm install @anthropic-ai/sdk @modelcontextprotocol/sdk dotenv\n\n      # Install dev dependencies\n      npm install -D @types/node typescript\n\n      # Create source file\n      new-item index.ts\n      ```\n    </CodeGroup>\n\n    Update your `package.json` to set `type: \"module\"` and a build script:\n\n    ```json package.json theme={null}\n    {\n      \"type\": \"module\",\n      \"scripts\": {\n        \"build\": \"tsc && chmod 755 build/index.js\"\n      }\n    }\n    ```\n\n    Create a `tsconfig.json` in the root of your project:\n\n    ```json tsconfig.json theme={null}\n    {\n      \"compilerOptions\": {\n        \"target\": \"ES2022\",\n        \"module\": \"Node16\",\n        \"moduleResolution\": \"Node16\",\n        \"outDir\": \"./build\",\n        \"rootDir\": \"./\",\n        \"strict\": true,\n        \"esModuleInterop\": true,\n        \"skipLibCheck\": true,\n        \"forceConsistentCasingInFileNames\": true\n      },\n      \"include\": [\"index.ts\"],\n      \"exclude\": [\"node_modules\"]\n    }\n    ```\n\n    ## Setting Up Your API Key\n\n    You'll need an Anthropic API key from the [Anthropic Console](https://console.anthropic.com/settings/keys).\n\n    Create a `.env` file to store it:\n\n    ```bash  theme={null}\n    echo \"ANTHROPIC_API_KEY=<your key here>\" > .env\n    ```\n\n    Add `.env` to your `.gitignore`:\n\n    ```bash  theme={null}\n    echo \".env\" >> .gitignore\n    ```\n\n    <Warning>\n      Make sure you keep your `ANTHROPIC_API_KEY` secure!\n    </Warning>\n\n    ## Creating the Client\n\n    ### Basic Client Structure\n\n    First, let's set up our imports and create the basic client class in `index.ts`:\n\n    ```typescript  theme={null}\n    import { Anthropic } from \"@anthropic-ai/sdk\";\n    import {\n      MessageParam,\n      Tool,\n    } from \"@anthropic-ai/sdk/resources/messages/messages.mjs\";\n    import { Client } from \"@modelcontextprotocol/sdk/client/index.js\";\n    import { StdioClientTransport } from \"@modelcontextprotocol/sdk/client/stdio.js\";\n    import readline from \"readline/promises\";\n    import dotenv from \"dotenv\";\n\n    dotenv.config();\n\n    const ANTHROPIC_API_KEY = process.env.ANTHROPIC_API_KEY;\n    if (!ANTHROPIC_API_KEY) {\n      throw new Error(\"ANTHROPIC_API_KEY is not set\");\n    }\n\n    class MCPClient {\n      private mcp: Client;\n      private anthropic: Anthropic;\n      private transport: StdioClientTransport | null = null;\n      private tools: Tool[] = [];\n\n      constructor() {\n        this.anthropic = new Anthropic({\n          apiKey: ANTHROPIC_API_KEY,\n        });\n        this.mcp = new Client({ name: \"mcp-client-cli\", version: \"1.0.0\" });\n      }\n      // methods will go here\n    }\n    ```\n\n    ### Server Connection Management\n\n    Next, we'll implement the method to connect to an MCP server:\n\n    ```typescript  theme={null}\n    async connectToServer(serverScriptPath: string) {\n      try {\n        const isJs = serverScriptPath.endsWith(\".js\");\n        const isPy = serverScriptPath.endsWith(\".py\");\n        if (!isJs && !isPy) {\n          throw new Error(\"Server script must be a .js or .py file\");\n        }\n        const command = isPy\n          ? process.platform === \"win32\"\n            ? \"python\"\n            : \"python3\"\n          : process.execPath;\n\n        this.transport = new StdioClientTransport({\n          command,\n          args: [serverScriptPath],\n        });\n        await this.mcp.connect(this.transport);\n\n        const toolsResult = await this.mcp.listTools();\n        this.tools = toolsResult.tools.map((tool) => {\n          return {\n            name: tool.name,\n            description: tool.description,\n            input_schema: tool.inputSchema,\n          };\n        });\n        console.log(\n          \"Connected to server with tools:\",\n          this.tools.map(({ name }) => name)\n        );\n      } catch (e) {\n        console.log(\"Failed to connect to MCP server: \", e);\n        throw e;\n      }\n    }\n    ```\n\n    ### Query Processing Logic\n\n    Now let's add the core functionality for processing queries and handling tool calls:\n\n    ```typescript  theme={null}\n    async processQuery(query: string) {\n      const messages: MessageParam[] = [\n        {\n          role: \"user\",\n          content: query,\n        },\n      ];\n\n      const response = await this.anthropic.messages.create({\n        model: \"claude-sonnet-4-20250514\",\n        max_tokens: 1000,\n        messages,\n        tools: this.tools,\n      });\n\n      const finalText = [];\n\n      for (const content of response.content) {\n        if (content.type === \"text\") {\n          finalText.push(content.text);\n        } else if (content.type === \"tool_use\") {\n          const toolName = content.name;\n          const toolArgs = content.input as { [x: string]: unknown } | undefined;\n\n          const result = await this.mcp.callTool({\n            name: toolName,\n            arguments: toolArgs,\n          });\n          finalText.push(\n            `[Calling tool ${toolName} with args ${JSON.stringify(toolArgs)}]`\n          );\n\n          messages.push({\n            role: \"user\",\n            content: result.content as string,\n          });\n\n          const response = await this.anthropic.messages.create({\n            model: \"claude-sonnet-4-20250514\",\n            max_tokens: 1000,\n            messages,\n          });\n\n          finalText.push(\n            response.content[0].type === \"text\" ? response.content[0].text : \"\"\n          );\n        }\n      }\n\n      return finalText.join(\"\\n\");\n    }\n    ```\n\n    ### Interactive Chat Interface\n\n    Now we'll add the chat loop and cleanup functionality:\n\n    ```typescript  theme={null}\n    async chatLoop() {\n      const rl = readline.createInterface({\n        input: process.stdin,\n        output: process.stdout,\n      });\n\n      try {\n        console.log(\"\\nMCP Client Started!\");\n        console.log(\"Type your queries or 'quit' to exit.\");\n\n        while (true) {\n          const message = await rl.question(\"\\nQuery: \");\n          if (message.toLowerCase() === \"quit\") {\n            break;\n          }\n          const response = await this.processQuery(message);\n          console.log(\"\\n\" + response);\n        }\n      } finally {\n        rl.close();\n      }\n    }\n\n    async cleanup() {\n      await this.mcp.close();\n    }\n    ```\n\n    ### Main Entry Point\n\n    Finally, we'll add the main execution logic:\n\n    ```typescript  theme={null}\n    async function main() {\n      if (process.argv.length < 3) {\n        console.log(\"Usage: node index.ts <path_to_server_script>\");\n        return;\n      }\n      const mcpClient = new MCPClient();\n      try {\n        await mcpClient.connectToServer(process.argv[2]);\n        await mcpClient.chatLoop();\n      } catch (e) {\n        console.error(\"Error:\", e);\n        await mcpClient.cleanup();\n        process.exit(1);\n      } finally {\n        await mcpClient.cleanup();\n        process.exit(0);\n      }\n    }\n\n    main();\n    ```\n\n    ## Running the Client\n\n    To run your client with any MCP server:\n\n    ```bash  theme={null}\n    # Build TypeScript\n    npm run build\n\n    # Run the client\n    node build/index.js path/to/server.py # python server\n    node build/index.js path/to/build/index.js # node server\n    ```\n\n    <Note>\n      If you're continuing [the weather tutorial from the server quickstart](https://github.com/modelcontextprotocol/quickstart-resources/tree/main/weather-server-typescript), your command might look something like this: `node build/index.js .../quickstart-resources/weather-server-typescript/build/index.js`\n    </Note>\n\n    **The client will:**\n\n    1. Connect to the specified server\n    2. List available tools\n    3. Start an interactive chat session where you can:\n       * Enter queries\n       * See tool executions\n       * Get responses from Claude\n\n    ## How It Works\n\n    When you submit a query:\n\n    1. The client gets the list of available tools from the server\n    2. Your query is sent to Claude along with tool descriptions\n    3. Claude decides which tools (if any) to use\n    4. The client executes any requested tool calls through the server\n    5. Results are sent back to Claude\n    6. Claude provides a natural language response\n    7. The response is displayed to you\n\n    ## Best practices\n\n    1. **Error Handling**\n       * Use TypeScript's type system for better error detection\n       * Wrap tool calls in try-catch blocks\n       * Provide meaningful error messages\n       * Gracefully handle connection issues\n\n    2. **Security**\n       * Store API keys securely in `.env`\n       * Validate server responses\n       * Be cautious with tool permissions\n\n    ## Troubleshooting\n\n    ### Server Path Issues\n\n    * Double-check the path to your server script is correct\n    * Use the absolute path if the relative path isn't working\n    * For Windows users, make sure to use forward slashes (/) or escaped backslashes (\\\\) in the path\n    * Verify the server file has the correct extension (.js for Node.js or .py for Python)\n\n    Example of correct path usage:\n\n    ```bash  theme={null}\n    # Relative path\n    node build/index.js ./server/build/index.js\n\n    # Absolute path\n    node build/index.js /Users/username/projects/mcp-server/build/index.js\n\n    # Windows path (either format works)\n    node build/index.js C:/projects/mcp-server/build/index.js\n    node build/index.js C:\\\\projects\\\\mcp-server\\\\build\\\\index.js\n    ```\n\n    ### Response Timing\n\n    * The first response might take up to 30 seconds to return\n    * This is normal and happens while:\n      * The server initializes\n      * Claude processes the query\n      * Tools are being executed\n    * Subsequent responses are typically faster\n    * Don't interrupt the process during this initial waiting period\n\n    ### Common Error Messages\n\n    If you see:\n\n    * `Error: Cannot find module`: Check your build folder and ensure TypeScript compilation succeeded\n    * `Connection refused`: Ensure the server is running and the path is correct\n    * `Tool execution failed`: Verify the tool's required environment variables are set\n    * `ANTHROPIC_API_KEY is not set`: Check your .env file and environment variables\n    * `TypeError`: Ensure you're using the correct types for tool arguments\n    * `BadRequestError`: Ensure you have enough credits to access the Anthropic API\n  </Tab>\n\n  <Tab title=\"Java\">\n    <Note>\n      This is a quickstart demo based on Spring AI MCP auto-configuration and boot starters.\n      To learn how to create sync and async MCP Clients manually, consult the [Java SDK Client](/sdk/java/mcp-client) documentation\n    </Note>\n\n    This example demonstrates how to build an interactive chatbot that combines Spring AI's Model Context Protocol (MCP) with the [Brave Search MCP Server](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search). The application creates a conversational interface powered by Anthropic's Claude AI model that can perform internet searches through Brave Search, enabling natural language interactions with real-time web data.\n    [You can find the complete code for this tutorial here.](https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/web-search/brave-chatbot)\n\n    ## System Requirements\n\n    Before starting, ensure your system meets these requirements:\n\n    * Java 17 or higher\n    * Maven 3.6+\n    * npx package manager\n    * Anthropic API key (Claude)\n    * Brave Search API key\n\n    ## Setting Up Your Environment\n\n    1. Install npx (Node Package eXecute):\n       First, make sure to install [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\n       and then run:\n\n       ```bash  theme={null}\n       npm install -g npx\n       ```\n\n    2. Clone the repository:\n\n       ```bash  theme={null}\n       git clone https://github.com/spring-projects/spring-ai-examples.git\n       cd model-context-protocol/web-search/brave-chatbot\n       ```\n\n    3. Set up your API keys:\n\n       ```bash  theme={null}\n       export ANTHROPIC_API_KEY='your-anthropic-api-key-here'\n       export BRAVE_API_KEY='your-brave-api-key-here'\n       ```\n\n    4. Build the application:\n\n       ```bash  theme={null}\n       ./mvnw clean install\n       ```\n\n    5. Run the application using Maven:\n       ```bash  theme={null}\n       ./mvnw spring-boot:run\n       ```\n\n    <Warning>\n      Make sure you keep your `ANTHROPIC_API_KEY` and `BRAVE_API_KEY` keys secure!\n    </Warning>\n\n    ## How it Works\n\n    The application integrates Spring AI with the Brave Search MCP server through several components:\n\n    ### MCP Client Configuration\n\n    1. Required dependencies in pom.xml:\n\n    ```xml  theme={null}\n    <dependency>\n        <groupId>org.springframework.ai</groupId>\n        <artifactId>spring-ai-starter-mcp-client</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.ai</groupId>\n        <artifactId>spring-ai-starter-model-anthropic</artifactId>\n    </dependency>\n    ```\n\n    2. Application properties (application.yml):\n\n    ```yml  theme={null}\n    spring:\n      ai:\n        mcp:\n          client:\n            enabled: true\n            name: brave-search-client\n            version: 1.0.0\n            type: SYNC\n            request-timeout: 20s\n            stdio:\n              root-change-notification: true\n              servers-configuration: classpath:/mcp-servers-config.json\n            toolcallback:\n              enabled: true\n        anthropic:\n          api-key: ${ANTHROPIC_API_KEY}\n    ```\n\n    This activates the `spring-ai-starter-mcp-client` to create one or more `McpClient`s based on the provided server configuration.\n    The `spring.ai.mcp.client.toolcallback.enabled=true` property enables the tool callback mechanism, that automatically registers all MCP tool as spring ai tools.\n    It is disabled by default.\n\n    3. MCP Server Configuration (`mcp-servers-config.json`):\n\n    ```json  theme={null}\n    {\n      \"mcpServers\": {\n        \"brave-search\": {\n          \"command\": \"npx\",\n          \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"],\n          \"env\": {\n            \"BRAVE_API_KEY\": \"<PUT YOUR BRAVE API KEY>\"\n          }\n        }\n      }\n    }\n    ```\n\n    ### Chat Implementation\n\n    The chatbot is implemented using Spring AI's ChatClient with MCP tool integration:\n\n    ```java  theme={null}\n    var chatClient = chatClientBuilder\n        .defaultSystem(\"You are useful assistant, expert in AI and Java.\")\n        .defaultToolCallbacks((Object[]) mcpToolAdapter.toolCallbacks())\n        .defaultAdvisors(new MessageChatMemoryAdvisor(new InMemoryChatMemory()))\n        .build();\n    ```\n\n    Key features:\n\n    * Uses Claude AI model for natural language understanding\n    * Integrates Brave Search through MCP for real-time web search capabilities\n    * Maintains conversation memory using InMemoryChatMemory\n    * Runs as an interactive command-line application\n\n    ### Build and run\n\n    ```bash  theme={null}\n    ./mvnw clean install\n    java -jar ./target/ai-mcp-brave-chatbot-0.0.1-SNAPSHOT.jar\n    ```\n\n    or\n\n    ```bash  theme={null}\n    ./mvnw spring-boot:run\n    ```\n\n    The application will start an interactive chat session where you can ask questions. The chatbot will use Brave Search when it needs to find information from the internet to answer your queries.\n\n    The chatbot can:\n\n    * Answer questions using its built-in knowledge\n    * Perform web searches when needed using Brave Search\n    * Remember context from previous messages in the conversation\n    * Combine information from multiple sources to provide comprehensive answers\n\n    ### Advanced Configuration\n\n    The MCP client supports additional configuration options:\n\n    * Client customization through `McpSyncClientCustomizer` or `McpAsyncClientCustomizer`\n    * Multiple clients with multiple transport types: `STDIO` and `SSE` (Server-Sent Events)\n    * Integration with Spring AI's tool execution framework\n    * Automatic client initialization and lifecycle management\n\n    For WebFlux-based applications, you can use the WebFlux starter instead:\n\n    ```xml  theme={null}\n    <dependency>\n        <groupId>org.springframework.ai</groupId>\n        <artifactId>spring-ai-mcp-client-webflux-spring-boot-starter</artifactId>\n    </dependency>\n    ```\n\n    This provides similar functionality but uses a WebFlux-based SSE transport implementation, recommended for production deployments.\n  </Tab>\n\n  <Tab title=\"Kotlin\">\n    [You can find the complete code for this tutorial here.](https://github.com/modelcontextprotocol/kotlin-sdk/tree/main/samples/kotlin-mcp-client)\n\n    ## System Requirements\n\n    Before starting, ensure your system meets these requirements:\n\n    * Java 17 or higher\n    * Anthropic API key (Claude)\n\n    ## Setting up your environment\n\n    First, let's install `java` and `gradle` if you haven't already.\n    You can download `java` from [official Oracle JDK website](https://www.oracle.com/java/technologies/downloads/).\n    Verify your `java` installation:\n\n    ```bash  theme={null}\n    java --version\n    ```\n\n    Now, let's create and set up your project:\n\n    <CodeGroup>\n      ```bash macOS/Linux theme={null}\n      # Create a new directory for our project\n      mkdir kotlin-mcp-client\n      cd kotlin-mcp-client\n\n      # Initialize a new kotlin project\n      gradle init\n      ```\n\n      ```powershell Windows theme={null}\n      # Create a new directory for our project\n      md kotlin-mcp-client\n      cd kotlin-mcp-client\n      # Initialize a new kotlin project\n      gradle init\n      ```\n    </CodeGroup>\n\n    After running `gradle init`, you will be presented with options for creating your project.\n    Select **Application** as the project type, **Kotlin** as the programming language, and **Java 17** as the Java version.\n\n    Alternatively, you can create a Kotlin application using the [IntelliJ IDEA project wizard](https://kotlinlang.org/docs/jvm-get-started.html).\n\n    After creating the project, add the following dependencies:\n\n    <CodeGroup>\n      ```kotlin build.gradle.kts theme={null}\n      val mcpVersion = \"0.4.0\"\n      val slf4jVersion = \"2.0.9\"\n      val anthropicVersion = \"0.8.0\"\n\n      dependencies {\n          implementation(\"io.modelcontextprotocol:kotlin-sdk:$mcpVersion\")\n          implementation(\"org.slf4j:slf4j-nop:$slf4jVersion\")\n          implementation(\"com.anthropic:anthropic-java:$anthropicVersion\")\n      }\n      ```\n\n      ```groovy build.gradle theme={null}\n      def mcpVersion = '0.3.0'\n      def slf4jVersion = '2.0.9'\n      def anthropicVersion = '0.8.0'\n      dependencies {\n          implementation \"io.modelcontextprotocol:kotlin-sdk:$mcpVersion\"\n          implementation \"org.slf4j:slf4j-nop:$slf4jVersion\"\n          implementation \"com.anthropic:anthropic-java:$anthropicVersion\"\n      }\n      ```\n    </CodeGroup>\n\n    Also, add the following plugins to your build script:\n\n    <CodeGroup>\n      ```kotlin build.gradle.kts theme={null}\n      plugins {\n          id(\"com.github.johnrengelman.shadow\") version \"8.1.1\"\n      }\n      ```\n\n      ```groovy build.gradle theme={null}\n      plugins {\n          id 'com.github.johnrengelman.shadow' version '8.1.1'\n      }\n      ```\n    </CodeGroup>\n\n    ## Setting up your API key\n\n    You'll need an Anthropic API key from the [Anthropic Console](https://console.anthropic.com/settings/keys).\n\n    Set up your API key:\n\n    ```bash  theme={null}\n    export ANTHROPIC_API_KEY='your-anthropic-api-key-here'\n    ```\n\n    <Warning>\n      Make sure your keep your `ANTHROPIC_API_KEY` secure!\n    </Warning>\n\n    ## Creating the Client\n\n    ### Basic Client Structure\n\n    First, let's create the basic client class:\n\n    ```kotlin  theme={null}\n    class MCPClient : AutoCloseable {\n        private val anthropic = AnthropicOkHttpClient.fromEnv()\n        private val mcp: Client = Client(clientInfo = Implementation(name = \"mcp-client-cli\", version = \"1.0.0\"))\n        private lateinit var tools: List<ToolUnion>\n\n        // methods will go here\n\n        override fun close() {\n            runBlocking {\n                mcp.close()\n                anthropic.close()\n            }\n        }\n    ```\n\n    ### Server connection management\n\n    Next, we'll implement the method to connect to an MCP server:\n\n    ```kotlin  theme={null}\n    suspend fun connectToServer(serverScriptPath: String) {\n        try {\n            val command = buildList {\n                when (serverScriptPath.substringAfterLast(\".\")) {\n                    \"js\" -> add(\"node\")\n                    \"py\" -> add(if (System.getProperty(\"os.name\").lowercase().contains(\"win\")) \"python\" else \"python3\")\n                    \"jar\" -> addAll(listOf(\"java\", \"-jar\"))\n                    else -> throw IllegalArgumentException(\"Server script must be a .js, .py or .jar file\")\n                }\n                add(serverScriptPath)\n            }\n\n            val process = ProcessBuilder(command).start()\n            val transport = StdioClientTransport(\n                input = process.inputStream.asSource().buffered(),\n                output = process.outputStream.asSink().buffered()\n            )\n\n            mcp.connect(transport)\n\n            val toolsResult = mcp.listTools()\n            tools = toolsResult?.tools?.map { tool ->\n                ToolUnion.ofTool(\n                    Tool.builder()\n                        .name(tool.name)\n                        .description(tool.description ?: \"\")\n                        .inputSchema(\n                            Tool.InputSchema.builder()\n                                .type(JsonValue.from(tool.inputSchema.type))\n                                .properties(tool.inputSchema.properties.toJsonValue())\n                                .putAdditionalProperty(\"required\", JsonValue.from(tool.inputSchema.required))\n                                .build()\n                        )\n                        .build()\n                )\n            } ?: emptyList()\n            println(\"Connected to server with tools: ${tools.joinToString(\", \") { it.tool().get().name() }}\")\n        } catch (e: Exception) {\n            println(\"Failed to connect to MCP server: $e\")\n            throw e\n        }\n    }\n    ```\n\n    Also create a helper function to convert from `JsonObject` to `JsonValue` for Anthropic:\n\n    ```kotlin  theme={null}\n    private fun JsonObject.toJsonValue(): JsonValue {\n        val mapper = ObjectMapper()\n        val node = mapper.readTree(this.toString())\n        return JsonValue.fromJsonNode(node)\n    }\n    ```\n\n    ### Query processing logic\n\n    Now let's add the core functionality for processing queries and handling tool calls:\n\n    ```kotlin  theme={null}\n    private val messageParamsBuilder: MessageCreateParams.Builder = MessageCreateParams.builder()\n        .model(Model.CLAUDE_SONNET_4_20250514)\n        .maxTokens(1024)\n\n    suspend fun processQuery(query: String): String {\n        val messages = mutableListOf(\n            MessageParam.builder()\n                .role(MessageParam.Role.USER)\n                .content(query)\n                .build()\n        )\n\n        val response = anthropic.messages().create(\n            messageParamsBuilder\n                .messages(messages)\n                .tools(tools)\n                .build()\n        )\n\n        val finalText = mutableListOf<String>()\n        response.content().forEach { content ->\n            when {\n                content.isText() -> finalText.add(content.text().getOrNull()?.text() ?: \"\")\n\n                content.isToolUse() -> {\n                    val toolName = content.toolUse().get().name()\n                    val toolArgs =\n                        content.toolUse().get()._input().convert(object : TypeReference<Map<String, JsonValue>>() {})\n\n                    val result = mcp.callTool(\n                        name = toolName,\n                        arguments = toolArgs ?: emptyMap()\n                    )\n                    finalText.add(\"[Calling tool $toolName with args $toolArgs]\")\n\n                    messages.add(\n                        MessageParam.builder()\n                            .role(MessageParam.Role.USER)\n                            .content(\n                                \"\"\"\n                                    \"type\": \"tool_result\",\n                                    \"tool_name\": $toolName,\n                                    \"result\": ${result?.content?.joinToString(\"\\n\") { (it as TextContent).text ?: \"\" }}\n                                \"\"\".trimIndent()\n                            )\n                            .build()\n                    )\n\n                    val aiResponse = anthropic.messages().create(\n                        messageParamsBuilder\n                            .messages(messages)\n                            .build()\n                    )\n\n                    finalText.add(aiResponse.content().first().text().getOrNull()?.text() ?: \"\")\n                }\n            }\n        }\n\n        return finalText.joinToString(\"\\n\", prefix = \"\", postfix = \"\")\n    }\n    ```\n\n    ### Interactive chat\n\n    We'll add the chat loop:\n\n    ```kotlin  theme={null}\n    suspend fun chatLoop() {\n        println(\"\\nMCP Client Started!\")\n        println(\"Type your queries or 'quit' to exit.\")\n\n        while (true) {\n            print(\"\\nQuery: \")\n            val message = readLine() ?: break\n            if (message.lowercase() == \"quit\") break\n            val response = processQuery(message)\n            println(\"\\n$response\")\n        }\n    }\n    ```\n\n    ### Main entry point\n\n    Finally, we'll add the main execution function:\n\n    ```kotlin  theme={null}\n    fun main(args: Array<String>) = runBlocking {\n        if (args.isEmpty()) throw IllegalArgumentException(\"Usage: java -jar <your_path>/build/libs/kotlin-mcp-client-0.1.0-all.jar <path_to_server_script>\")\n        val serverPath = args.first()\n        val client = MCPClient()\n        client.use {\n            client.connectToServer(serverPath)\n            client.chatLoop()\n        }\n    }\n    ```\n\n    ## Running the client\n\n    To run your client with any MCP server:\n\n    ```bash  theme={null}\n    ./gradlew build\n\n    # Run the client\n    java -jar build/libs/<your-jar-name>.jar path/to/server.jar # jvm server\n    java -jar build/libs/<your-jar-name>.jar path/to/server.py # python server\n    java -jar build/libs/<your-jar-name>.jar path/to/build/index.js # node server\n    ```\n\n    <Note>\n      If you're continuing the weather tutorial from the server quickstart, your command might look something like this: `java -jar build/libs/kotlin-mcp-client-0.1.0-all.jar .../samples/weather-stdio-server/build/libs/weather-stdio-server-0.1.0-all.jar`\n    </Note>\n\n    **The client will:**\n\n    1. Connect to the specified server\n    2. List available tools\n    3. Start an interactive chat session where you can:\n       * Enter queries\n       * See tool executions\n       * Get responses from Claude\n\n    ## How it works\n\n    Here's a high-level workflow schema:\n\n    ```mermaid  theme={null}\n    ---\n    config:\n        theme: neutral\n    ---\n    sequenceDiagram\n        actor User\n        participant Client\n        participant Claude\n        participant MCP_Server as MCP Server\n        participant Tools\n\n        User->>Client: Send query\n        Client<<->>MCP_Server: Get available tools\n        Client->>Claude: Send query with tool descriptions\n        Claude-->>Client: Decide tool execution\n        Client->>MCP_Server: Request tool execution\n        MCP_Server->>Tools: Execute chosen tools\n        Tools-->>MCP_Server: Return results\n        MCP_Server-->>Client: Send results\n        Client->>Claude: Send tool results\n        Claude-->>Client: Provide final response\n        Client-->>User: Display response\n    ```\n\n    When you submit a query:\n\n    1. The client gets the list of available tools from the server\n    2. Your query is sent to Claude along with tool descriptions\n    3. Claude decides which tools (if any) to use\n    4. The client executes any requested tool calls through the server\n    5. Results are sent back to Claude\n    6. Claude provides a natural language response\n    7. The response is displayed to you\n\n    ## Best practices\n\n    1. **Error Handling**\n       * Leverage Kotlin's type system to model errors explicitly\n       * Wrap external tool and API calls in `try-catch` blocks when exceptions are possible\n       * Provide clear and meaningful error messages\n       * Handle network timeouts and connection issues gracefully\n\n    2. **Security**\n       * Store API keys and secrets securely in `local.properties`, environment variables, or secret managers\n       * Validate all external responses to avoid unexpected or unsafe data usage\n       * Be cautious with permissions and trust boundaries when using tools\n\n    ## Troubleshooting\n\n    ### Server Path Issues\n\n    * Double-check the path to your server script is correct\n    * Use the absolute path if the relative path isn't working\n    * For Windows users, make sure to use forward slashes (/) or escaped backslashes (\\\\) in the path\n    * Make sure that the required runtime is installed (java for Java, npm for Node.js, or uv for Python)\n    * Verify the server file has the correct extension (.jar for Java, .js for Node.js or .py for Python)\n\n    Example of correct path usage:\n\n    ```bash  theme={null}\n    # Relative path\n    java -jar build/libs/client.jar ./server/build/libs/server.jar\n\n    # Absolute path\n    java -jar build/libs/client.jar /Users/username/projects/mcp-server/build/libs/server.jar\n\n    # Windows path (either format works)\n    java -jar build/libs/client.jar C:/projects/mcp-server/build/libs/server.jar\n    java -jar build/libs/client.jar C:\\\\projects\\\\mcp-server\\\\build\\\\libs\\\\server.jar\n    ```\n\n    ### Response Timing\n\n    * The first response might take up to 30 seconds to return\n    * This is normal and happens while:\n      * The server initializes\n      * Claude processes the query\n      * Tools are being executed\n    * Subsequent responses are typically faster\n    * Don't interrupt the process during this initial waiting period\n\n    ### Common Error Messages\n\n    If you see:\n\n    * `Connection refused`: Ensure the server is running and the path is correct\n    * `Tool execution failed`: Verify the tool's required environment variables are set\n    * `ANTHROPIC_API_KEY is not set`: Check your environment variables\n  </Tab>\n\n  <Tab title=\"C#\">\n    [You can find the complete code for this tutorial here.](https://github.com/modelcontextprotocol/csharp-sdk/tree/main/samples/QuickstartClient)\n\n    ## System Requirements\n\n    Before starting, ensure your system meets these requirements:\n\n    * .NET 8.0 or higher\n    * Anthropic API key (Claude)\n    * Windows, Linux, or macOS\n\n    ## Setting up your environment\n\n    First, create a new .NET project:\n\n    ```bash  theme={null}\n    dotnet new console -n QuickstartClient\n    cd QuickstartClient\n    ```\n\n    Then, add the required dependencies to your project:\n\n    ```bash  theme={null}\n    dotnet add package ModelContextProtocol --prerelease\n    dotnet add package Anthropic.SDK\n    dotnet add package Microsoft.Extensions.Hosting\n    dotnet add package Microsoft.Extensions.AI\n    ```\n\n    ## Setting up your API key\n\n    You'll need an Anthropic API key from the [Anthropic Console](https://console.anthropic.com/settings/keys).\n\n    ```bash  theme={null}\n    dotnet user-secrets init\n    dotnet user-secrets set \"ANTHROPIC_API_KEY\" \"<your key here>\"\n    ```\n\n    ## Creating the Client\n\n    ### Basic Client Structure\n\n    First, let's setup the basic client class in the file `Program.cs`:\n\n    ```csharp  theme={null}\n    using Anthropic.SDK;\n    using Microsoft.Extensions.AI;\n    using Microsoft.Extensions.Configuration;\n    using Microsoft.Extensions.Hosting;\n    using ModelContextProtocol.Client;\n    using ModelContextProtocol.Protocol.Transport;\n\n    var builder = Host.CreateApplicationBuilder(args);\n\n    builder.Configuration\n        .AddEnvironmentVariables()\n        .AddUserSecrets<Program>();\n    ```\n\n    This creates the beginnings of a .NET console application that can read the API key from user secrets.\n\n    Next, we'll setup the MCP Client:\n\n    ```csharp  theme={null}\n    var (command, arguments) = GetCommandAndArguments(args);\n\n    var clientTransport = new StdioClientTransport(new()\n    {\n        Name = \"Demo Server\",\n        Command = command,\n        Arguments = arguments,\n    });\n\n    await using var mcpClient = await McpClientFactory.CreateAsync(clientTransport);\n\n    var tools = await mcpClient.ListToolsAsync();\n    foreach (var tool in tools)\n    {\n        Console.WriteLine($\"Connected to server with tools: {tool.Name}\");\n    }\n    ```\n\n    Add this function at the end of the `Program.cs` file:\n\n    ```csharp  theme={null}\n    static (string command, string[] arguments) GetCommandAndArguments(string[] args)\n    {\n        return args switch\n        {\n            [var script] when script.EndsWith(\".py\") => (\"python\", args),\n            [var script] when script.EndsWith(\".js\") => (\"node\", args),\n            [var script] when Directory.Exists(script) || (File.Exists(script) && script.EndsWith(\".csproj\")) => (\"dotnet\", [\"run\", \"--project\", script, \"--no-build\"]),\n            _ => throw new NotSupportedException(\"An unsupported server script was provided. Supported scripts are .py, .js, or .csproj\")\n        };\n    }\n    ```\n\n    This creates an MCP client that will connect to a server that is provided as a command line argument. It then lists the available tools from the connected server.\n\n    ### Query processing logic\n\n    Now let's add the core functionality for processing queries and handling tool calls:\n\n    ```csharp  theme={null}\n    using var anthropicClient = new AnthropicClient(new APIAuthentication(builder.Configuration[\"ANTHROPIC_API_KEY\"]))\n        .Messages\n        .AsBuilder()\n        .UseFunctionInvocation()\n        .Build();\n\n    var options = new ChatOptions\n    {\n        MaxOutputTokens = 1000,\n        ModelId = \"claude-sonnet-4-20250514\",\n        Tools = [.. tools]\n    };\n\n    Console.ForegroundColor = ConsoleColor.Green;\n    Console.WriteLine(\"MCP Client Started!\");\n    Console.ResetColor();\n\n    PromptForInput();\n    while(Console.ReadLine() is string query && !\"exit\".Equals(query, StringComparison.OrdinalIgnoreCase))\n    {\n        if (string.IsNullOrWhiteSpace(query))\n        {\n            PromptForInput();\n            continue;\n        }\n\n        await foreach (var message in anthropicClient.GetStreamingResponseAsync(query, options))\n        {\n            Console.Write(message);\n        }\n        Console.WriteLine();\n\n        PromptForInput();\n    }\n\n    static void PromptForInput()\n    {\n        Console.WriteLine(\"Enter a command (or 'exit' to quit):\");\n        Console.ForegroundColor = ConsoleColor.Cyan;\n        Console.Write(\"> \");\n        Console.ResetColor();\n    }\n    ```\n\n    ## Key Components Explained\n\n    ### 1. Client Initialization\n\n    * The client is initialized using `McpClientFactory.CreateAsync()`, which sets up the transport type and command to run the server.\n\n    ### 2. Server Connection\n\n    * Supports Python, Node.js, and .NET servers.\n    * The server is started using the command specified in the arguments.\n    * Configures to use stdio for communication with the server.\n    * Initializes the session and available tools.\n\n    ### 3. Query Processing\n\n    * Leverages [Microsoft.Extensions.AI](https://learn.microsoft.com/dotnet/ai/ai-extensions) for the chat client.\n    * Configures the `IChatClient` to use automatic tool (function) invocation.\n    * The client reads user input and sends it to the server.\n    * The server processes the query and returns a response.\n    * The response is displayed to the user.\n\n    ## Running the Client\n\n    To run your client with any MCP server:\n\n    ```bash  theme={null}\n    dotnet run -- path/to/server.csproj # dotnet server\n    dotnet run -- path/to/server.py # python server\n    dotnet run -- path/to/server.js # node server\n    ```\n\n    <Note>\n      If you're continuing the weather tutorial from the server quickstart, your command might look something like this: `dotnet run -- path/to/QuickstartWeatherServer`.\n    </Note>\n\n    The client will:\n\n    1. Connect to the specified server\n    2. List available tools\n    3. Start an interactive chat session where you can:\n       * Enter queries\n       * See tool executions\n       * Get responses from Claude\n    4. Exit the session when done\n\n    Here's an example of what it should look like it connected to a weather server quickstart:\n\n    <Frame>\n      <img src=\"https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=fcf28dde150d6db879402ad8150c6b23\" data-og-width=\"1115\" width=\"1115\" data-og-height=\"666\" height=\"666\" data-path=\"images/quickstart-dotnet-client.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?w=280&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=0c82cdfe1350b4a924a44d7beaa39f70 280w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?w=560&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4fd6f3ed867741b44ae12940788be646 560w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?w=840&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=1b5fcfaf8b63b9ea71bf36aa20388a28 840w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?w=1100&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=cb969889d05ec8771c12b887f2940c7d 1100w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?w=1650&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=81b2cb62f60a9f3afb2d66cf3ee3df79 1650w, https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/quickstart-dotnet-client.png?w=2500&fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=ac9271a3dd0d7b424bb390ad0c31e14e 2500w\" />\n    </Frame>\n  </Tab>\n</Tabs>\n\n## Next steps\n\n<CardGroup cols={2}>\n  <Card title=\"Example servers\" icon=\"grid\" href=\"/examples\">\n    Check out our gallery of official MCP servers and implementations\n  </Card>\n\n  <Card title=\"Example clients\" icon=\"cubes\" href=\"/clients\">\n    View the list of clients that support MCP integrations\n  </Card>\n</CardGroup>",
  "content_length": 53920
}