{
  "title": "Migrating from Text Completions",
  "source_url": "https://docs.claude.com/en/api/migrating-from-text-completions-to-messages",
  "content": "Migrating from Text Completions to Messages\n\n<Note>\n  The Text Completions API has been deprecated in favor of the Messages API.\n</Note>\n\nWhen migrating from Text Completions to [Messages](/en/api/messages), consider the following changes.\n\n### Inputs and outputs\n\nThe largest change between Text Completions and the Messages is the way in which you specify model inputs and receive outputs from the model.\n\nWith Text Completions, inputs are raw strings:\n\n```Python Python theme={null}\nprompt = \"\\n\\nHuman: Hello there\\n\\nAssistant: Hi, I'm Claude. How can I help?\\n\\nHuman: Can you explain Glycolysis to me?\\n\\nAssistant:\"\n```\n\nWith Messages, you specify a list of input messages instead of a raw prompt:\n\n<CodeGroup>\n  ```json Shorthand theme={null}\n  messages = [\n    {\"role\": \"user\", \"content\": \"Hello there.\"},\n    {\"role\": \"assistant\", \"content\": \"Hi, I'm Claude. How can I help?\"},\n    {\"role\": \"user\", \"content\": \"Can you explain Glycolysis to me?\"},\n  ]\n  ```\n\n  ```json Expanded theme={null}\n  messages = [\n    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello there.\"}]},\n    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"Hi, I'm Claude. How can I help?\"}]},\n    {\"role\": \"user\", \"content\":[{\"type\": \"text\", \"text\": \"Can you explain Glycolysis to me?\"}]},\n  ]\n  ```\n</CodeGroup>\n\nEach input message has a `role` and `content`.\n\n<Tip>\n  **Role names**\n\n  The Text Completions API expects alternating `\\n\\nHuman:` and `\\n\\nAssistant:` turns, but the Messages API expects `user` and `assistant` roles. You may see documentation referring to either \"human\" or \"user\" turns. These refer to the same role, and will be \"user\" going forward.\n</Tip>\n\nWith Text Completions, the model's generated text is returned in the `completion` values of the response:\n\n```Python Python theme={null}\n>>> response = anthropic.completions.create(...)\n>>> response.completion\n\" Hi, I'm Claude\"\n```\n\nWith Messages, the response is the `content` value, which is a list of content blocks:\n\n```Python Python theme={null}\n>>> response = anthropic.messages.create(...)\n>>> response.content\n[{\"type\": \"text\", \"text\": \"Hi, I'm Claude\"}]\n```\n\n### Putting words in Claude's mouth\n\nWith Text Completions, you can pre-fill part of Claude's response:\n\n```Python Python theme={null}\nprompt = \"\\n\\nHuman: Hello\\n\\nAssistant: Hello, my name is\"\n```\n\nWith Messages, you can achieve the same result by making the last input message have the `assistant` role:\n\n```Python Python theme={null}\nmessages = [\n  {\"role\": \"human\", \"content\": \"Hello\"},\n  {\"role\": \"assistant\", \"content\": \"Hello, my name is\"},\n]\n```\n\nWhen doing so, response `content` will continue from the last input message `content`:\n\n```JSON JSON theme={null}\n{\n  \"role\": \"assistant\",\n  \"content\": [{\"type\": \"text\", \"text\": \" Claude. How can I assist you today?\" }],\n  ...\n}\n```\n\n### System prompt\n\nWith Text Completions, the [system prompt](/en/docs/build-with-claude/prompt-engineering/system-prompts) is specified by adding text before the first `\\n\\nHuman:` turn:\n\n```Python Python theme={null}\nprompt = \"Today is January 1, 2024.\\n\\nHuman: Hello, Claude\\n\\nAssistant:\"\n```\n\nWith Messages, you specify the system prompt with the `system` parameter:\n\n```Python Python theme={null}\nanthropic.Anthropic().messages.create(\n    model=\"claude-sonnet-4-5\",\n    max_tokens=1024,\n    system=\"Today is January 1, 2024.\", # <-- system prompt\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n    ]\n)\n```\n\n### Model names\n\nThe Messages API requires that you specify the full model version (e.g. `claude-sonnet-4-5-20250929`).\n\nWe previously supported specifying only the major version number (e.g. `claude-2`), which resulted in automatic upgrades to minor versions. However, we no longer recommend this integration pattern, and Messages do not support it.\n\n### Stop reason\n\nText Completions always have a `stop_reason` of either:\n\n* `\"stop_sequence\"`: The model either ended its turn naturally, or one of your custom stop sequences was generated.\n* `\"max_tokens\"`: Either the model generated your specified `max_tokens` of content, or it reached its [absolute maximum](/en/docs/about-claude/models/overview#model-comparison-table).\n\nMessages have a `stop_reason` of one of the following values:\n\n* `\"end_turn\"`: The conversational turn ended naturally.\n* `\"stop_sequence\"`: One of your specified custom stop sequences was generated.\n* `\"max_tokens\"`: (unchanged)\n\n### Specifying max tokens\n\n* Text Completions: `max_tokens_to_sample` parameter. No validation, but capped values per-model.\n* Messages: `max_tokens` parameter. If passing a value higher than the model supports, returns a validation error.\n\n### Streaming format\n\nWhen using `\"stream\": true` in with Text Completions, the response included any of `completion`, `ping`, and `error` server-sent-events.\n\nMessages can contain multiple content blocks of varying types, and so its streaming format is somewhat more complex. See [Messages streaming](/en/docs/build-with-claude/streaming) for details.",
  "content_length": 5024
}