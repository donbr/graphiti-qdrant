{
  "title": "How to run flows in Docker containers",
  "source_url": "https://docs-3.prefect.io/v3/how-to-guides/deployment_infra/docker",
  "content": "Learn how to execute deployments in isolated Docker containers\n\nIn this example, you will set up:\n\n* a Docker [**work pool**](/v3/deploy/infrastructure-concepts/work-pools/): stores the infrastructure configuration for your deployment\n* a Docker [**worker**](/v3/deploy/infrastructure-concepts/workers/): process that polls the Prefect API for flow runs to execute as Docker containers\n* a [**deployment**](/v3/deploy/index/): a flow that should run according to the configuration on your Docker work pool\n\nThen you can execute your deployment via the Prefect API (through the SDK, CLI, UI, etc).\n\nYou must have [Docker](https://docs.docker.com/engine/install/) installed and running on your machine.\n\n<Note>\n  **Executing flows in a long-lived container**\n\n  This guide shows how to run a flow in an ephemeral container that is removed after the flow run completes.\n  To instead learn how to run flows in a static, long-lived container, see [this](/v3/deploy/static-infrastructure-examples/docker/) guide.\n</Note>\n\n### Create a work pool\n\nA work pool provides default infrastructure configurations that all jobs inherit and can override.\nYou can adjust many defaults, such as the base Docker image, container cleanup behavior, and resource limits.\n\nTo set up a **Docker** type work pool with the default values, run:\n\n```bash  theme={null}\nprefect work-pool create --type docker my-docker-pool\n```\n\n... or create the work pool in the UI.\n\nTo confirm the work pool creation was successful, run:\n\n```bash  theme={null}\nprefect work-pool ls\n```\n\nYou should see your new `my-docker-pool` listed in the output.\n\nNext, check that you can see this work pool in your Prefect UI.\nNavigate to the **Work Pools** tab and verify that you see `my-docker-pool` listed.\nWhen you click into `my-docker-pool`, you should see a red status icon signifying that this work pool is not ready.\n\nTo make the work pool ready, you'll need to start a worker.\nWe'll show how to do this next.\n\n### Start a worker\n\nWorkers are a lightweight polling process that kick off scheduled flow runs on a specific type of infrastructure (such as Docker).\nTo start a worker on your local machine, open a new terminal and confirm that your virtual environment has `prefect` installed.\n\nRun the following command in this new terminal to start the worker:\n\n```bash  theme={null}\nprefect worker start --pool my-docker-pool\n```\n\nYou should see the worker start.\nIt's now polling the Prefect API to check for any scheduled flow runs it should pick up and then submit for execution.\nYou'll see your new worker listed in the UI under the **Workers** tab of the Work Pools page with a recent last polled date.\nThe work pool should have a `Ready` status indicator.\n\n<Tip>\n  **Pro Tip:**\n\n  If `my-docker-pool` does not already exist, the below command will create it for you automatically with the default settings for that work pool type, in this case `docker`.\n\n  ```bash  theme={null}\n  prefect worker start --pool my-docker-pool --type docker\n  ```\n</Tip>\n\nKeep this terminal session active for the worker to continue to pick up jobs.\nSince you are running this worker locally, the worker will if you close the terminal.\nIn a production setting this worker should run as a [daemonized or managed process](/v3/deploy/daemonize-processes/).\n\n## Create the deployment\n\nFrom the previous steps, you now have:\n\n* A work pool\n* A worker\n\nNext, you'll create a deployment from your flow code.\n\n### Automatically bake your code into a Docker image\n\nCreate a deployment from Python code by calling the `.deploy` method on a flow:\n\n```python deploy_buy.py theme={null}\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities\")\n\nif __name__ == \"__main__\":\n    buy.deploy(\n        name=\"my-code-baked-into-an-image-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        image=\"my_registry/my_image:my_image_tag\" # YOUR IMAGE REGISTRY\n    )\n```\n\nNow, run the script to create a deployment (in future examples this step is omitted for brevity):\n\n```bash  theme={null}\npython deploy_buy.py\n```\n\nYou should see messages in your terminal that Docker is building your image.\nWhen the deployment build succeeds, you will see information in your terminal showing you how to start a worker for your\ndeployment, and how to run your deployment.\nYour deployment is visible on the `Deployments` page in the UI.\n\nBy default, `.deploy` builds a Docker image with your flow code baked into it and pushes the image to the\n[Docker Hub](https://hub.docker.com/) registry implied by the `image` argument to `.deploy`.\n\n<Note>\n  **Authentication to Docker Hub**\n\n  Your environment must be authenticated to your Docker registry to push an image to it.\n</Note>\n\nYou can specify a registry other than Docker Hub by providing the full registry path in the `image` argument.\n\n<Warning>\n  If building a Docker image, your environment with your deployment needs Docker installed and running.\n</Warning>\n\nTo avoid pushing to a registry, set `push=False` in the `.deploy` method:\n\n```python  theme={null}\n\nif __name__ == \"__main__\":\n    buy.deploy(\n        name=\"my-code-baked-into-an-image-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        image=\"my_registry/my_image:my_image_tag\",\n        push=False\n    )\n```\n\nTo avoid building an image, set `build=False` in the `.deploy` method:\n\n```python  theme={null}\n\nif __name__ == \"__main__\":\n    buy.deploy(\n        name=\"my-code-baked-into-an-image-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        image=\"my_registry/already-built-image:1.0\",\n        build=False\n    )\n```\n\nThe specified image must be available in your deployment's execution environment for accessible flow code.\n\nPrefect generates a Dockerfile for you that builds an image based off of one of Prefect's published images.\nThe generated Dockerfile copies the current directory into the Docker image and installs any dependencies listed\nin a `requirements.txt` file.\n\n### Automatically build a custom Docker image with a local Dockerfile\n\nIf you want to use a custom image, specify the path to your Dockerfile via `DockerImage`:\n\n```python my_flow.py theme={null}\nfrom prefect import flow\nfrom prefect.docker import DockerImage\n\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities\")\n\n\nif __name__ == \"__main__\":\n    buy.deploy(\n        name=\"my-custom-dockerfile-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        image=DockerImage(\n            name=\"my_image\",\n            tag=\"deploy-guide\",\n            dockerfile=\"Dockerfile\"\n    ),\n    push=False\n)\n\n```\n\nThe `DockerImage` object enables image customization.\n\nFor example, you can install a private Python package from GCP's artifact registry like this:\n\n1. Create a custom base Dockerfile.\n\n   ```Dockerfile sample.Dockerfile theme={null}\n   FROM python:3.12\n\n   ARG AUTHED_ARTIFACT_REG_URL\n   COPY ./requirements.txt /requirements.txt\n\n   RUN pip install --extra-index-url ${AUTHED_ARTIFACT_REG_URL} -r /requirements.txt\n   ```\n\n2. Create your deployment with the `DockerImage` class:\n\n   ```python deploy_using_private_package.py theme={null}\n   from prefect import flow\n   from prefect.deployments.runner import DockerImage\n   from prefect.blocks.system import Secret\n   from myproject.cool import do_something_cool\n\n\n   @flow(log_prints=True)\n   def my_flow():\n       do_something_cool()\n\n\n   if __name__ == \"__main__\":\n       artifact_reg_url = Secret.load(\"artifact-reg-url\")\n\n       my_flow.deploy(\n           name=\"my-deployment\",\n           work_pool_name=\"my-docker-pool\",\n           image=DockerImage(\n               name=\"my-image\",\n               tag=\"test\",\n               dockerfile=\"sample.Dockerfile\",\n               buildargs={\"AUTHED_ARTIFACT_REG_URL\": artifact_reg_url.get()},\n           ),\n       )\n   ```\n\nNote that this example used a [Prefect Secret block](/v3/develop/blocks/) to load the URL configuration for\nthe artifact registry above.\n\nSee all the optional keyword arguments for the [`DockerImage` class](https://docker-py.readthedocs.io/en/stable/images.html#docker.models.images.ImageCollection.build).\n\n<Tip>\n  **Default Docker namespace**\n\n  You can set the `PREFECT_DEFAULT_DOCKER_BUILD_NAMESPACE` setting to append a default Docker namespace to all images\n  you build with `.deploy`. This is helpful if you use a private registry to store your images.\n\n  To set a default Docker namespace for your current profile run:\n\n  ```bash  theme={null}\n  prefect config set PREFECT_DEFAULT_DOCKER_BUILD_NAMESPACE=<docker-registry-url>/<organization-or-username>\n  ```\n\n  Once set, you can omit the namespace from your image name when creating a deployment:\n\n  ```python with_default_docker_namespace.py theme={null}\n  if __name__ == \"__main__\":\n      buy.deploy(\n          name=\"my-code-baked-into-an-image-deployment\",\n          work_pool_name=\"my-docker-pool\",\n          image=\"my_image:my_image_tag\"\n      )\n  ```\n\n  The above code builds an image with the format `<docker-registry-url>/<organization-or-username>/my_image:my_image_tag`\n  when `PREFECT_DEFAULT_DOCKER_BUILD_NAMESPACE` is set.\n</Tip>\n\n### Store your code in git-based cloud storage\n\nWhile baking code into Docker images is a popular deployment option, many teams store their workflow code in git-based\nstorage, such as GitHub, Bitbucket, or GitLab.\n\nIf you don't specify an `image` argument for `.deploy`, you must specify where to pull the flow code from at runtime\nwith the `from_source` method.\n\nHere's how to pull your flow code from a GitHub repository:\n\n```python git_storage.py theme={null}\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        \"https://github.com/my_github_account/my_repo/my_file.git\",\n        entrypoint=\"flows/no-image.py:hello_world\",\n    ).deploy(\n        name=\"no-image-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        build=False\n    )\n```\n\nThe `entrypoint` is the path to the file the flow is located in and the function name, separated by a colon.\n\nSee the [Store flow code](/v3/deploy/infrastructure-concepts/store-flow-code/) guide for more flow code storage options.\n\n### Additional configuration with `.deploy`\n\nNext, see deployment configuration options.\n\nTo pass parameters to your flow, you can use the `parameters` argument in the `.deploy` method. Just pass in a dictionary of\nkey-value pairs.\n\n```python pass_params.py theme={null}\nfrom prefect import flow\n\n\n@flow\ndef hello_world(name: str):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    hello_world.deploy(\n        name=\"pass-params-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        parameters=dict(name=\"Prefect\"),\n        image=\"my_registry/my_image:my_image_tag\",\n    )\n```\n\nThe `job_variables` parameter allows you to fine-tune the infrastructure settings for a deployment.\nThe values passed in override default values in the specified work pool's\n[base job template](/v3/deploy/infrastructure-concepts/work-pools/#base-job-template).\n\nYou can override environment variables, such as `image_pull_policy` and `image`, for a specific deployment with the `job_variables`\nargument.\n\n```python job_var_image_pull.py theme={null}\nif __name__ == \"__main__\":\n    get_repo_info.deploy(\n        name=\"my-deployment-never-pull\",\n        work_pool_name=\"my-docker-pool\",\n        job_variables={\"image_pull_policy\": \"Never\"},\n        image=\"my-image:my-tag\",\n        push=False\n    )\n```\n\nSimilarly, you can override the environment variables specified in a work pool through the `job_variables` parameter:\n\n```python job_var_env_vars.py theme={null}\nif __name__ == \"__main__\":\n    get_repo_info.deploy(\n        name=\"my-deployment-never-pull\",\n        work_pool_name=\"my-docker-pool\",\n        job_variables={\"env\": {\"EXTRA_PIP_PACKAGES\": \"boto3\"} },\n        image=\"my-image:my-tag\",\n        push=False\n    )\n```\n\nThe dictionary key \"EXTRA\\_PIP\\_PACKAGES\" denotes a special environment variable that Prefect uses to install additional\nPython packages at runtime.\nThis approach is an alternative to building an image with a custom `requirements.txt` copied into it.\n\nSee [Override work pool job variables](/v3/deploy/infrastructure-concepts/customize) for more information about how to customize these variables.\n\n### Work with multiple deployments with `deploy`\n\nCreate multiple deployments from one or more Python files that use `.deploy`.\nYou can manage these deployments independently of one another to deploy the same flow with different configurations\nin the same codebase.\n\nTo create multiple deployments at once, use the `deploy` function, which is analogous to the `serve` function:\n\n```python  theme={null}\nfrom prefect import deploy, flow\n\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        buy.to_deployment(name=\"dev-deploy\", work_pool_name=\"my-docker-pool\"),\n        buy.to_deployment(name=\"prod-deploy\", work_pool_name=\"my-other-docker-pool\"),\n        image=\"my-registry/my-image:dev\",\n        push=False,\n    )\n```\n\nIn the example above you created two deployments from the same flow, but with different work pools.\nAlternatively, you can create two deployments from different flows:\n\n```python  theme={null}\nfrom prefect import deploy, flow\n\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities.\")\n\n\n@flow(log_prints=True)\ndef sell():\n    print(\"Selling securities.\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        buy.to_deployment(name=\"buy-deploy\"),\n        sell.to_deployment(name=\"sell-deploy\"),\n        work_pool_name=\"my-docker-pool\",\n        image=\"my-registry/my-image:dev\",\n        push=False,\n    )\n```\n\nIn the example above, the code for both flows is baked into the same image.\n\nYou can specify one or more flows to pull from a remote location at runtime with the `from_source` method.\nHere's an example of deploying two flows, one defined locally and one defined in a remote repository:\n\n```python  theme={null}\nfrom prefect import deploy, flow\n\n\n@flow(log_prints=True)\ndef local_flow():\n    print(\"I'm a flow!\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        local_flow.to_deployment(name=\"example-deploy-local-flow\"),\n        flow.from_source(\n            source=\"https://github.com/org/repo.git\",\n            entrypoint=\"flows.py:my_flow\",\n        ).to_deployment(\n            name=\"example-deploy-remote-flow\",\n        ),\n        work_pool_name=\"my-docker-pool\",\n        image=\"my-registry/my-image:dev\",\n    )\n```\n\nYou can pass any number of flows to the `deploy` function.\nThis is useful if using a monorepo approach to your workflows.\n\n## Learn more\n\n* [Deploy flows on Kubernetes](/v3/how-to-guides/deployment_infra/kubernetes/)\n* [Deploy flows on serverless infrastructure](/v3/how-to-guides/deployment_infra/serverless)\n* [Daemonize workers](/v3/deploy/daemonize-processes/)",
  "content_length": 14817
}