{
  "title": "Social Analytics Dashboard",
  "source_url": "https://docs-3.prefect.io/v3/examples/atproto-dashboard-with-prefect-assets",
  "content": "Build a social media analytics dashboard using Prefect Assets, ATProto/Bluesky APIs, dbt transformations, and Streamlit visualization.\n\n<a href=\"https://github.com/zzstoatzz/atproto-dashboard\" target=\"_blank\">View full project on GitHub</a>\n\n**Build data pipelines with Prefect Assets â€“ declarative, dependency-aware, and observable.**\n\nThis example demonstrates how to use **Prefect Assets** to build a social media analytics pipeline.\nThe full implementation with [ATProto](https://atproto.com) integration, [dbt](https://www.getdbt.com) transformations, and a [Streamlit](https://streamlit.io) dashboard\ndashboard is available at: [https://github.com/zzstoatzz/atproto-dashboard](https://github.com/zzstoatzz/atproto-dashboard)\n\n## Key Prefect Features\n\n* **`@materialize` decorator** â€“ Transform functions into versioned, cacheable data assets\n* **Automatic dependency tracking** â€“ Prefect infers dependencies from function parameters\n* **S3-backed assets** â€“ Store assets directly in S3 with built-in versioning\n* **Artifact creation** â€“ Generate rich UI artifacts for observability\n* **Flow orchestration** â€“ Coordinate asset materialization with retries and scheduling\n\n## The Pattern: Asset-Based Data Pipelines\n\nInstead of manually managing data dependencies and storage:\n\n1. Define assets with `@materialize` and unique keys (e.g., S3 paths)\n2. Declare dependencies via function parameters or `asset_deps`\n3. Let Prefect handle execution order, caching, and storage\n4. Get automatic lineage tracking and observability\n\n## Running This Example\n\nThis simplified example demonstrates the core patterns. For the complete implementation:\n\n```bash  theme={null}\ngit clone https://github.com/zzstoatzz/atproto-dashboard\ncd atproto-dashboard\n# Follow README for setup and configuration\n```\n\n## Core Pattern: Define Assets and Dependencies\n\nAssets represent data products in your pipeline. Each asset has:\n\n* A unique key (often an S3 path or other storage location)\n* A materialization function decorated with `@materialize`\n* Dependencies (automatically tracked via function parameters)\n\nDefine assets with descriptive keys\n\n```python  theme={null}\nimport json\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom textwrap import dedent\nfrom typing import Any\n\nfrom prefect import flow\nfrom prefect.artifacts import create_markdown_artifact\nfrom prefect.assets import Asset, materialize\n\nraw_data_asset = Asset(key=\"pipeline://raw_data\")\nprocessed_data_asset = Asset(key=\"pipeline://processed_data\")\nanalytics_asset = Asset(key=\"pipeline://analytics\")\n\n```\n\n### Step 1: Fetch Raw Data\n\nThe first asset fetches data from an external source. In the [full implementation](https://github.com/zzstoatzz/atproto-dashboard),\nthis connects to the ATProto/Bluesky API to fetch social media data.\n\n```python  theme={null}\n@materialize(raw_data_asset)\ndef fetch_raw_data() -> dict[str, Any]:\n    \"\"\"Fetch raw data from an external source.\"\"\"\n    print(\"Fetching raw data...\")\n\n    data = {\n        \"items\": [\"item1\", \"item2\", \"item3\"],\n        \"fetched_at\": datetime.now(timezone.utc).isoformat(),\n        \"count\": 3,\n    }\n\n    print(f\"âœ“ Fetched {data['count']} items\")\n    return data\n\n\n```\n\n### Step 2: Process the Data\n\nThis asset demonstrates **automatic dependency tracking**. By accepting `raw_data` as a parameter,\nPrefect knows this asset depends on `raw_data_asset` and ensures it's materialized first.\n\nIn production, this would store data to S3 with partitioning. Here we use local storage for simplicity.\n\n```python  theme={null}\n@materialize(processed_data_asset)\ndef process_data(raw_data: dict[str, Any]) -> dict[str, Any]:\n    \"\"\"Process raw data into a structured format with automatic dependency tracking.\"\"\"\n    print(f\"Processing {raw_data['count']} items...\")\n\n    processed = {\n        \"items\": [item.upper() for item in raw_data[\"items\"]],\n        \"processed_at\": datetime.now(timezone.utc).isoformat(),\n        \"source_count\": raw_data[\"count\"],\n    }\n\n    storage_dir = Path(\"./data\")\n    storage_dir.mkdir(exist_ok=True)\n    with open(storage_dir / \"processed.json\", \"w\") as f:\n        json.dump(processed, f, indent=2)\n\n    print(f\"âœ“ Processed and stored {len(processed['items'])} items\")\n    return processed\n\n\n```\n\n### Step 3: Create Analytics\n\nThis asset demonstrates **chained dependencies** (it depends on `processed_data`, which depends on `raw_data`)\nand **artifact creation** for rich observability in the Prefect UI.\n\nIn the full implementation, this runs dbt transformations to create analytics models.\n\n```python  theme={null}\n@materialize(analytics_asset)\ndef create_analytics(processed_data: dict[str, Any]) -> dict[str, Any]:\n    \"\"\"Generate analytics with chained dependencies and create UI artifacts.\"\"\"\n    print(\"Creating analytics...\")\n\n    analytics = {\n        \"total_items\": len(processed_data[\"items\"]),\n        \"source_timestamp\": processed_data[\"processed_at\"],\n        \"created_at\": datetime.now(timezone.utc).isoformat(),\n    }\n\n    create_markdown_artifact(\n        key=\"analytics-summary\",\n        markdown=dedent(\n            f\"\"\"\n            # Analytics Summary\n\n            - **Total Items**: {analytics[\"total_items\"]}\n            - **Created**: {analytics[\"created_at\"]}\n            - **Source**: {analytics[\"source_timestamp\"]}\n\n            This artifact appears in the Prefect UI for observability.\n            \"\"\"\n        ),\n        description=\"Analytics summary for this pipeline run\",\n    )\n\n    print(f\"âœ“ Analytics created for {analytics['total_items']} items\")\n    return analytics\n\n\n```\n\n## Flow: Orchestrate Asset Materialization\n\nThe flow calls each asset function, and Prefect handles:\n\n* Dependency resolution (ensuring correct execution order)\n* Automatic caching (skip re-computation if upstream assets haven't changed)\n* Observability (tracking lineage and execution in the UI)\n\n```python  theme={null}\n@flow(name=\"asset-pipeline-demo\", log_prints=True)\ndef run_asset_pipeline() -> dict[str, Any]:\n    \"\"\"\n    Orchestrate the asset pipeline.\n\n    By calling the materialization functions in sequence and passing results,\n    Prefect automatically:\n    - Tracks dependencies between assets\n    - Ensures execution order\n    - Provides observability in the UI\n    - Enables caching and versioning\n    \"\"\"\n    print(\"ðŸš€ Starting asset pipeline\")\n\n    # Materialize assets - Prefect tracks dependencies automatically\n    raw = fetch_raw_data()\n    processed = process_data(raw)\n    analytics = create_analytics(processed)\n\n    print(f\"âœ… Pipeline complete! Processed {analytics['total_items']} items\")\n    return analytics\n\n\nif __name__ == \"__main__\":\n    run_asset_pipeline()\n\n```\n\n## What Makes Assets Powerful?\n\n1. **Automatic Dependency Tracking**\n   * Prefect infers dependencies from function parameters\n   * Ensures correct execution order without manual DAG definition\n   * Tracks asset lineage for observability\n\n2. **Caching and Versioning**\n   * Assets are versioned based on their inputs\n   * Skip re-computation when upstream data hasn't changed\n   * Efficient incremental processing\n\n3. **Storage Integration**\n   * Asset keys can be S3 paths, database URIs, or any identifier\n   * Built-in support for `prefect-aws`, `prefect-gcp`, etc.\n   * Automatic data persistence and retrieval\n\n4. **Observability**\n   * Every materialization tracked in the Prefect UI\n   * Artifacts provide rich context (tables, markdown, links)\n   * Full lineage and execution history\n\n5. **Production Ready**\n   * Built-in retry logic and error handling\n   * Scheduling and automation via Prefect deployments\n   * Scales from local development to cloud production\n\n## Full Implementation\n\nThis example demonstrates the core patterns. The complete implementation includes:\n\n* Real ATProto API integration\n* S3-backed asset storage with partitioning\n* dbt transformations with DuckDB\n* Streamlit dashboard for visualization\n* Production-ready error handling and logging\n\nSee the full project at: [https://github.com/zzstoatzz/atproto-dashboard](https://github.com/zzstoatzz/atproto-dashboard)\n\n## Learn More\n\n* [Prefect Assets Documentation](https://docs.prefect.io/v3/concepts/assets)\n* [prefect-aws Integration](https://docs.prefect.io/integrations/prefect-aws)",
  "content_length": 8233
}