{
  "title": "prefect-databricks",
  "source_url": "https://docs-3.prefect.io/integrations/prefect-databricks/index",
  "content": "Prefect integrations for interacting with Databricks.\n\n## Getting started\n\n### Prerequisites\n\n* A [Databricks account](https://databricks.com/) and the necessary permissions to access desired services.\n\n### Install `prefect-databricks`\n\nThe following command will install a version of `prefect-databricks` compatible with your installed version of `prefect`.\nIf you don't already have `prefect` installed, it will install the newest version of `prefect` as well.\n\n```bash  theme={null}\npip install \"prefect[databricks]\"\n```\n\nUpgrade to the latest versions of `prefect` and `prefect-databricks`:\n\n```bash  theme={null}\npip install -U \"prefect[databricks]\"\n```\n\n### List jobs on the Databricks instance\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_databricks import DatabricksCredentials\nfrom prefect_databricks.jobs import jobs_list\n\n\n@flow\ndef example_execute_endpoint_flow():\n    databricks_credentials = DatabricksCredentials.load(\"my-block\")\n    jobs = jobs_list(\n        databricks_credentials,\n        limit=5\n    )\n    return jobs\n\nif __name__ == \"__main__\":\n    example_execute_endpoint_flow()\n```\n\n### Use `with_options` to customize options on any existing task or flow\n\n```python  theme={null}\ncustom_example_execute_endpoint_flow = example_execute_endpoint_flow.with_options(\n    name=\"My custom flow name\",\n    retries=2,\n    retry_delay_seconds=10,\n)\n```\n\n### Launch a new cluster and run a Databricks notebook\n\nNotebook named `example.ipynb` on Databricks which accepts a name parameter:\n\n```python  theme={null}\nname = dbutils.widgets.get(\"name\")\nmessage = f\"Don't worry {name}, I got your request! Welcome to prefect-databricks!\"\nprint(message)\n```\n\nPrefect flow that launches a new cluster to run `example.ipynb`:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_databricks import DatabricksCredentials\nfrom prefect_databricks.jobs import jobs_runs_submit\nfrom prefect_databricks.models.jobs import (\n    AutoScale,\n    AwsAttributes,\n    JobTaskSettings,\n    NotebookTask,\n    NewCluster,\n)\n\n\n@flow\ndef jobs_runs_submit_flow(notebook_path, **base_parameters):\n    databricks_credentials = DatabricksCredentials.load(\"my-block\")\n\n    # specify new cluster settings\n    aws_attributes = AwsAttributes(\n        availability=\"SPOT\",\n        zone_id=\"us-west-2a\",\n        ebs_volume_type=\"GENERAL_PURPOSE_SSD\",\n        ebs_volume_count=3,\n        ebs_volume_size=100,\n    )\n    auto_scale = AutoScale(min_workers=1, max_workers=2)\n    new_cluster = NewCluster(\n        aws_attributes=aws_attributes,\n        autoscale=auto_scale,\n        node_type_id=\"m4.large\",\n        spark_version=\"10.4.x-scala2.12\",\n        spark_conf={\"spark.speculation\": True},\n    )\n\n    # specify notebook to use and parameters to pass\n    notebook_task = NotebookTask(\n        notebook_path=notebook_path,\n        base_parameters=base_parameters,\n    )\n\n    # compile job task settings\n    job_task_settings = JobTaskSettings(\n        new_cluster=new_cluster,\n        notebook_task=notebook_task,\n        task_key=\"prefect-task\"\n    )\n\n    run = jobs_runs_submit(\n        databricks_credentials=databricks_credentials,\n        run_name=\"prefect-job\",\n        tasks=[job_task_settings]\n    )\n\n    return run\n\nif __name__ == \"__main__\":\n    jobs_runs_submit_flow(\"/Users/username@gmail.com/example.ipynb\", name=\"Marvin\")\n```\n\nNote, instead of using the built-in models, you may also input valid JSON. For example, `AutoScale(min_workers=1, max_workers=2)` is equivalent to `{\"min_workers\": 1, \"max_workers\": 2}`.\n\n## Resources\n\nFor assistance using Databricks, consult the [Databricks documentation](https://www.databricks.com/databricks-documentation).\n\nRefer to the `prefect-databricks` [SDK documentation](https://reference.prefect.io/prefect_databricks/) to explore all the capabilities of the `prefect-databricks` library.",
  "content_length": 3848
}