{
  "title": "AI-Powered Data Analyst",
  "source_url": "https://docs-3.prefect.io/v3/examples/ai-data-analyst-with-pydantic-ai",
  "content": "Build a resilient AI data analyst using Prefect and `pydantic-ai` to analyze datasets, detect anomalies, and generate insights.\n\n<a href=\"https://github.com/PrefectHQ/prefect/blob/main/examples/ai_data_analyst_with_pydantic_ai.py\" target=\"_blank\">View on GitHub</a>\n\nThis example shows how to build resilient AI workflows using Prefect and `pydantic-ai`.\nThe integration provides automatic retries for LLM calls, full observability of agent decisions,\nand durable execution semantics that make workflows idempotent and rerunnable.\n\n## The Scenario: AI Data Analyst\n\nYou need to analyze datasets programmatically, but writing custom analysis code for each dataset is time-consuming.\nInstead, you'll build an AI agent that:\n\n1. Understands your dataset structure\n2. Decides which analyses are most valuable\n3. Uses Python tools to calculate statistics and detect anomalies\n4. Generates actionable insights\n\nAll while being resilient to LLM failures, tool errors, and network issues.\n\nThis example demonstrates:\n\n* [`PrefectAgent`](https://ai.pydantic.dev/durable_execution/prefect/) ‚Äì Wraps `pydantic-ai` agents for durable execution\n* **Agent Tools** ‚Äì Python functions the AI can call, automatically wrapped as Prefect tasks\n* [`TaskConfig`](https://ai.pydantic.dev/durable_execution/prefect/#task-configuration) ‚Äì Custom retry policies and timeouts for AI operations\n* [**Durable Execution**](https://ai.pydantic.dev/durable_execution/prefect/#durable-execution) ‚Äì Automatic idempotency and failure recovery\n\n## Setup\n\nInstall dependencies (if not already installed):\n\n```bash  theme={null}\nuv add pydantic-ai[prefect] pandas\n# or with pip:\npip install \"pydantic-ai[prefect]\" pandas\n```\n\n```python  theme={null}\nfrom __future__ import annotations\n\nfrom typing import Any\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.durable_exec.prefect import PrefectAgent, TaskConfig\n\nfrom prefect import flow, task\n\n```\n\n## Agent Tools\n\nThese functions are \"tools\" that the AI agent can call to analyze data.\nPrefect automatically wraps each tool execution as a task for observability and retries.\n\n```python  theme={null}\ndef calculate_statistics(ctx: RunContext[pd.DataFrame], column: str) -> dict[str, Any]:\n    \"\"\"Calculate descriptive statistics for a column.\n\n    The AI agent can call this tool to understand data distribution,\n    and Prefect ensures it retries on failure.\"\"\"\n    df = ctx.deps\n    if column not in df.columns:\n        return {\"error\": f\"Column '{column}' not found. Available: {list(df.columns)}\"}\n\n    stats = df[column].describe().to_dict()\n    stats[\"missing_count\"] = int(df[column].isna().sum())\n    stats[\"unique_count\"] = int(df[column].nunique())\n    return {\n        k: (float(v) if isinstance(v, (int, float)) else v) for k, v in stats.items()\n    }\n\n\ndef detect_anomalies(\n    ctx: RunContext[pd.DataFrame], column: str, threshold: float = 3.0\n) -> list[dict[str, Any]]:\n    \"\"\"Detect anomalies using standard deviation method.\n\n    Identifies values that are more than `threshold` standard deviations from the mean.\n    This tool demonstrates how complex analysis logic can be made reliable with Prefect.\"\"\"\n    df = ctx.deps\n    if column not in df.columns:\n        return [{\"error\": f\"Column '{column}' not found\"}]\n\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        return [{\"error\": f\"Column '{column}' is not numeric\"}]\n\n    mean = df[column].mean()\n    std = df[column].std()\n\n    if std == 0:\n        return []\n\n    anomalies = df[abs(df[column] - mean) > (threshold * std)]\n    return [\n        {\n            \"index\": int(idx),\n            \"value\": float(row[column]),\n            \"z_score\": float((row[column] - mean) / std),\n        }\n        for idx, row in anomalies.head(10).iterrows()\n    ]\n\n\ndef get_column_info(ctx: RunContext[pd.DataFrame]) -> dict[str, Any]:\n    \"\"\"Get overview of all columns in the dataset.\n\n    Helps the AI agent understand the dataset structure before analysis.\"\"\"\n    df = ctx.deps\n    return {\n        \"columns\": list(df.columns),\n        \"shape\": {\"rows\": len(df), \"columns\": len(df.columns)},\n        \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n    }\n\n\n```\n\n## Analysis Results Model\n\nStructured output ensures the AI returns consistent, parseable results.\n\n```python  theme={null}\nclass DataAnalysis(BaseModel):\n    \"\"\"Structured analysis results from the AI agent.\"\"\"\n\n    summary: str = Field(description=\"High-level summary of the dataset\")\n    key_findings: list[str] = Field(\n        description=\"Key findings discovered from the data\", min_length=3, max_length=5\n    )\n    recommendations: list[str] = Field(\n        description=\"Actionable recommendations based on the findings\",\n        min_length=3,\n        max_length=5,\n    )\n    columns_analyzed: list[str] = Field(\n        description=\"List of columns that were analyzed\"\n    )\n\n    def __str__(self) -> str:\n        \"\"\"Format the analysis results for clean display.\"\"\"\n        findings = \"\\n\".join(\n            f\"  {i}. {finding}\" for i, finding in enumerate(self.key_findings, 1)\n        )\n        recommendations = \"\\n\".join(\n            f\"  {i}. {rec}\" for i, rec in enumerate(self.recommendations, 1)\n        )\n\n        return f\"\"\"\n{\"=\" * 80}\nANALYSIS RESULTS\n{\"=\" * 80}\n\nüìã Summary:\n{self.summary}\n\nüîë Key Findings:\n{findings}\n\nüí° Recommendations:\n{recommendations}\n\nüìä Columns Analyzed: {\", \".join(self.columns_analyzed)}\n{\"=\" * 80}\n\"\"\"\n\n\n```\n\n## Creating the AI Agent\n\nWe configure the agent with tools and wrap it with PrefectAgent for durability.\n\n```python  theme={null}\ndef create_data_analyst_agent() -> PrefectAgent[pd.DataFrame, DataAnalysis]:\n    \"\"\"Create an AI data analyst with Prefect durability.\n\n    The PrefectAgent wrapper automatically:\n    - Wraps agent.run as a Prefect flow\n    - Wraps LLM calls as Prefect tasks with retries\n    - Wraps tool calls as separate Prefect tasks\n    \"\"\"\n\n    # Create the base pydantic-ai agent\n    agent = Agent(\n        \"openai:gpt-4o\",\n        name=\"data-analyst-agent\",\n        output_type=DataAnalysis,\n        deps_type=pd.DataFrame,\n        # Register tools that the agent can use\n        tools=[calculate_statistics, detect_anomalies, get_column_info],\n        system_prompt=(\n            \"You are an expert data analyst. Analyze the provided dataset using \"\n            \"the available tools. Focus on finding meaningful patterns, anomalies, \"\n            \"and actionable insights. Always start by understanding the dataset \"\n            \"structure with get_column_info.\"\n        ),\n    )\n\n    # Wrap with PrefectAgent for durable execution with custom retry policy\n    return PrefectAgent(\n        agent,\n        model_task_config=TaskConfig(\n            retries=3,  # Retry LLM calls up to 3 times\n            retry_delay_seconds=[1.0, 2.0, 4.0],  # Exponential backoff\n            timeout_seconds=60.0,  # 60s timeout for LLM calls\n        ),\n        tool_task_config=TaskConfig(\n            retries=2,  # Retry tool calls up to 2 times\n            retry_delay_seconds=[0.5, 1.0],\n        ),\n    )\n\n\n```\n\n## Sample Dataset Generator\n\nCreate a realistic sales dataset for demonstration.\n\n```python  theme={null}\n@task\ndef create_sample_dataset() -> pd.DataFrame:\n    \"\"\"Generate a sample sales dataset with some anomalies.\n\n    In production, you'd load real data from a file, database, or API.\"\"\"\n    data = {\n        \"product\": [\"Widget\", \"Gadget\", \"Doohickey\", \"Widget\", \"Gadget\"] * 20,\n        \"sales\": [100, 150, 200, 110, 145] * 19\n        + [100, 150, 200, 1000, 2000],  # Last 2 are anomalies\n        \"region\": [\"North\", \"South\", \"East\", \"West\", \"Central\"] * 20,\n        \"month\": [1, 2, 3, 4, 5] * 20,\n    }\n    return pd.DataFrame(data)\n\n\n```\n\n## Main Analysis Flow\n\nOrchestrate the entire AI analysis workflow with Prefect.\n\n```python  theme={null}\n@flow(name=\"ai-data-analyst\", log_prints=True)\nasync def analyze_dataset_with_ai() -> DataAnalysis:\n    \"\"\"Run AI-powered data analysis with automatic retries and observability.\n\n    This flow demonstrates how Prefect makes AI workflows production-ready:\n    1. Dataset preparation is tracked as a task\n    2. AI agent execution is wrapped for durability\n    3. All LLM and tool calls are logged and retryable\n    4. Results are structured and validated with Pydantic\n    \"\"\"\n\n    # Prepare the dataset\n    print(\"üìä Preparing dataset...\")\n    df = create_sample_dataset()\n    print(f\"Dataset shape: {df.shape}\\n\")\n\n    # Create the AI agent with Prefect durability\n    print(\"ü§ñ Initializing AI data analyst...\")\n    agent = create_data_analyst_agent()\n\n    # Run the analysis - all LLM and tool calls are automatically retried on failure\n    print(\"üîç Running AI analysis...\\n\")\n    result = await agent.run(\n        \"Analyze this sales dataset. Identify patterns, anomalies, and provide recommendations.\",\n        deps=df,\n    )\n\n    # Display results\n    print(result.output)\n\n    return result.output\n\n\n```\n\n## Serve the Flow\n\nTo get full durable execution with automatic idempotency, serve the flow to create a deployment.\nDeployed flows enable Prefect's transactional semantics for agent operations.\n\n```python  theme={null}\nif __name__ == \"__main__\":\n    import os\n    import sys\n\n    # Check if OpenAI API key is set\n    if not os.getenv(\"OPENAI_API_KEY\"):\n        print(\"‚ùå Error: OPENAI_API_KEY environment variable not set\")\n        print(\"Set it with: export OPENAI_API_KEY='your-key-here'\")\n        sys.exit(1)\n\n    # Serve the flow - this creates a deployment and runs a worker process\n    analyze_dataset_with_ai.serve(\n        name=\"ai-data-analyst-deployment\",\n        tags=[\"ai\", \"pydantic-ai\", \"data-analysis\"],\n    )\n\n```\n\n## Triggering Flow Runs\n\nOnce served, trigger runs via:\n\n**Prefect UI:**\n\n1. Navigate to [http://localhost:4200](http://localhost:4200)\n2. Go to Deployments ‚Üí \"ai-data-analyst-deployment\"\n3. Click \"Run\" ‚Üí \"Quick Run\"\n\n**CLI:**\n\n```bash  theme={null}\nprefect deployment run ai-data-analyst/ai-data-analyst-deployment --watch\n```\n\n## Local Testing\n\nFor quick local testing without deployment:\n\n```python  theme={null}\nimport asyncio\nasyncio.run(analyze_dataset_with_ai())\n```\n\n## What Just Happened?\n\nWhen you serve and trigger this flow, Prefect and `pydantic-ai` work together to create a resilient AI pipeline:\n\n1. **Deployment Creation** ‚Äì `serve()` creates a deployment and starts a worker to execute flow runs\n2. **Durable AI Execution** ‚Äì The `PrefectAgent` wrapper makes all AI operations retryable:\n   * LLM calls retry up to 3 times with exponential backoff (1s, 2s, 4s)\n   * Tool calls retry up to 2 times\n   * All operations respect 60s timeout\n3. **Tool Observability** ‚Äì Each time the AI calls a tool (`get_column_info`, `calculate_statistics`, `detect_anomalies`),\n   the call is run as a Prefect task\n4. **Structured Results** ‚Äì Pydantic validates the AI's output, ensuring it matches the expected schema\n5. **Automatic Idempotency** ‚Äì When a deployed flow run is retried, Prefect's transactional semantics ensure that\n   completed tasks are skipped and only failed operations are re-executed. This prevents duplicate API calls and\n   wasted compute.\n\n## Key Takeaways\n\n* **Deploy for Durability** ‚Äì Use `flow.serve()` or `flow.deploy()` to unlock automatic idempotency and transactional semantics\n* **Retry Intelligence** ‚Äì Failed flow runs can be retried from the UI, skipping already-completed tasks\n* **Tool Observability** ‚Äì Every AI decision and tool call is tracked, logged, and independently retryable\n* **Zero Boilerplate** ‚Äì Just wrap your pydantic-ai agent with `PrefectAgent`\n* **Customizable Policies** ‚Äì Fine-tune retries, timeouts, and error handling per operation type\n\n**Try it yourself:**\n\n1. Set your OpenAI API key: `export OPENAI_API_KEY='your-key'`\n2. Start the Prefect server: `prefect server start`\n3. Serve the flow: `uv run -s examples/ai_data_analyst_with_pydantic_ai.py`\n4. Trigger a run from the UI ([http://localhost:4200](http://localhost:4200)) or CLI\n5. Watch all AI operations tracked in real-time\n\nFor more on AI orchestration with Prefect:\n\n* [pydantic-ai + Prefect documentation](https://ai.pydantic.dev/durable_execution/prefect/)\n* [Task configuration and retries](/v3/how-to-guides/workflows/write-and-run#task-configuration)\n* [Workflow deployments](/v3/how-to-guides/deployments/create-deployments)",
  "content_length": 12355
}