{
  "title": "How to run flows on Kubernetes",
  "source_url": "https://docs-3.prefect.io/v3/how-to-guides/deployment_infra/kubernetes",
  "content": "Learn how to run flows on Kubernetes using containers.\n\nThis guide explains how to run flows on Kubernetes.\nThough much of the guide is general to any Kubernetes cluster, it focuses on\nAmazon Elastic Kubernetes Service (EKS). Prefect is tested against\nKubernetes 1.26.0 and newer minor versions.\n\n## Prerequisites\n\n1. A Prefect Cloud account\n2. A cloud provider (AWS, GCP, or Azure) account\n3. Python and Prefect [installed](/v3/get-started/install/)\n4. Helm [installed](https://helm.sh/docs/intro/install/)\n5. Kubernetes CLI (kubectl)[installed](https://kubernetes.io/docs/tasks/tools/install-kubectl/)\n6. Admin access for Prefect Cloud and your cloud provider. You can downgrade it after this setup.\n\n## Create a cluster\n\nIf you already have one, skip ahead to the next section.\n\n<Tabs>\n  <Tab title=\"AWS\">\n    One easy way to get set up with a cluster in EKS is with [`eksctl`](https://eksctl.io/).\n    Node pools can be backed by either EC2 instances or FARGATE.\n    Choose FARGATE so there's less to manage.\n    The following command takes around 15 minutes and must not be interrupted:\n\n    ```bash  theme={null}\n    # Replace the cluster name with your own value\n    eksctl create cluster --fargate --name <CLUSTER-NAME>\n\n    # Authenticate to the cluster.\n    aws eks update-kubeconfig --name <CLUSTER-NAME>\n    ```\n  </Tab>\n\n  <Tab title=\"GCP\">\n    You can get a GKE cluster up and running with a few commands using the\n    [`gcloud` CLI](https://cloud.google.com/sdk/docs/install).\n    This builds a bare-bones cluster that is accessible over the open\n    internet - but it should **not** be used in a production environment.\n    To deploy the cluster, your project must have a VPC network configured.\n\n    First, authenticate to GCP by setting the following configuration options:\n\n    ```bash  theme={null}\n    # Authenticate to gcloud\n    gcloud auth login\n\n    # Specify the project & zone to deploy the cluster to\n    # Replace the project name with your GCP project name\n    gcloud config set project <GCP-PROJECT-NAME>\n    gcloud config set compute/zone <AVAILABILITY-ZONE>\n    ```\n\n    Next, deploy the cluster. This command takes \\~15 minutes to complete.\n    Once the cluster has been created, authenticate to the cluster.\n\n    ```bash  theme={null}\n    # Create cluster\n    # Replace the cluster name with your own value\n    gcloud container clusters create <CLUSTER-NAME> --num-nodes=1 \\\n    --machine-type=n1-standard-2\n\n    # Authenticate to the cluster\n    gcloud container clusters <CLUSTER-NAME> --region <AVAILABILITY-ZONE>\n    ```\n\n    <Warning>\n      **GCP potential errors**\n\n      ```\n      ERROR: (gcloud.container.clusters.create) ResponseError: code=400, message=Service account \"000000000000-compute@developer.gserviceaccount.com\" is disabled.\n      ```\n\n      * You must enable the default service account in the IAM console, or\n        specify a different service account with the appropriate permissions.\n\n      ```\n      creation failed: Constraint constraints/compute.vmExternalIpAccess violated for project 000000000000. Add instance projects/<GCP-PROJECT-NAME>/zones/us-east1-b/instances/gke-gke-guide-1-default-pool-c369c84d-wcfl to the constraint to use external IP with it.\"\n      ```\n\n      * Organization policy blocks creation of external (public) IPs. Override\n        this policy (if you have the appropriate permissions) under the `Organizational Policy`\n        page within IAM.\n    </Warning>\n  </Tab>\n\n  <Tab title=\"Azure\">\n    Create an AKS cluster using the\n    [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/get-started-with-azure-cli),\n    or use the Cloud Shell directly from the Azure portal [shell.azure.com](https://shell.azure.com).\n\n    First, authenticate to Azure if not already done.\n\n    ```bash  theme={null}\n      az login\n    ```\n\n    Next, deploy the cluster - this command takes \\~4 minutes to complete.\n    Once the cluster is created, authenticate to the cluster.\n\n    ```bash  theme={null}\n\n      # Create a Resource Group at the desired location, e.g. westus\n      az group create --name <RESOURCE-GROUP-NAME> --location <LOCATION>\n\n      # Create a kubernetes cluster with default kubernetes version, default SKU load balancer (Standard) and default vm set type (VirtualMachineScaleSets)\n      az aks create --resource-group <RESOURCE-GROUP-NAME> --name <CLUSTER-NAME>\n\n      # Configure kubectl to connect to your Kubernetes cluster\n      az aks get-credentials --resource-group <RESOURCE-GROUP-NAME> --name <CLUSTER-NAME>\n\n      # Verify the connection by listing the cluster nodes\n      kubectl get nodes\n    ```\n  </Tab>\n</Tabs>\n\n## Create a container registry\n\nBesides a cluster, the other critical resource is a container registry.\nA registry is not strictly required, but in most cases you'll want to use custom\nimages and/or have more control over where images are stored.\nIf you already have a registry, skip ahead to the next section.\n\n<Tabs>\n  <Tab title=\"AWS\">\n    Create a registry using the AWS CLI and authenticate the docker daemon to\n    that registry:\n\n    ```bash  theme={null}\n    # Replace the image name with your own value\n    aws ecr create-repository --repository-name <IMAGE-NAME>\n\n    # Login to ECR\n    # Replace the region and account ID with your own values\n    aws ecr get-login-password --region <REGION> | docker login \\\n      --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com\n    ```\n  </Tab>\n\n  <Tab title=\"GCP\">\n    Create a registry using the gcloud CLI and authenticate the docker daemon to\n    that registry:\n\n    ```bash  theme={null}\n    # Create artifact registry repository to host your custom image\n    # Replace the repository name with your own value; it can be the\n    # same name as your image\n    gcloud artifacts repositories create <REPOSITORY-NAME> \\\n    --repository-format=docker --location=us\n\n    # Authenticate to artifact registry\n    gcloud auth configure-docker us-docker.pkg.dev\n    ```\n  </Tab>\n\n  <Tab title=\"Azure\">\n    Create a registry using the Azure CLI and authenticate the docker daemon to\n    that registry:\n\n    ```bash  theme={null}\n    # Name must be a lower-case alphanumeric\n    # Tier SKU can easily be updated later, e.g. az acr update --name <REPOSITORY-NAME> --sku Standard\n    az acr create --resource-group <RESOURCE-GROUP-NAME> \\\n      --name <REPOSITORY-NAME> \\\n      --sku Basic\n\n    # Attach ACR to AKS cluster\n    # You need Owner, Account Administrator, or Co-Administrator role on your Azure subscription as per Azure docs\n    az aks update --resource-group <RESOURCE-GROUP-NAME> --name <CLUSTER-NAME> --attach-acr <REPOSITORY-NAME>\n\n    # You can verify AKS can now reach ACR\n    az aks check-acr --resource-group RESOURCE-GROUP-NAME> --name <CLUSTER-NAME> --acr <REPOSITORY-NAME>.azurecr.io\n\n    ```\n  </Tab>\n</Tabs>\n\n## Create a Kubernetes work pool\n\n[Work pools](/v3/deploy/infrastructure-concepts/work-pools/) allow you to manage deployment\ninfrastructure.\nThis section shows you how to configure the default values for your\nKubernetes base job template.\nThese values can be overridden by individual deployments.\n\nSwitch to the Prefect Cloud UI to create a new Kubernetes work pool.\n(Alternatively, you could use the Prefect CLI to create a work pool.)\n\n1. Click on the **Work Pools** tab on the left sidebar\n2. Click the **+** button at the top of the page\n3. Select **Kubernetes** as the work pool type\n4. Click **Next** to configure the work pool settings\n5. Set the `namespace` field to `prefect`\n\n<Note>\n  If you set a different namespace, use your selected namespace instead of `prefect` in all commands below.\n</Note>\n\nYou may come back to this page to configure the work pool options at any time.\n\n### Configure work pool options\n\nHere are some popular configuration options.\n\n**Environment Variables**\n\nAdd environment variables to set when starting a flow run.\nIf you are using a Prefect-maintained image and haven't overwritten the image's\nentrypoint, you can specify Python packages to install at runtime with `{\"EXTRA_PIP_PACKAGES\":\"my_package\"}`.\nFor example `{\"EXTRA_PIP_PACKAGES\":\"pandas==1.2.3\"}` installs pandas version 1.2.3.\nAlternatively, you can specify package installation in a custom Dockerfile, which\nallows you to use image caching.\nAs shown below, Prefect can help create a Dockerfile with your flow code and the\npackages specified in a `requirements.txt` file baked in.\n\n**Namespace**\n\nSet the Kubernetes namespace to create jobs within, such as `prefect`. By default, set\nto **default**.\n\n**Image**\n\nSpecify the Docker container image for created jobs.\nIf not set, the latest Prefect 3 image is used (for example, `prefecthq/prefect:3-latest`).\nYou can override this on each deployment through `job_variables`.\n\n**Image Pull Policy**\n\nSelect from the dropdown options to specify when to pull the image.\nWhen using the `IfNotPresent` policy, make sure to use unique image tags, or\nold images may get cached on your nodes.\n\n**Finished Job TTL**\n\nNumber of seconds before finished jobs are automatically cleaned up by the Kubernetes\ncontroller.\nSet to 60 so completed flow runs are cleaned up after a minute.\n\n**Pod Watch Timeout Seconds**\n\nNumber of seconds for pod creation to complete before timing out.\nConsider setting to 300, especially if using a **serverless** type node pool, as\nthese tend to have longer startup times.\n\n**Kubernetes cluster config**\n\nSpecify a KubernetesClusterConfig block to configure the Kubernetes cluster for job creation.\nIn most cases, leave the cluster config blank since the worker should already have appropriate\naccess and permissions.\nWe recommend using this setting when deploying a worker to a cluster that differs from the one\nexecuting the flow runs.\n\n<Note>\n  **Advanced Settings**\n\n  Modify the default base job template to add other fields or delete existing\n  fields.\n\n  Select the **Advanced** tab and edit the JSON representation of the base job template.\n\n  For example, to set a CPU request, add the following section under variables:\n\n  ```json  theme={null}\n  \"cpu_request\": {\n    \"title\": \"CPU Request\",\n    \"description\": \"The CPU allocation to request for this pod.\",\n    \"default\": \"default\",\n    \"type\": \"string\"\n  },\n  ```\n\n  Next add the following to the first `containers` item under `job_configuration`:\n\n  ```json  theme={null}\n  ...\n  \"containers\": [\n    {\n      ...,\n      \"resources\": {\n        \"requests\": {\n          \"cpu\": \"{{ cpu_request }}\"\n        }\n      }\n    }\n  ],\n  ...\n  ```\n\n  Running deployments with this work pool will request the specified CPU.\n</Note>\n\nAfter configuring the work pool settings, move to the next screen.\n\nGive the work pool a name and save.\n\nYour new Kubernetes work pool should appear in the list of work pools.\n\n## Create a Prefect Cloud API key\n\nIf you already have a Prefect Cloud API key, you can skip these steps.\n\nTo create a Prefect Cloud API key:\n\n1. Log in to the Prefect Cloud UI.\n2. Click on your profile avatar picture in the top right corner.\n3. Click on your name to go to your profile settings.\n4. In the left sidebar, click on [API Keys](https://app.prefect.cloud/my/api-keys).\n5. Click the **+** button to create a new API key.\n6. Securely store the API key, ideally using a password manager.\n\n## Deploy a worker using Helm\n\nAfter you create a cluster and work pool, the next step is to deploy a worker.\nThe worker sets up the necessary Kubernetes infrastructure to run your flows.\nThe recommended method for deploying a worker is with the [Prefect Helm Chart](https://github.com/PrefectHQ/prefect-helm/tree/main/charts/prefect-worker).\n\n### Add the Prefect Helm repository\n\nAdd the Prefect Helm repository to your Helm client:\n\n```bash  theme={null}\nhelm repo add prefect https://prefecthq.github.io/prefect-helm\nhelm repo update\n```\n\n### Create a namespace\n\nCreate a new namespace in your Kubernetes cluster to deploy the Prefect worker:\n\n```bash  theme={null}\nkubectl create namespace prefect\n```\n\n### Create a Kubernetes secret for the Prefect API key\n\n```bash  theme={null}\nkubectl create secret generic prefect-api-key \\\n--namespace=prefect --from-literal=key=your-prefect-cloud-api-key\n```\n\n### Configure Helm chart values\n\nCreate a `values.yaml` file to customize the Prefect worker configuration.\nAdd the following contents to the file:\n\n```yaml  theme={null}\nworker:\n  cloudApiConfig:\n    accountId: <target account ID>\n    workspaceId: <target workspace ID>\n  config:\n    workPool: <target work pool name>\n```\n\nThese settings ensure that the worker connects to the proper account, workspace,\nand work pool.\n\nView your Account ID and Workspace ID in your browser URL when logged into Prefect Cloud.\nFor example: \\<[https://app.prefect.cloud/account/abc-my-account-id-is-here/workspaces/123-my-workspace-id-is-here>](https://app.prefect.cloud/account/abc-my-account-id-is-here/workspaces/123-my-workspace-id-is-here>).\n\n### Create a Helm release\n\nInstall the Prefect worker using the Helm chart with your custom `values.yaml` file:\n\n```bash  theme={null}\nhelm install prefect-worker prefect/prefect-worker \\\n  --namespace=prefect \\\n  -f values.yaml\n```\n\n### Verify deployment\n\nCheck the status of your Prefect worker deployment:\n\n```bash  theme={null}\nkubectl get pods -n prefect\n```\n\n## Define a flow\n\nStart simple with a flow that just logs a message.\nIn a directory named `flows`, create a file named `hello.py` with the following contents:\n\n```python  theme={null}\nfrom prefect import flow, tags\nfrom prefect.logging import get_run_logger\n\n@flow\ndef hello(name: str = \"Marvin\"):\n    logger = get_run_logger()\n    logger.info(f\"Hello, {name}!\")\n\nif __name__ == \"__main__\":\n    with tags(\"local\"):\n        hello()\n```\n\nRun the flow locally with `python hello.py` to verify that it works.\nUse the `tags` context manager to tag the flow run as `local`.\nThis step is not required, but does add some helpful metadata.\n\n## Define a Prefect deployment\n\nPrefect has two recommended options for creating a deployment with dynamic infrastructure.\nYou can define a deployment in a Python script using the `flow.deploy` mechanics or in a\n`prefect.yaml` definition file.\nThe `prefect.yaml` file currently allows for more customization in terms of push and pull\nsteps.\n\nTo learn about the Python deployment creation method with `flow.deploy` see\n[Workers](/v3/how-to-guides/deployment_infra/docker).\n\nThe [`prefect.yaml`](/v3/deploy/infrastructure-concepts/prefect-yaml/#managing-deployments) file is used\nby the `prefect deploy` command to deploy your flows.\nAs a part of that process it also builds and pushes your image.\nCreate a new file named `prefect.yaml` with the following contents:\n\n```yaml  theme={null}\n# Generic metadata about this project\nname: flows\nprefect-version: 3.0.0\n\n# build section allows you to manage and build docker images\nbuild:\n- prefect_docker.deployments.steps.build_docker_image:\n    id: build-image\n    requires: prefect-docker>=0.4.0\n    image_name: \"{{ $PREFECT_IMAGE_NAME }}\"\n    tag: latest\n    dockerfile: auto\n    platform: \"linux/amd64\"\n\n# push section allows you to manage if and how this project is uploaded to remote locations\npush:\n- prefect_docker.deployments.steps.push_docker_image:\n    requires: prefect-docker>=0.4.0\n    image_name: \"{{ build-image.image_name }}\"\n    tag: \"{{ build-image.tag }}\"\n\n# pull section allows you to provide instructions for cloning this project in remote\nlocations\npull:\n- prefect.deployments.steps.set_working_directory:\n    directory: /opt/prefect/flows\n\n# the definitions section allows you to define reusable components for your deployments\ndefinitions:\n  tags: &common_tags\n    - \"eks\"\n  work_pool: &common_work_pool\n    name: \"kubernetes\"\n    job_variables:\n      image: \"{{ build-image.image }}\"\n\n# the deployments section allows you to provide configuration for deploying flows\ndeployments:\n- name: \"default\"\n  tags: *common_tags\n  schedule: null\n  entrypoint: \"flows/hello.py:hello\"\n  work_pool: *common_work_pool\n\n- name: \"arthur\"\n  tags: *common_tags\n  schedule: null\n  entrypoint: \"flows/hello.py:hello\"\n  parameters:\n    name: \"Arthur\"\n  work_pool: *common_work_pool\n```\n\nWe define two deployments of the `hello` flow: `default` and `arthur`.\nBy specifying `dockerfile: auto`, Prefect automatically creates a dockerfile\nthat installs any `requirements.txt` and copies over the current directory.\n\nYou can pass a custom Dockerfile instead with `dockerfile: Dockerfile` or\n`dockerfile: path/to/Dockerfile`.\nWe are specifically building for the `linux/amd64` platform.\nThis specification is often necessary when images are built on Macs with M series chips\nbut run on cloud provider instances.\n\n<Note>\n  **Deployment specific build, push, and pull**\n\n  You can override the build, push, and pull steps for each deployment.\n  This allows for more custom behavior, such as specifying a different image for each\n  deployment.\n</Note>\n\nDefine your requirements in a `requirements.txt` file:\n\n```\nprefect>=3.0.0\nprefect-docker>=0.4.0\nprefect-kubernetes>=0.3.1\n```\n\nThe directory should now look something like this:\n\n```\n.\n├── prefect.yaml\n└── flows\n    ├── requirements.txt\n    └── hello.py\n```\n\n### Tag images with a Git SHA\n\nIf your code is stored in a GitHub repository, it's good practice to tag your images\nwith the Git SHA of the code used to build it.\nDo this in the `prefect.yaml` file with a few minor modifications, since it's not yet\nan option with the Python deployment creation method.\n\nUse the `run_shell_script` command to grab the SHA and pass it to the `tag`\nparameter of `build_docker_image`:\n\n```yaml  theme={null}\nbuild:\n- prefect.deployments.steps.run_shell_script:\n    id: get-commit-hash\n    script: git rev-parse --short HEAD\n    stream_output: false\n- prefect_docker.deployments.steps.build_docker_image:\n    id: build-image\n    requires: prefect-docker>=0.4.0\n    image_name: \"{{ $PREFECT_IMAGE_NAME }}\"\n    tag: \"{{ get-commit-hash.stdout }}\"\n    dockerfile: auto\n    platform: \"linux/amd64\"\n```\n\nSet the SHA as a tag for easy identification in the UI:\n\n```yaml  theme={null}\ndefinitions:\n  tags: &common_tags\n    - \"eks\"\n    - \"{{ get-commit-hash.stdout }}\"\n  work_pool: &common_work_pool\n    name: \"kubernetes\"\n    job_variables:\n      image: \"{{ build-image.image }}\"\n```\n\n## Authenticate to Prefect\n\nBefore deploying the flows to Prefect, you need to authenticate through the Prefect CLI.\nYou also need to ensure that all of your flow's dependencies are present at `deploy` time.\n\nThis example uses a virtual environment to ensure consistency across environments.\n\n```bash  theme={null}\n# Create a virtualenv & activate it\nvirtualenv prefect-demo\nsource prefect-demo/bin/activate\n\n# Install dependencies of your flow\nprefect-demo/bin/pip install -r requirements.txt\n\n# Authenticate to Prefect & select the appropriate\n# workspace to deploy your flows to\nprefect-demo/bin/prefect cloud login\n```\n\n## Deploy the flows\n\nYou're ready to deploy your flows to build your images.\nThe image name determines its registry.\nYou have configured our `prefect.yaml` file to get the image name from the\n`PREFECT_IMAGE_NAME` environment variable, so set that first:\n\n<Tabs>\n  <Tab title=\"AWS\">\n    ```bash  theme={null}\n    export PREFECT_IMAGE_NAME=<AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com/<IMAGE-NAME>\n    ```\n  </Tab>\n\n  <Tab title=\"GCP\">\n    ```bash  theme={null}\n    export PREFECT_IMAGE_NAME=us-docker.pkg.dev/<GCP-PROJECT-NAME>/<REPOSITORY-NAME>/<IMAGE-NAME>\n    ```\n  </Tab>\n\n  <Tab title=\"Azure\">\n    ```bash  theme={null}\n    export PREFECT_IMAGE_NAME=<REPOSITORY-NAME>.azurecr.io/<IMAGE-NAME>\n    ```\n  </Tab>\n</Tabs>\n\nTo deploy your flows, ensure your Docker daemon is running. Deploy all the\nflows with `prefect deploy --all` or deploy them individually by name: `prefect deploy\n-n hello/default` or `prefect deploy -n hello/arthur`.\n\n## Run the flows\n\nOnce the deployments are successfully created, you can run them from the UI or the CLI:\n\n```bash  theme={null}\nprefect deployment run hello/default\nprefect deployment run hello/arthur\n```\n\nYou can now check the status of your two deployments in the UI.",
  "content_length": 20078
}