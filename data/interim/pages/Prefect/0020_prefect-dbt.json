{
  "title": "prefect-dbt",
  "source_url": "https://docs-3.prefect.io/integrations/prefect-dbt/index",
  "content": "With `prefect-dbt`, you can trigger and observe dbt Cloud jobs, execute dbt Core CLI commands, and incorporate other tools, such as [Snowflake](/integrations/prefect-snowflake/index), into your dbt runs.\nPrefect provides a global view of the state of your workflows and allows you to take action based on state changes.\n\nPrefect integrations may provide pre-built [blocks](/v3/develop/blocks), [flows](/v3/develop/write-flows), or [tasks](/v3/develop/write-tasks) for interacting with external systems.\nBlock types in this library allow you to do things such as run a dbt Cloud job or execute a dbt Core command.\n\n## Getting started\n\n### Prerequisites\n\n* A [dbt Cloud account](https://cloud.getdbt.com/) if using dbt Cloud.\n\n### Install `prefect-dbt`\n\nThe following command will install a version of `prefect-dbt` compatible with your installed version of `prefect`.\nIf you don't already have `prefect` installed, it will install the newest version of `prefect` as well.\n\n```bash  theme={null}\npip install \"prefect[dbt]\"\n```\n\nUpgrade to the latest versions of `prefect` and `prefect-dbt`:\n\n```bash  theme={null}\npip install -U \"prefect[dbt]\"\n```\n\nIf necessary, see [additional installation options for dbt Core with BigQuery, Snowflake, and Postgres](#additional-installation-options).\n\n### Register newly installed blocks types\n\nRegister the block types in the `prefect-dbt` module to make them available for use.\n\n```bash  theme={null}\nprefect block register -m prefect_dbt\n```\n\n## dbt Cloud\n\nIf you have an existing dbt Cloud job, use the pre-built flow `run_dbt_cloud_job` to trigger a job run and wait until the job run is finished. If some nodes fail, `run_dbt_cloud_job` can efficiently retry the unsuccessful nodes. Prior to running this flow, save your dbt Cloud credentials to a DbtCloudCredentials block and create a dbt Cloud Job block:\n\n### Save dbt Cloud credentials to a block\n\nBlocks can be [created through code](/v3/develop/blocks) or through the UI.\n\nTo create a dbt Cloud Credentials block:\n\n1. Log into your [dbt Cloud account](https://cloud.getdbt.com/settings/profile).\n2. Click **API Tokens** on the sidebar.\n3. Copy a Service Token.\n4. Copy the account ID from the URL: `https://cloud.getdbt.com/settings/accounts/<ACCOUNT_ID>`.\n5. Create and run the following script, replacing the placeholders:\n\n```python  theme={null}\nfrom prefect_dbt.cloud import DbtCloudCredentials\n\n\nDbtCloudCredentials(\n    api_key=\"API-KEY-PLACEHOLDER\",\n    account_id=\"ACCOUNT-ID-PLACEHOLDER\"\n).save(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\n```\n\n### Create a dbt Cloud job block\n\n1. In dbt Cloud, click on **Deploy** -> **Jobs**.\n2. Select a job.\n3. Copy the job ID from the URL: `https://cloud.getdbt.com/deploy/<ACCOUNT_ID>/projects/<PROJECT_ID>/jobs/<JOB_ID>`\n4. Create and run the following script, replacing the placeholders.\n\n```python  theme={null}\nfrom prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"CREDENTIALS-BLOCK-PLACEHOLDER\")\ndbt_cloud_job = DbtCloudJob(\n    dbt_cloud_credentials=dbt_cloud_credentials,\n    job_id=\"JOB-ID-PLACEHOLDER\"\n).save(\"JOB-BLOCK-NAME-PLACEHOLDER\")\n```\n\n### Run a dbt Cloud job and wait for completion\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt.cloud import DbtCloudJob\nfrom prefect_dbt.cloud.jobs import run_dbt_cloud_job\nimport asyncio\n\n@flow\nasync def run_dbt_job_flow():\n    result = await run_dbt_cloud_job(\n        dbt_cloud_job = await DbtCloudJob.load(\"JOB-BLOCK-NAME-PLACEHOLDER\"),\n        targeted_retries = 0,\n    )\n    return await result\n\nif __name__ == \"__main__\":\n    asyncio.run(run_dbt_job_flow())\n```\n\n## dbt Core\n\n### prefect-dbt 0.7.0 and later\n\nVersions 0.7.0 and later of `prefect-dbt` include the `PrefectDbtRunner` class, which provides an improved interface for running dbt Core commands with better logging, failure handling, and automatic asset lineage.\n\n<Tip>\n  The `PrefectDbtRunner` is inspired by the `DbtRunner` from dbt Core, and its `invoke` method accepts the same arguments.\n  Refer to the [`DbtRunner` documentation](https://docs.getdbt.com/reference/programmatic-invocations) for more information on how to call `invoke`.\n</Tip>\n\nBasic usage:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner\n\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner().invoke([\"build\"])\n\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\nWhen calling `.invoke()` in a flow or task, each node in dbt's execution graph is reflected as a task in Prefect's execution graph.\nLogs from each node will belong to the corresponding task, and each task's state is determined by the state of that node's execution.\n\n```bash  theme={null}\n15:54:59.119 | INFO    | Flow run 'imposing-partridge' - Found 8 models, 3 seeds, 18 data tests, 543 macros\n15:54:59.134 | INFO    | Flow run 'imposing-partridge' - \n15:54:59.148 | INFO    | Flow run 'imposing-partridge' - Concurrency: 1 threads (target='dev')\n15:54:59.164 | INFO    | Flow run 'imposing-partridge' - \n15:54:59.665 | INFO    | Task run 'model my_first_dbt_model' - 1 of 29 OK created sql table model main.my_first_dbt_model ..................... [OK in 0.18s]\n15:54:59.671 | INFO    | Task run 'model my_first_dbt_model' - Finished in state Completed()\n...\n15:55:02.373 | ERROR   | Task run 'model product_metrics' -   Runtime Error in model product_metrics (models/marts/product/product_metrics.sql)\n  Binder Error: Values list \"o\" does not have a column named \"product_id\"\n  \n  LINE 47:         on p.product_id = o.product_id\n15:55:02.857 | ERROR   | Task run 'model product_metrics' - Finished in state Failed('Task run encountered an exception Exception: Node model.demo.product_metrics finished with status error')\n```\n\n<Warning>\n  The task runs created by calling `.invoke()` run separately from dbt Core, and do not affect dbt's execution behavior.\n  These tasks do not persist results and cannot be cached.\n\n  Use [dbt's native retry functionality](https://docs.getdbt.com/reference/commands/retry) in combination with [runtime data from `prefect`](/v3/how-to-guides/workflows/access-runtime-info) to retry failed nodes.\n\n  ```python  theme={null}\n  from prefect import flow\n  from prefect.runtime.flow_run import get_run_count\n  from prefect_dbt import PrefectDbtRunner\n\n\n  @flow(retries=2)\n  def run_dbt():\n      runner = PrefectDbtRunner()\n\n      if get_run_count() == 1:\n          runner.invoke([\"build\"])\n      else:\n          runner.invoke([\"retry\"])\n\n\n  if __name__ == \"__main__\":\n      run_dbt()\n  ```\n</Warning>\n\n#### Assets\n\nPrefect Cloud maintains a graph of [assets](/v3/concepts/assets), objects produced by your workflows.\n\nAny dbt seed, source or model will appear on your asset graph in Prefect Cloud once it has been executed using the `PrefectDbtRunner`.\nThe upstream dependencies of an asset materialized by `prefect-dbt` are derived from the `depends_on` field in dbt's `manifest.json`.\n\nThe asset's `key` will be its corresponding dbt resource's `relation_name`.\n\nThe `name` and `description` asset properties are populated by a dbt resource's name description.\n\nThe `owners` asset property is populated if there is data assigned to the `owner` key under a resoure's `meta` config.\n\n```yaml  theme={null}\nmodels:\n  - name: product_metrics\n    description: \"Product metrics and categorization\"\n    config:\n      meta:\n        owner: \"kevin-g\"\n```\n\nAsset metadata is collected from the result of the node's execution.\n\n```json  theme={null}\n{\n  \"node_path\": \"marts/product/product_metrics.sql\",\n  \"node_name\": \"product_metrics\",\n  \"unique_id\": \"model.demo.product_metrics\",\n  \"resource_type\": \"model\",\n  \"materialized\": \"table\",\n  \"node_status\": \"error\",\n  \"node_started_at\": \"2025-06-26T20:55:05.661126\",\n  \"node_finished_at\": \"2025-06-26T20:55:05.733257\",\n  \"meta\": {\n    \"owner\": \"kevin-g\"\n  },\n  \"node_relation\": {\n    \"database\": \"dev\",\n    \"schema\": \"main_marts\",\n    \"alias\": \"product_metrics\",\n    \"relation_name\": \"\\\"dev\\\".\\\"main_marts\\\".\\\"product_metrics\\\"\"\n  }\n}\n```\n\nOptionally, the compiled code of a dbt model can be appended to the asset description.\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner\n\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner(include_compiled_code=True).invoke([\"build\"])\n\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\n#### dbt settings\n\nThe `PrefectDbtSettings` class, based on Pydantic's `BaseSettings` class, automatically detects `DBT_`-prefixed environment variables that have a direct effect on the `PrefectDbtRunner` class.\nIf no environment variables are set, dbt's defaults are used.\n\nProvide a `PrefectDbtSettings` instance to `PrefectDbtRunner` to customize dbt settings or override environment variables.\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner, PrefectDbtSettings\n\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner(\n        settings=PrefectDbtSettings(\n            project_dir=\"test\",\n            profiles_dir=\"examples/run_dbt\"\n        )\n    ).invoke([\"build\"])\n\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\n#### Logging\n\nThe `PrefectDbtRunner` class maps all dbt log levels to standard Python logging levels, so filtering for log levels like `WARNING` or `ERROR` in the Prefect UI applies to dbt's logs.\n\nBy default, the logging level used by dbt is Prefect's logging level, which can be configured using the `PREFECT_LOGGING_LEVEL` Prefect setting.\n\nThe dbt logging level can be set independently from Prefect's by using the `DBT_LOG_LEVEL` environment variable, setting `log_level` in `PrefectDbtSettings`, or passing the `--log-level` flag or `log_level` kwarg to `.invoke()`.\nOnly logging levels of higher severity (more restrictive) than Prefect's logging level will have an effect.\n\n```python  theme={null}\nfrom dbt_common.events.base_types import EventLevel\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner, PrefectDbtSettings\n\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner(\n        settings=PrefectDbtSettings(\n            project_dir=\"test\",\n            profiles_dir=\"examples/run_dbt\",\n            log_level=EventLevel.ERROR, # explicitly choose a higher log level for dbt\n        )\n    ).invoke([\"build\"])\n\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\n#### `profiles.yml` templating\n\nThe `PrefectDbtRunner` class supports templating in your `profiles.yml` file, allowing you to reference Prefect blocks and variables that will be resolved at runtime.\nThis enables you to store sensitive credentials securely using Prefect blocks, and configure different targets based on the Prefect workspace.\n\nFor example, a Prefect variable called `target` can have a different value in development (`dev`) and production (`prod`) workspaces.\nThis allows you to use the same `profiles.yml` file to automatically reference a local DuckDB instance in development and a Snowflake instance in production.\n\n```yaml  theme={null}\nexample:\n  outputs:\n    dev:\n      type: duckdb\n      path: dev.duckdb\n      threads: 1\n\n    prod:\n      type: snowflake\n      account: \"{{ prefect.blocks.snowflake-credentials.warehouse-access.account }}\"\n      user: \"{{ prefect.blocks.snowflake-credentials.warehouse-access.user }}\"\n      password: \"{{ prefect.blocks.snowflake-credentials.warehouse-access.password }}\"\n      database: \"{{ prefect.blocks.snowflake-connector.prod-connector.database }}\"\n      schema: \"{{ prefect.blocks.snowflake-connector.prod-connector.schema }}\"\n      warehouse: \"{{ prefect.blocks.snowflake-connector.prod-connector.warehouse }}\"\n      threads: 4\n\n  target: \"{{ prefect.variables.target }}\"\n```\n\n#### Failure handling\n\nBy default, any dbt node execution failures cause the entire dbt run to raise an exception with a message containing detailed information about the failure.\n\n```\nFailures detected during invocation of dbt command 'build':\nTest not_null_my_first_dbt_model_id failed with message: \"Got 1 result, configured to fail if != 0\"\n```\n\nThe `PrefectDbtRunner`'s `raise_on_failure` option can be set to `False` to prevent failures in dbt from causing the failure of the flow or task in which `.invoke()` is called.\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner\n\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner(\n        raise_on_failure=False  # Failed tests will not fail the flow run\n    ).invoke([\"build\"])\n\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\n#### Native dbt configuration\n\nYou can disable automatic asset lineage detection for all resources in your dbt project config, or for specific resources in their own config:\n\n```yaml  theme={null}\nprefect:\n  enable_assets: False\n```\n\n### prefect-dbt 0.6.6 and earlier\n\n`prefect-dbt` supports a couple of ways to run dbt Core commands.\nA `DbtCoreOperation` block will run the commands as shell commands, while other tasks use dbt's [Programmatic Invocation](#programmatic-invocation).\n\nOptionally, specify the `project_dir`.\nIf `profiles_dir` is not set, the `DBT_PROFILES_DIR` environment variable will be used.\nIf `DBT_PROFILES_DIR` is not set, the default directory will be used `$HOME/.dbt/`.\n\n#### Use an existing profile\n\nIf you have an existing dbt `profiles.yml` file, specify the `profiles_dir` where the file is located:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt.cli.commands import DbtCoreOperation\n\n\n@flow\ndef trigger_dbt_flow() -> str:\n    result = DbtCoreOperation(\n        commands=[\"pwd\", \"dbt debug\", \"dbt run\"],\n        project_dir=\"PROJECT-DIRECTORY-PLACEHOLDER\",\n        profiles_dir=\"PROFILES-DIRECTORY-PLACEHOLDER\"\n    ).run()\n    return result\n\n\nif __name__ == \"__main__\":\n    trigger_dbt_flow()\n```\n\nIf you are already using Prefect blocks such as the [Snowflake Connector block](integrations/prefect-snowflake), you can use those blocks to [create a new `profiles.yml` with a `DbtCliProfile` block](#create-a-new-profile-with-blocks).\n\n##### Use environment variables with Prefect secret blocks\n\nIf you use environment variables in `profiles.yml`, set a Prefect Secret block as an environment variable:\n\n```python  theme={null}\nimport os\nfrom prefect.blocks.system import Secret\n\n\nsecret_block = Secret.load(\"DBT_PASSWORD_PLACEHOLDER\")\n\n# Access the stored secret\nDBT_PASSWORD = secret_block.get()\nos.environ[\"DBT_PASSWORD\"] = DBT_PASSWORD\n```\n\nThis example `profiles.yml` file could then access that variable.\n\n```yaml  theme={null}\nprofile:\n  target: prod\n  outputs:\n    prod:\n      type: postgres\n      host: 127.0.0.1\n      # IMPORTANT: Make sure to quote the entire Jinja string here\n      user: dbt_user\n      password: \"{{ env_var('DBT_PASSWORD') }}\"\n```\n\n#### Create a new `profiles.yml` file with blocks\n\nIf you don't have a `profiles.yml` file, you can use a DbtCliProfile block to create `profiles.yml`.\nThen, specify `profiles_dir` where `profiles.yml` will be written.\nHere's example code with placeholders:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt.cli import DbtCliProfile, DbtCoreOperation\n\n\n@flow\ndef trigger_dbt_flow():\n    dbt_cli_profile = DbtCliProfile.load(\"DBT-CORE-OPERATION-BLOCK-PLACEHOLDER\")\n    with DbtCoreOperation(\n        commands=[\"dbt debug\", \"dbt run\"],\n        project_dir=\"PROJECT-DIRECTORY-PLACEHOLDER\",\n        profiles_dir=\"PROFILES-DIRECTORY-PLACEHOLDER\",\n        dbt_cli_profile=dbt_cli_profile,\n    ) as dbt_operation:\n        dbt_process = dbt_operation.trigger()\n        # do other things before waiting for completion\n        dbt_process.wait_for_completion()\n        result = dbt_process.fetch_result()\n    return result\n\n\nif __name__ == \"__main__\":\n    trigger_dbt_flow()\n```\n\n<Warning>\n  **Supplying the `dbt_cli_profile` argument will overwrite existing `profiles.yml` files**\n\n  If you already have a `profiles.yml` file in the specified `profiles_dir`, the file will be overwritten. If you do not specify a profiles directory, `profiles.yml` at `~/.dbt/` would be overwritten.\n</Warning>\n\nVisit the SDK reference in the side navigation to see other built-in `TargetConfigs` blocks.\n\nIf the desired service profile is not available, you can build one from the generic `TargetConfigs` class.\n\n#### Programmatic Invocation\n\n`prefect-dbt` has some pre-built tasks that use dbt's [programmatic invocation](https://docs.getdbt.com/reference/programmatic-invocations).\n\nFor example:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_dbt.cli.tasks import from prefect import flow\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command, dbt_build_task\n\n\n@flow\ndef dbt_build_flow():\n    trigger_dbt_cli_command(\n        command=\"dbt deps\", project_dir=\"/Users/test/my_dbt_project_dir\",\n    )\n    dbt_build_task(\n        project_dir = \"/Users/test/my_dbt_project_dir\",\n        create_summary_artifact = True,\n        summary_artifact_key = \"dbt-build-task-summary\",\n        extra_command_args=[\"--select\", \"foo_model\"]\n    )\n\n\nif __name__ == \"__main__\":\n    dbt_build_flow()\n```\n\nSee the [SDK docs](https://reference.prefect.io/prefect_dbt/) for other pre-built tasks.\n\n##### Create a summary artifact\n\nThese pre-built tasks can also create artifacts. These artifacts have extra information about dbt Core runs, such as messages and compiled code for nodes that fail or have errors.\n\n<img src=\"https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=fc5044f3fd6b7e41bb5e74c74ac4ac09\" alt=\"prefect-dbt Summary Artifact\" data-og-width=\"597\" width=\"597\" data-og-height=\"933\" height=\"933\" data-path=\"images/prefect-dbt-summary-artifact.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?w=280&fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=c21798df9da02ae1f5193423dca91cfd 280w, https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?w=560&fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=215c6897bf1c9f4e0d440058b7d1e73a 560w, https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?w=840&fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=dcc05662b0cf6a0d527d41ca9cd6a36f 840w, https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?w=1100&fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=caf563a85e6e5d1afec584a047958b17 1100w, https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?w=1650&fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=b750585c0911f67c5c83123a5415a0c6 1650w, https://mintcdn.com/prefect-bd373955/9tQZbEaDbWbFiuGw/images/prefect-dbt-summary-artifact.png?w=2500&fit=max&auto=format&n=9tQZbEaDbWbFiuGw&q=85&s=c8a9acb3fb00b0b45f2b13a6246cd3a1 2500w\" />\n\n#### BigQuery CLI profile block example\n\nTo create dbt Core target config and profile blocks for BigQuery:\n\n1. Save and load a `GcpCredentials` block.\n2. Determine the schema / dataset you want to use in BigQuery.\n3. Create a short script, replacing the placeholders.\n\n```python  theme={null}\nfrom prefect_gcp.credentials import GcpCredentials\nfrom prefect_dbt.cli import BigQueryTargetConfigs, DbtCliProfile\n\n\ncredentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\ntarget_configs = BigQueryTargetConfigs(\n    schema=\"SCHEMA-NAME-PLACEHOLDER\",  # also known as dataset\n    credentials=credentials,\n)\ntarget_configs.save(\"TARGET-CONFIGS-BLOCK-NAME-PLACEHOLDER\")\n\ndbt_cli_profile = DbtCliProfile(\n    name=\"PROFILE-NAME-PLACEHOLDER\",\n    target=\"TARGET-NAME-placeholder\",\n    target_configs=target_configs,\n)\ndbt_cli_profile.save(\"DBT-CLI-PROFILE-BLOCK-NAME-PLACEHOLDER\")\n```\n\nTo create a dbt Core operation block:\n\n1. Determine the dbt commands you want to run.\n2. Create a short script, replacing the placeholders.\n\n```python  theme={null}\nfrom prefect_dbt.cli import DbtCliProfile, DbtCoreOperation\n\n\ndbt_cli_profile = DbtCliProfile.load(\"DBT-CLI-PROFILE-BLOCK-NAME-PLACEHOLDER\")\ndbt_core_operation = DbtCoreOperation(\n    commands=[\"DBT-CLI-COMMANDS-PLACEHOLDER\"],\n    dbt_cli_profile=dbt_cli_profile,\n    overwrite_profiles=True,\n)\ndbt_core_operation.save(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n```\n\nLoad the saved block that holds your credentials:\n\n```python  theme={null}\nfrom prefect_dbt.cloud import DbtCoreOperation\n\n\nDbtCoreOperation.load(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n```\n\n## Resources\n\nFor assistance using dbt, consult the [dbt documentation](https://docs.getdbt.com/docs/building-a-dbt-project/documentation).\n\nRefer to the `prefect-dbt` [SDK documentation](https://reference.prefect.io/prefect_dbt/) to explore all the capabilities of the `prefect-dbt` library.\n\n### Additional installation options\n\nAdditional installation options for dbt Core with BigQuery, Snowflake, and Postgres are shown below.\n\n#### Additional capabilities for dbt Core and Snowflake profiles\n\nFirst install the main library compatible with your Prefect version:\n\n```bash  theme={null}\npip install \"prefect[dbt]\"\n```\n\nThen install the additional capabilities you need.\n\n```bash  theme={null}\npip install \"prefect-dbt[snowflake]\"\n```\n\n#### Additional capabilities for dbt Core and BigQuery profiles\n\n```bash  theme={null}\npip install \"prefect-dbt[bigquery]\"\n```\n\n#### Additional capabilities for dbt Core and Postgres profiles\n\n```bash  theme={null}\npip install \"prefect-dbt[postgres]\"\n```\n\nOr, install all of the extras.\n\n```bash  theme={null}\npip install -U \"prefect-dbt[all_extras]\"\n```",
  "content_length": 21441
}