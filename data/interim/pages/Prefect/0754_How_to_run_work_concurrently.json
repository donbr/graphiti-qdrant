{
  "title": "How to run work concurrently",
  "source_url": "https://docs-3.prefect.io/v3/how-to-guides/workflows/run-work-concurrently",
  "content": "## Calling tasks directly\n\nTasks can be called directly (i.e. using [`__call__`](https://docs.python.org/3/reference/datamodel.html#object.__call__)), but they **will not** run concurrently.\n\n```python  theme={null}\nimport time\n\nfrom prefect import task\n\n@task\ndef stop_at_floor(floor: int):\n    print(f\"elevator moving to floor {floor}\")\n    time.sleep(floor)\n    print(f\"elevator stops on floor {floor}\")\n\nstop_at_floor(0.1) # blocks for 0.1 seconds\nstop_at_floor(0.2) # blocks for 0.2 seconds\nstop_at_floor(0.3) # blocks for 0.3 seconds\n```\n\nWhen you call a task directly, it will block the main thread until the task completes.\n\nContinue reading to learn how to run tasks concurrently via [task runners](/v3/concepts/task-runners).\n\n## Using `.submit`\n\nTasks in your workflows can be run concurrently using the `.submit()` method.\n\n```python  theme={null}\nimport time\n\nfrom prefect import flow, task\nfrom prefect.futures import wait\n\n@task\ndef stop_at_floor(floor: int):\n    print(f\"elevator moving to floor {floor}\")\n    time.sleep(floor)\n    print(f\"elevator stops on floor {floor}\")\n\n@flow\ndef elevator():\n    floors = []\n    for floor in range(10, 0, -1):\n        floors.append(stop_at_floor.submit(floor))\n    wait(floors)\n```\n\nBy default, tasks are submitted via the `ThreadPoolTaskRunner`, which runs tasks concurrently in a thread pool.\n\n<Warning>\n  A common mistake is to pass non-thread-safe objects to tasks that you submit to a task runner. Avoid passing non-thread-safe objects to tasks you intend to run concurrently.\n\n  See [Design Considerations](/v3/concepts/task-runners#design-considerations) for more information.\n</Warning>\n\n### Using a different task runner\n\nTo run submitted tasks with a different task runner, you can pass a `task_runner` argument to the `@flow` decorator.\n\n<Note>\n  To run this example, you'll need to install the `prefect[dask]` extra\n</Note>\n\n```python  theme={null}\nimport time\n\nfrom prefect import flow, task\nfrom prefect.futures import wait\nfrom prefect_dask.task_runners import DaskTaskRunner\n\n@task\ndef stop_at_floor(floor: int):\n    print(f\"elevator moving to floor {floor}\")\n    time.sleep(floor)\n    print(f\"elevator stops on floor {floor}\")\n\n@flow(task_runner=DaskTaskRunner())\ndef elevator():\n    floors = []\n    for floor in range(10, 0, -1):\n        floors.append(stop_at_floor.submit(floor))\n    wait(floors)\n```\n\n### Handling futures\n\nWhen you submit a task, you'll receive a `PrefectFuture` object back which you can use to track the task's execution. Use the `.result()` method to get the result of the task.\n\n```python  theme={null}\nfrom prefect import task, flow\n\n@task\ndef cool_task():\n    return \"sup\"\n    \n@flow\ndef my_workflow():\n    future = cool_task.submit()\n    result = future.result()\n    print(result)\n```\n\nIf you don't need to the result of the task, you can use the `.wait()` method to wait for execution to complete.\n\n```python  theme={null}\nfrom prefect import task, flow\n\n@task\ndef cool_task():\n    return \"sup\"\n    \n@flow\ndef my_workflow():\n    future = cool_task.submit()\n    future.wait()\n```\n\nTo wait for multiple futures to complete, use the `wait()` utility.\n\n```python  theme={null}\nfrom prefect import task, flow\nfrom prefect.futures import wait\n\n\n@task\ndef cool_task():\n    return \"sup\"\n    \n    \n@flow\ndef my_workflow():\n    futures = [cool_task.submit() for _ in range(10)]\n    wait(futures)\n```\n\n<Tip>\n  **Passing futures between tasks**\n\n  If you pass `PrefectFuture` objects between tasks or flows, the task or flow receiving the future will wait for the future to complete before starting execution.\n\n  ```python  theme={null}\n  from prefect import task, flow\n\n  @task\n  def cool_task():\n      return \"sup\"\n\n\n  @task\n  def what_did_cool_task_say(what_it_said: str):\n      return f\"cool task said {what_it_said}\"\n\n  @flow\n  def my_workflow():\n      future = cool_task.submit()\n      print(what_did_cool_task_say(future))\n  ```\n</Tip>\n\n## Using `.map`\n\nFor a convenient way to iteratively submit tasks, use the `.map()` method.\n\n```python  theme={null}\nimport time\n\nfrom prefect import flow, task\nfrom prefect.futures import wait\n\n@task\ndef stop_at_floor(floor: int):\n    print(f\"elevator moving to floor {floor}\")\n    time.sleep(floor)\n    print(f\"elevator stops on floor {floor}\")\n\n@flow\ndef elevator():\n    floors = list(range(10, 0, -1))\n    floors = stop_at_floor.map(floors)\n    wait(floors)\n```\n\nLike `.submit`, `.map` uses the task runner configured on the parent flow. Changing the task runner will change where mapped tasks are executed.\n\n### Using the `unmapped` annotation\n\nSometimes you may not want to map a task over a certain input value.\n\nBy default, non-iterable values will not be mapped over (so `unmapped` is not required):\n\n```python  theme={null}\nfrom prefect import flow, task\n\n@task\ndef add_together(x, y):\n    return x + y\n\n@flow\ndef sum_it(numbers: list[int], static_value: int):\n    futures = add_together.map(numbers, static_value)\n    return futures.result()\n\nresulting_sum = sum_it([1, 2, 3], 5)\nassert resulting_sum == [6, 7, 8]\n```\n\n... but if your argument is an iterable type, wrap it with `unmapped` to tell `.map` to treat it\nas static:\n\n```python  theme={null}\nfrom prefect import flow, task, unmapped\n\n@task\ndef sum_plus(x, static_iterable):\n    return x + sum(static_iterable)\n\n@flow\ndef sum_it(numbers, static_iterable):\n    futures = sum_plus.map(numbers, unmapped(static_iterable))\n    return futures.result()\n\nresulting_sum = sum_it([4, 5, 6], [1, 2, 3])\nassert resulting_sum == [10, 11, 12]\n```\n\n### Bulk `PrefectFuture` operations\n\nWhen using `.map` as in the above example, the result of the task is a list of futures.\n\nYou can wait for or retrieve the results from these futures with `wait` or `result` methods:\n\n```python  theme={null}\nfutures = some_task.map(some_iterable)\nresults = futures.result()\n```\n\nwhich is syntactic sugar for the corresponding list comprehension:\n\n```python  theme={null}\nfutures = some_task.map(some_iterable)\nresults = [future.result() for future in futures]\n```\n\n### Nested mapped tasks\n\nTo model more complex concurrent workflows, you can map tasks within other tasks:\n\n```python {16} theme={null}\nimport re\n\nfrom prefect import flow, task\nfrom prefect.futures import wait\n\ndef count_words(text: str) -> int:\n    \"\"\"Count the number of words in a text.\"\"\"\n    return len(text.split())\n\ndef extract_emails(text: str) -> list[str]:\n    return re.findall(r\"[\\w.+-]+@[\\w-]+\\.[\\w.-]+\", text)\n\n@task\ndef analyze_texts(texts: list[str]) -> dict[str, list[int | list[str]]]:\n    futures = {\n        op.__name__: task(op).map(texts) for op in [count_words, extract_emails]\n    }\n    wait([f for futs in futures.values() for f in futs])\n    return {name: [f.result() for f in futs] for name, futs in futures.items()}\n\n@flow\ndef run_text_analysis():\n    \"\"\"Analyze a batch of social media posts with multiple operations.\"\"\"\n    results = analyze_texts(\n        texts=[\n            \"Just visited #Paris! Contact me at visitor@example.com #travel #vacation\",\n            \"Working on my new #project. Reach out at developer@example.com if interested!\",\n            \"Happy to announce our company event #celebration #milestone email: events@company.org\",\n        ]\n    )\n    print(\"\\nAnalysis Results:\")\n    print(f\"  Word counts: {results['count_words']}\")\n    print(f\"  Extracted emails: {results['extract_emails']}\\n\")\n    return results\n\nrun_text_analysis()\n```\n\n<Accordion title=\"Output\">\n  ```python  theme={null}\n  00:03:45.159 | INFO    | Flow run 'hilarious-collie' - Beginning flow run 'hilarious-collie' for flow 'run-text-analysis'\n  00:03:45.233 | INFO    | Task run 'count_words-01a' - Finished in state Completed()\n  00:03:45.236 | INFO    | Task run 'extract_emails-7a7' - Finished in state Completed()\n  00:03:45.237 | INFO    | Task run 'extract_emails-ca2' - Finished in state Completed()\n  00:03:45.239 | INFO    | Task run 'count_words-01d' - Finished in state Completed()\n  00:03:45.240 | INFO    | Task run 'count_words-f0a' - Finished in state Completed()\n  00:03:45.242 | INFO    | Task run 'extract_emails-0c6' - Finished in state Completed()\n  00:03:45.247 | INFO    | Task run 'analyze_texts-53b' - Finished in state Completed()\n\n  Analysis Results:\n    Word counts: [9, 11, 10]\n    Extracted emails: [['visitor@example.com'], ['developer@example.com'], ['events@company.org']]\n\n  00:03:45.491 | INFO    | Flow run 'hilarious-collie' - Finished in state Completed()\n  ```\n</Accordion>\n\nThis pattern is useful when you need to:\n\n1. Process combinations of parameters concurrently\n2. Apply multiple transformations to multiple datasets\n3. Create a grid of operations where each cell is an independent task\n\n## Creating state dependencies\n\nYou may also use the [`wait_for=[]`](https://reference.prefect.io/prefect/tasks/#prefect.tasks.Task.submit) parameter\nwhen calling a task by specifying upstream task dependencies. This enables you to control task execution\norder for tasks that do not share data dependencies.\n\n```python  theme={null}\nfrom prefect import flow, task\n@task\ndef task_a():\n    pass\n\n@task\ndef task_b():\n    pass\n\n@task\ndef task_c():\n    pass\n    \n@task\ndef task_d():\n    pass\n\n@flow\ndef my_flow():\n    a = task_a.submit()\n    b = task_b.submit()\n    # Wait for task_a and task_b to complete\n    c = task_c.submit(wait_for=[a, b])\n    # task_d will wait for task_c to complete\n    # Note: If waiting for one task it must still be in a list.\n    d = task_d(wait_for=[c])\n```\n\n## Handling failures in concurrent work\n\nInstead of failing your entire workflow when a single concurrent task fails, you may want to run concurrent work to completion, even if some tasks fail. To run tasks concurrently and handle failures afterwards, use the `wait()` utility along with the `.state` attribute on futures:\n\n```python  theme={null}\nfrom typing import Any\n\nfrom prefect import flow, task\nfrom prefect.futures import wait\nfrom prefect.states import State\n\n@task\ndef process_data(item: int) -> str:\n    if item < 0:\n        raise ValueError(f\"Cannot process negative value: {item}\")\n    return f\"Processed {item}\"\n\n@flow\ndef batch_processing():\n    items = [1, -2, 3, -4, 5]\n    \n    # Submit all tasks and return the futures\n    futures = process_data.map(items)\n    \n    # Wait for all futures to complete concurrently\n    done, not_done = wait(futures)\n    \n    # Check each future's state\n    successful: list[Any] = []\n    failed: list[State] = []\n    \n    for future in done:\n        if future.state.is_completed():\n            successful.append(future.result())\n        else:\n            failed.append(future.state)\n    \n    print(f\"Processed {len(successful)} items successfully\")\n    print(f\"Failed to process {len(failed)} items\")\n    \n    return successful\n```\n\nThe `wait()` function returns two sets of futures: `done` and `not_done`. Each future has a `.state` attribute you can inspect to determine how the associated task run's result (or exception) should be treated downstream.\n\n<Note>\n  The \"right way\" to handle failures will depend on your use case. Review the [final state determination](/v3/concepts/states#final-state-determination) documentation for more information.\n</Note>\n\n## Using `asyncio`\n\nIf you have tasks are defined as async functions, you can use `asyncio` from the Python standard library to run them concurrently.\n\n```python  theme={null}\nimport asyncio\n\nfrom prefect import flow, task\n\n@task\nasync def stop_at_floor(floor: int):\n    print(f\"elevator moving to floor {floor}\")\n    await asyncio.sleep(floor)\n    print(f\"elevator stops on floor {floor}\")\n\n@flow\nasync def elevator():\n    floors = list(range(10, 0, -1))\n    await asyncio.gather(*[stop_at_floor(floor) for floor in floors])\n\n\nif __name__ == \"__main__\":\n    asyncio.run(elevator())\n```\n\n## Real-world applications\n\nMapped tasks are particularly valuable in common data science and ETL workflows such as:\n\n1. **Machine learning model evaluation**: Train multiple models on multiple datasets concurrently\n2. **ETL pipelines**: Process multiple data sources with multiple transformations\n3. **API data enrichment**: Enrich multiple records with data from multiple external services\n\nFor example, imagine you want to find the best training configuration for a series of datasets, and you want to process all datasets concurrently:\n\n```python  theme={null}\nimport random\nfrom dataclasses import dataclass\n\nfrom prefect import flow, task\nfrom prefect.futures import PrefectFuture, wait\n\n@dataclass\nclass Dataset:\n    name: str\n\n@dataclass\nclass ModelConfig:\n    name: str\n\n@task(task_run_name=\"train on {dataset.name} with {model_config.name}\")\ndef train_model(dataset: Dataset, model_config: ModelConfig) -> dict:\n    return {\n        \"dataset\": dataset.name,\n        \"model\": model_config.name,\n        \"score\": random.random(),\n    }\n\n@flow\ndef evaluate_models(datasets: list[Dataset], model_configs: list[ModelConfig]):\n    all_futures: list[PrefectFuture[dict[str, object]]] = []\n    for dataset in datasets:\n        futures = train_model.map(\n            dataset=dataset,\n            model_config=model_configs,\n        )\n        all_futures.extend(futures)\n\n    results = [future.result() for future in wait(all_futures).done]\n\n    print(f\"\\nBest model: {max(results, key=lambda r: r['score'])}\")\n\nevaluate_models(\n    datasets=[\n        Dataset(\"customers\"), Dataset(\"products\"), Dataset(\"orders\")\n    ],\n    model_configs=[\n        ModelConfig(\"random_forest\"), ModelConfig(\"gradient_boosting\")\n    ],\n)\n```\n\n<Accordion title=\"Output\">\n  ```python  theme={null}\n  00:56:47.873 | INFO    | Flow run 'precious-walrus' - Beginning flow run 'precious-walrus' for flow 'evaluate-models'\n  00:56:47.981 | INFO    | Task run 'train on customers with random_forest' - Finished in state Completed()\n  00:56:47.984 | INFO    | Task run 'train on orders with gradient_boosting' - Finished in state Completed()\n  00:56:47.984 | INFO    | Task run 'train on customers with gradient_boosting' - Finished in state Completed()\n  00:56:47.985 | INFO    | Task run 'train on products with random_forest' - Finished in state Completed()\n  00:56:47.988 | INFO    | Task run 'train on orders with random_forest' - Finished in state Completed()\n  00:56:47.990 | INFO    | Task run 'train on products with gradient_boosting' - Finished in state Completed()\n\n  Best model: {'dataset': 'products', 'model': 'random_forest', 'score': 0.5603239415052655}\n\n  00:56:48.121 | INFO    | Flow run 'precious-walrus' - Finished in state Completed()\n  ```\n</Accordion>",
  "content_length": 14529
}