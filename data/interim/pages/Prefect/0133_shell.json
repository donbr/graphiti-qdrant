{
  "title": "shell",
  "source_url": "https://docs-3.prefect.io/v3/api-ref/python/prefect-cli-shell",
  "content": "# `prefect.cli.shell`\n\nProvides a set of tools for executing shell commands as Prefect flows.\nIncludes functionalities for running shell commands ad-hoc or serving them as Prefect flows,\nwith options for logging output, scheduling, and deployment customization.\n\n## Functions\n\n### `output_stream` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/cli/shell.py#L34\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\noutput_stream(pipe: IO[str], logger_function: Callable[[str], None]) -> None\n```\n\nRead from a pipe line by line and log using the provided logging function.\n\n**Args:**\n\n* `pipe`: A file-like object for reading process output.\n* `logger_function`: A logging function from the logger.\n\n### `output_collect` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/cli/shell.py#L47\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\noutput_collect(pipe: IO[str], container: list[str]) -> None\n```\n\nCollects output from a subprocess pipe and stores it in a container list.\n\n**Args:**\n\n* `pipe`: The output pipe of the subprocess, either stdout or stderr.\n* `container`: A list to store the collected output lines.\n\n### `run_shell_process` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/cli/shell.py#L60\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\nrun_shell_process(command: str, log_output: bool = True, stream_stdout: bool = False, log_stderr: bool = False, popen_kwargs: Optional[Dict[str, Any]] = None)\n```\n\nAsynchronously executes the specified shell command and logs its output.\n\nThis function is designed to be used within Prefect flows to run shell commands as part of task execution.\nIt handles both the execution of the command and the collection of its output for logging purposes.\n\n**Args:**\n\n* `command`: The shell command to execute.\n* `log_output`: If True, the output of the command (both stdout and stderr) is logged to Prefect.\n* `stream_stdout`: If True, the stdout of the command is streamed to Prefect logs.\n* `log_stderr`: If True, the stderr of the command is logged to Prefect logs.\n* `popen_kwargs`: Additional keyword arguments to pass to the `subprocess.Popen` call.\n\n### `watch` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/cli/shell.py#L136\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\nwatch(command: str, log_output: bool = typer.Option(True, help='Log the output of the command to Prefect logs.'), flow_run_name: str = typer.Option(None, help='Name of the flow run.'), flow_name: str = typer.Option('Shell Command', help='Name of the flow.'), stream_stdout: bool = typer.Option(True, help='Stream the output of the command.'), tag: Annotated[Optional[List[str]], typer.Option(help='Optional tags for the flow run.')] = None)\n```\n\nExecutes a shell command and observes it as Prefect flow.\n\n**Args:**\n\n* `command`: The shell command to be executed.\n* `log_output`: If True, logs the command's output. Defaults to True.\n* `flow_run_name`: An optional name for the flow run.\n* `flow_name`: An optional name for the flow. Useful for identification in the Prefect UI.\n* `tag`: An optional list of tags for categorizing and filtering flows in the Prefect UI.\n\n### `serve` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/cli/shell.py#L171\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\nserve(command: str, flow_name: str = typer.Option(..., help='Name of the flow'), deployment_name: str = typer.Option('CLI Runner Deployment', help='Name of the deployment'), deployment_tags: List[str] = typer.Option(None, '--tag', help='Tag for the deployment (can be provided multiple times)'), log_output: bool = typer.Option(True, help='Stream the output of the command', hidden=True), stream_stdout: bool = typer.Option(True, help='Stream the output of the command'), cron_schedule: str = typer.Option(None, help='Cron schedule for the flow'), timezone: str = typer.Option(None, help='Timezone for the schedule'), concurrency_limit: int = typer.Option(None, min=1, help='The maximum number of flow runs that can execute at the same time'), run_once: bool = typer.Option(False, help='Run the agent loop once, instead of forever.'))\n```\n\nCreates and serves a Prefect deployment that runs a specified shell command according to a cron schedule or ad hoc.\n\nThis function allows users to integrate shell command execution into Prefect workflows seamlessly. It provides options for\nscheduled execution via cron expressions, flow and deployment naming for better management, and the application of tags for\neasier categorization and filtering within the Prefect UI. Additionally, it supports streaming command output to Prefect logs,\nsetting concurrency limits to control flow execution, and optionally running the deployment once for ad-hoc tasks.\n\n**Args:**\n\n* `command`: The shell command the flow will execute.\n* `name`: The name assigned to the flow. This is required..\n* `deployment_tags`: Optional tags for the deployment to facilitate filtering and organization.\n* `log_output`: If True, streams the output of the shell command to the Prefect logs. Defaults to True.\n* `cron_schedule`: A cron expression that defines when the flow will run. If not provided, the flow can be triggered manually.\n* `timezone`: The timezone for the cron schedule. This is important if the schedule should align with local time.\n* `concurrency_limit`: The maximum number of instances of the flow that can run simultaneously.\n* `deployment_name`: The name of the deployment. This helps distinguish deployments within the Prefect platform.\n* `run_once`: When True, the flow will only run once upon deployment initiation, rather than continuously.",
  "content_length": 5977
}