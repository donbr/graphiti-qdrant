{
  "title": "Caching",
  "source_url": "https://docs-3.prefect.io/v3/concepts/caching",
  "content": "Caching refers to the ability of a task run to enter a `Completed` state and return a predetermined\nvalue without actually running the code that defines the task.\nCaching allows you to efficiently reuse [results of tasks](/v3/develop/results/) that may be expensive to compute\nand ensure that your pipelines are idempotent when retrying them due to unexpected failure.\n\nBy default Prefect's caching logic is based on the following attributes of a task invocation:\n\n* the inputs provided to the task\n* the code definition of the task\n* the prevailing flow run ID, or if executed autonomously, the prevailing task run ID\n\nThese values are hashed to compute the task's *cache key*.\nThis implies that, by default, calling the same task with the same inputs more than once within a flow\nwill result in cached behavior for all calls after the first.\nThis behavior can be configured - see [customizing the cache](/v3/develop/write-tasks#customizing-the-cache) below.\n\n<Warning>\n  **Caching requires result persistence**\n\n  Caching requires result persistence, which is off by default.\n  To turn on result persistence for all of your tasks use the `PREFECT_RESULTS_PERSIST_BY_DEFAULT` setting:\n\n  ```\n  prefect config set PREFECT_RESULTS_PERSIST_BY_DEFAULT=true\n  ```\n\n  See [managing results](/v3/develop/results/) for more details on managing your result configuration, and\n  [settings](/v3/develop/settings-and-profiles) for more details on managing Prefect settings.\n</Warning>\n\n## Cache keys\n\nTo determine whether a task run should retrieve a cached state, Prefect uses the concept of a \"cache key\".\nA cache key is a computed string value that determines where the task's return value will be persisted within\nits configured result storage.\nWhen a task run begins, Prefect first computes its cache key and uses this key to lookup a record in the task's result\nstorage.\nIf an unexpired record is found, this result is returned and the task does not run, but instead, enters a\n`Cached` state with the corresponding result value.\n\nCache keys can be shared by the same task across different flows, and even among different tasks,\nso long as they all share a common result storage location.\n\nBy default Prefect stores results locally in `~/.prefect/storage/`.\nThe filenames in this directory will correspond exactly to computed cache keys from your task runs.\n\n<Warning>\n  **Relationship with result persistence**\n\n  Task caching and result persistence are intimately related. Because task caching relies on loading a\n  known result, task caching will only work when your task can persist its output\n  to a fixed and known location.\n\n  Therefore any configuration which explicitly avoids result persistence will result in your task never\n  using a cache, for example setting `persist_result=False`.\n</Warning>\n\n## Cache policies\n\nCache key computation can be configured through the use of *cache policies*.\nA cache policy is a recipe for computing cache keys for a given task.\n\nPrefect comes prepackaged with a few common cache policies:\n\n* `DEFAULT`: this cache policy uses the task's inputs, its code definition, as well as the prevailing flow run ID\n  to compute the task's cache key.\n* `INPUTS`: this cache policy uses *only* the task's inputs to compute the cache key.\n* `TASK_SOURCE`: this cache policy only considers raw lines of code in the task (and not the source code of nested tasks) to compute the cache key.\n* `FLOW_PARAMETERS`: this cache policy uses *only* the parameter values provided to the parent flow run\n  to compute the cache key.\n* `NO_CACHE`: this cache policy always returns `None` and therefore avoids caching and result persistence altogether.\n\nThese policies can be set using the `cache_policy` keyword on the [task decorator](https://reference.prefect.io/prefect/tasks/#prefect.tasks.task).\n\n## Customizing the cache\n\nPrefect allows you to configure task caching behavior in numerous ways.\n\n### Cache expiration\n\nAll cache keys can optionally be given an *expiration* through the `cache_expiration` keyword on\nthe [task decorator](https://reference.prefect.io/prefect/tasks/#prefect.tasks.task).\nThis keyword accepts a `datetime.timedelta` specifying a duration for which the cached value should be\nconsidered valid.\n\nProviding an expiration value results in Prefect persisting an expiration timestamp alongside the result\nrecord for the task.\nThis expiration is then applied to *all* other tasks that may share this cache key.\n\n### Cache policies\n\nCache policies can be composed and altered using basic Python syntax to form more complex policies.\nFor example, all task policies except for `NO_CACHE` can be *added* together to form new policies that combine\nthe individual policies' logic into a larger cache key computation.\nCombining policies in this way results in caches that are *easier* to invalidate.\n\nFor example:\n\n```python  theme={null}\nfrom prefect import task\nfrom prefect.cache_policies import TASK_SOURCE, INPUTS\n@task(cache_policy=TASK_SOURCE + INPUTS)\ndef my_cached_task(x: int):\n    return x + 42\n```\n\nThis task will rerun anytime you provide new values for `x`, *or* anytime you change the underlying code.\n\nThe `INPUTS` policy is a special policy that allows you to *subtract* string values to ignore\ncertain task inputs:\n\n```python  theme={null}\nfrom prefect import task\nfrom prefect.cache_policies import INPUTS\n\n\nmy_custom_policy = INPUTS - 'debug'\n\n@task(cache_policy=my_custom_policy)\ndef my_cached_task(x: int, debug: bool = False):\n    print('running...')\n    return x + 42\n\n\nmy_cached_task(1)\nmy_cached_task(1, debug=True) # still uses the cache\n```\n\n### Cache key functions\n\nYou can configure custom cache policy logic through the use of cache key functions.\nA cache key function is a function that accepts two positional arguments:\n\n* The first argument corresponds to the `TaskRunContext`, which stores task run metadata. For example,\n  this object has attributes `task_run_id`, `flow_run_id`, and `task`, all of which can be used in your\n  custom logic.\n* The second argument corresponds to a dictionary of input values to the task. For example,\n  if your task has the signature `fn(x, y, z)` then the dictionary will have keys \"x\", \"y\", and \"z\" with corresponding values that can be used to compute your cache key.\n\nThis function can then be specified using the `cache_key_fn` argument on\nthe [task decorator](https://reference.prefect.io/prefect/tasks/#prefect.tasks.task).\n\nFor example:\n\n```python  theme={null}\nfrom prefect import task\n\n\ndef static_cache_key(context, parameters):\n    # return a constant\n    return \"static cache key\"\n\n\n@task(cache_key_fn=static_cache_key)\ndef my_cached_task(x: int):\n    return x + 1\n```\n\n### Cache storage\n\nBy default, cache records are collocated with task results and files containing task results will include metadata used for caching.\nConfiguring a cache policy with a `key_storage` argument allows cache records to be stored separately from task results.\n\nWhen cache key storage is configured, persisted task results will only include the return value of your task and cache records can be deleted or modified\nwithout effecting your task results.\n\nYou can configure where cache records are stored by using the `.configure` method with a `key_storage` argument on a cache policy.\nThe `key_storage` argument accepts either a path to a local directory or a storage block.\n\n### Cache isolation\n\nCache isolation controls how concurrent task runs interact with cache records. Prefect supports two isolation levels: `READ_COMMITTED` and `SERIALIZABLE`.\n\nBy default, cache records operate with a `READ_COMMITTED` isolation level. This guarantees that reading a cache record will see the latest committed cache value,\nbut allows multiple executions of the same task to occur simultaneously.\n\nFor stricter isolation, you can use the `SERIALIZABLE` isolation level. This ensures that only one execution of a task occurs at a time for a given cache\nrecord via a locking mechanism.\n\nTo configure the isolation level, use the `.configure` method with an `isolation_level` argument on a cache policy. When using `SERIALIZABLE`, you must\nalso provide a `lock_manager` that implements locking logic for your system.\n\n#### Recommended Lock Managers by Execution Context\n\nWe recommend using a locking implementation that matches how you are running your work concurrently.\n\n| Execution Context  | Recommended Lock Manager | Notes                                                        |\n| ------------------ | ------------------------ | ------------------------------------------------------------ |\n| Threads/Coroutines | `MemoryLockManager`      | In-memory locking suitable for single-process execution      |\n| Processes          | `FileSystemLockManager`  | File-based locking for multiple processes on same machine    |\n| Multiple Machines  | `RedisLockManager`       | Distributed locking via Redis for cross-machine coordination |\n\n## Multi-task caching\n\nThere are some situations in which multiple tasks need to always run together or not at all.\nThis can be achieved in Prefect by configuring these tasks to always write to their caches within\na single [*transaction*](/v3/develop/transactions).",
  "content_length": 9187
}