{
  "title": "How to customize asset metadata",
  "source_url": "https://docs-3.prefect.io/v3/advanced/assets",
  "content": "This guide covers how to enhance your assets with rich metadata, custom properties, and explicit dependency management beyond what's automatically inferred from your task graph.\n\n<span class=\"badge cloud\" />\n\nBoth `@materialize` and `asset_deps` accept either a string referencing an asset key or a full `Asset` class instance. Using the `Asset` class is the way to provide additional metadata like names, descriptions, and ownership information beyond just the key.\n\n## The Asset class\n\nWhile you can use simple string keys with the `@materialize` decorator, the `Asset` class provides more control over asset properties and metadata. Create `Asset` instances to add organizational context and improve discoverability.\n\n### Asset initialization fields\n\nThe `Asset` class accepts the following parameters:\n\n* **`key`** (required): A valid URI that uniquely identifies your asset. This is the only required field.\n\n* **`properties`** (optional): An `AssetProperties` instance containing metadata about the asset.\n\n```python  theme={null}\nfrom prefect.assets import Asset, AssetProperties\n\n# Simple asset with just a key\nbasic_asset = Asset(key=\"s3://my-bucket/data.csv\")\n\n# Asset with full properties\ndetailed_asset = Asset(\n    key=\"s3://my-bucket/processed-data.csv\",\n    properties=AssetProperties(\n        name=\"Processed Customer Data\",\n        description=\"Clean customer data with PII removed\",\n        owners=[\"data-team@company.com\", \"alice@company.com\"],\n        url=\"https://dashboard.company.com/datasets/customer-data\"\n    )\n)\n```\n\nEach of these fields will be displayed alongside the asset in the UI.\n\n<Note>\n  **Interactive fields**\n\n  The owners field can optionally reference user emails, as well as user and team handles within your Prefect Cloud workspace.\n  The URL field becomes a clickable link when this asset is displayed.\n</Note>\n\n<Warning>\n  **Updates occur at runtime**\n\n  Updates to asset metadata are always performed at workflow runtime whenever a materializing task is executed that references the asset.\n</Warning>\n\n## Using assets in materializations\n\nOnce you've defined your `Asset` instances, use them directly with the `@materialize` decorator:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect.assets import Asset, AssetProperties, materialize\n\n\ndetailed_asset = Asset(\n    key=\"s3://my-bucket/processed-data.csv\",\n    properties=AssetProperties(\n        name=\"Processed Customer Data\",\n        description=\"Clean customer data with PII removed\",\n        owners=[\"data-team@company.com\", \"alice@company.com\"],\n        url=\"https://dashboard.company.com/datasets/customer-data\"\n    )\n)\n\nproperties = AssetProperties(\n    name=\"Sales Analytics Dataset\",\n    description=\"This dataset contains daily sales figures by region along with customer segmentation data\",\n    owners=[\"analytics-team\", \"john.doe@company.com\"],\n    url=\"https://analytics.company.com/sales-dashboard\"\n)\n\nsales_asset = Asset(\n    key=\"snowflake://warehouse/analytics/sales_summary\",\n    properties=properties\n)\n\n\n@materialize(detailed_asset)\ndef process_customer_data():\n    # Your processing logic here\n    pass\n\n\n@materialize(sales_asset)\ndef generate_sales_report():\n    # Your reporting logic here\n    pass\n\n\n@flow\ndef analytics_pipeline():\n    process_customer_data()\n    generate_sales_report()\n```\n\n## Adding runtime metadata\n\nBeyond static properties, you can add dynamic metadata during task execution. This is useful for tracking runtime information like row counts, processing times, or data quality metrics.\n\n### Using `Asset.add_metadata()`\n\nThe preferred approach is to use the `add_metadata()` method on your `Asset` instances. This prevents typos in asset keys and provides better IDE support:\n\n```python  theme={null}\nfrom prefect.assets import Asset, AssetProperties, materialize\n\ncustomer_data = Asset(\n    key=\"s3://my-bucket/customer-data.csv\",\n    properties=AssetProperties(\n        name=\"Customer Data\",\n        owners=[\"data-team@company.com\"]\n    )\n)\n\n@materialize(customer_data)\ndef process_customers():\n    # Your processing logic\n    result = perform_customer_processing()\n    \n    # Add runtime metadata\n    customer_data.add_metadata({\n        \"record_count\": len(result),\n        \"processing_duration_seconds\": 45.2,\n        \"data_quality_score\": 0.95,\n        \"last_updated\": \"2024-01-15T10:30:00Z\"\n    })\n    \n    return result\n```\n\n### Using `add_asset_metadata()` utility\n\nAlternatively, you can use the `add_asset_metadata()` function, which requires specifying the asset key:\n\n```python  theme={null}\nfrom prefect.assets import materialize, add_asset_metadata\n\n@materialize(\"s3://my-bucket/processed-data.csv\")\ndef process_data():\n    result = perform_processing()\n    \n    add_asset_metadata(\n        \"s3://my-bucket/processed-data.csv\",\n        {\"rows_processed\": len(result), \"processing_time\": \"2.5s\"}\n    )\n    \n    return result\n```\n\n### Accumulating metadata\n\nYou can call metadata methods multiple times to accumulate information:\n\n```python  theme={null}\n@materialize(customer_data)\ndef comprehensive_processing():\n    # First processing step\n    raw_data = extract_data()\n    customer_data.add_metadata({\"raw_records\": len(raw_data)})\n    \n    # Second processing step\n    cleaned_data = clean_data(raw_data)\n    customer_data.add_metadata({\n        \"cleaned_records\": len(cleaned_data),\n        \"records_removed\": len(raw_data) - len(cleaned_data)\n    })\n    \n    # Final step\n    final_data = enrich_data(cleaned_data)\n    customer_data.add_metadata({\n        \"final_records\": len(final_data),\n        \"enrichment_success_rate\": 0.92\n    })\n    \n    return final_data\n```\n\n## Explicit asset dependencies\n\nWhile Prefect automatically infers dependencies from your task graph, you can explicitly declare asset relationships using the `asset_deps` parameter. This is useful when:\n\n* The task graph doesn't fully capture your data dependencies due to dynamic execution rules\n* You need to reference assets that aren't directly passed between tasks\n* You want to be explicit about critical dependencies for documentation purposes\n\n### Hard-coding dependencies\n\nUse `asset_deps` to explicitly declare which assets your materialization depends on. You can reference assets by key string or by full `Asset` instance:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect.assets import Asset, AssetProperties, materialize\n\n\n# Define your assets\nraw_data_asset = Asset(key=\"s3://my-bucket/raw-data.csv\")\nconfig_asset = Asset(key=\"s3://my-bucket/processing-config.json\")\nprocessed_asset = Asset(key=\"s3://my-bucket/processed-data.csv\")\n\n@materialize(raw_data_asset)\ndef extract_raw_data():\n    pass\n\n@materialize(\n    processed_asset,\n    asset_deps=[raw_data_asset, config_asset]  # Explicit dependencies\n)\ndef process_data():\n    # This function depends on both raw data and config\n    # even if they're not directly passed as parameters\n    pass\n\n@flow\ndef explicit_dependencies_flow():\n    extract_raw_data()\n    process_data()  # Explicitly depends on raw_data_asset and config_asset\n```\n\n### Mixing inferred and explicit dependencies\n\nYou can combine task graph inference with explicit dependencies:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect.assets import Asset, materialize\n\n\nupstream_asset = Asset(key=\"s3://my-bucket/upstream.csv\")\nconfig_asset = Asset(key=\"s3://my-bucket/config.json\")\ndownstream_asset = Asset(key=\"s3://my-bucket/downstream.csv\")\n\n@materialize(upstream_asset)\ndef create_upstream():\n    return \"upstream_data\"\n\n@materialize(\n    downstream_asset,\n    asset_deps=[config_asset]  # Explicit dependency on config\n)\ndef create_downstream(upstream_data):  # Inferred dependency on upstream_asset\n    # This asset depends on:\n    # 1. upstream_asset (inferred from task graph)\n    # 2. config_asset (explicit via asset_deps)\n    pass\n\n@flow\ndef mixed_dependencies():\n    data = create_upstream()\n    create_downstream(data)\n```\n\n### Best practices for `asset_deps` references\n\nUse *string keys* when referencing assets that are materialized by other Prefect workflows. This avoids duplicate metadata definitions and lets the materializing workflow be the source of truth:\n\n```python  theme={null}\nfrom prefect.assets import materialize\n\n# Good: Reference by key when another workflow materializes the asset\n@materialize(\n    \"s3://my-bucket/final-report.csv\",\n    asset_deps=[\"s3://my-bucket/data-from-other-workflow.csv\"]  # String key\n)\ndef create_report():\n    pass\n```\n\nUse *full `Asset` instances* when referencing assets that are completely external to Prefect. This provides metadata about external systems that Prefect wouldn't otherwise know about:\n\n```python  theme={null}\nfrom prefect.assets import Asset, AssetProperties, materialize\n\n\n# Good: Full Asset for external systems\nexternal_database = Asset(\n    key=\"postgres://prod-db/public/users\",\n    properties=AssetProperties(\n        name=\"Production Users Table\",\n        description=\"Main user database maintained by the platform team\",\n        owners=[\"platform-team@company.com\"],\n        url=\"https://internal-db-dashboard.com/users\"\n    )\n)\n\n@materialize(\n    \"s3://my-bucket/user-analytics.csv\",\n    asset_deps=[external_database]  # Full Asset for external system\n)\ndef analyze_users():\n    pass\n```\n\n## Updating asset properties\n\nAsset properties should have one source of truth to avoid conflicts. When you materialize an asset with properties, those properties perform a complete overwrite of all metadata fields for that asset.\n\n<Warning>\n  **Important**\n\n  Any `Asset` instance with properties will completely replace all existing metadata. Partial updates are not supported - you must provide all the metadata you want to preserve.\n</Warning>\n\n```python  theme={null}\nfrom prefect.assets import Asset, AssetProperties, materialize\n\n\n# Initial materialization with full properties\ninitial_asset = Asset(\n    key=\"s3://my-bucket/evolving-data.csv\",\n    properties=AssetProperties(\n        name=\"Evolving Dataset\",\n        description=\"Initial description\",\n        owners=[\"team-a@company.com\"],\n        url=\"https://dashboard.company.com/evolving-data\"\n    )\n)\n\n@materialize(initial_asset)\ndef initial_creation():\n    pass\n\n# Later materialization - OVERWRITES all properties\nupdated_asset = Asset(\n    key=\"s3://my-bucket/evolving-data.csv\",\n    properties=AssetProperties(\n        name=\"Evolving Dataset\",  # Must include to preserve\n        description=\"Updated description with new insights\",  # Updated\n        owners=[\"team-a@company.com\"],  # Must include to preserve\n        # url is now None because it wasn't included\n    )\n)\n\n@materialize(updated_asset)\ndef update_dataset():\n    pass\n\n# The final asset will have:\n# - name: \"Evolving Dataset\" (preserved)\n# - description: \"Updated description with new insights\" (updated)\n# - owners: [\"team-a@company.com\"] (preserved)\n# - url: None (lost because not included in update)\n```\n\n<Tip>\n  **Best practice**\n\n  Designate one workflow as the authoritative source for each asset's metadata. Other workflows that reference the asset should use string keys only to avoid conflicting metadata definitions.\n</Tip>\n\n## Further Reading\n\n* [Learn about asset health and asset events](/v3/concepts/assets)",
  "content_length": 11239
}