{
  "title": "services",
  "source_url": "https://docs-3.prefect.io/v3/api-ref/python/prefect-utilities-services",
  "content": "# `prefect.utilities.services`\n\n## Functions\n\n### `critical_service_loop` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/utilities/services.py#L21\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\ncritical_service_loop(workload: Callable[..., Coroutine[Any, Any, Any]], interval: float, memory: int = 10, consecutive: int = 3, backoff: int = 1, printer: Callable[..., None] = print, run_once: bool = False, jitter_range: Optional[float] = None) -> None\n```\n\nRuns the given `workload` function on the specified `interval`, while being\nforgiving of intermittent issues like temporary HTTP errors.  If more than a certain\nnumber of `consecutive` errors occur, print a summary of up to `memory` recent\nexceptions to `printer`, then begin backoff.\n\nThe loop will exit after reaching the consecutive error limit `backoff` times.\nOn each backoff, the interval will be doubled. On a successful loop, the backoff\nwill be reset.\n\n**Args:**\n\n* `workload`: the function to call\n* `interval`: how frequently to call it\n* `memory`: how many recent errors to remember\n* `consecutive`: how many consecutive errors must we see before we begin backoff\n* `backoff`: how many times we should allow consecutive errors before exiting\n* `printer`: a `print`-like function where errors will be reported\n* `run_once`: if set, the loop will only run once then return\n* `jitter_range`: if set, the interval will be a random variable (rv) drawn from\n  a clamped Poisson distribution where lambda = interval and the rv is bound\n  between `interval * (1 - range) < rv < interval * (1 + range)`\n\n### `start_client_metrics_server` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/utilities/services.py#L162\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\nstart_client_metrics_server() -> None\n```\n\nStart the process-wide Prometheus metrics server for client metrics (if enabled\nwith `PREFECT_CLIENT_METRICS_ENABLED`) on the port `PREFECT_CLIENT_METRICS_PORT`.\n\n### `stop_client_metrics_server` <sup><a href=\"https://github.com/PrefectHQ/prefect/blob/main/src/prefect/utilities/services.py#L177\" target=\"_blank\"><Icon icon=\"github\" style=\"width: 14px; height: 14px;\" /></a></sup>\n\n```python  theme={null}\nstop_client_metrics_server() -> None\n```\n\nStop the process-wide Prometheus metrics server for client metrics, if it has\npreviously been started",
  "content_length": 2487
}