{
  "title": "How to deploy a web application powered by background tasks",
  "source_url": "https://docs-3.prefect.io/v3/advanced/background-tasks",
  "content": "Learn how to background heavy tasks from a web application to dedicated infrastructure.\n\nThis example demonstrates how to use [background tasks](/v3/concepts/tasks#background-tasks) in the context of a web application using Prefect for task submission, execution, monitoring, and result storage. We'll build out an application using FastAPI to offer API endpoints to our clients, and task workers to execute the background tasks these endpoints defer.\n\n<Tip>\n  Refer to the [examples repository](https://github.com/PrefectHQ/examples/tree/main/apps/background-tasks) for the complete example's source code.\n</Tip>\n\nThis pattern is useful when you need to perform operations that are too long for a standard web request-response cycle, such as data processing, sending emails, or interacting with external APIs that might be slow.\n\n## Overview\n\nThis example will build out:\n\n* `@prefect.task` definitions representing the work you want to run in the background\n* A `fastapi` application providing API endpoints to:\n  * Receive task parameters via `POST` request and submit the task to Prefect with `.delay()`\n  * Allow polling for the task's status via a `GET` request using its `task_run_id`\n* A `Dockerfile` to build a multi-stage image for the web app, Prefect server and task worker(s)\n* A `compose.yaml` to manage lifecycles of the web app, Prefect server and task worker(s)\n\n```bash  theme={null}\n├── Dockerfile\n├── README.md\n├── compose.yaml\n├── pyproject.toml\n├── src\n│   └── foo\n│       ├── __init__.py\n│       ├── _internal/*.py\n│       ├── api.py\n│       └── task.py\n```\n\nYou can follow along by cloning the [examples repository](https://github.com/PrefectHQ/examples) or instead use [`uv`](https://docs.astral.sh/uv/getting-started/installation/) to bootstrap a your own new project:\n\n```bash  theme={null}\nuv init --lib foo\nuv add prefect marvin\n```\n\nThis example application is structured as a library with a `src/foo` directory for portability and organization.\n\n<Note>\n  This example does ***not*** require:\n\n  * Prefect Cloud\n  * creating a Prefect Deployment\n  * creating a work pool\n</Note>\n\n## Useful things to remember\n\n* You can call any Python code from your task definitions (including other flows and tasks!)\n* Prefect [Results](/v3/concepts/caching) allow you to save/serialize the `return` value of your task definitions to your result storage (e.g. a local directory, S3, GCS, etc), enabling [caching](/v3/concepts/caching) and [idempotency](/v3/advanced/transactions).\n\n## Defining the background task\n\nThe core of the background processing is a Python function decorated with `@prefect.task`. This marks the function as a unit of work that Prefect can manage (e.g. observe, cache, retry, etc.)\n\n```python src/foo/task.py theme={null}\nfrom typing import Any, TypeVar\n\nimport marvin\n\nfrom prefect import task, Task\nfrom prefect.cache_policies import INPUTS, TASK_SOURCE\nfrom prefect.states import State\nfrom prefect.task_worker import serve\nfrom prefect.client.schemas.objects import TaskRun\n\nT = TypeVar(\"T\")\n\n\ndef _print_output(task: Task, task_run: TaskRun, state: State[T]):\n    result = state.result()\n    print(f\"result type: {type(result)}\")\n    print(f\"result: {result!r}\")\n\n\n@task(cache_policy=INPUTS + TASK_SOURCE, on_completion=[_print_output])\nasync def create_structured_output(data: Any, target: type[T], instructions: str) -> T:\n    return await marvin.cast_async(\n        data,\n        target=target,\n        instructions=instructions,\n    )\n\n\ndef main():\n    serve(create_structured_output)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nKey details:\n\n* `@task`: Decorator to define our task we want to run in the background.\n* `cache_policy`: Caching based on `INPUTS` and `TASK_SOURCE`.\n* `serve(create_structured_output)`: This function starts a task worker subscribed to newly `delay()`ed task runs.\n\n## Building the FastAPI application\n\nThe FastAPI application provides API endpoints to trigger the background task and check its status.\n\n```python src/foo/api.py theme={null}\nimport logging\nfrom uuid import UUID\n\nfrom fastapi import Depends, FastAPI, Response\nfrom fastapi.responses import JSONResponse\n\nfrom foo._internal import get_form_data, get_task_result, StructuredOutputRequest\nfrom foo.task import create_structured_output\n\nlogger = logging.getLogger(__name__)\n\napp = FastAPI()\n\n\n@app.post(\"/tasks\", status_code=202)\nasync def submit_task(\n    form_data: StructuredOutputRequest = Depends(get_form_data),\n) -> JSONResponse:\n    \"\"\"Submit a task to Prefect for background execution.\"\"\"\n    future = create_structured_output.delay(\n        form_data.payload,\n        target=form_data.target_type,\n        instructions=form_data.instructions,\n    )\n    logger.info(f\"Submitted task run: {future.task_run_id}\")\n    return {\"task_run_id\": str(future.task_run_id)}\n\n\n@app.get(\"/tasks/{task_run_id}/status\")\nasync def get_task_status_api(task_run_id: UUID) -> Response:\n    \"\"\"Checks the status of a submitted task run.\"\"\"\n    status, data = await get_task_result(task_run_id)\n\n    response_data = {\"task_run_id\": str(task_run_id), \"status\": status}\n    http_status_code = 200\n\n    if status == \"completed\":\n        response_data[\"result\"] = data\n    elif status == \"error\":\n        response_data[\"message\"] = data\n        # Optionally set a different HTTP status for errors\n    return JSONResponse(response_data, status_code=http_status_code)\n```\n\n<Accordion title=\"Checking Task Status with the Prefect Client\">\n  The `get_task_result` helper function (in `src/foo/_internal/_prefect.py`) uses the Prefect Python client to interact with the Prefect API:\n\n  ```python src/foo/_internal/_prefect.py theme={null}\n  from typing import Any, Literal, cast\n  from uuid import UUID\n\n\n  from prefect.client.orchestration import get_client\n  from prefect.client.schemas.objects import TaskRun\n  from prefect.logging import get_logger\n\n  logger = get_logger(__name__)\n\n  Status = Literal[\"completed\", \"pending\", \"error\"]\n\n\n  def _any_task_run_result(task_run: TaskRun) -> Any:\n      try:\n          return cast(Any, task_run.state.result(_sync=True))  # type: ignore\n      except Exception as e:\n          logger.warning(f\"Could not retrieve result for task run {task_run.id}: {e}\")\n          return None\n\n\n  async def get_task_result(task_run_id: UUID) -> tuple[Status, Any]:\n      \"\"\"Get task result or status.\n\n      Returns:\n          tuple: (status, data)\n              status: \"completed\", \"pending\", or \"error\"\n              data: the result if completed, error message if error, None if pending\n      \"\"\"\n      try:\n          async with get_client() as client:\n              task_run = await client.read_task_run(task_run_id)\n              if not task_run.state:\n                  return \"pending\", None\n\n              if task_run.state.is_completed():\n                  try:\n                      result = _any_task_run_result(task_run)\n                      return \"completed\", result\n                  except Exception as e:\n                      logger.warning(\n                          f\"Could not retrieve result for completed task run {task_run_id}: {e}\"\n                      )\n                      return \"completed\", \"<Could not retrieve result>\"\n\n              elif task_run.state.is_failed():\n                  try:\n                      error_result = _any_task_run_result(task_run)\n                      error_message = (\n                          str(error_result)\n                          if error_result\n                          else \"Task failed without specific error message.\"\n                      )\n                      return \"error\", error_message\n                  except Exception as e:\n                      logger.warning(\n                          f\"Could not retrieve error result for failed task run {task_run_id}: {e}\"\n                      )\n                      return \"error\", \"<Could not retrieve error message>\"\n\n              else:\n                  return \"pending\", None\n\n      except Exception as e:\n          logger.error(f\"Error checking task status for {task_run_id}: {e}\")\n          return \"error\", f\"Failed to check task status: {str(e)}\"\n  ```\n\n  This function fetches the `TaskRun` object from the API and checks its `state` to determine if it's `Completed`, `Failed`, or still `Pending`/`Running`. If completed, it attempts to retrieve the result using `task_run.state.result()`. If failed, it tries to get the error message.\n</Accordion>\n\n## Building the Docker Image\n\nA multi-stage `Dockerfile` is used to create optimized images for each service (Prefect server, task worker, and web API). This approach helps keep image sizes small and separates build dependencies from runtime dependencies.\n\n```dockerfile Dockerfile theme={null}\n# Stage 1: Base image with Python and uv\nFROM --platform=linux/amd64 ghcr.io/astral-sh/uv:python3.12-bookworm-slim as base\n\nWORKDIR /app\n\nENV UV_SYSTEM_PYTHON=1\nENV PATH=\"/root/.local/bin:$PATH\"\n\nCOPY pyproject.toml uv.lock* ./\n\n# Note: We install all dependencies needed for all stages here.\n# A more optimized approach might separate dependencies per stage.\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install --system -r pyproject.toml\n\nCOPY src/ /app/src\n\nFROM base as server\n\nCMD [\"prefect\", \"server\", \"start\"]\n\n# --- Task Worker Stage --- #\nFROM base as task\n\n# Command to start the task worker by running the task script\n# This script should call `prefect.task_worker.serve(...)`\nCMD [\"python\", \"src/foo/task.py\"]\n\n# --- API Stage --- #\nFROM base as api\n\n# Command to start the FastAPI server using uvicorn\nCMD [\"uvicorn\", \"src.foo.api:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n```\n\n<Accordion title=\"Dockerfile Key Details\">\n  * **Base Stage (`base`)**: Sets up Python, `uv`, installs all dependencies from `pyproject.toml` into a base layer to make use of Docker caching, and copies the source code.\n  * **Server Stage (`server`)**: Builds upon the `base` stage. Sets the default command (`CMD`) to start the Prefect server.\n  * **Task Worker Stage (`task`)**: Builds upon the `base` stage. Sets the `CMD` to run the `src/foo/task.py` script, which is expected to contain the `serve()` call for the task(s).\n  * **API Stage (`api`)**: Builds upon the `base` stage. Sets the `CMD` to start the FastAPI application using `uvicorn`.\n\n  The `compose.yaml` file then uses the `target` build argument to specify which of these final stages (`server`, `task`, `api`) to use for each service container.\n</Accordion>\n\n## Declaring the application services\n\nWe use `compose.yaml` to define and run the multi-container application, managing the lifecycles of the FastAPI web server, the Prefect API server, database and task worker(s).\n\n```yaml compose.yaml theme={null}\nservices:\n\n  prefect-server:\n    build:\n      context: .\n      target: server\n    ports:\n      - \"4200:4200\"\n    volumes:\n      - prefect-data:/root/.prefect # Persist Prefect DB\n    environment:\n      # Allow connections from other containers\n      PREFECT_SERVER_API_HOST: 0.0.0.0\n  # Task Worker\n  task:\n    build:\n      context: .\n      target:\n    deploy:\n      replicas: 1 # task workers are safely horizontally scalable (think redis stream consumer groups)\n    volumes:\n      # Mount storage for results\n      - ./task-storage:/task-storage\n    depends_on:\n      prefect-server:\n        condition: service_started\n    environment:\n      PREFECT_API_URL: http://prefect-server:4200/api\n      PREFECT_LOCAL_STORAGE_PATH: /task-storage\n      PREFECT_LOGGING_LOG_PRINTS: \"true\"\n      PREFECT_RESULTS_PERSIST_BY_DEFAULT: \"true\"\n      MARVIN_ENABLE_DEFAULT_PRINT_HANDLER: \"false\"\n      OPENAI_API_KEY: ${OPENAI_API_KEY}\n\n    develop:\n      # Optionally watch for code changes for development\n      watch:\n        - action: sync\n          path: .\n          target: /app\n          ignore:\n            - .venv/\n            - task-storage/\n        - action: rebuild\n          path: uv.lock\n\n  api:\n    build:\n      context: .\n      target: api\n    volumes:\n      # Mount storage for results\n      - ./task-storage:/task-storage\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      task:\n        condition: service_started\n      prefect-server:\n        condition: service_started\n    environment:\n      PREFECT_API_URL: http://prefect-server:4200/api\n      PREFECT_LOCAL_STORAGE_PATH: /task-storage\n    develop:\n      # Optionally watch for code changes for development\n      watch:\n        - action: sync\n          path: .\n          target: /app\n          ignore:\n            - .venv/\n            - task-storage/\n        - action: rebuild\n          path: uv.lock\n\nvolumes:\n  # Named volumes for data persistence\n  prefect-data: {}\n  task-storage: {}\n```\n\nIn a production use-case, you'd likely want to:\n\n* write a `Dockerfile` for each service\n* add a `postgres` service and [configure it as the Prefect database](/v3/manage/server/index#quickstart%3A-configure-a-postgresql-database-with-docker).\n* remove the hot-reloading configuration in the `develop` section\n\n<Accordion title=\"Key Service Configurations\">\n  - **`prefect-server`**: Runs the Prefect API server and UI.\n    * `build`: Uses a multi-stage `Dockerfile` (not shown here, but present in the example repo) targeting the `server` stage.\n    * `ports`: Exposes the Prefect API/UI on port `4200`.\n    * `volumes`: Uses a named volume `prefect-data` to persist the Prefect SQLite database (`/root/.prefect/prefect.db`) across container restarts.\n    * `PREFECT_SERVER_API_HOST=0.0.0.0`: Makes the API server listen on all interfaces within the Docker network, allowing the `task` and `api` services to connect.\n\n  - **`task`**: Runs the Prefect task worker process (executing `python src/foo/task.py` which calls `serve`).\n    * `build`: Uses the `task` stage from the `Dockerfile`.\n    * `depends_on`: Ensures the `prefect-server` service is started before this service attempts to connect.\n    * `PREFECT_API_URL`: Crucial setting that tells the worker where to find the Prefect API to poll for submitted task runs.\n    * `PREFECT_LOCAL_STORAGE_PATH=/task-storage`: Configures the worker to store task run results in the `/task-storage` directory inside the container. This path is mounted to the host using the `task-storage` named volume via `volumes: - ./task-storage:/task-storage` (or just `task-storage:` if using a named volume without a host path binding).\n    * `PREFECT_RESULTS_PERSIST_BY_DEFAULT=true`: Tells Prefect tasks to automatically save their results using the configured storage (defined by `PREFECT_LOCAL_STORAGE_PATH` in this case).\n    * `PREFECT_LOGGING_LOG_PRINTS=true`: Configures the Prefect logger to capture output from `print()` statements within tasks.\n    * `OPENAI_API_KEY=${OPENAI_API_KEY}`: Passes secrets needed by the task code from the host environment (via a `.env` file loaded by Docker Compose) into the container's environment.\n\n  - **`api`**: Runs the FastAPI web application.\n    * `build`: Uses the `api` stage from the `Dockerfile`.\n    * `depends_on`: Waits for the `prefect-server` (required for submitting tasks and checking status) and optionally the `task` worker.\n    * `PREFECT_API_URL`: Tells the FastAPI application where to send `.delay()` calls and status check requests.\n    * `PREFECT_LOCAL_STORAGE_PATH`: May be needed if the API itself needs to directly read result files (though typically fetching results via `task_run.state.result()` is preferred).\n\n  - **`volumes`**: Defines named volumes (`prefect-data`, `task-storage`) to persist data generated by the containers.\n</Accordion>\n\n## Running this example\n\nAssuming you have obtained the code (either by cloning the repository or using `uv init` as described previously) and are in the project directory:\n\n1. **Prerequisites:** Ensure Docker Desktop (or equivalent) with `docker compose` support is running.\n\n2. **Build and Run Services:**\n   This example's task uses [marvin](https://github.com/PrefectHQ/marvin), which (by default) requires an OpenAI API key. Provide it as an environment variable when starting the services:\n\n   ```bash  theme={null}\n   OPENAI_API_KEY=<your-openai-api-key> docker compose up --build --watch\n   ```\n\n   This command will:\n\n   * `--build`: Build the container images if they don't exist or if the Dockerfile/context has changed.\n   * `--watch`: Watch for changes in the project source code and automatically sync/rebuild services (useful for development).\n   * Add `--detach` or `-d` to run the containers in the background.\n\n3. **Access Services:**\n   * If you cloned the existing example, check out the basic [htmx](https://htmx.org/) UI at [http://localhost:8000](http://localhost:8000)\n   * FastAPI docs: [http://localhost:8000/docs](http://localhost:8000/docs)\n   * Prefect UI (for observing task runs): [http://localhost:4200](http://localhost:4200)\n\n### Cleaning up\n\n```bash  theme={null}\ndocker compose down\n\n# also remove the named volumes\ndocker compose down -v\n```\n\n## Next Steps\n\nThis example provides a repeatable pattern for integrating Prefect-managed background tasks with any python web application. You can:\n\n* Explore the [background tasks examples repository](https://github.com/PrefectHQ/prefect-background-task-examples) for more examples.\n* Adapt `src/**/*.py` to define and submit your specific web app and background tasks.\n* Configure Prefect settings (environment variables in `compose.yaml`) further, for example, using different result storage or logging levels.\n* Deploy these services to cloud infrastructure using managed container services.",
  "content_length": 17509
}