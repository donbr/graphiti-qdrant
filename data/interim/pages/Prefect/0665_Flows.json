{
  "title": "Flows",
  "source_url": "https://docs-3.prefect.io/v3/concepts/flows",
  "content": "Flows compose work into a workflow.\n\n```python  theme={null}\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef explain_flows():\n    print(\"run any python code here!\")\n    print(\"encapsulate that business logic!\")\n\nif __name__ == \"__main__\":\n    explain_flows()\n```\n\n## What is a flow?\n\nFlows are defined as decorated Python functions. Above, `explain_flows` is an instance of a flow.\n\nFlows accept inputs, perform work, and potentially return a result.\n\nGenerally, flows behave like Python functions, but they have some additional capabilities:\n\n* Metadata about their execution, like each [state](/v3/concepts/states/) the flow enters, is automatically tracked.\n* Input arguments can be type validated as workflow [parameters](#specify-flow-parameters).\n* [Retries](/v3/how-to-guides/workflows/retries) can be performed on failure, with configurable delay and retry limits.\n* [Timeouts](/v3/how-to-guides/workflows/write-and-run#cancel-a-workflow-if-it-runs-for-too-long) can be enforced to prevent unintentional, long-running workflows.\n* A flow can be [deployed](/v3/how-to-guides/deployments/create-deployments/), which exposes an API for interacting with it remotely.\n\n<Tip>\n  Flows do not need to call other Prefect tasks or flows, but they can.\n</Tip>\n\n### Running a flow\n\nA **flow run** is a representation of a single invocation of a flow.\n\n#### The life of a flow run\n\nEach flow run has its own [state](/v3/concepts/states/) lifecycle that is tracked by the Prefect database.\n\nA normal flow run lifetime looks like this:\n\n```mermaid  theme={null}\nflowchart TD\n    A[Scheduled] -->|â° Time to run| B[Pending]\n    B -->|ðŸš€ Starting execution| C[Running]\n    C -->|âœ… Success| D[Completed]\n    C -.->|âŒ Error occurred| E[Failed]\n    C -.->|ðŸ›‘ User intervention| F[Cancelled]\n    C -.->|ðŸ’¥ Infrastructure failure| G[Crashed]\n\n    style A fill:#ff9,stroke:#333,stroke-width:2px,color:#000\n    style B fill:#f9f,stroke:#333,stroke-width:2px,color:#000\n    style C fill:#9ff,stroke:#333,stroke-width:2px,color:#000\n    style D fill:#9f9,stroke:#333,stroke-width:2px,color:#000\n    style E fill:#f99,stroke:#333,stroke-width:2px,color:#000\n    style F fill:#faa,stroke:#333,stroke-width:2px,color:#000\n    style G fill:#f66,stroke:#333,stroke-width:2px,color:#fff\n\n    classDef default fill-opacity:0.9\n```\n\nA flow run's lifecycle may be interrupted at any point, whether by:\n\n* manual or accidental cancellation or deletion of the flow run\n* disappearance or malfunction of the flow run's host infrastructure\n* other unforeseen issues and circumstances (e.g. networking!)\n\nFrom the perspective of a Prefect server and its clients, a flow run should eventually reach a terminal state. If it doesn't for one of the above reasons, it is called a [\"zombie\" flow run](/v3/advanced/detect-zombie-flows/).\n\n#### Different ways to create a flow run\n\nThe simplest way to create a flow run is to call a `@flow` decorated function (i.e. `__call__`), just like a normal Python function.\n\n```python  theme={null}\nfrom prefect import flow\n\n@flow\ndef beep():\n    print(\"boop\")\n\nbeep()\n```\n\nYou can also create a flow run by:\n\n* Using external schedulers (e.g. `cron` or [Modal](https://modal.com/)) to invoke flows among vanilla Python code\n* Triggering an ad-hoc run of a deployment that exists in Prefect Cloud or your Prefect server\n* Configuring a [schedule](/v3/how-to-guides/deployments/create-schedules) or [automation](/v3/how-to-guides/automations/creating-automations) to trigger a flow on an interval or sequence of events\n\n[Deployments](/v3/how-to-guides/deployments/create-deployments/) exist to enable [arbitrary infrastructures](/v3/concepts/work-pools/) and schedules for your flow to run on.\n\nHowever and wherever you run your flow, Prefect monitors the **flow run**, capturing its state for observability.\nTo customize the default instrumentation of your workflow, you may [log a variety of metadata](/v3/how-to-guides/workflows/add-logging) or [emit events](/v3/advanced/use-custom-event-grammar) about flow runs for monitoring, troubleshooting, and auditing purposes.\n\n### Specify flow parameters\n\nAs with any Python function, you can pass arguments to a flow, including both positional and keyword arguments.\nThese arguments defined on your flow function are called **parameters**.\nWithin a flow run, you can access the values of your parameters via [runtime context](/v3/concepts/runtime-context/#access-runtime-information).\n\nPrefect automatically performs type conversion of inputs using any provided type hints.\nType hints provide a simple way to enforce typing on your flow parameters and can be customized with [Pydantic](https://pydantic-docs.helpmanual.io/).\nPrefect supports any Pydantic model as a type hint for a flow parameter.\n\nSimilarly, when invoking a flow run from a [deployment](/v3/how-to-guides/deployments/create-deployments/), Prefect will attempt to coerce provided parameters to the parameter schema implied by your flow function's type signature\n\n<Accordion title=\"View the parameter schema for a flow\">\n  You can get a sense of the parameter schema for a flow by inspecting the type signature of the flow function.\n\n  ```python  theme={null}\n  import inspect\n  from prefect import flow\n\n  @flow\n  def schleeb(x: int, y: str, z: bool | None = None):\n      print(f\"x: {x}, y: {y}, z: {z}\")\n\n  inspect.signature(schleeb)\n  ```\n\n  ```bash  theme={null}\n  <Signature(x: int, y: str, z: bool | None = None)>\n  ```\n\n  Or retrieve the actual schema inferred from the flow function's type signature as a `BaseModel` instance.\n\n  ```python  theme={null}\n  schleeb.parameters.model_json_schema()\n  ```\n\n  ```json  theme={null}\n  {\n    \"description\": \"Simple data model corresponding to an OpenAPI `Schema`.\",\n    \"properties\": {\n      \"title\": {\n        \"const\": \"Parameters\",\n        \"default\": \"Parameters\",\n        \"title\": \"Title\",\n        \"type\": \"string\"\n      },\n      \"type\": {\n        \"const\": \"object\",\n        \"default\": \"object\",\n        \"title\": \"Type\",\n        \"type\": \"string\"\n      },\n      \"properties\": {\n        \"type\": \"object\",\n        \"additionalProperties\": true,\n        \"title\": \"Properties\"\n      },\n      \"required\": {\n        \"items\": {\n          \"type\": \"string\"\n        },\n        \"title\": \"Required\",\n        \"type\": \"array\"\n      },\n      \"definitions\": {\n        \"additionalProperties\": true,\n        \"title\": \"Definitions\",\n        \"type\": \"object\"\n      }\n    },\n    \"title\": \"ParameterSchema\",\n    \"type\": \"object\"\n  }\n  ```\n</Accordion>\n\n<Warning>\n  **Prefect API requires keyword arguments**\n\n  When creating flow runs from the Prefect API, you must specify parameter names when overriding defaults.\n  The values passed cannot be positional.\n</Warning>\n\nParameters are validated before a flow is run.\nIf a flow run for a deployment receives invalid parameters, it moves from a `Pending` state to a `Failed` state without entering a `Running` state.\n\n<Note>\n  Flow run parameters cannot exceed `512kb` in size.\n\n  When possible, prefer passing a reference to a large object and load it during your flow run.\n</Note>\n\nFor a deep dive into flow parameters, see the [form-building tutorial](/v3/advanced/form-building).\n\n## Organize flows with subflows and tasks\n\nA single flow function *can* contain all of your workflow's code.\nHowever, if you put all your code in a single flow function and any line of code fails, the entire flow fails and must be retried from the beginning.\nIt is possible to go overboard with encapsulation, but making your workflows more granular can often help make your code easier to reason about and debug.\n\nFlows can call [tasks](/v3/concepts/tasks) to perform concurrent and transactional work quickly.\n\nFlows are free to call other flows (each potentially containing their flows and tasks, and so on), the resulting runs referred to as \"child\" flow or task runs.\n\n### Why both flows and tasks?\n\nFlows are convenient for composition, deployment, and server-side interaction and maintain a consistent context for task runs.\n\nTasks are quick, cacheable, retryable, have [transactional semantics](/v3/advanced/transactions/) and are easy to run concurrently.\n\n### Considerations when nesting flows\n\nIn the UI, each child flow run is linked to its parent and can be individually observed.\n\nFor most purposes, nested flow runs behave just like unnested flow runs. There is a full representation of the nested flow run in the backend as if it had been called separately. Nested flow runs differ from normal flow runs in that they resolve any passed task futures into data. This allows data to be passed from the parent flow run to a nested flow run easily.\n\nWhen a nested flow run starts, it creates a new [task runner](/v3/concepts/task-runners/) for any tasks it contains.\nWhen the nested flow run completes, the task runner shuts down.\nNested flow runs block execution of the parent flow run until completion.\nHowever, asynchronous nested flows can run concurrently with [AnyIO task groups](https://anyio.readthedocs.io/en/stable/tasks.html) or [asyncio.gather](https://docs.python.org/3/library/asyncio-task.html#id6).\n\nThe relationship between nested runs is recorded through a special task run in the parent flow run that represents the child flow run.\nThe `state_details` field of the task run representing the child flow run includes a `child_flow_run_id`.\nThe `state_details` field of the nested flow run includes a `parent_task_run_id`.\n\nYou can define multiple flows within the same file.\nWhether running locally or through a [deployment](/v3/how-to-guides/deployments/create-deployments), you must indicate which flow is the entrypoint for a flow run.\n\n<Warning>\n  **Cancel nested flow runs**\n\n  A nested flow run cannot be cancelled without cancelling its parent flow run.\n  If you need to be able to cancel a nested flow run independent of its parent flow run, we recommend deploying it separately and starting it with\n  the [run\\_deployment](https://reference.prefect.io/prefect/deployments/flow_runs/#prefect.deployments.flow_runs.run_deployment) method.\n</Warning>\n\nSome scenarios where you might want to define a nested flow rather than call tasks individually include:\n\n* **Observability**: Nested flows, like any other flow run, have first-class observability within the Prefect UI and Prefect Cloud. You'll\n  see nested flows' status in the **Runs** dashboard rather than having to dig down into the tasks within a specific flow run.\n  See [Final state determination](#final-state-determination) for examples of using task state within flows.\n* **Conditional business logic**: If you have a group of tasks that run only under certain conditions, you can group them within a nested flow and\n  conditionally run the nested flow rather than each task individually.\n* **Parameterized workflows**: Flows have first-class support for parameterization, making it easy to run the same group of tasks in different use\n  cases by simply passing different parameters to the nested flow in which they run.\n* **Task runners**: Nested flows enable you to specify the task runner used for tasks within the flow. For example, to optimize\n  parallel execution of certain tasks with Dask, group them in a nested flow that uses the Dask task runner. You can use a different\n  task runner for each nested flow.\n\n## Supported function types\n\nAlmost any standard Python function can be turned into a Prefect flow by adding the `@flow` decorator.\n\nIn particular, Prefect supports:\n\n* Synchronous functions\n* Asynchronous functions\n* Instance methods\n* Class methods\n* Static methods\n* Generators\n\n<Warning>\n  **Generator functions are consumed when returned from flows**\n\n  The result of a completed flow must be serializable, but generators cannot be serialized.\n  Therefore, if you return a generator from a flow, the generator will be fully consumed and its yielded values will be returned as a list.\n  This can lead to unexpected behavior or blocking if the generator is infinite or very large.\n\n  Here is an example of proactive generator consumption:\n\n  ```python  theme={null}\n  from prefect import flow\n\n\n  def gen():\n      yield from [1, 2, 3]\n      print('Generator consumed!')\n\n\n  @flow\n  def f():\n      return gen()\n\n\n  f()  # prints 'Generator consumed!'\n  ```\n\n  If you need to return a generator without consuming it, you can `yield` it instead of using `return`.\n  Values yielded from generator flows are not considered final results and do not face the same serialization constraints:\n\n  ```python  theme={null}\n  from prefect import flow\n\n\n  def gen():\n      yield from [1, 2, 3]\n      print('Generator consumed!')\n\n\n  @flow\n  def f():\n      yield gen()\n\n\n  generator = next(f())\n  list(generator) # prints 'Generator consumed!'\n  ```\n</Warning>\n\n## Final state determination\n\nA [state](/v3/concepts/states) is a record of the status of a particular task run or flow run.\n\nThe final state of a flow is determined by its ***return value***. The following rules apply:\n\n* If an exception is raised directly in the flow function, the flow run is marked as `FAILED`.\n* If a flow returns a manually created state, it is used as the state of the final flow run. This allows for manual determination of final state.\n* If a flow returns an iterable of states, the presence of *any* `FAILED` state will cause the run to be marked as `FAILED`.\n\nIn *any other situation* in which the flow returns without error, it will be marked as `COMPLETED`.\n\n<Warning>\n  If you manipulate states programmatically, you can create situations in which tasks\n  within a flow can fail and not cause flow run failure.\n  For example:\n\n  ```python  theme={null}\n  from prefect import flow, task \n\n\n  @task \n  def add_one(x):\n      return x + 1\n\n\n  @flow \n  def my_flow():\n      # avoided raising an exception via `return_state=True`\n      state = add_one(\"1\", return_state=True)\n      assert state.is_failed()\n\n      # the flow function returns successfully!\n      return\n  ```\n\n  If `state` were returned from the flow function, the run would be marked as `FAILED`.\n</Warning>\n\n### Return a future\n\nIf a flow returns one or more futures, the final state is determined based on the underlying states.\n\n```python  theme={null}\nfrom prefect import flow, task\n\n\n@task\ndef always_fails_task():\n    raise ValueError(\"I fail successfully\")\n\n\n@task\ndef always_succeeds_task():\n    print(\"I'm fail safe!\")\n    return \"success\"\n\n\n@flow\ndef always_succeeds_flow():\n    x = always_fails_task.submit().result(raise_on_failure=False)\n    y = always_succeeds_task.submit(wait_for=[x])\n    return y\n\n\nif __name__ == \"__main__\":\n    always_succeeds_flow()\n```\n\nThis flow run finishes in a **Completed** final state because the flow returns the future of the task that succeeds.\n\n### Return multiple states or futures\n\nIf a flow returns a mix of futures and states, the final state is determined by resolving all futures to states,\nthen determining if any of the states are not `COMPLETED`.\n\n```python  theme={null}\nfrom prefect import task, flow\n\n\n@task\ndef always_fails_task():\n    raise ValueError(\"I am bad task\")\n\n\n@task\ndef always_succeeds_task():\n    return \"foo\"\n\n\n@flow\ndef always_succeeds_flow():\n    return \"bar\"\n\n\n@flow\ndef always_fails_flow():\n    x = always_fails_task()\n    y = always_succeeds_task()\n    z = always_succeeds_flow()\n    return x, y, z\n```\n\nRunning `always_fails_flow` fails because one of the three returned futures fails.\n\nIf multiple states are returned, they must be contained in a `set`, `list`, or `tuple`.\n\n### Return a manual state\n\nIf a flow returns a manually created state, the final state is determined based upon the return value.\n\n```python  theme={null}\nfrom prefect import task, flow\nfrom prefect.states import Completed, Failed\n\n\n@task\ndef always_fails_task():\n    raise ValueError(\"I fail successfully\")\n\n\n@task\ndef always_succeeds_task():\n    print(\"I'm fail safe!\")\n    return \"success\"\n\n\n@flow\ndef always_succeeds_flow():\n    x = always_fails_task.submit()\n    y = always_succeeds_task.submit()\n    if y.result() == \"success\":\n        return Completed(message=\"I am happy with this result\")\n    else:\n        return Failed(message=\"How did this happen!?\")\n\n\nif __name__ == \"__main__\":\n    always_succeeds_flow()\n```\n\nIf a flow run returns any other object, then it is recorded as `COMPLETED`\n\n### Custom named states\n\nYou can also create custom named states to provide more granularity in your flow run states.\n\nFor example, we could create a `Skipped` state to indicate that a flow run was skipped.\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect.states import Completed\n\n@flow\ndef my_flow(work_to_do: bool):\n    if not work_to_do:\n        return Completed(message=\"No work to do ðŸ’¤\", name=\"Skipped\")\n    else:\n        return Completed(message=\"Work was done ðŸ’ª\")\n\n\nif __name__ == \"__main__\":\n    my_flow(work_to_do=False)\n```",
  "content_length": 16839
}