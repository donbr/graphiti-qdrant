{
  "title": "dbt Model Orchestration",
  "source_url": "https://docs-3.prefect.io/v3/examples/run-dbt-with-prefect",
  "content": "Orchestrate any dbt project with bullet-proof retries, observability, and a single Python file – no YAML or shell scripts required.\n\n<a href=\"https://github.com/PrefectHQ/prefect/blob/main/examples/run_dbt_with_prefect.py\" target=\"_blank\">View on GitHub</a>\n\n**Transform unreliable dbt scripts into production-grade data pipelines with enterprise observability, automatic failure recovery, and zero-downtime deployments.**\n\nWhen you combine Prefect with dbt, you get the **perfect marriage of best-in-class analytics tools**:\n\n* **Python** gives you the flexibility to integrate with any data source, API, or system your analytics need.\n* **dbt Core** handles the heavy lifting of SQL transformations, testing, and documentation.\n* **Prefect** wraps the entire workflow in battle-tested orchestration: automatic [retries](https://docs.prefect.io/v3/develop/write-tasks#retries), [scheduling](https://docs.prefect.io/v3/deploy/index#workflow-scheduling-and-parametrization), and [observability](https://docs.prefect.io/v3/develop/logging#prefect-loggers).\n\nThe result? Your analytics team gets reliable, observable data pipelines that leverage the strengths of both platforms. Point this combo at any warehouse and it will transform your data while providing enterprise-grade workflow management.\n\n> **Note**: This example uses **dbt Core** (the open-source CLI). For dbt Cloud integration, see the [dbt Cloud examples](https://docs.prefect.io/integrations/prefect-dbt#dbt-cloud) in the Prefect documentation.\n\nThis example demonstrates these Prefect features:\n\n* [`@task`](https://docs.prefect.io/v3/develop/write-tasks#write-and-run-tasks) – wrap dbt commands in retries & observability.\n* [`log_prints`](https://docs.prefect.io/v3/develop/logging#configure-logging) – surface dbt output automatically in Prefect logs.\n* Automatic [**retries**](https://docs.prefect.io/v3/develop/write-tasks#retries) with exponential back-off for flaky network connections.\n* [**prefect-dbt integration**](https://docs.prefect.io/integrations/prefect-dbt) – native dbt execution with enhanced logging and failure handling.\n\n### The Scenario: Reliable Analytics Workflows\n\nYour analytics team uses dbt to model data in DuckDB for rapid local development and testing, but deploys to Snowflake in production. You need a workflow that:\n\n* Anyone can run locally without complex setup (DuckDB)\n* Automatically retries on network failures or temporary dbt errors\n* Provides clear logs and observability for debugging\n* Can be easily scheduled and deployed to production\n\n### Our Solution\n\nWrite three focused Python functions (download project, run dbt commands, orchestrate workflow), add Prefect decorators, and let Prefect handle [retries](https://docs.prefect.io/v3/develop/write-tasks#retries), [logging](https://docs.prefect.io/v3/develop/logging#prefect-loggers), and [scheduling](https://docs.prefect.io/v3/deploy/index#workflow-scheduling-and-parametrization). The entire example is self-contained – no git client or global dbt configuration required.\n\n*For more on integrating Prefect with dbt, see the [Prefect documentation](https://docs.prefect.io/integrations/dbt).*\n\n### Running the example locally\n\n```bash  theme={null}\npython 02_flows/prefect_and_dbt.py\n```\n\nWatch as Prefect orchestrates the complete dbt lifecycle: downloading the project, running models, executing tests, and materializing results. The flow creates a local DuckDB file you can explore with any SQL tool.\n\n## Code walkthrough\n\n1. **Project Setup** – Download and cache a demo dbt project from GitHub\n2. **dbt CLI Wrapper** – Execute dbt commands with automatic retries and logging using prefect-dbt\n3. **Orchestration Flow** – Run the complete dbt lifecycle in sequence\n4. **Execution** – Self-contained example that works out of the box\n\n```python  theme={null}\nimport io\nimport shutil\nimport urllib.request\nimport zipfile\nfrom pathlib import Path\n\nfrom prefect_dbt import PrefectDbtRunner, PrefectDbtSettings\n\nfrom prefect import flow, task\n\nDEFAULT_REPO_ZIP = (\n    \"https://github.com/PrefectHQ/examples/archive/refs/heads/examples-markdown.zip\"\n)\n\n```\n\n***\n\n## Project Setup – download and cache dbt project\n\nTo keep this example fully self-contained, we download a demo dbt project\ndirectly from GitHub as a ZIP file. This means users don't need git installed.\n[Learn more about tasks in the Prefect documentation](https://docs.prefect.io/v3/develop/write-tasks)\n\n```python  theme={null}\n@task(retries=2, retry_delay_seconds=5, log_prints=True)\ndef build_dbt_project(repo_zip_url: str = DEFAULT_REPO_ZIP) -> Path:\n    \"\"\"Download and extract the demo dbt project, returning its local path.\n\n    To keep the example fully self-contained we grab the GitHub archive as a ZIP\n    so users do **not** need `git` installed. The project is extracted from the\n    PrefectHQ/examples repository into a sibling directory next to this script\n    (`prefect_dbt_project`). If that directory already exists we skip the download\n    to speed up subsequent runs.\n    \"\"\"\n\n    project_dir = Path(__file__).parent / \"prefect_dbt_project\"\n    if project_dir.exists():\n        print(f\"Using cached dbt project at {project_dir}\\n\")\n        return project_dir\n\n    tmp_extract_base = project_dir.parent / \"_tmp_dbt_extract\"\n    if tmp_extract_base.exists():\n        shutil.rmtree(tmp_extract_base)\n\n    print(f\"Downloading dbt project archive → {repo_zip_url}\\n\")\n    with urllib.request.urlopen(repo_zip_url) as resp:\n        data = resp.read()\n\n    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n        zf.extractall(tmp_extract_base)\n\n    # Find the folder containing dbt_project.yml (in resources/prefect_dbt_project)\n    candidates = list(\n        tmp_extract_base.rglob(\"**/resources/prefect_dbt_project/dbt_project.yml\")\n    )\n    if not candidates:\n        raise ValueError(\n            \"dbt_project.yml not found in resources/prefect_dbt_project – structure unexpected\"\n        )\n\n    project_root = candidates[0].parent\n    shutil.move(str(project_root), str(project_dir))\n    shutil.rmtree(tmp_extract_base)\n\n    print(f\"Extracted dbt project to {project_dir}\\n\")\n    return project_dir\n\n\n```\n\n***\n\n## Create profiles.yml for DuckDB – needed for dbt to work\n\nThis task creates a simple profiles.yml file for DuckDB so dbt can connect\nto the database. This keeps the example self-contained.\n\n```python  theme={null}\n@task(retries=2, retry_delay_seconds=5, log_prints=True)\ndef create_dbt_profiles(project_dir: Path) -> None:\n    \"\"\"Create a profiles.yml file for DuckDB connection.\n\n    This creates a simple DuckDB profile so dbt can run without external\n    database configuration. The profile points to a local DuckDB file.\n    This will overwrite any existing profiles.yml to ensure correct formatting.\n    \"\"\"\n\n    profiles_content = f\"\"\"demo:\n  outputs:\n    dev:\n      type: duckdb\n      path: {project_dir}/demo.duckdb\n      threads: 1\n  target: dev\"\"\"\n\n    profiles_path = project_dir / \"profiles.yml\"\n    with open(profiles_path, \"w\") as f:\n        f.write(profiles_content)\n\n    print(f\"Created/updated profiles.yml at {profiles_path}\")\n\n\n```\n\n***\n\n## dbt CLI Wrapper – execute commands with retries and logging using prefect-dbt\n\nThis task uses the modern PrefectDbtRunner from prefect-dbt integration which\nprovides native dbt execution with enhanced logging, failure handling, and\nautomatic event emission.\n[Learn more about retries in the Prefect documentation](https://docs.prefect.io/v3/develop/write-tasks#retries)\n\n```python  theme={null}\n@task(retries=2, retry_delay_seconds=5, log_prints=True)\ndef run_dbt_commands(commands: list[str], project_dir: Path) -> None:\n    \"\"\"Run dbt commands using the modern prefect-dbt integration.\n\n    Uses PrefectDbtRunner which provides enhanced logging, failure handling,\n    and automatic Prefect event emission for dbt node status changes.\n    This is much more robust than subprocess calls and integrates natively\n    with Prefect's observability features.\n    \"\"\"\n\n    print(f\"Running dbt commands: {commands}\\n\")\n\n    # Configure dbt settings to point to our project directory\n    settings = PrefectDbtSettings(\n        project_dir=str(project_dir),\n        profiles_dir=str(project_dir),  # Use project dir for profiles too\n    )\n\n    # Create runner and execute commands\n    # Use raise_on_failure=False to handle dbt failures more gracefully\n    runner = PrefectDbtRunner(settings=settings, raise_on_failure=False)\n\n    for command in commands:\n        print(f\"Executing: dbt {command}\")\n        runner.invoke(command.split())\n        print(f\"Completed: dbt {command}\\n\")\n\n\n```\n\n***\n\n## Orchestration Flow – run the complete dbt lifecycle\n\nThis flow orchestrates the standard dbt workflow: debug → deps → seed → run → test.\nEach step is a separate task run in Prefect, providing granular observability\nand automatic retry handling for any step that fails. Now using the flexible\nprefect-dbt integration for enhanced dbt execution.\n[Learn more about flows in the Prefect documentation](https://docs.prefect.io/v3/develop/write-flows)\n\n```python  theme={null}\n@flow(name=\"dbt_flow\", log_prints=True)\ndef dbt_flow(repo_zip_url: str = DEFAULT_REPO_ZIP) -> None:\n    \"\"\"Run the demo dbt project with Prefect using prefect-dbt integration.\n\n    Steps executed:\n    1. Download and setup the dbt project\n    2. Create profiles.yml for DuckDB connection\n    3. `dbt deps`   – download any package dependencies (none for this tiny demo).\n    4. `dbt seed`   – load seed CSVs if they exist (safe to run even when empty).\n    5. `dbt run`    – build the model(s) defined under `models/`.\n    6. `dbt test`   – execute any tests declared in the project.\n\n    Each step runs as a separate Prefect task with automatic retries and logging.\n    Uses the modern prefect-dbt integration for enhanced observability and\n    native dbt execution.\n    \"\"\"\n\n    project_dir = build_dbt_project(repo_zip_url)\n    create_dbt_profiles(project_dir)\n\n    # dbt commands – executed sequentially using prefect-dbt integration\n    run_dbt_commands([\"deps\"], project_dir)\n    run_dbt_commands([\"seed\"], project_dir)\n    run_dbt_commands([\"run\"], project_dir)\n    run_dbt_commands([\"test\"], project_dir)\n\n    # Let users know where the DuckDB file was written for exploration\n    duckdb_path = project_dir / \"demo.duckdb\"\n    print(f\"\\nDone! DuckDB file located at: {duckdb_path.resolve()}\")\n\n\n```\n\n### What Just Happened?\n\nHere's the sequence of events when you run this flow:\n\n1. **Project Download** – Prefect registered a task run to download and extract the dbt project from GitHub (with automatic caching for subsequent runs).\n2. **dbt Lifecycle** – Five separate task runs executed the standard dbt workflow: `deps`, `seed`, `run`, and `test`.\n3. **Native dbt Integration** – Each dbt command used the `DbtCoreOperation` for enhanced logging, failure handling, and automatic event emission.\n4. **Automatic Retries** – Each dbt command would automatically retry on failure (network issues, temporary dbt errors, etc.).\n5. **Centralized Logging** – All dbt output streamed directly to Prefect logs with proper log level mapping.\n6. **Event Emission** – Prefect automatically emitted events for each dbt node execution, enabling advanced monitoring and alerting.\n7. **Local Results** – A DuckDB file appeared at `prefect_dbt_project/demo.duckdb` ready for analysis.\n\n**Prefect + prefect-dbt transformed a series of shell commands into a resilient, observable workflow** – no YAML files, no cron jobs, just Python with enterprise-grade dbt integration.\n\n### Why This Matters\n\nTraditional dbt orchestration often involves brittle shell scripts, complex YAML configurations, or heavyweight workflow tools. Prefect with the prefect-dbt integration gives you **enterprise-grade orchestration with zero operational overhead**:\n\n* **Reliability**: Automatic retries with exponential backoff handle transient failures\n* **Native Integration**: DbtCoreOperation provides enhanced logging, failure handling, and event emission\n* **Observability**: Every dbt command and node is logged, timed, and searchable in the Prefect UI with proper log level mapping\n* **Event-Driven**: Automatic Prefect events for dbt node status changes enable advanced monitoring and alerting\n* **Portability**: The same Python file runs locally, in CI/CD, and in production\n* **Composability**: Easily extend this flow with data quality checks, Slack alerts, or downstream dependencies\n\nThis pattern scales from prototype analytics to production data platforms. Whether you're running dbt against DuckDB for rapid local iteration or Snowflake for enterprise analytics, Prefect ensures your workflows are reliable, observable, and maintainable.\n\nTo learn more about orchestrating analytics workflows with Prefect, check out:\n\n* [prefect-dbt integration guide](https://docs.prefect.io/integrations/prefect-dbt)\n* [Task configuration and retries](https://docs.prefect.io/v3/develop/write-tasks#retries)\n* [Workflow scheduling and deployment](https://docs.prefect.io/v3/deploy/index#workflow-scheduling-and-parametrization)\n\n```python  theme={null}\nif __name__ == \"__main__\":\n    dbt_flow()\n\n```",
  "content_length": 13153
}