{
  "title": "prefect-gcp",
  "source_url": "https://docs-3.prefect.io/integrations/prefect-gcp/index",
  "content": "`prefect-gcp` helps you leverage the capabilities of Google Cloud Platform (GCP) in your workflows.\nFor example, you can run flows on Vertex AI or Cloud Run, read and write data to BigQuery and Cloud Storage, and retrieve secrets with Secret Manager.\n\n## Getting started\n\n### Prerequisites\n\n* A [GCP account](https://cloud.google.com/) and the necessary permissions to access desired services.\n\n### Install `prefect-gcp`\n\nInstall `prefect-gcp` as an extra of `prefect`.\nIf you don't already have `prefect` installed, it will install the newest version of `prefect` as well.\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install -U \"prefect[gcp]\"\n  ```\n\n  ```bash uv theme={null}\n  uv pip install -U \"prefect[gcp]\"\n  ```\n</CodeGroup>\n\nIf using BigQuery, Cloud Storage, Secret Manager, or Vertex AI, see [additional installation options](#install-extras).\n\n#### Install extras\n\nTo install `prefect-gcp` with all additional capabilities, run the install command above and then run the following command:\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install -U \"prefect-gcp[all_extras]\"\n  ```\n\n  ```bash uv theme={null}\n  uv pip install -U \"prefect-gcp[all_extras]\"\n  ```\n</CodeGroup>\n\nOr, install extras individually:\n\n<CodeGroup>\n  ```bash pip theme={null}\n  # Use Cloud Storage\n  pip install -U \"prefect-gcp[cloud_storage]\"\n\n  # Use BigQuery\n  pip install -U \"prefect-gcp[bigquery]\"\n\n  # Use Secret Manager\n  pip install -U \"prefect-gcp[secret_manager]\"\n\n  # Use Vertex AI\n  pip install -U \"prefect-gcp[aiplatform]\"\n  ```\n\n  ```bash uv theme={null}\n  # Use Cloud Storage\n  uv pip install -U \"prefect-gcp[cloud_storage]\"\n\n  # Use BigQuery\n  uv pip install -U \"prefect-gcp[bigquery]\"\n\n  # Use Secret Manager\n  uv pip install -U \"prefect-gcp[secret_manager]\"\n\n  # Use Vertex AI\n  uv pip install -U \"prefect-gcp[aiplatform]\"\n  ```\n</CodeGroup>\n\n### Register newly installed block types\n\nRegister the block types in the module to make them available for use.\n\n```bash  theme={null}\nprefect block register -m prefect_gcp\n```\n\n## Blocks setup\n\n### Credentials\n\nAuthenticate with a service account to use `prefect-gcp` services.\n\n1. Refer to the [GCP service account documentation](https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating) to create and download a service account key file.\n2. Copy the JSON contents.\n3. Use the Python code below, replace the placeholders with your information.\n\n```python  theme={null}\nfrom prefect_gcp import GcpCredentials\n\n# replace this PLACEHOLDER dict with your own service account info\nservice_account_info = {\n  \"type\": \"service_account\",\n  \"project_id\": \"PROJECT_ID\",\n  \"private_key_id\": \"KEY_ID\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nPRIVATE_KEY\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"SERVICE_ACCOUNT_EMAIL\",\n  \"client_id\": \"CLIENT_ID\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/SERVICE_ACCOUNT_EMAIL\"\n}\n\nGcpCredentials(\n    service_account_info=service_account_info\n).save(\"CREDENTIALS-BLOCK-NAME\")\n```\n\nThis credential block can be used to create other `prefect_gcp` blocks.\n\n<Warning>\n  **`service_account_info` vs `service_account_file`**\n\n  The advantage of using `service_account_info`, instead of `service_account_file`, is that it is accessible across containers.\n\n  If `service_account_file` is used, the provided path *must be available* in the container executing the flow.\n</Warning>\n\n### BigQuery\n\nRead data from and write to Google BigQuery within your Prefect flows.\n\nBe sure to [install](#install-extras) `prefect-gcp` with the BigQuery extra.\n\n```python  theme={null}\nfrom prefect_gcp.bigquery import GcpCredentials, BigQueryWarehouse\n\ngcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n\nbigquery_block = BigQueryWarehouse(\n    gcp_credentials = gcp_credentials,\n    fetch_size = 1  # Optional: specify a default number of rows to fetch when calling fetch_many\n)\nbigquery_block.save(\"BIGQUERY-BLOCK-NAME\")\n```\n\n### Secret Manager\n\nManage secrets in Google Cloud Platform's Secret Manager.\n\n```python  theme={null}\nfrom prefect_gcp import GcpCredentials, GcpSecret\ngcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n\ngcp_secret = GcpSecret(\n    secret_name = \"your-secret-name\",\n    secret_version = \"latest\",\n    gcp_credentials = gcp_credentials\n)\n\ngcp_secret.save(\"SECRET-BLOCK-NAME\")\n```\n\n### Cloud Storage\n\nCreate a block to interact with a GCS bucket.\n\n```python  theme={null}\nfrom prefect_gcp import GcpCredentials, GcsBucket\n\ngcs_bucket = GcsBucket(\n    bucket=\"BUCKET-NAME\",\n    gcp_credentials=GcpCredentials.load(\"BIGQUERY-BLOCK-NAME\")\n)\ngcs_bucket.save(\"GCS-BLOCK-NAME\")\n\n```\n\n## Run flows on Google Cloud Run or Vertex AI\n\nRun flows on [Google Cloud Run](https://cloud.google.com/run) or [Vertex AI](https://cloud.google.com/vertex-ai) to dynamically scale your infrastructure.\n\nPrefect Cloud offers [Google Cloud Run push work pools](/v3/how-to-guides/deployment_infra/serverless). Push work pools submit runs directly to Google Cloud Run, instead of requiring a worker to actively poll for flow runs to execute.\n\nSee the [Google Cloud Run Worker Guide](/integrations/prefect-gcp/gcp-worker-guide) for a walkthrough of using Google Cloud Run in a hybrid work pool.\n\n## Examples\n\n### Interact with BigQuery\n\nThis code creates a new dataset in BigQuery, defines a table, insert rows, and fetches data from the table:\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_gcp.bigquery import GcpCredentials, BigQueryWarehouse\n\n@flow\ndef bigquery_flow():\n    all_rows = []\n    gcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n\n    client = gcp_credentials.get_bigquery_client()\n    client.create_dataset(\"test_example\", exists_ok=True)\n\n    with BigQueryWarehouse(gcp_credentials=gcp_credentials) as warehouse:\n        warehouse.execute(\n            \"CREATE TABLE IF NOT EXISTS test_example.customers (name STRING, address STRING);\"\n        )\n        warehouse.execute_many(\n            \"INSERT INTO test_example.customers (name, address) VALUES (%(name)s, %(address)s);\",\n            seq_of_parameters=[\n                {\"name\": \"Marvin\", \"address\": \"Highway 42\"},\n                {\"name\": \"Ford\", \"address\": \"Highway 42\"},\n                {\"name\": \"Unknown\", \"address\": \"Highway 42\"},\n            ],\n        )\n        while True:\n            # Repeated fetch* calls using the same operation will\n            # skip re-executing and instead return the next set of results\n            new_rows = warehouse.fetch_many(\"SELECT * FROM test_example.customers\", size=2)\n            if len(new_rows) == 0:\n                break\n            all_rows.extend(new_rows)\n    return all_rows\n\n\nif __name__ == \"__main__\":\n    bigquery_flow()\n```\n\n### Use Prefect with Google Cloud Storage\n\nInteract with Google Cloud Storage.\n\nThe code below uses `prefect_gcp` to upload a file to a Google Cloud Storage bucket and download the same file under a different filename.\n\n```python  theme={null}\nfrom pathlib import Path\nfrom prefect import flow\nfrom prefect_gcp import GcpCredentials, GcsBucket\n\n\n@flow\ndef cloud_storage_flow():\n    # create a dummy file to upload\n    file_path = Path(\"test-example.txt\")\n    file_path.write_text(\"Hello, Prefect!\")\n\n    gcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n    gcs_bucket = GcsBucket(\n        bucket=\"BUCKET-NAME\",\n        gcp_credentials=gcp_credentials\n    )\n\n    gcs_bucket_path = gcs_bucket.upload_from_path(file_path)\n    downloaded_file_path = gcs_bucket.download_object_to_path(\n        gcs_bucket_path, \"downloaded-test-example.txt\"\n    )\n    return downloaded_file_path.read_text()\n\n\nif __name__ == \"__main__\":\n    cloud_storage_flow()\n```\n\n<Info>\n  **Upload and download directories**\n\n  `GcsBucket` supports uploading and downloading entire directories.\n</Info>\n\n### Save secrets with Google Secret Manager\n\nRead and write secrets with Google Secret Manager.\n\nBe sure to [install](#instal-prefect-gcp) `prefect-gcp` with the Secret Manager extra.\n\nThe code below writes a secret to the Secret Manager, reads the secret data, and deletes the secret.\n\n```python  theme={null}\nfrom prefect import flow\nfrom prefect_gcp import GcpCredentials, GcpSecret\n\n\n@flow\ndef secret_manager_flow():\n    gcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n    gcp_secret = GcpSecret(secret_name=\"test-example\", gcp_credentials=gcp_credentials)\n    gcp_secret.write_secret(secret_data=b\"Hello, Prefect!\")\n    secret_data = gcp_secret.read_secret()\n    gcp_secret.delete_secret()\n    return secret_data\n\n\nif __name__ == \"__main__\":\n    secret_manager_flow()\n```\n\n## Resources\n\nFor assistance using GCP, consult the [Google Cloud documentation](https://cloud.google.com/docs).\n\nGCP can also authenticate without storing credentials in a block.\nSee [Access third-party secrets](/v3/develop/secrets) for an example that uses AWS Secrets Manager and Snowflake.\n\nRefer to the `prefect-gcp` [SDK documentation](https://reference.prefect.io/prefect_gcp/) to explore all of the capabilities of the `prefect-gcp` library.",
  "content_length": 9255
}