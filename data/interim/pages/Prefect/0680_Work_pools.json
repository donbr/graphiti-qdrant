{
  "title": "Work pools",
  "source_url": "https://docs-3.prefect.io/v3/concepts/work-pools",
  "content": "Learn how to configure dynamic infrastructure provisioning with work pools\n\nWork pools are a bridge between the Prefect orchestration layer and the infrastructure where flows are run.\n\nThe primary reason to use work pools is for **dynamic infrastructure provisioning and configuration**.\nFor example, you might have a workflow that has expensive infrastructure requirements and runs infrequently.\nIn this case, you don't want an idle process running within that infrastructure.\n\nOther advantages of work pools:\n\n* Configure default infrastructure configurations on your work pools that all jobs inherit and can override.\n* Allow platform teams to use work pools to expose opinionated (and enforced) interfaces to the infrastructure that they oversee.\n* Allow work pools to prioritize (or limit) flow runs through the use of [work queues](/v3/deploy/infrastructure-concepts/work-pools/#work-queues).\n\nWork pools remain a consistent interface for configuring deployment infrastructure, but only some work pool types require you to run a [worker](/v3/concepts/workers).\n\n| Type                                                  | Description                                                                            | You run a worker |\n| ----------------------------------------------------- | -------------------------------------------------------------------------------------- | ---------------- |\n| [Hybrid](/v3/concepts/workers)                        | a worker in your infrastructure submits runs to your infrastructure                    | Yes              |\n| [Push](/v3/how-to-guides/deployment_infra/serverless) | runs are automatically submitted to your configured serverless infrastructure provider | No               |\n| [Managed](/v3/how-to-guides/deployment_infra/managed) | runs are automatically submitted to Prefect-managed infrastructure                     | No               |\n\nEach type of work pool is optimized for different use cases, allowing you to choose the best fit for your specific infrastructure and workflow requirements.\nBy using work pools, you can efficiently manage the distribution and execution of your Prefect flows across environments and infrastructures.\n\n<Tip>\n  **Work pools are like pub/sub topics**\n\n  Work pools help coordinate deployments with workers\n  through a known channel: the pool itself. This is similar to how \"topics\" are used to connect producers and consumers in a\n  pub/sub or message-based system. By switching a deployment's work pool, users can quickly change the worker that will execute their runs,\n  making it easy to promote runs through environments â€” or even to debug locally.\n</Tip>\n\nThe following diagram provides a high-level overview of the conceptual elements involved in defining a work-pool based\ndeployment that is polled by a worker and executes a flow run based on that deployment.\n\n```mermaid  theme={null}\n%%{\n  init: {\n    'theme': 'neutral',\n    'themeVariables': {\n      'margin': '10px'\n    }\n  }\n}%%\n\nflowchart LR\n\n    B(Deployment Definition)\n\n    subgraph Server [Prefect API]\n        C(Deployment)\n    end\n\n    subgraph Remote Storage [Remote Storage]\n        D(Flow Code)\n    end\n\n    E(Worker)\n\n    subgraph Infrastructure [Infrastructure]\n        F((Flow Run))\n    end\n\n    B --> C\n    B -.-> D\n    C --> E\n    D -.-> E\n    E -.-> F\n```\n\n### Work pool types\n\nThe following work pool types are supported by Prefect:\n\n<Tabs>\n  <Tab title=\"Prefect Cloud\">\n    | Infrastructure Type                  | Description                                                                                                                                                                                                                                       |\n    | ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n    | Process                              | Execute flow runs as subprocesses on a worker. Works well for local execution when first getting started.                                                                                                                                         |\n    | AWS Elastic Container Service        | Execute flow runs within containers on AWS ECS. Works with EC2 and Fargate clusters. Requires an AWS account.                                                                                                                                     |\n    | Azure Container Instances            | Execute flow runs within containers on Azure's Container Instances service. Requires an Azure account.                                                                                                                                            |\n    | Docker                               | Execute flow runs within Docker containers. Works well for managing flow execution environments through Docker images. Requires  access to a running Docker daemon.                                                                               |\n    | Google Cloud Run                     | Execute flow runs within containers on Google Cloud Run. Requires a Google Cloud Platform account.                                                                                                                                                |\n    | Google Cloud Run V2                  | Execute flow runs within containers on Google Cloud Run (V2 API). Requires a Google Cloud Platform account.                                                                                                                                       |\n    | Google Vertex AI                     | Execute flow runs within containers on Google Vertex AI. Requires a Google Cloud Platform account.                                                                                                                                                |\n    | Kubernetes                           | Execute flow runs within jobs scheduled on a Kubernetes cluster. Requires a Kubernetes cluster.                                                                                                                                                   |\n    | Google Cloud Run - Push              | Execute flow runs within containers on Google Cloud Run. Requires a Google Cloud Platform account. Flow runs are pushed directly to your environment, without the need for a Prefect worker.                                                      |\n    | AWS Elastic Container Service - Push | Execute flow runs within containers on AWS ECS. Works with existing ECS clusters and serverless execution through AWS Fargate. Requires an AWS account. Flow runs are pushed directly to your environment, without the need for a Prefect worker. |\n    | Azure Container Instances - Push     | Execute flow runs within containers on Azure's Container Instances service. Requires an Azure account. Flow runs are pushed directly to your environment, without the need for a Prefect worker.                                                  |\n    | Modal - Push                         | Execute [flow runs on Modal](/v3/how-to-guides/deployment_infra/modal). Requires a Modal account. Flow runs are pushed directly to your Modal workspace, without the need for a Prefect worker.                                                   |\n    | Coiled                               | Execute flow runs in the cloud platform of your choice with Coiled.  Makes it easy to run in your account without setting up Kubernetes or other cloud infrastructure.                                                                            |\n    | Prefect Managed                      | Execute flow runs within containers on Prefect managed infrastructure.                                                                                                                                                                            |\n  </Tab>\n\n  <Tab title=\"Self-hosted Prefect server\">\n    | Infrastructure Type           | Description                                                                                                                                                        |\n    | ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n    | Process                       | Execute flow runs as subprocesses on a worker. Works well for local execution when first getting started.                                                          |\n    | AWS Elastic Container Service | Execute flow runs within containers on AWS ECS. Works with EC2 and Fargate clusters. Requires an AWS account.                                                      |\n    | Azure Container Instances     | Execute flow runs within containers on Azure's Container Instances service. Requires an Azure account.                                                             |\n    | Docker                        | Execute flow runs within Docker containers. Works well for managing flow execution environments through Docker images. Requires access to a running Docker daemon. |\n    | Google Cloud Run              | Execute flow runs within containers on Google Cloud Run. Requires a Google Cloud Platform account.                                                                 |\n    | Google Cloud Run V2           | Execute flow runs within containers on Google Cloud Run (V2 API). Requires a Google Cloud Platform account.                                                        |\n    | Google Vertex AI              | Execute flow runs within containers on Google Vertex AI. Requires a Google Cloud Platform account.                                                                 |\n    | Kubernetes                    | Execute flow runs within jobs scheduled on a Kubernetes cluster. Requires a Kubernetes cluster.                                                                    |\n  </Tab>\n</Tabs>\n\n### Work queues\n\nWork queues offer advanced control over how runs are executed. Each work pool has a \"default\" queue which is used if another  work queue name is not specified.\nAdd additional queues to a work pool to enable greater control over work delivery through fine-grained priority and concurrency.\n\n#### Queue priority\n\nEach work queue has a priority indicated by a unique positive integer. Lower numbers take greater priority in the allocation of work with `1` being the highest priority.\nYou can add new queues without changing the rank of the higher-priority queues.\n\n#### Queue concurrency limits\n\nWork queues can also have their own concurrency limits. Each queue is also subject to the global work pool concurrency limit,\nwhich cannot be exceeded.\n\n#### Precise control with priority and concurrency\n\nTogether, work queue priority and concurrency enable precise control over work. For example, a pool may have three queues:\n\n* a \"low\" queue with priority `10` and no concurrency limit\n* a \"high\" queue with priority `5` and a concurrency limit of `3`\n* a \"critical\" queue with priority `1` and a concurrency limit of `1`\n\nThis arrangement enables a pattern of two levels of priority: \"high\" and \"low\" for regularly scheduled flow runs,\nwith the remaining \"critical\" queue for unplanned, urgent work, such as a backfill.\n\nPriority determines the order of flow runs submitted for execution.\nIf all flow runs are capable of being executed with no limitation due to concurrency or otherwise,\npriority is still used to determine order of submission, but there is no impact to execution.\n\nIf not all flow runs can execute, usually as a result of concurrency limits, priority determines which queues receive\nprecedence to submit runs for execution.\n\nPriority for flow run submission proceeds from the highest priority to the lowest priority. In the previous example, all work from the\n\"critical\" queue (priority 1) is submitted, before any work is submitted from \"high\" (priority 5). Once all work is submitted\nfrom priority queue \"critical\", work from the \"high\" queue begins submission.\n\nIf new flow runs are received on the \"critical\" queue while flow runs are still in scheduled on the \"high\" and \"low\" queues, flow run\nsubmission goes back to ensuring all scheduled work is first satisfied. This happens from the highest priority queue, until it is empty,\nin waterfall fashion.\n\n<Tip>\n  **Work queue status**\n\n  A work queue has a `READY` status when it has been polled by a worker in the last 60 seconds. Pausing a work queue gives it a\n  `PAUSED` status and means that it will accept no new work until it is unpaused. A user can control the work queue's paused status in the UI.\n  Unpausing a work queue gives the work queue a `NOT_READY` status unless a worker has polled it in the last 60 seconds.\n</Tip>\n\n## Further reading\n\n* Learn more about [workers](/v3/deploy/infrastructure-concepts/workers) and how they interact with work pools\n* Learn how to [deploy flows](/v3/deploy/infrastructure-concepts/prefect-yaml) that run in work pools\n* Learn how to set up work pools for:\n\n  * [Kubernetes](/v3/how-to-guides/deployment_infra/kubernetes)\n  * [Docker](/v3/how-to-guides/deployment_infra/docker)\n  * [Serverless platforms](/v3/how-to-guides/deployment_infra/serverless)\n  * [Infrastructure managed by Prefect Cloud](/v3/how-to-guides/deployment_infra/managed)",
  "content_length": 13549
}