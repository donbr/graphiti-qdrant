{
  "title": "Simple web scraper",
  "source_url": "https://docs-3.prefect.io/v3/examples/simple-web-scraper",
  "content": "Learn how to scrape article content from web pages with Prefect tasks, retries, and automatic logging.\n\n<a href=\"https://github.com/PrefectHQ/prefect/blob/main/examples/simple_web_scraper.py\" target=\"_blank\">View on GitHub</a>\n\nThis example shows how Prefect enhances regular Python code without getting in its way.\nYou'll write code exactly as you normally would, and Prefect's decorators add production-ready\nfeatures with zero boilerplate.\n\nIn this example you will:\n\n1. Write regular Python functions for web scraping\n2. Add production features ([retries](https://docs.prefect.io/v3/develop/write-tasks#retries), [logging](https://docs.prefect.io/v3/develop/logging#configure-logging)) with just two decorators:\n   * `@task` - Turn any function into a [retryable, observable unit](https://docs.prefect.io/v3/develop/write-tasks#write-and-run-tasks)\n   * `@flow` - Compose tasks into a [reliable pipeline](https://docs.prefect.io/v3/develop/write-flows#write-and-run-flows)\n3. Keep your code clean and Pythonic - no framework-specific patterns needed\n\n## The Power of Regular Python\n\nNotice how the code below is just standard Python with two decorators. You could remove\nthe decorators and the code would still work - Prefect just makes it more resilient.\n\n* Regular Python functions? âœ“\n* Standard libraries (requests, BeautifulSoup)? âœ“\n* Normal control flow (if/else, loops)? âœ“\n* Prefect's magic? Just two decorators! âœ“\n\n```python  theme={null}\nfrom __future__ import annotations\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom prefect import flow, task\n\n```\n\n## Defining tasks\n\nWe separate network IO from parsing so both pieces can be retried or cached independently.\n\n```python  theme={null}\n@task(retries=3, retry_delay_seconds=2)\ndef fetch_html(url: str) -> str:\n    \"\"\"Download page HTML (with retries).\n\n    This is just a regular requests call - Prefect adds retry logic\n    without changing how we write the code.\"\"\"\n    print(f\"Fetching {url} â€¦\")\n    response = requests.get(url, timeout=10)\n    response.raise_for_status()\n    return response.text\n\n\n@task\ndef parse_article(html: str) -> str:\n    \"\"\"Extract article text, skipping code blocks.\n\n    Regular BeautifulSoup parsing with standard Python string operations.\n    Prefect adds observability without changing the logic.\"\"\"\n    soup = BeautifulSoup(html, \"html.parser\")\n\n    # Find main content - just regular BeautifulSoup\n    article = soup.find(\"article\") or soup.find(\"main\")\n    if not article:\n        return \"\"\n\n    # Standard Python all the way\n    for code in article.find_all([\"pre\", \"code\"]):\n        code.decompose()\n\n    content = []\n    for elem in article.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"ul\", \"ol\", \"li\"]):\n        text = elem.get_text().strip()\n        if not text:\n            continue\n\n        if elem.name.startswith(\"h\"):\n            content.extend([\"\\n\" + \"=\" * 80, text.upper(), \"=\" * 80 + \"\\n\"])\n        else:\n            content.extend([text, \"\"])\n\n    return \"\\n\".join(content)\n\n\n```\n\n## Defining a flow\n\n`@flow` elevates a function to a *flow* â€“ the orchestration nucleus that can call\ntasks, other flows, and any Python you need. We enable `log_prints=True` so each\n`print()` surfaces in Prefect Cloud or the local API.\n\n```python  theme={null}\n@flow(log_prints=True)\ndef scrape(urls: list[str] | None = None) -> None:\n    \"\"\"Scrape and print article content from URLs.\n\n    A regular Python function that composes our tasks together.\n    Prefect adds logging and dependency management automatically.\"\"\"\n\n    if urls:\n        for url in urls:\n            content = parse_article(fetch_html(url))\n            print(content if content else \"No article content found.\")\n\n\n```\n\n## Run it!\n\nFeel free to tweak the URL list or the regex and re-run. Prefect hot-reloads your\ncode instantly â€“ no container builds required.\n\n```python  theme={null}\nif __name__ == \"__main__\":\n    urls = [\n        \"https://www.prefect.io/blog/airflow-to-prefect-why-modern-teams-choose-prefect\"\n    ]\n    scrape(urls=urls)\n\n```\n\n## What just happened?\n\nWhen you ran this script, Prefect did a few things behind the scenes:\n\n1. Turned each decorated function into a *task run* or *flow run* with structured state.\n2. Applied retry logic to the network call â€“ a flaky connection would auto-retry up to 3 times.\n3. Captured all `print()` statements so you can view them in the Prefect UI or logs.\n4. Passed the HTML between tasks **in memory** â€“ no external storage required.\n\nYet the code itself is standard Python. You could copy-paste the body of `fetch_html` or\n`parse_article` into a notebook and they'd work exactly the same.\n\n## Key Takeaways\n\n* **Less boilerplate, more Python** â€“ You focus on the scraping logic, Prefect adds production features.\n* **Observability out of the box** â€“ Every run is tracked, making debugging and monitoring trivial.\n* **Portability** â€“ The same script runs on your laptop today and on Kubernetes tomorrow.\n* **Reliability** â€“ Retries, timeouts, and state management are just one decorator away.\n\nHappy scraping â€“ and happy orchestrating! ðŸŽ‰",
  "content_length": 5057
}