{
  "title": "Task runners",
  "source_url": "https://docs-3.prefect.io/v3/concepts/task-runners",
  "content": "Learn about task runners for concurrent, parallel or distributed execution of tasks.\n\nTask runners are a simple and consistent interface to concurrency primitives - they are not required for task execution.\nCalling a task function directly executes the function in the main thread by default,\nblocking execution of its caller until the task completes.\n\nTo enable concurrent, parallel, or distributed execution of tasks, use the `.submit()` or `.map()` methods to submit tasks to a **task runner**.\n\n## Available task runners\n\nThe default task runner in Prefect is the [`ThreadPoolTaskRunner`](/v3/api-ref/python/prefect-task_runners#threadpooltaskrunner),\nwhich runs tasks concurrently in independent threads.\n\nFor CPU-intensive tasks that benefit from process isolation, use the [`ProcessPoolTaskRunner`](/v3/api-ref/python/prefect-task_runners#processpooltaskrunner),\nwhich runs tasks in separate processes using Python's `multiprocessing` module.\n\nFor distributed task execution across multiple machines, you can use one of the following task runners, which are available as extras of the `prefect` library:\n\n* [`DaskTaskRunner`](/integrations/prefect-dask) can run tasks using [`dask.distributed`](http://distributed.dask.org/) (install `prefect[dask]`)\n* [`RayTaskRunner`](/integrations/prefect-ray) can run tasks using [Ray](https://www.ray.io/) (install `prefect[ray]`)\n\n<Note>\n  **Concurrency vs. parallelism**\n\n  * **Concurrency** refers to a system that can do more than one thing simultaneously,\n    but not at the *exact* same time. Think of concurrent execution as non-blocking:\n    within the restrictions of resources available in the execution environment and data dependencies between tasks,\n    execution of one task does not block execution of other tasks in a flow.\n  * **Parallelism** refers to a system that can do more than one thing at the *exact* same time.\n    Within the restrictions of resources available, parallel execution can run tasks at the same time,\n    such as for operations mapped across a dataset.\n</Note>\n\n## Configure a task runner\n\nTo configure a specific task runner, provide a `task_runner` keyword argument to the parent flow:\n\n<CodeGroup>\n  ```python {12} title=\"use threads to run tasks concurrently\" theme={null}\n  from prefect import flow, task\n  from prefect.futures import wait\n  from prefect.task_runners import ThreadPoolTaskRunner\n  import time\n\n  @task\n  def stop_at_floor(floor):\n      print(f\"elevator moving to floor {floor}\")\n      time.sleep(floor)\n      print(f\"elevator stops on floor {floor}\")\n\n  @flow(task_runner=ThreadPoolTaskRunner(max_workers=3))\n  def elevator():\n      floors = []\n\n      for floor in range(10, 0, -1):\n          floors.append(stop_at_floor.submit(floor))\n\n      wait(floors) # wait for the sequence of futures to complete\n  ```\n\n  ```python {12} title=\"use isolated processes to run tasks in parallel\" theme={null}\n  from prefect import flow, task\n  from prefect.futures import wait\n  from prefect.task_runners import ProcessPoolTaskRunner\n  import time\n\n  @task\n  def stop_at_floor(floor):\n      print(f\"elevator moving to floor {floor}\")\n      time.sleep(floor)\n      print(f\"elevator stops on floor {floor}\")\n\n  @flow(task_runner=ProcessPoolTaskRunner(max_workers=3))\n  def elevator():\n      floors = []\n\n      for floor in range(10, 0, -1):\n          floors.append(stop_at_floor.submit(floor))\n\n      wait(floors) # wait for the sequence of futures to complete\n  ```\n</CodeGroup>\n\nThe `max_workers` parameter of the `ThreadPoolTaskRunner` and `ProcessPoolTaskRunner` controls the number of threads or processes (respectively) that the task runner will use to execute tasks.\n\n## Submit tasks to a task runner\n\nWhen you use `.submit()` to submit a task to a task runner, the task runner creates a\n[`PrefectFuture`](/v3/api-ref/python/prefect-futures#prefect.futures.PrefectFuture) for access to the state and\nresult of the task.\n\nA `PrefectFuture` is an object that provides:\n\n* a reference to the result returned by the task\n* a [`State`](/v3/api-ref/python/prefect-server#prefect.server.schemas.states) indicating the current state of the task run\n\n<Warning>\n  `PrefectFuture` objects must be resolved explicitly before returning from a flow or task.\n  Dependencies between futures will be automatically resolved whenever their dependents are resolved.\n  This means that only *terminal* futures need to be resolved, either by:\n\n  * returning the terminal futures from your flow or task\n  * calling `.wait()` or `.result()` on each terminal future\n  * using one of the top level `wait` or `as_completed` utilities to resolve terminal futures\n\n  Not doing so may leave your tasks in an unfinished state.\n</Warning>\n\nWhen you pass a future into a task, Prefect automatically waits for the \"upstream\" task (the one that the future references),\nto reach a final state before starting the downstream task.\n\nThis means that the downstream task won't receive the `PrefectFuture` you passed as an argument.\nInstead, the downstream task receives the value that the upstream task returned.\n\nFor example:\n\n```python  theme={null}\nfrom prefect import flow, task\n\n@task\ndef say_hello(name):\n    return f\"Hello {name}!\"\n\n@task\ndef print_result(result):\n    print(type(result))\n    print(result)\n\n@flow(name=\"hello-flow\")\ndef hello_world():\n    future = say_hello.submit(\"Marvin\")\n    print_result.submit(future).wait()\n\nhello_world()\n```\n\nIf we run this, we see that we only had to wait for the final `print_result` future as Prefect automatically resolved `say_hello` to a string.\n\n### Access results from submitted tasks\n\nYou can access the result of a future explicitly with the `.result()` method.\n\n```python  theme={null}\nfrom prefect import flow, task\n\n@task\ndef my_task():\n    return 42\n\n@flow\ndef my_flow():\n    future = my_task.submit()\n    result = future.result()\n    print(result)\n\nmy_flow()\n```\n\nThe `.result()` method waits for the task to complete before returning the result to the caller.\nIf the task run fails, `.result()` will raise the task run's exception. Disable this behavior\nwith the `raise_on_failure` option:\n\n```python  theme={null}\nfrom prefect import flow, task\n\n@task\ndef my_task():\n    return \"I'm a task!\"\n\n\n@flow\ndef my_flow():\n    future = my_task.submit()\n    result = future.result(raise_on_failure=False)\n    if future.state.is_failed():\n        # `result` is an exception! handle accordingly\n        ...\n    else:\n        # `result` is the expected return value of our task\n        ...\n```\n\n<Note>\n  **A few notes on `.result()`**\n\n  * `.result()` is a blocking call.\n    This means that calling `.result()` will block the caller until the task run completes.\n  * Only use `.result()` when you need to interact directly with the return value of your submitted task;\n    for example, you **should** use `.result()` if passing the return value to a standard Python function (not a\n    Prefect task) but do not need to use `.result()` if you are passing the value to another task (as these futures will be [automatically resolved](/v3/develop/task-runners/#submit-tasks-to-a-task-runner)).\n</Note>\n\n## Design considerations\n\nWhen choosing how and when to achieve concurrency using task runners, consider the following:\n\n1. **Task granularity**: The \"proper\" size for tasks depends on the nature and complexity of the work you're doing, e.g. too many small tasks might create overhead - see [Writing tasks](/v3/develop/write-tasks) for more.\n\n2. **Resource constraints**: Be aware of environment limitations. Using `.map` can create many task instances very quickly, which might exceed your resource availability.\n\n3. **Data transfer**: Large data passed between tasks can impact performance. Consider passing references to external storage when dealing with large datasets.\n\n4. **Parallelism**: For true parallelism (rather than just concurrency), consider using a specialized task runner like the `DaskTaskRunner` or `RayTaskRunner` (or [propose a new task runner type](https://github.com/PrefectHQ/prefect/issues/new?template=2_feature_enhancement.yaml)).\n\n5. **Beware of unsafe global state**: Use of concurrency or parallelism features like `.submit` and `.map` must respect the underlying primitives to avoid unexpected behavior. For example, the default `ThreadPoolTaskRunner` runs each task in a separate thread, which means that any global state must be threadsafe. Similarly, `DaskTaskRunner` and `RayTaskRunner` are multi-process runners that require global state to be [picklable](https://docs.python.org/3/library/pickle.html).\n\n## Further reading\n\n* [Run tasks concurrently](/v3/how-to-guides/workflows/run-work-concurrently)",
  "content_length": 8651
}