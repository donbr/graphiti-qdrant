{
  "title": "How to write transactional workflows",
  "source_url": "https://docs-3.prefect.io/v3/advanced/transactions",
  "content": "Prefect supports *transactional semantics* in your workflows that allow you to rollback on task failure\nand configure groups of tasks that run as an atomic unit.\n\nA *transaction* in Prefect corresponds to a job that needs to be done.\nA transaction runs at most one time, and produces a result record upon completion at a unique address\nspecified by a dynamically computed cache key.\nThese records can be shared across tasks and flows.\n\nUnder the hood, every Prefect task run is governed by a transaction.\nIn the default mode of task execution, all you need to understand about transactions are [the policies\ndetermining the task's cache key computation](/v3/concepts/caching).\n\n<Tip>\n  **Transactions and states**\n\n  Transactions and states are similar but different in important ways.\n  Transactions determine whether a task should or should not execute, whereas states enable visibility into\n  code execution status.\n</Tip>\n\n## Write your first transaction\n\nTasks can be grouped into a common transaction using the `transaction` context manager:\n\n```python  theme={null}\nimport os\nfrom time import sleep\n\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task\ndef write_file(contents: str):\n    \"Writes to a file.\"\n    with open(\"side-effect.txt\", \"w\") as f:\n        f.write(contents)\n\n\n@write_file.on_rollback\ndef del_file(transaction):\n    \"Deletes file.\"\n    os.unlink(\"side-effect.txt\")\n\n\n@task\ndef quality_test():\n    \"Checks contents of file.\"\n    with open(\"side-effect.txt\", \"r\") as f:\n        data = f.readlines()\n\n    if len(data) < 2:\n        raise ValueError(\"Not enough data!\")\n\n\n@flow\ndef pipeline(contents: str):\n    with transaction():\n        write_file(contents)\n        sleep(2) # sleeping to give you a chance to see the file\n        quality_test()\n\n\nif __name__ == \"__main__\":\n    pipeline(contents=\"hello world\")\n```\n\nIf you run this flow `pipeline(contents=\"hello world!\")` it will fail.\nImportantly, after the flow has exited, there is no `\"side-effect.txt\"` file in\nyour working directory.\nThis is because the `write_file` task's `on_rollback` hook was executed due to the transaction failing.\n\n<Tip>\n  **`on_rollback` hooks are different than `on_failure` hooks**\n\n  Note that the `on_rollback` hook is executed when the `quality_test` task fails, not the `write_file`\n  task that it is associated with it, which succeeded.\n  This is because rollbacks occur whenever the transaction a task is participating in fails, even if that\n  failure is outside the task's local scope.\n  This behavior makes transactions a valuable pattern for managing pipeline failure.\n</Tip>\n\n## Transaction lifecycle\n\nEvery transaction goes through at most four lifecycle stages:\n\n* **BEGIN**: in this phase, the transaction's key is computed and looked up. If a record already exists at\n  the key location the transaction considers itself committed.\n* **STAGE**: in this phase, the transaction stages a piece of data to be committed to its result location.\n  Whether this data is committed or rolled back depends on the commit mode of the transaction.\n* **ROLLBACK**: if the transaction encounters *any* error **after** staging, it rolls itself back and does\n  not proceed to commit anything.\n* **COMMIT**: in this final phase, the transaction writes its record to its configured location. At this point\n  the transaction is complete.\n\nIt is important to note that rollbacks only occur *after* the transaction has been staged.\nRevisiting our example from above, there are actually *three* transactions at play:\n\n* the larger transaction that begins when `with transaction()` is executed; this transaction remains active\n  throughout the duration of the subtransactions within it.\n* the transaction associated with the `write_file` task. Upon completion of the `write_file` task, this\n  transaction is now **STAGED**.\n* the transaction associated with the `quality_test` task. This transaction fails before it can be staged,\n  causing a rollback in its parent transaction which then rolls back any staged subtransactions. In particular,\n  the staged `write_file`'s transaction is rolled back.\n\n<Tip>\n  **Tasks also have `on_commit` lifecycle hooks**\n\n  In addition to the `on_rollback` hook, a task can also register `on_commit` hooks that execute whenever\n  its transaction is committed.\n  A task run persists its result only at transaction commit time, which could be significantly\n  after the task's completion time if it is within a long running transaction.\n\n  The signature for an `on_commit` hook is the same as that of an `on_rollback` hook:\n\n  ```python  theme={null}\n  @write_file.on_commit\n  def confirmation(transaction):\n      print(\"committing a record now using the task's cache key!\")\n  ```\n</Tip>\n\n## Idempotency\n\nYou can ensure sections of code are functionally idempotent by wrapping them in a transaction. By specifying a `key` for your transaction, you can ensure that\nyour code is executed only once.\n\nFor example, here's a flow that downloads some data from an API and writes it to a file:\n\n```python  theme={null}\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task\ndef download_data():\n    \"\"\"Imagine this downloads some data from an API\"\"\"\n    return \"some data\"\n\n\n@task\ndef write_data(data: str):\n    \"\"\"This writes the data to a file\"\"\"\n    with open(\"data.txt\", \"w\") as f:\n        f.write(data)\n\n\n@flow(log_prints=True)\ndef pipeline():\n    with transaction(key=\"download-and-write-data\") as txn:\n        if txn.is_committed():\n            print(\"Data file has already been written. Exiting early.\")\n            return\n        data = download_data()\n        write_data(data)\n\n\nif __name__ == \"__main__\":\n    pipeline()\n```\n\nIf you run this flow, it will write data to a file the first time, but it will exit early on subsequent runs because the transaction has already been committed.\n\nGiving the transaction a `key` will cause the transaction to write a record on commit signifying that the transaction has completed.\nThe call to `txn.is_committed()` will return `True` only if the persisted record exists.\n\n### Handling race conditions\n\nPersisting transaction records works well to ensure sequential executions are idempotent, but what about when about when multiple transactions with the same key run at\nthe same time?\n\nBy default, transactions have an isolation level of `READ_COMMITED` which means that they can see any previously committed records, but they are not prevented from overwriting\na record that was created by another transaction between the time they started and the time they committed.\n\nTo see this behavior in action in the following script:\n\n```python  theme={null}\nimport threading\n\nfrom prefect import flow, task\nfrom prefect.transactions import transaction\n\n\n@task\ndef download_data():\n    return f\"{threading.current_thread().name} is the winner!\"\n\n\n@task\ndef write_file(contents: str):\n    \"Writes to a file.\"\n    with open(\"race-condition.txt\", \"w\") as f:\n        f.write(contents)\n\n\n@flow\ndef pipeline(transaction_key: str):\n    with transaction(key=transaction_key) as txn:\n        if txn.is_committed():\n            print(\"Data file has already been written. Exiting early.\")\n            return\n        data = download_data()\n        write_file(data)\n\n\nif __name__ == \"__main__\":\n    # Run the pipeline twice to see the race condition\n    transaction_key = f\"race-condition-{uuid.uuid4()}\"\n    thread_1 = threading.Thread(target=pipeline, name=\"Thread 1\", args=(transaction_key,))\n    thread_2 = threading.Thread(target=pipeline, name=\"Thread 2\", args=(transaction_key,))\n\n    thread_1.start()\n    thread_2.start()\n\n    thread_1.join()\n    thread_2.join()\n```\n\nIf you run this script, you will see that sometimes \"Thread 1 is the winner!\" is written to the file and sometimes \"Thread 2 is the winner!\" is written\n**even though the transactions have the same key**. You can ensure subsequent runs don't exit early by changing the `key` argument between runs.\n\nTo prevent race conditions, you can set the `isolation_level` of a transaction to `SERIALIZABLE`. This will cause each transaction to take a lock on the\nprovided key. This will prevent other transactions from starting until the first transaction has completed.\n\nHere's an updated example that uses `SERIALIZABLE` isolation:\n\n```python  theme={null}\nimport threading\nimport uuid\nfrom prefect import flow, task\nfrom prefect.locking.filesystem import FileSystemLockManager\nfrom prefect.results import ResultStore\nfrom prefect.settings import PREFECT_HOME\nfrom prefect.transactions import IsolationLevel, transaction\n\n\n@task\ndef download_data():\n    return f\"{threading.current_thread().name} is the winner!\"\n\n\n@task\ndef write_file(contents: str):\n    \"Writes to a file.\"\n    with open(\"race-condition.txt\", \"w\") as f:\n        f.write(contents)\n\n\n@flow\ndef pipeline(transaction_key: str):\n    with transaction(\n        key=transaction_key,\n        isolation_level=IsolationLevel.SERIALIZABLE,\n        store=ResultStore(\n            lock_manager=FileSystemLockManager(\n                lock_files_directory=PREFECT_HOME.value() / \"locks\"\n            )\n        ),\n    ) as txn:\n        if txn.is_committed():\n            print(\"Data file has already been written. Exiting early.\")\n            return\n        data = download_data()\n        write_file(data)\n\n\nif __name__ == \"__main__\":\n    transaction_key = f\"race-condition-{uuid.uuid4()}\"\n    thread_1 = threading.Thread(target=pipeline, name=\"Thread 1\", args=(transaction_key,))\n    thread_2 = threading.Thread(target=pipeline, name=\"Thread 2\", args=(transaction_key,))\n\n    thread_1.start()\n    thread_2.start()\n\n    thread_1.join()\n    thread_2.join()\n```\n\nTo use a transaction with the `SERIALIZABLE` isolation level, you must also provide a `lock_manager` to the `transaction` context manager. The\nlock manager is responsible for acquiring and releasing locks on the transaction key. In the example above, we use a `FileSystemLockManager` which\nwill manage locks as files on the current instance's filesystem.\n\nPrefect offers several lock managers for different concurrency use cases:\n\n| Lock Manager        | Storage        | Supports                                    | Module/Package               |\n| ------------------- | -------------- | ------------------------------------------- | ---------------------------- |\n| `MemoryLockManager` | In-memory      | Single-process workflows using threads      | `prefect.locking.memory`     |\n| `FileLockManager`   | Filesystem     | Multi-process workflows on a single machine | `prefect.locking.filesystem` |\n| `RedisLockManager`  | Redis database | Distributed workflows                       | `prefect-redis`              |\n\n## Access data within transactions\n\nKey-value pairs can be set within a transaction and accessed elsewhere within the transaction, including within the `on_rollback` hook.\n\nThe code below shows how to set a key-value pair within a transaction and access it within the `on_rollback` hook:\n\n```python  theme={null}\nimport os\nfrom time import sleep\n\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task\ndef write_file(filename: str, contents: str):\n    \"Writes to a file.\"\n    with open(filename, \"w\") as f:\n        f.write(contents)\n\n\n@write_file.on_rollback\ndef del_file(txn):\n    \"Deletes file.\"\n    os.unlink(txn.get(\"filename\"))\n\n\n@task\ndef quality_test(filename):\n    \"Checks contents of file.\"\n    with open(filename, \"r\") as f:\n        data = f.readlines()\n\n    if len(data) < 2:\n        raise ValueError(f\"Not enough data!\")\n\n\n@flow\ndef pipeline(filename: str, contents: str):\n    with transaction() as txn:\n        txn.set(\"filename\", filename)\n        write_file(filename, contents)\n        sleep(2)  # sleeping to give you a chance to see the file\n        quality_test(filename)\n\n\nif __name__ == \"__main__\":\n    pipeline(\n        filename=\"side-effect.txt\",\n        contents=\"hello world\",\n    )\n```\n\nThe value of `contents` is accessible within the `on_rollback` hook.\n\nUse `get_transaction()` to access the transaction object and `txn.get(\"key\")` to access the value of the key.",
  "content_length": 12130
}