{
  "title": "Share Memory Across Users Using Graphs",
  "source_url": null,
  "content": "In this recipe, we will demonstrate how to share memory across different users by utilizing graphs. We will set up a user thread, add graph-specific data, and integrate the OpenAI client to show how to use both user and graph memory to enhance the context of a chatbot.\n\nFirst, we initialize the Zep client, create a user, and create a thread:\n\n<CodeBlocks>\n  ```python\n  # Initialize the Zep client\n  zep_client = Zep(api_key=\"YOUR_API_KEY\")  # Ensure your API key is set appropriately\n\n  # Add one example user\n  user_id = uuid.uuid4().hex\n  zep_client.user.add(\n      user_id=user_id,\n      first_name=\"Alice\",\n      last_name=\"Smith\",\n      email=\"alice.smith@example.com\"\n  )\n\n  # Create a new thread for the user\n  thread_id = uuid.uuid4().hex\n  zep_client.thread.create(\n      thread_id=thread_id,\n      user_id=user_id,\n  )\n  ```\n\n  ```typescript\n  import { ZepClient } from \"@getzep/zep-cloud\";\n  import { randomUUID } from \"crypto\";\n\n  // Initialize the Zep client\n  const zepClient = new ZepClient({ apiKey: \"YOUR_API_KEY\" });\n\n  // Add one example user\n  const userId = randomUUID().replace(/-/g, \"\");\n  await zepClient.user.add({\n      userId: userId,\n      firstName: \"Alice\",\n      lastName: \"Smith\",\n      email: \"alice.smith@example.com\"\n  });\n\n  // Create a new thread for the user\n  const threadId = randomUUID().replace(/-/g, \"\");\n  await zepClient.thread.create({\n      threadId: threadId,\n      userId: userId\n  });\n  ```\n\n  ```go\n  import (\n      \"context\"\n      \"log\"\n\n      \"github.com/getzep/zep-go/v3\"\n      \"github.com/getzep/zep-go/v3/client\"\n      \"github.com/getzep/zep-go/v3/option\"\n      \"github.com/google/uuid\"\n  )\n\n  // Initialize the Zep client\n  zepClient := client.NewClient(option.WithAPIKey(\"YOUR_API_KEY\"))\n\n  // Add one example user\n  userId := uuid.New().String()\n  _, err := zepClient.User.Add(context.Background(), &zep.CreateUserRequest{\n      UserID:    userId,\n      FirstName: zep.String(\"Alice\"),\n      LastName:  zep.String(\"Smith\"),\n      Email:     zep.String(\"alice.smith@example.com\"),\n  })\n  if err != nil {\n      log.Fatalf(\"Error: %v\", err)\n  }\n\n  // Create a new thread for the user\n  threadId := uuid.New().String()\n  _, err = zepClient.Thread.Create(context.Background(), &zep.CreateThreadRequest{\n      ThreadID: threadId,\n      UserID:   userId,\n  })\n  if err != nil {\n      log.Fatalf(\"Error: %v\", err)\n  }\n  ```\n</CodeBlocks>\n\nNext, we create a new graph and add structured business data to the graph, in the form of a JSON string. This step uses the [Graphs API](/graph-overview).\n\n<CodeBlocks>\n  ```python\n  graph_id = uuid.uuid4().hex\n  zep_client.graph.create(graph_id=graph_id)\n\n  product_json_data = [\n      {\n          \"type\": \"Sedan\",\n          \"gas_mileage\": \"25 mpg\",\n          \"maker\": \"Toyota\"\n      },\n      # ... more cars\n  ]\n\n  json_string = json.dumps(product_json_data)\n  zep_client.graph.add(\n      graph_id=graph_id,\n      type=\"json\",\n      data=json_string,\n  )\n  ```\n\n  ```typescript\n  const graphId = randomUUID().replace(/-/g, \"\");\n  await zepClient.graph.create({ graphId: graphId });\n\n  const productJsonData = [\n      {\n          type: \"Sedan\",\n          gas_mileage: \"25 mpg\",\n          maker: \"Toyota\"\n      },\n      // ... more cars\n  ];\n\n  const jsonString = JSON.stringify(productJsonData);\n  await zepClient.graph.add({\n      graphId: graphId,\n      type: \"json\",\n      data: jsonString\n  });\n  ```\n\n  ```go\n  import \"encoding/json\"\n\n  graphId := uuid.New().String()\n  _, err = zepClient.Graph.Create(context.Background(), &zep.CreateGraphRequest{\n      GraphID: graphId,\n  })\n  if err != nil {\n      log.Fatalf(\"Error: %v\", err)\n  }\n\n  productJsonData := []map[string]string{\n      {\n          \"type\":        \"Sedan\",\n          \"gas_mileage\": \"25 mpg\",\n          \"maker\":       \"Toyota\",\n      },\n      // ... more cars\n  }\n\n  jsonBytes, err := json.Marshal(productJsonData)\n  if err != nil {\n      log.Fatalf(\"Error: %v\", err)\n  }\n  jsonString := string(jsonBytes)\n\n  _, err = zepClient.Graph.Add(context.Background(), &zep.AddDataRequest{\n      GraphID: &graphId,\n      Type:    zep.GraphDataTypeJSON,\n      Data:    jsonString,\n  })\n  if err != nil {\n      log.Fatalf(\"Error: %v\", err)\n  }\n  ```\n</CodeBlocks>\n\nFinally, we initialize the OpenAI client and define a `chatbot_response` function that retrieves user and graph memory, constructs a system/developer message, and generates a contextual response. This leverages the [Threads API](/retrieving-memory#zeps-context-block), [graph API](/searching-the-graph), and the OpenAI chat completions endpoint.\n\n<CodeBlocks>\n  ```python\n  # Initialize the OpenAI client\n  oai_client = OpenAI()\n\n  def chatbot_response(user_message, thread_id):\n      # Retrieve user memory\n      user_memory = zep_client.thread.get_user_context(thread_id)\n\n      # Search the graph using the user message as the query\n      results = zep_client.graph.search(graph_id=graph_id, query=user_message, scope=\"edges\")\n      relevant_graph_edges = results.edges\n      product_context_block = \"Below are some facts related to our car inventory that may help you respond to the user: \\n\"\n      for edge in relevant_graph_edges:\n          product_context_block += f\"{edge.fact}\\n\"\n\n      # Combine context blocks for the developer message\n      developer_message = f\"You are a helpful chat bot assistant for a car sales company. Answer the user's message while taking into account the following background information:\\n{user_memory.context}\\n{product_context_block}\"\n\n      # Generate a response using the OpenAI API\n      completion = oai_client.chat.completions.create(\n          model=\"gpt-4o-mini\",\n          messages=[\n              {\"role\": \"developer\", \"content\": developer_message},\n              {\"role\": \"user\", \"content\": user_message}\n          ]\n      )\n      response = completion.choices[0].message.content\n\n      # Add the conversation to memory\n      messages = [\n          Message(name=\"Alice\", role=\"user\", content=user_message),\n          Message(name=\"AI assistant\", role=\"assistant\", content=response)\n      ]\n      zep_client.thread.add_messages(thread_id, messages=messages)\n\n      return response\n  ```\n\n  ```typescript\n  import OpenAI from \"openai\";\n\n  // Initialize the OpenAI client\n  const oaiClient = new OpenAI();\n\n  async function chatbotResponse(userMessage: string, threadId: string): Promise<string> {\n      // Retrieve user memory\n      const userMemory = await zepClient.thread.getUserContext(threadId);\n\n      // Search the graph using the user message as the query\n      const results = await zepClient.graph.search({\n          graphId: graphId,\n          query: userMessage,\n          scope: \"edges\"\n      });\n\n      const relevantGraphEdges = results.edges || [];\n      let productContextBlock = \"Below are some facts related to our car inventory that may help you respond to the user: \\n\";\n      for (const edge of relevantGraphEdges) {\n          productContextBlock += `${edge.fact}\\n`;\n      }\n\n      // Combine context blocks for the developer message\n      const developerMessage = `You are a helpful chat bot assistant for a car sales company. Answer the user's message while taking into account the following background information:\\n${userMemory.context}\\n${productContextBlock}`;\n\n      // Generate a response using the OpenAI API\n      const completion = await oaiClient.chat.completions.create({\n          model: \"gpt-4o-mini\",\n          messages: [\n              { role: \"developer\", content: developerMessage },\n              { role: \"user\", content: userMessage }\n          ]\n      });\n      const response = completion.choices[0].message.content || \"\";\n\n      // Add the conversation to memory\n      await zepClient.thread.addMessages(threadId, {\n          messages: [\n              { name: \"Alice\", role: \"user\", content: userMessage },\n              { name: \"AI assistant\", role: \"assistant\", content: response }\n          ]\n      });\n\n      return response;\n  }\n  ```\n\n  ```go\n  import (\n      \"context\"\n      \"log\"\n\n      \"github.com/sashabaranov/go-openai\"\n  )\n\n  // Initialize the OpenAI client\n  oaiClient := openai.NewClient(\"YOUR_OPENAI_API_KEY\")\n\n  func chatbotResponse(userMessage, threadId string) (string, error) {\n      ctx := context.Background()\n\n      // Retrieve user memory\n      userMemory, err := zepClient.Thread.GetUserContext(ctx, threadId, &zep.ThreadGetUserContextRequest{})\n      if err != nil {\n          return \"\", err\n      }\n\n      // Search the graph using the user message as the query\n      results, err := zepClient.Graph.Search(ctx, &zep.GraphSearchQuery{\n          GraphID: &graphId,\n          Query:   userMessage,\n          Scope:   zep.GraphSearchScopeEdges.Ptr(),\n      })\n      if err != nil {\n          return \"\", err\n      }\n\n      relevantGraphEdges := results.Edges\n      productContextBlock := \"Below are some facts related to our car inventory that may help you respond to the user: \\n\"\n      for _, edge := range relevantGraphEdges {\n          productContextBlock += edge.Fact + \"\\n\"\n      }\n\n      // Combine context blocks for the developer message\n      developerMessage := \"You are a helpful chat bot assistant for a car sales company. Answer the user's message while taking into account the following background information:\\n\" +\n          userMemory.Context + \"\\n\" + productContextBlock\n\n      // Generate a response using the OpenAI API\n      completion, err := oaiClient.CreateChatCompletion(ctx, openai.ChatCompletionRequest{\n          Model: openai.GPT4oMini,\n          Messages: []openai.ChatCompletionMessage{\n              {\n                  Role:    \"developer\",\n                  Content: developerMessage,\n              },\n              {\n                  Role:    \"user\",\n                  Content: userMessage,\n              },\n          },\n      })\n      if err != nil {\n          return \"\", err\n      }\n      response := completion.Choices[0].Message.Content\n\n      // Add the conversation to memory\n      _, err = zepClient.Thread.AddMessages(ctx, threadId, &zep.AddThreadMessagesRequest{\n          Messages: []*zep.Message{\n              {\n                  Name:    zep.String(\"Alice\"),\n                  Role:    zep.RoleTypeUserRole,\n                  Content: userMessage,\n              },\n              {\n                  Name:    zep.String(\"AI assistant\"),\n                  Role:    zep.RoleTypeAssistantRole,\n                  Content: response,\n              },\n          },\n      })\n      if err != nil {\n          return \"\", err\n      }\n\n      return response, nil\n  }\n  ```\n</CodeBlocks>\n\nThis recipe demonstrated how to share memory across users by utilizing graphs with Zep. We set up user threads, added structured graph data, and integrated the OpenAI client to generate contextual responses, providing a robust approach to memory sharing across different users.",
  "content_length": 10833
}