{
  "title": "LiveKit voice agents",
  "source_url": null,
  "content": "> Add persistent memory to LiveKit voice agents using the zep-livekit package.\n\nThe `zep-livekit` package provides seamless integration between Zep and LiveKit voice agents. Choose between [user-specific conversation memory](/users) or structured [knowledge graph memory](/graph-overview) for intelligent context retrieval in real-time voice interactions.\n\n<Frame background=\"subtle\">\n  <iframe src=\"https://www.youtube.com/embed/FRU8i44bS1E?vq=hd1080\" frameBorder=\"0\" allowFullScreen />\n</Frame>\n\n## Install dependencies\n\n<CodeBlocks>\n  ```bash pip\n  pip install zep-livekit zep-cloud \"livekit-agents[openai,silero]>=1.0.0\"\n  ```\n\n  ```bash uv  \n  uv add zep-livekit zep-cloud \"livekit-agents[openai,silero]>=1.0.0\"\n  ```\n\n  ```bash poetry\n  poetry add zep-livekit zep-cloud \"livekit-agents[openai,silero]>=1.0.0\"\n  ```\n</CodeBlocks>\n\n<Callout intent=\"warning\">\n  **Version Requirements**: This integration requires LiveKit Agents v1.0+ (not v0.x). The examples use the current AgentSession API pattern introduced in v1.0.\n</Callout>\n\n## Environment setup\n\nSet your API keys as environment variables:\n\n```bash\nexport ZEP_API_KEY=\"your_zep_api_key\"\nexport OPENAI_API_KEY=\"your_openai_api_key\"\nexport LIVEKIT_URL=\"your_livekit_url\"\nexport LIVEKIT_API_KEY=\"your_livekit_api_key\"\nexport LIVEKIT_API_SECRET=\"your_livekit_secret\"\n```\n\n## Agent types\n\n**ZepUserAgent**: Uses [user threads](/users) for conversation memory with automatic context injection\\\n**ZepGraphAgent**: Accesses structured knowledge through [custom entity models](/customizing-graph-structure)\n\n## User memory agent\n\n<Steps>\n  ### Step 1: Setup required imports\n\n  ```python\n  import asyncio\n  import logging\n  import os\n  from livekit import agents\n  from livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli\n  from livekit.plugins import openai, silero\n  from zep_cloud.client import AsyncZep\n  from zep_livekit import ZepUserAgent\n  ```\n\n  ### Step 2: Initialize Zep client and create user\n\n  ```python\n  async def entrypoint(ctx: JobContext):\n      # Initialize Zep client\n      zep_client = AsyncZep(api_key=os.environ.get(\"ZEP_API_KEY\"))\n      \n      # Create unique user and thread IDs\n      participant_name = ctx.room.remote_participants[0].name or \"User\"\n      user_id = f\"livekit_{participant_name}_{ctx.room.name}\"\n      thread_id = f\"thread_{ctx.room.name}\"\n      \n      # Create user in Zep (if not exists)\n      try:\n          await zep_client.user.add(\n              user_id=user_id,\n              first_name=participant_name\n          )\n      except Exception as e:\n          logging.info(f\"User might already exist: {e}\")\n      \n      # Create thread for conversation memory\n      try:\n          await zep_client.thread.create(thread_id=thread_id, user_id=user_id)\n      except Exception as e:\n          logging.info(f\"Thread might already exist: {e}\")\n  ```\n\n  ### Step 3: Create agent with memory\n\n  ```python\n      # Create agent session with components\n      session = agents.AgentSession(\n          stt=openai.STT(),\n          llm=openai.LLM(model=\"gpt-4o-mini\"),\n          tts=openai.TTS(),\n          vad=silero.VAD.load(),\n      )\n      \n      # Create Zep memory agent with enhanced configuration\n      zep_agent = ZepUserAgent(\n          zep_client=zep_client,\n          user_id=user_id,\n          thread_id=thread_id,\n          user_message_name=participant_name,\n          assistant_message_name=\"Assistant\",\n          instructions=\"You are a helpful voice assistant with persistent memory. \"\n                      \"Remember details from previous conversations and reference them naturally.\"\n      )\n      \n      # Start the session with the agent\n      await session.start(agent=zep_agent, room=ctx.room)\n  ```\n\n  ### Step 4: Run the voice assistant\n\n  ```python\n      # Voice assistant will now have persistent memory\n      logging.info(\"Voice assistant with Zep memory is running\")\n      \n      # Keep the session running\n      await session.aclose()\n  ```\n</Steps>\n\n<Callout intent=\"info\">\n  **Automatic Memory Integration**: ZepUserAgent automatically captures voice conversation turns and injects relevant context from previous conversations, enabling natural continuity across voice sessions.\n</Callout>\n\n## ZepUserAgent configuration\n\nThe `ZepUserAgent` supports several parameters for customizing memory behavior:\n\n```python\nzep_agent = ZepUserAgent(\n    zep_client=zep_client,\n    user_id=\"user_123\",\n    thread_id=\"thread_456\",\n    user_message_name=\"Alice\",  # Name attribution for user messages\n    assistant_message_name=\"Assistant\",  # Name attribution for AI messages\n    instructions=\"Custom system instructions for the agent\"\n)\n```\n\n**Parameters:**\n\n* `user_message_name`: Optional name for attributing user messages in Zep memory\n* `assistant_message_name`: Optional name for attributing assistant messages in Zep memory\n* `instructions`: System instructions that override the default LiveKit agent instructions\n\n## Knowledge graph agent\n\n<Steps>\n  ### Step 1: Define custom entity models\n\n  ```python\n  from zep_cloud.external_clients.ontology import EntityModel, EntityText\n  from pydantic import Field\n\n  class Person(EntityModel):\n      \"\"\"A person entity for voice interactions.\"\"\"\n      role: EntityText = Field(\n          description=\"person's role or profession\",\n          default=None\n      )\n      interests: EntityText = Field(\n          description=\"topics the person is interested in\",\n          default=None\n      )\n\n  class Topic(EntityModel):\n      \"\"\"A conversation topic or subject.\"\"\"\n      category: EntityText = Field(\n          description=\"category of the topic\",\n          default=None\n      )\n      importance: EntityText = Field(\n          description=\"importance level of this topic to the user\",\n          default=None\n      )\n  ```\n\n  ### Step 2: Setup graph with ontology\n\n  ```python\n  from zep_livekit import ZepGraphAgent\n\n  async def setup_graph_agent(ctx: JobContext):\n      zep_client = AsyncZep(api_key=os.environ.get(\"ZEP_API_KEY\"))\n      \n      # Set ontology for structured knowledge\n      await zep_client.graph.set_ontology(\n          entities={\n              \"Person\": Person,\n              \"Topic\": Topic,\n          }\n      )\n      \n      # Create knowledge graph\n      graph_id = f\"livekit_graph_{ctx.room.name}\"\n      try:\n          await zep_client.graph.create(\n              graph_id=graph_id,\n              name=\"LiveKit Voice Knowledge Graph\"\n          )\n      except Exception as e:\n          logging.info(f\"Graph might already exist: {e}\")\n  ```\n\n  ### Step 3: Create graph memory agent\n\n  ```python\n      # Create agent session with components\n      session = agents.AgentSession(\n          stt=openai.STT(),\n          llm=openai.LLM(model=\"gpt-4o-mini\"),\n          tts=openai.TTS(),\n          vad=silero.VAD.load(),\n      )\n      \n      # Create Zep graph agent\n      zep_agent = ZepGraphAgent(\n          zep_client=zep_client,\n          graph_id=graph_id,\n          facts_limit=15,  # Max facts in context\n          entity_limit=8,   # Max entities in context\n          search_filters={\n              \"node_labels\": [\"Person\"]  # Filter to Person entities only\n          },\n          instructions=\"You are a knowledgeable voice assistant. Use the provided \"\n                      \"context about entities and facts to give informed responses.\"\n      )\n      \n      # Start the session with the graph agent\n      await session.start(agent=zep_agent, room=ctx.room)\n  ```\n</Steps>\n\n<Callout intent=\"info\">\n  **Search Filters**: The `search_filters` parameter allows you to constrain which entities the agent considers when retrieving context. Use `node_labels` to filter by specific entity types defined in your ontology.\n</Callout>\n\n<Callout intent=\"info\">\n  **Graph Memory Context**: ZepGraphAgent automatically extracts structured knowledge from voice conversations and injects relevant facts and entities as context for more intelligent responses.\n</Callout>\n\n## Room-based memory isolation\n\nLiveKit rooms provide natural memory isolation boundaries:\n\n```python\n### Each room gets its own memory context\nroom_name = ctx.room.name\nuser_id = f\"livekit_user_{room_name}\"\nthread_id = f\"thread_{room_name}\"\ngraph_id = f\"graph_{room_name}\"\n\n### Memory is isolated per room/session\nzep_agent = ZepUserAgent(\n    zep_client=zep_client,\n    user_id=user_id,\n    thread_id=thread_id,\n    user_message_name=\"User\",\n    assistant_message_name=\"Assistant\"\n)\n```\n\n## Voice-specific considerations\n\n**Turn Management**: Voice conversations have different turn dynamics than text chat. Zep automatically handles:\n\n* Overlapping speech detection\n* Turn boundary identification\n* Context window management for real-time responses\n\n**Memory Persistence**: Key voice interaction details are preserved:\n\n* Speaker identification\n* Conversation topics and themes\n* User preferences expressed through voice\n* Temporal relationships between topics\n\n## Complete example\n\n```python\nimport asyncio\nimport logging\nimport os\nfrom livekit import agents\nfrom livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli\nfrom livekit.plugins import openai, silero\nfrom zep_cloud.client import AsyncZep\nfrom zep_livekit import ZepUserAgent\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n    \n    # Setup Zep integration\n    zep_client = AsyncZep(api_key=os.environ.get(\"ZEP_API_KEY\"))\n    participant_name = ctx.room.remote_participants[0].name or \"User\"\n    user_id = f\"livekit_{participant_name}_{ctx.room.name}\"\n    thread_id = f\"thread_{ctx.room.name}\"\n    \n    # Create user and thread\n    try:\n        await zep_client.user.add(user_id=user_id, first_name=participant_name)\n        await zep_client.thread.create(thread_id=thread_id, user_id=user_id)\n    except Exception:\n        pass  # Already exists\n    \n    # Create agent session\n    session = agents.AgentSession(\n        stt=openai.STT(),\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        tts=openai.TTS(),\n        vad=silero.VAD.load(),\n    )\n    \n    # Create voice assistant with Zep memory\n    zep_agent = ZepUserAgent(\n        zep_client=zep_client,\n        user_id=user_id,\n        thread_id=thread_id,\n        user_message_name=participant_name,\n        assistant_message_name=\"Assistant\",\n        instructions=\"You are a helpful voice assistant with persistent memory. \"\n                    \"Remember details from previous conversations.\"\n    )\n    \n    # Start the session with the agent\n    await session.start(agent=zep_agent, room=ctx.room)\n    \n    logging.info(\"Voice assistant with Zep memory is running\")\n    await session.aclose()\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\n## Learn more\n\n* [LiveKit Agents Documentation](https://docs.livekit.io/agents/)\n* [Zep LiveKit Integration Repository](https://github.com/getzep/zep/tree/main/integrations/python/zep_livekit)\n* [LiveKit Python SDK](https://github.com/livekit/python-sdks)",
  "content_length": 10978
}