{
  "title": "Adding batch data",
  "source_url": null,
  "content": "> Efficiently add large amounts of data to your graph\n\nThe batch add method enables efficient concurrent processing of large amounts of data to your graph. This experimental feature is designed for scenarios where you need to add multiple episodes quickly, such as backfills, document collections, or historical data imports.\n\n<Warning>\n  This is an experimental feature. While faster than sequential processing, batch ingestion may result in slightly different graph structure compared to sequential processing due to the concurrent nature of the operation.\n</Warning>\n\n## How batch processing works\n\nThe batch add method processes episodes concurrently for improved performance while still preserving temporal relationships between episodes. Unlike sequential processing where episodes are handled one at a time, batch processing can handle up to 20 episodes simultaneously.\n\nThe batch method works with data with a temporal dimension such as evolving chat histories and can process up to 20 episodes at a time of mixed types (text, json, message).\n\n## When to use batch processing\n\nBatch processing is ideal for:\n\n* Historical data backfills\n* Document collection imports\n* Large datasets where processing speed is prioritized\n* Data with a temporal dimension\n\nBatch processing works for all types of data, including data with a temporal dimension such as evolving chat histories.\n\n## Usage example\n\nThe batch add method returns an array of episodes, each containing a `task_id` that can be used to track the processing status of the batch operation. All episodes in a batch share the same `task_id`.\n\n<CodeBlocks>\n  ```python Python\n  from zep_cloud.client import Zep\n  from zep_cloud import EpisodeData\n  import json\n\n  client = Zep(\n      api_key=API_KEY,\n  )\n\n  episodes = [\n      EpisodeData(\n          data=\"This is an example text episode.\",\n          type=\"text\"\n      ),\n      EpisodeData(\n          data=json.dumps({\"name\": \"Eric Clapton\", \"age\": 78, \"genre\": \"Rock\"}),\n          type=\"json\"\n      ),\n      EpisodeData(\n          data=\"User: I really enjoyed the concert last night\",\n          type=\"message\"\n      )\n  ]\n\n  result = client.graph.add_batch(episodes=episodes, graph_id=graph_id)\n\n  # Each episode in the result contains a task_id for tracking batch processing\n  task_id = result[0].task_id\n  print(f\"Batch task ID: {task_id}\")\n  ```\n\n  ```typescript TypeScript\n  import { ZepClient, EpisodeData } from \"@getzep/zep-cloud\";\n\n  const client = new ZepClient({\n    apiKey: API_KEY,\n  });\n\n  const episodes: EpisodeData[] = [\n      {\n          data: \"This is an example text episode.\",\n          type: \"text\"\n      },\n      {\n          data: JSON.stringify({ name: \"Eric Clapton\", age: 78, genre: \"Rock\" }),\n          type: \"json\"\n      },\n      {\n          data: \"User: I really enjoyed the concert last night\",\n          type: \"message\"\n      }\n  ];\n\n  const result = await client.graph.addBatch({ graphId, episodes });\n\n  // Each episode in the result contains a task_id for tracking batch processing\n  const taskId = result[0].taskId;\n  console.log(`Batch task ID: ${taskId}`);\n  ```\n\n  ```go Go\n  import (\n      \"context\"\n      \"encoding/json\"\n      \"log\"\n\n      \"github.com/getzep/zep-go/v3\"\n      zepclient \"github.com/getzep/zep-go/v3/client\"\n  )\n\n  jsonData, _ := json.Marshal(map[string]interface{}{\n      \"name\": \"Eric Clapton\",\n      \"age\": 78,\n      \"genre\": \"Rock\",\n  })\n\n  batchReq := &v3.AddDataBatchRequest{\n      Episodes: []*v3.EpisodeData{\n          {\n              Data: \"This is an example text episode.\",\n              Type: v3.GraphDataTypeText,\n          },\n          {\n              Data: string(jsonData),\n              Type: v3.GraphDataTypeJSON,\n          },\n          {\n              Data: \"User: I really enjoyed the concert last night\",\n              Type: v3.GraphDataTypeMessage,\n          },\n      },\n      GraphID: &graphID,\n  }\n\n  result, err := client.Graph.AddBatch(context.TODO(), batchReq)\n  if err != nil {\n      log.Fatalf(\"Failed to add batch episodes: %v\", err)\n  }\n\n  // Each episode in the result contains a task_id for tracking batch processing\n  taskID := result[0].TaskID\n  log.Printf(\"Batch task ID: %s\", *taskID)\n  ```\n</CodeBlocks>\n\n## Tracking batch processing status\n\nUse the `task_id` returned from batch operations to poll for completion status using `client.task.get()`. This allows you to check when the entire batch has finished processing. See the [Check Data Ingestion Status](/cookbook/check-data-ingestion-status#checking-operation-status-with-task-polling) recipe for a complete example of task polling.\n\n## Adding batch message data to threads\n\nIn addition to adding batch data to your graph, you can add batch message data directly into user threads. The `thread.add_messages_batch` method returns a `task_id` at the root level of the response object that can be used to track the batch processing status. This functionality is important when you want to maintain the structure of threads for your user data, which can affect how the `thread.get_user_context()` method works since it relies on the past messages of a given thread.\n\n<Note>\n  The `thread.add_messages_batch` operation supports a maximum of 30 messages per batch.\n</Note>\n\n<CodeBlocks>\n  ```python Python\n  from zep_cloud import Zep\n  from zep_cloud.types import Message, RoleType\n\n  client = Zep(api_key=API_KEY)\n\n  # Create multiple messages for batch addition\n  messages = [\n      Message(\n          content=\"Hello, I need help with my account\",\n          role=\"user\",\n          name=\"customer\"\n      ),\n      Message(\n          content=\"I'd be happy to help you with your account. What specific issue are you experiencing?\",\n          role=\"assistant\"\n      ),\n      Message(\n          content=\"I can't access my dashboard and keep getting an error\",\n          role=\"user\",\n          name=\"customer\"\n      ),\n      Message(\n          content=\"Let me help you troubleshoot that. Can you tell me what error message you're seeing?\",\n          role=\"assistant\"\n      )\n  ]\n\n  # Add messages in batch to create/populate a thread\n  response = client.thread.add_messages_batch(\n      thread_id=\"your_thread_id\",\n      messages=messages,\n      return_context=True\n  )\n\n  # The task_id is at the root level of the response\n  task_id = response.task_id\n  print(f\"Thread batch task ID: {task_id}\")\n  ```\n\n  ```typescript TypeScript\n  import { ZepClient, AddThreadMessagesRequest } from \"@getzep/zep-cloud\";\n\n  const client = new ZepClient({\n    apiKey: API_KEY,\n  });\n\n  const request: AddThreadMessagesRequest = {\n    messages: [\n      {\n        content: \"Hello, I need help with my account\",\n        role: \"user\",\n        name: \"customer\"\n      },\n      {\n        content: \"I'd be happy to help you with your account. What specific issue are you experiencing?\",\n        role: \"assistant\"\n      },\n      {\n        content: \"I can't access my dashboard and keep getting an error\",\n        role: \"user\",\n        name: \"customer\"\n      },\n      {\n        content: \"Let me help you troubleshoot that. Can you tell me what error message you're seeing?\",\n        role: \"assistant\"\n      }\n    ],\n    returnContext: true\n  };\n\n  // Use addMessagesBatch for concurrent processing (useful for data migrations)\n  const response = await client.thread.addMessagesBatch(\"your_thread_id\", request);\n\n  // The task_id is at the root level of the response\n  const taskId = response.taskId;\n  console.log(`Thread batch task ID: ${taskId}`);\n  ```\n\n  ```go Go\n  import (\n      \"context\"\n      \"github.com/getzep/zep-go/v3\"\n  )\n\n  ctx := context.Background()\n\n  // Add messages in batch to create/populate a thread\n  response, err := client.Thread.AddMessagesBatch(ctx, \"your_thread_id\", &zep.AddThreadMessagesRequest{\n      Messages: []*zep.Message{\n          {\n              Content: \"Hello, I need help with my account\",\n              Role:    \"user\",\n              Name:    zep.String(\"customer\"),\n          },\n          {\n              Content: \"I'd be happy to help you with your account. What specific issue are you experiencing?\",\n              Role:    \"assistant\",\n          },\n          {\n              Content: \"I can't access my dashboard and keep getting an error\",\n              Role:    \"user\",\n              Name:    zep.String(\"customer\"),\n          },\n          {\n              Content: \"Let me help you troubleshoot that. Can you tell me what error message you're seeing?\",\n              Role:    \"assistant\",\n          },\n      },\n      ReturnContext: zep.Bool(true),\n  })\n  if err != nil {\n      // Handle error\n  }\n\n  // The task_id is at the root level of the response\n  taskID := response.TaskID\n  log.Printf(\"Thread batch task ID: %s\", *taskID)\n  ```\n</CodeBlocks>\n\n## Important details\n\n* Maximum of 20 episodes per batch\n* Episodes can be of mixed types (text, json, message)\n* As an experimental feature, may produce slightly different graph structure compared to sequential processing\n* Each episode still respects the 10,000 character limit\n\n## Data size and chunking\n\nThe same data size limits apply to batch processing as sequential processing. Each episode in the batch is limited to 10,000 characters. For larger documents, chunk them into smaller episodes before adding to the batch.\n\nFor chunking strategies and best practices, see the [data size limit and chunking section](/adding-data-to-the-graph#data-size-limit-and-chunking) in the main adding data guide.",
  "content_length": 9427
}