{
  "title": "Built-in Tools",
  "source_url": null,
  "content": "Built-in tools are native tools provided by LLM providers that can be used to enhance your agent's capabilities. Unlike [common tools](../common-tools/), which are custom implementations that Pydantic AI executes, built-in tools are executed directly by the model provider.\n\n## Overview\n\nPydantic AI supports the following built-in tools:\n\n- **WebSearchTool**: Allows agents to search the web\n- **CodeExecutionTool**: Enables agents to execute code in a secure environment\n- **ImageGenerationTool**: Enables agents to generate images\n- **WebFetchTool**: Enables agents to fetch web pages\n- **MemoryTool**: Enables agents to use memory\n- **MCPServerTool**: Enables agents to use remote MCP servers with communication handled by the model provider\n\nThese tools are passed to the agent via the `builtin_tools` parameter and are executed by the model provider's infrastructure.\n\nProvider Support\n\nNot all model providers support built-in tools. If you use a built-in tool with an unsupported provider, Pydantic AI will raise a UserError when you try to run the agent.\n\nIf a provider supports a built-in tool that is not currently supported by Pydantic AI, please file an issue.\n\n## Web Search Tool\n\nThe WebSearchTool allows your agent to search the web, making it ideal for queries that require up-to-date data.\n\n### Provider Support\n\n| Provider | Supported | Notes | | --- | --- | --- | | OpenAI Responses | ✅ | Full feature support. To include search results on the BuiltinToolReturnPart that's available via ModelResponse.builtin_tool_calls, enable the OpenAIResponsesModelSettings.openai_include_web_search_sources [model setting](../agents/#model-run-settings). | | Anthropic | ✅ | Full feature support | | Google | ✅ | No parameter support. No BuiltinToolCallPart or BuiltinToolReturnPart is generated when streaming. Using built-in tools and function tools (including [output tools](../output/#tool-output)) at the same time is not supported; to use structured output, use [`PromptedOutput`](../output/#prompted-output) instead. | | Groq | ✅ | Limited parameter support. To use web search capabilities with Groq, you need to use the [compound models](https://console.groq.com/docs/compound). | | OpenAI Chat Completions | ❌ | Not supported | | Bedrock | ❌ | Not supported | | Mistral | ❌ | Not supported | | Cohere | ❌ | Not supported | | HuggingFace | ❌ | Not supported | | Outlines | ❌ | Not supported |\n\n### Usage\n\n[Learn about Gateway](../gateway) web_search_anthropic.py\n\n```python\nfrom pydantic_ai import Agent, WebSearchTool\n\nagent = Agent('gateway/anthropic:claude-sonnet-4-0', builtin_tools=[WebSearchTool()])\n\nresult = agent.run_sync('Give me a sentence with the biggest news in AI this week.')\nprint(result.output)\n#> Scientists have developed a universal AI detector that can identify deepfake videos.\n\n```\n\nweb_search_anthropic.py\n\n```python\nfrom pydantic_ai import Agent, WebSearchTool\n\nagent = Agent('anthropic:claude-sonnet-4-0', builtin_tools=[WebSearchTool()])\n\nresult = agent.run_sync('Give me a sentence with the biggest news in AI this week.')\nprint(result.output)\n#> Scientists have developed a universal AI detector that can identify deepfake videos.\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\nWith OpenAI, you must use their Responses API to access the web search tool.\n\n[Learn about Gateway](../gateway) web_search_openai.py\n\n```python\nfrom pydantic_ai import Agent, WebSearchTool\n\nagent = Agent('gateway/openai-responses:gpt-5', builtin_tools=[WebSearchTool()])\n\nresult = agent.run_sync('Give me a sentence with the biggest news in AI this week.')\nprint(result.output)\n#> Scientists have developed a universal AI detector that can identify deepfake videos.\n\n```\n\nweb_search_openai.py\n\n```python\nfrom pydantic_ai import Agent, WebSearchTool\n\nagent = Agent('openai-responses:gpt-5', builtin_tools=[WebSearchTool()])\n\nresult = agent.run_sync('Give me a sentence with the biggest news in AI this week.')\nprint(result.output)\n#> Scientists have developed a universal AI detector that can identify deepfake videos.\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n### Configuration Options\n\nThe `WebSearchTool` supports several configuration parameters:\n\n[Learn about Gateway](../gateway) web_search_configured.py\n\n```python\nfrom pydantic_ai import Agent, WebSearchTool, WebSearchUserLocation\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-0',\n    builtin_tools=[\n        WebSearchTool(\n            search_context_size='high',\n            user_location=WebSearchUserLocation(\n                city='San Francisco',\n                country='US',\n                region='CA',\n                timezone='America/Los_Angeles',\n            ),\n            blocked_domains=['example.com', 'spam-site.net'],\n            allowed_domains=None,  # Cannot use both blocked_domains and allowed_domains with Anthropic\n            max_uses=5,  # Anthropic only: limit tool usage\n        )\n    ],\n)\n\nresult = agent.run_sync('Use the web to get the current time.')\nprint(result.output)\n#> In San Francisco, it's 8:21:41 pm PDT on Wednesday, August 6, 2025.\n\n```\n\nweb_search_configured.py\n\n```python\nfrom pydantic_ai import Agent, WebSearchTool, WebSearchUserLocation\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-0',\n    builtin_tools=[\n        WebSearchTool(\n            search_context_size='high',\n            user_location=WebSearchUserLocation(\n                city='San Francisco',\n                country='US',\n                region='CA',\n                timezone='America/Los_Angeles',\n            ),\n            blocked_domains=['example.com', 'spam-site.net'],\n            allowed_domains=None,  # Cannot use both blocked_domains and allowed_domains with Anthropic\n            max_uses=5,  # Anthropic only: limit tool usage\n        )\n    ],\n)\n\nresult = agent.run_sync('Use the web to get the current time.')\nprint(result.output)\n#> In San Francisco, it's 8:21:41 pm PDT on Wednesday, August 6, 2025.\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n#### Provider Support\n\n| Parameter | OpenAI | Anthropic | Groq | | --- | --- | --- | --- | | `search_context_size` | ✅ | ❌ | ❌ | | `user_location` | ✅ | ✅ | ❌ | | `blocked_domains` | ❌ | ✅ | ✅ | | `allowed_domains` | ❌ | ✅ | ✅ | | `max_uses` | ❌ | ✅ | ❌ |\n\nAnthropic Domain Filtering\n\nWith Anthropic, you can only use either `blocked_domains` or `allowed_domains`, not both.\n\n## Code Execution Tool\n\nThe CodeExecutionTool enables your agent to execute code in a secure environment, making it perfect for computational tasks, data analysis, and mathematical operations.\n\n### Provider Support\n\n| Provider | Supported | Notes | | --- | --- | --- | | OpenAI | ✅ | To include code execution output on the BuiltinToolReturnPart that's available via ModelResponse.builtin_tool_calls, enable the OpenAIResponsesModelSettings.openai_include_code_execution_outputs [model setting](../agents/#model-run-settings). If the code execution generated images, like charts, they will be available on ModelResponse.images as BinaryImage objects. The generated image can also be used as [image output](../output/#image-output) for the agent run. | | Google | ✅ | Using built-in tools and function tools (including [output tools](../output/#tool-output)) at the same time is not supported; to use structured output, use [`PromptedOutput`](../output/#prompted-output) instead. | | Anthropic | ✅ | | | Groq | ❌ | | | Bedrock | ❌ | | | Mistral | ❌ | | | Cohere | ❌ | | | HuggingFace | ❌ | | | Outlines | ❌ | |\n\n### Usage\n\n[Learn about Gateway](../gateway) code_execution_basic.py\n\n```python\nfrom pydantic_ai import Agent, CodeExecutionTool\n\nagent = Agent('gateway/anthropic:claude-sonnet-4-0', builtin_tools=[CodeExecutionTool()])\n\nresult = agent.run_sync('Calculate the factorial of 15.')\nprint(result.output)\n#> The factorial of 15 is **1,307,674,368,000**.\nprint(result.response.builtin_tool_calls)\n\"\"\"\n[\n    (\n        BuiltinToolCallPart(\n            tool_name='code_execution',\n            args={\n                'code': 'import math\\n\\n# Calculate factorial of 15\\nresult = math.factorial(15)\\nprint(f\"15! = {result}\")\\n\\n# Let\\'s also show it in a more readable format with commas\\nprint(f\"15! = {result:,}\")'\n            },\n            tool_call_id='srvtoolu_017qRH1J3XrhnpjP2XtzPCmJ',\n            provider_name='anthropic',\n        ),\n        BuiltinToolReturnPart(\n            tool_name='code_execution',\n            content={\n                'content': [],\n                'return_code': 0,\n                'stderr': '',\n                'stdout': '15! = 1307674368000\\n15! = 1,307,674,368,000',\n                'type': 'code_execution_result',\n            },\n            tool_call_id='srvtoolu_017qRH1J3XrhnpjP2XtzPCmJ',\n            timestamp=datetime.datetime(...),\n            provider_name='anthropic',\n        ),\n    )\n]\n\"\"\"\n\n```\n\ncode_execution_basic.py\n\n```python\nfrom pydantic_ai import Agent, CodeExecutionTool\n\nagent = Agent('anthropic:claude-sonnet-4-0', builtin_tools=[CodeExecutionTool()])\n\nresult = agent.run_sync('Calculate the factorial of 15.')\nprint(result.output)\n#> The factorial of 15 is **1,307,674,368,000**.\nprint(result.response.builtin_tool_calls)\n\"\"\"\n[\n    (\n        BuiltinToolCallPart(\n            tool_name='code_execution',\n            args={\n                'code': 'import math\\n\\n# Calculate factorial of 15\\nresult = math.factorial(15)\\nprint(f\"15! = {result}\")\\n\\n# Let\\'s also show it in a more readable format with commas\\nprint(f\"15! = {result:,}\")'\n            },\n            tool_call_id='srvtoolu_017qRH1J3XrhnpjP2XtzPCmJ',\n            provider_name='anthropic',\n        ),\n        BuiltinToolReturnPart(\n            tool_name='code_execution',\n            content={\n                'content': [],\n                'return_code': 0,\n                'stderr': '',\n                'stdout': '15! = 1307674368000\\n15! = 1,307,674,368,000',\n                'type': 'code_execution_result',\n            },\n            tool_call_id='srvtoolu_017qRH1J3XrhnpjP2XtzPCmJ',\n            timestamp=datetime.datetime(...),\n            provider_name='anthropic',\n        ),\n    )\n]\n\"\"\"\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\nIn addition to text output, code execution with OpenAI can generate images as part of their response. Accessing this image via ModelResponse.images or [image output](../output/#image-output) requires the OpenAIResponsesModelSettings.openai_include_code_execution_outputs [model setting](../agents/#model-run-settings) to be enabled.\n\n[Learn about Gateway](../gateway) code_execution_openai.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage, CodeExecutionTool\nfrom pydantic_ai.models.openai import OpenAIResponsesModelSettings\n\nagent = Agent(\n    'gateway/openai-responses:gpt-5',\n    builtin_tools=[CodeExecutionTool()],\n    output_type=BinaryImage,\n    model_settings=OpenAIResponsesModelSettings(openai_include_code_execution_outputs=True),\n)\n\nresult = agent.run_sync('Generate a chart of y=x^2 for x=-5 to 5.')\nassert isinstance(result.output, BinaryImage)\n\n```\n\ncode_execution_openai.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage, CodeExecutionTool\nfrom pydantic_ai.models.openai import OpenAIResponsesModelSettings\n\nagent = Agent(\n    'openai-responses:gpt-5',\n    builtin_tools=[CodeExecutionTool()],\n    output_type=BinaryImage,\n    model_settings=OpenAIResponsesModelSettings(openai_include_code_execution_outputs=True),\n)\n\nresult = agent.run_sync('Generate a chart of y=x^2 for x=-5 to 5.')\nassert isinstance(result.output, BinaryImage)\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n## Image Generation Tool\n\nThe ImageGenerationTool enables your agent to generate images.\n\n### Provider Support\n\n| Provider | Supported | Notes | | --- | --- | --- | | OpenAI Responses | ✅ | Full feature support. Only supported by models newer than `gpt-5`. Metadata about the generated image, like the [`revised_prompt`](https://platform.openai.com/docs/guides/tools-image-generation#revised-prompt) sent to the underlying image model, is available on the BuiltinToolReturnPart that's available via ModelResponse.builtin_tool_calls. | | Google | ✅ | No parameter support. Only supported by [image generation models](https://ai.google.dev/gemini-api/docs/image-generation) like `gemini-2.5-flash-image` and `gemini-3-pro-image-preview`. These models do not support [function tools](../tools/). These models will always have the option of generating images, even if this built-in tool is not explicitly specified. | | Anthropic | ❌ | | | Groq | ❌ | | | Bedrock | ❌ | | | Mistral | ❌ | | | Cohere | ❌ | | | HuggingFace | ❌ | |\n\n### Usage\n\nGenerated images are available on ModelResponse.images as BinaryImage objects:\n\n[Learn about Gateway](../gateway) image_generation_openai.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage, ImageGenerationTool\n\nagent = Agent('gateway/openai-responses:gpt-5', builtin_tools=[ImageGenerationTool()])\n\nresult = agent.run_sync('Tell me a two-sentence story about an axolotl with an illustration.')\nprint(result.output)\n\"\"\"\nOnce upon a time, in a hidden underwater cave, lived a curious axolotl named Pip who loved to explore. One day, while venturing further than usual, Pip discovered a shimmering, ancient coin that granted wishes!\n\"\"\"\n\nassert isinstance(result.response.images[0], BinaryImage)\n\n```\n\nimage_generation_openai.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage, ImageGenerationTool\n\nagent = Agent('openai-responses:gpt-5', builtin_tools=[ImageGenerationTool()])\n\nresult = agent.run_sync('Tell me a two-sentence story about an axolotl with an illustration.')\nprint(result.output)\n\"\"\"\nOnce upon a time, in a hidden underwater cave, lived a curious axolotl named Pip who loved to explore. One day, while venturing further than usual, Pip discovered a shimmering, ancient coin that granted wishes!\n\"\"\"\n\nassert isinstance(result.response.images[0], BinaryImage)\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\nImage generation with Google [image generation models](https://ai.google.dev/gemini-api/docs/image-generation) does not require the `ImageGenerationTool` built-in tool to be explicitly specified:\n\nimage_generation_google.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage\n\nagent = Agent('google-gla:gemini-2.5-flash-image')\n\nresult = agent.run_sync('Tell me a two-sentence story about an axolotl with an illustration.')\nprint(result.output)\n\"\"\"\nOnce upon a time, in a hidden underwater cave, lived a curious axolotl named Pip who loved to explore. One day, while venturing further than usual, Pip discovered a shimmering, ancient coin that granted wishes!\n\"\"\"\n\nassert isinstance(result.response.images[0], BinaryImage)\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\nThe `ImageGenerationTool` can be used together with `output_type=BinaryImage` to get [image output](../output/#image-output). If the `ImageGenerationTool` built-in tool is not explicitly specified, it will be enabled automatically:\n\n[Learn about Gateway](../gateway) image_generation_output.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage\n\nagent = Agent('gateway/openai-responses:gpt-5', output_type=BinaryImage)\n\nresult = agent.run_sync('Generate an image of an axolotl.')\nassert isinstance(result.output, BinaryImage)\n\n```\n\nimage_generation_output.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage\n\nagent = Agent('openai-responses:gpt-5', output_type=BinaryImage)\n\nresult = agent.run_sync('Generate an image of an axolotl.')\nassert isinstance(result.output, BinaryImage)\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n### Configuration Options\n\nThe `ImageGenerationTool` supports several configuration parameters:\n\n[Learn about Gateway](../gateway) image_generation_configured.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage, ImageGenerationTool\n\nagent = Agent(\n    'gateway/openai-responses:gpt-5',\n    builtin_tools=[\n        ImageGenerationTool(\n            background='transparent',\n            input_fidelity='high',\n            moderation='low',\n            output_compression=100,\n            output_format='png',\n            partial_images=3,\n            quality='high',\n            size='1024x1024',\n        )\n    ],\n    output_type=BinaryImage,\n)\n\nresult = agent.run_sync('Generate an image of an axolotl.')\nassert isinstance(result.output, BinaryImage)\n\n```\n\nimage_generation_configured.py\n\n```python\nfrom pydantic_ai import Agent, BinaryImage, ImageGenerationTool\n\nagent = Agent(\n    'openai-responses:gpt-5',\n    builtin_tools=[\n        ImageGenerationTool(\n            background='transparent',\n            input_fidelity='high',\n            moderation='low',\n            output_compression=100,\n            output_format='png',\n            partial_images=3,\n            quality='high',\n            size='1024x1024',\n        )\n    ],\n    output_type=BinaryImage,\n)\n\nresult = agent.run_sync('Generate an image of an axolotl.')\nassert isinstance(result.output, BinaryImage)\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\nFor more details, check the API documentation.\n\n#### Provider Support\n\n| Parameter | OpenAI | Google | | --- | --- | --- | | `background` | ✅ | ❌ | | `input_fidelity` | ✅ | ❌ | | `moderation` | ✅ | ❌ | | `output_compression` | ✅ | ❌ | | `output_format` | ✅ | ❌ | | `partial_images` | ✅ | ❌ | | `quality` | ✅ | ❌ | | `size` | ✅ | ❌ |\n\n## Web Fetch Tool\n\nThe WebFetchTool enables your agent to pull URL contents into its context, allowing it to pull up-to-date information from the web.\n\n### Provider Support\n\n| Provider | Supported | Notes | | --- | --- | --- | | Anthropic | ✅ | Full feature support. Uses Anthropic's [Web Fetch Tool](https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-fetch-tool) internally to retrieve URL contents. | | Google | ✅ | No parameter support. The limits are fixed at 20 URLs per request with a maximum of 34MB per URL. Using built-in tools and function tools (including [output tools](../output/#tool-output)) at the same time is not supported; to use structured output, use [`PromptedOutput`](../output/#prompted-output) instead. | | OpenAI | ❌ | | | Groq | ❌ | | | Bedrock | ❌ | | | Mistral | ❌ | | | Cohere | ❌ | | | HuggingFace | ❌ | | | Outlines | ❌ | |\n\n### Usage\n\nweb_fetch_basic.py\n\n```python\nfrom pydantic_ai import Agent, WebFetchTool\n\nagent = Agent('google-gla:gemini-2.5-flash', builtin_tools=[WebFetchTool()])\n\nresult = agent.run_sync('What is this? https://ai.pydantic.dev')\nprint(result.output)\n#> A Python agent framework for building Generative AI applications.\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n### Configuration Options\n\nThe `WebFetchTool` supports several configuration parameters:\n\n[Learn about Gateway](../gateway) web_fetch_configured.py\n\n```python\nfrom pydantic_ai import Agent, WebFetchTool\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-0',\n    builtin_tools=[\n        WebFetchTool(\n            allowed_domains=['ai.pydantic.dev', 'docs.pydantic.dev'],\n            max_uses=10,\n            enable_citations=True,\n            max_content_tokens=50000,\n        )\n    ],\n)\n\nresult = agent.run_sync(\n    'Compare the documentation at https://ai.pydantic.dev and https://docs.pydantic.dev'\n)\nprint(result.output)\n\"\"\"\nBoth sites provide comprehensive documentation for Pydantic projects. ai.pydantic.dev focuses on PydanticAI, a framework for building AI agents, while docs.pydantic.dev covers Pydantic, the data validation library. They share similar documentation styles and both emphasize type safety and developer experience.\n\"\"\"\n\n```\n\nweb_fetch_configured.py\n\n```python\nfrom pydantic_ai import Agent, WebFetchTool\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-0',\n    builtin_tools=[\n        WebFetchTool(\n            allowed_domains=['ai.pydantic.dev', 'docs.pydantic.dev'],\n            max_uses=10,\n            enable_citations=True,\n            max_content_tokens=50000,\n        )\n    ],\n)\n\nresult = agent.run_sync(\n    'Compare the documentation at https://ai.pydantic.dev and https://docs.pydantic.dev'\n)\nprint(result.output)\n\"\"\"\nBoth sites provide comprehensive documentation for Pydantic projects. ai.pydantic.dev focuses on PydanticAI, a framework for building AI agents, while docs.pydantic.dev covers Pydantic, the data validation library. They share similar documentation styles and both emphasize type safety and developer experience.\n\"\"\"\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n#### Provider Support\n\n| Parameter | Anthropic | Google | | --- | --- | --- | | `max_uses` | ✅ | ❌ | | `allowed_domains` | ✅ | ❌ | | `blocked_domains` | ✅ | ❌ | | `enable_citations` | ✅ | ❌ | | `max_content_tokens` | ✅ | ❌ |\n\nAnthropic Domain Filtering\n\nWith Anthropic, you can only use either `blocked_domains` or `allowed_domains`, not both.\n\n## Memory Tool\n\nThe MemoryTool enables your agent to use memory.\n\n### Provider Support\n\n| Provider | Supported | Notes | | --- | --- | --- | | Anthropic | ✅ | Requires a tool named `memory` to be defined that implements [specific sub-commands](https://docs.claude.com/en/docs/agents-and-tools/tool-use/memory-tool#tool-commands). You can use a subclass of [`anthropic.lib.tools.BetaAbstractMemoryTool`](https://github.com/anthropics/anthropic-sdk-python/blob/main/src/anthropic/lib/tools/_beta_builtin_memory_tool.py) as documented below. | | Google | ❌ | | | OpenAI | ❌ | | | Groq | ❌ | | | Bedrock | ❌ | | | Mistral | ❌ | | | Cohere | ❌ | | | HuggingFace | ❌ | |\n\n### Usage\n\nThe Anthropic SDK provides an abstract [`BetaAbstractMemoryTool`](https://github.com/anthropics/anthropic-sdk-python/blob/main/src/anthropic/lib/tools/_beta_builtin_memory_tool.py) class that you can subclass to create your own memory storage solution (e.g., database, cloud storage, encrypted files, etc.). Their [`LocalFilesystemMemoryTool`](https://github.com/anthropics/anthropic-sdk-python/blob/main/examples/memory/basic.py) example can serve as a starting point.\n\nThe following example uses a subclass that hard-codes a specific memory. The bits specific to Pydantic AI are the `MemoryTool` built-in tool and the `memory` tool definition that forwards commands to the `call` method of the `BetaAbstractMemoryTool` subclass.\n\n[Learn about Gateway](../gateway) anthropic_memory.py\n\n```python\nfrom typing import Any\n\nfrom anthropic.lib.tools import BetaAbstractMemoryTool\nfrom anthropic.types.beta import (\n    BetaMemoryTool20250818CreateCommand,\n    BetaMemoryTool20250818DeleteCommand,\n    BetaMemoryTool20250818InsertCommand,\n    BetaMemoryTool20250818RenameCommand,\n    BetaMemoryTool20250818StrReplaceCommand,\n    BetaMemoryTool20250818ViewCommand,\n)\n\nfrom pydantic_ai import Agent, MemoryTool\n\n\nclass FakeMemoryTool(BetaAbstractMemoryTool):\n    def view(self, command: BetaMemoryTool20250818ViewCommand) -> str:\n        return 'The user lives in Mexico City.'\n\n    def create(self, command: BetaMemoryTool20250818CreateCommand) -> str:\n        return f'File created successfully at {command.path}'\n\n    def str_replace(self, command: BetaMemoryTool20250818StrReplaceCommand) -> str:\n        return f'File {command.path} has been edited'\n\n    def insert(self, command: BetaMemoryTool20250818InsertCommand) -> str:\n        return f'Text inserted at line {command.insert_line} in {command.path}'\n\n    def delete(self, command: BetaMemoryTool20250818DeleteCommand) -> str:\n        return f'File deleted: {command.path}'\n\n    def rename(self, command: BetaMemoryTool20250818RenameCommand) -> str:\n        return f'Renamed {command.old_path} to {command.new_path}'\n\n    def clear_all_memory(self) -> str:\n        return 'All memory cleared'\n\nfake_memory = FakeMemoryTool()\n\nagent = Agent('gateway/anthropic:claude-sonnet-4-5', builtin_tools=[MemoryTool()])\n\n\n@agent.tool_plain\ndef memory(**command: Any) -> Any:\n    return fake_memory.call(command)\n\n\nresult = agent.run_sync('Remember that I live in Mexico City')\nprint(result.output)\n\"\"\"\nGot it! I've recorded that you live in Mexico City. I'll remember this for future reference.\n\"\"\"\n\nresult = agent.run_sync('Where do I live?')\nprint(result.output)\n#> You live in Mexico City.\n\n```\n\nanthropic_memory.py\n\n```python\nfrom typing import Any\n\nfrom anthropic.lib.tools import BetaAbstractMemoryTool\nfrom anthropic.types.beta import (\n    BetaMemoryTool20250818CreateCommand,\n    BetaMemoryTool20250818DeleteCommand,\n    BetaMemoryTool20250818InsertCommand,\n    BetaMemoryTool20250818RenameCommand,\n    BetaMemoryTool20250818StrReplaceCommand,\n    BetaMemoryTool20250818ViewCommand,\n)\n\nfrom pydantic_ai import Agent, MemoryTool\n\n\nclass FakeMemoryTool(BetaAbstractMemoryTool):\n    def view(self, command: BetaMemoryTool20250818ViewCommand) -> str:\n        return 'The user lives in Mexico City.'\n\n    def create(self, command: BetaMemoryTool20250818CreateCommand) -> str:\n        return f'File created successfully at {command.path}'\n\n    def str_replace(self, command: BetaMemoryTool20250818StrReplaceCommand) -> str:\n        return f'File {command.path} has been edited'\n\n    def insert(self, command: BetaMemoryTool20250818InsertCommand) -> str:\n        return f'Text inserted at line {command.insert_line} in {command.path}'\n\n    def delete(self, command: BetaMemoryTool20250818DeleteCommand) -> str:\n        return f'File deleted: {command.path}'\n\n    def rename(self, command: BetaMemoryTool20250818RenameCommand) -> str:\n        return f'Renamed {command.old_path} to {command.new_path}'\n\n    def clear_all_memory(self) -> str:\n        return 'All memory cleared'\n\nfake_memory = FakeMemoryTool()\n\nagent = Agent('anthropic:claude-sonnet-4-5', builtin_tools=[MemoryTool()])\n\n\n@agent.tool_plain\ndef memory(**command: Any) -> Any:\n    return fake_memory.call(command)\n\n\nresult = agent.run_sync('Remember that I live in Mexico City')\nprint(result.output)\n\"\"\"\nGot it! I've recorded that you live in Mexico City. I'll remember this for future reference.\n\"\"\"\n\nresult = agent.run_sync('Where do I live?')\nprint(result.output)\n#> You live in Mexico City.\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\n## MCP Server Tool\n\nThe MCPServerTool allows your agent to use remote MCP servers with communication handled by the model provider.\n\nThis requires the MCP server to live at a public URL the provider can reach and does not support many of the advanced features of Pydantic AI's agent-side [MCP support](../mcp/client/), but can result in optimized context use and caching, and faster performance due to the lack of a round-trip back to Pydantic AI.\n\n### Provider Support\n\n| Provider | Supported | Notes | | --- | --- | --- | | OpenAI Responses | ✅ | Full feature support. [Connectors](https://platform.openai.com/docs/guides/tools-connectors-mcp#connectors) can be used by specifying a special `x-openai-connector:<connector_id>` URL. | | Anthropic | ✅ | Full feature support | | Google | ❌ | Not supported | | Groq | ❌ | Not supported | | OpenAI Chat Completions | ❌ | Not supported | | Bedrock | ❌ | Not supported | | Mistral | ❌ | Not supported | | Cohere | ❌ | Not supported | | HuggingFace | ❌ | Not supported |\n\n### Usage\n\n[Learn about Gateway](../gateway) mcp_server_anthropic.py\n\n```python\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='deepwiki',\n            url='https://mcp.deepwiki.com/mcp',  # (1)\n        )\n    ]\n)\n\nresult = agent.run_sync('Tell me about the pydantic/pydantic-ai repo.')\nprint(result.output)\n\"\"\"\nThe pydantic/pydantic-ai repo is a Python agent framework for building Generative AI applications.\n\"\"\"\n\n```\n\n1. The [DeepWiki MCP server](https://docs.devin.ai/work-with-devin/deepwiki-mcp) does not require authorization.\n\nmcp_server_anthropic.py\n\n```python\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='deepwiki',\n            url='https://mcp.deepwiki.com/mcp',  # (1)\n        )\n    ]\n)\n\nresult = agent.run_sync('Tell me about the pydantic/pydantic-ai repo.')\nprint(result.output)\n\"\"\"\nThe pydantic/pydantic-ai repo is a Python agent framework for building Generative AI applications.\n\"\"\"\n\n```\n\n1. The [DeepWiki MCP server](https://docs.devin.ai/work-with-devin/deepwiki-mcp) does not require authorization.\n\n*(This example is complete, it can be run \"as is\")*\n\nWith OpenAI, you must use their Responses API to access the MCP server tool:\n\n[Learn about Gateway](../gateway) mcp_server_openai.py\n\n```python\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'gateway/openai-responses:gpt-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='deepwiki',\n            url='https://mcp.deepwiki.com/mcp',  # (1)\n        )\n    ]\n)\n\nresult = agent.run_sync('Tell me about the pydantic/pydantic-ai repo.')\nprint(result.output)\n\"\"\"\nThe pydantic/pydantic-ai repo is a Python agent framework for building Generative AI applications.\n\"\"\"\n\n```\n\n1. The [DeepWiki MCP server](https://docs.devin.ai/work-with-devin/deepwiki-mcp) does not require authorization.\n\nmcp_server_openai.py\n\n```python\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'openai-responses:gpt-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='deepwiki',\n            url='https://mcp.deepwiki.com/mcp',  # (1)\n        )\n    ]\n)\n\nresult = agent.run_sync('Tell me about the pydantic/pydantic-ai repo.')\nprint(result.output)\n\"\"\"\nThe pydantic/pydantic-ai repo is a Python agent framework for building Generative AI applications.\n\"\"\"\n\n```\n\n1. The [DeepWiki MCP server](https://docs.devin.ai/work-with-devin/deepwiki-mcp) does not require authorization.\n\n*(This example is complete, it can be run \"as is\")*\n\n### Configuration Options\n\nThe `MCPServerTool` supports several configuration parameters for custom MCP servers:\n\n[Learn about Gateway](../gateway) mcp_server_configured_url.py\n\n```python\nimport os\n\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'gateway/openai-responses:gpt-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='github',\n            url='https://api.githubcopilot.com/mcp/',\n            authorization_token=os.getenv('GITHUB_ACCESS_TOKEN', 'mock-access-token'),  # (1)\n            allowed_tools=['search_repositories', 'list_commits'],\n            description='GitHub MCP server',\n            headers={'X-Custom-Header': 'custom-value'},\n        )\n    ]\n)\n\nresult = agent.run_sync('Tell me about the pydantic/pydantic-ai repo.')\nprint(result.output)\n\"\"\"\nThe pydantic/pydantic-ai repo is a Python agent framework for building Generative AI applications.\n\"\"\"\n\n```\n\n1. The [GitHub MCP server](https://github.com/github/github-mcp-server) requires an authorization token.\n\nmcp_server_configured_url.py\n\n```python\nimport os\n\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'openai-responses:gpt-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='github',\n            url='https://api.githubcopilot.com/mcp/',\n            authorization_token=os.getenv('GITHUB_ACCESS_TOKEN', 'mock-access-token'),  # (1)\n            allowed_tools=['search_repositories', 'list_commits'],\n            description='GitHub MCP server',\n            headers={'X-Custom-Header': 'custom-value'},\n        )\n    ]\n)\n\nresult = agent.run_sync('Tell me about the pydantic/pydantic-ai repo.')\nprint(result.output)\n\"\"\"\nThe pydantic/pydantic-ai repo is a Python agent framework for building Generative AI applications.\n\"\"\"\n\n```\n\n1. The [GitHub MCP server](https://github.com/github/github-mcp-server) requires an authorization token.\n\nFor OpenAI Responses, you can use a [connector](https://platform.openai.com/docs/guides/tools-connectors-mcp#connectors) by specifying a special `x-openai-connector:` URL:\n\n*(This example is complete, it can be run \"as is\")*\n\n[Learn about Gateway](../gateway) mcp_server_configured_connector_id.py\n\n```python\nimport os\n\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'gateway/openai-responses:gpt-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='google-calendar',\n            url='x-openai-connector:connector_googlecalendar',\n            authorization_token=os.getenv('GOOGLE_API_KEY', 'mock-api-key'), # (1)\n        )\n    ]\n)\n\nresult = agent.run_sync('What do I have on my calendar today?')\nprint(result.output)\n#> You're going to spend all day playing with Pydantic AI.\n\n```\n\n1. OpenAI's Google Calendar connector requires an [authorization token](https://platform.openai.com/docs/guides/tools-connectors-mcp#authorizing-a-connector).\n\nmcp_server_configured_connector_id.py\n\n```python\nimport os\n\nfrom pydantic_ai import Agent, MCPServerTool\n\nagent = Agent(\n    'openai-responses:gpt-5',\n    builtin_tools=[\n        MCPServerTool(\n            id='google-calendar',\n            url='x-openai-connector:connector_googlecalendar',\n            authorization_token=os.getenv('GOOGLE_API_KEY', 'mock-api-key'), # (1)\n        )\n    ]\n)\n\nresult = agent.run_sync('What do I have on my calendar today?')\nprint(result.output)\n#> You're going to spend all day playing with Pydantic AI.\n\n```\n\n1. OpenAI's Google Calendar connector requires an [authorization token](https://platform.openai.com/docs/guides/tools-connectors-mcp#authorizing-a-connector).\n\n*(This example is complete, it can be run \"as is\")*\n\n#### Provider Support\n\n| Parameter | OpenAI | Anthropic | | --- | --- | --- | | `authorization_token` | ✅ | ✅ | | `allowed_tools` | ✅ | ✅ | | `description` | ✅ | ❌ | | `headers` | ✅ | ❌ |\n\n## API Reference\n\nFor complete API documentation, see the [API Reference](../api/builtin_tools/).",
  "content_length": 33573
}