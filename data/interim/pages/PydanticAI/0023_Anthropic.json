{
  "title": "Anthropic",
  "source_url": null,
  "content": "## Install\n\nTo use `AnthropicModel` models, you need to either install `pydantic-ai`, or install `pydantic-ai-slim` with the `anthropic` optional group:\n\n```bash\npip install \"pydantic-ai-slim[anthropic]\"\n\n```\n\n```bash\nuv add \"pydantic-ai-slim[anthropic]\"\n\n```\n\n## Configuration\n\nTo use [Anthropic](https://anthropic.com) through their API, go to [console.anthropic.com/settings/keys](https://console.anthropic.com/settings/keys) to generate an API key.\n\n`AnthropicModelName` contains a list of available Anthropic models.\n\n## Environment variable\n\nOnce you have the API key, you can set it as an environment variable:\n\n```bash\nexport ANTHROPIC_API_KEY='your-api-key'\n\n```\n\nYou can then use `AnthropicModel` by name:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('gateway/anthropic:claude-sonnet-4-5')\n...\n\n```\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('anthropic:claude-sonnet-4-5')\n...\n\n```\n\nOr initialise the model directly with just the model name:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\n\nmodel = AnthropicModel('claude-sonnet-4-5')\nagent = Agent(model)\n...\n\n```\n\n## `provider` argument\n\nYou can provide a custom `Provider` via the `provider` argument:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.providers.anthropic import AnthropicProvider\n\nmodel = AnthropicModel(\n    'claude-sonnet-4-5', provider=AnthropicProvider(api_key='your-api-key')\n)\nagent = Agent(model)\n...\n\n```\n\n## Custom HTTP Client\n\nYou can customize the `AnthropicProvider` with a custom `httpx.AsyncClient`:\n\n```python\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.providers.anthropic import AnthropicProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = AnthropicModel(\n    'claude-sonnet-4-5',\n    provider=AnthropicProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n\n```\n\n## Prompt Caching\n\nAnthropic supports [prompt caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching) to reduce costs by caching parts of your prompts. Pydantic AI provides four ways to use prompt caching:\n\n1. **Cache User Messages with CachePoint**: Insert a `CachePoint` marker in your user messages to cache everything before it\n1. **Cache System Instructions**: Set AnthropicModelSettings.anthropic_cache_instructions to `True` (uses 5m TTL by default) or specify `'5m'` / `'1h'` directly\n1. **Cache Tool Definitions**: Set AnthropicModelSettings.anthropic_cache_tool_definitions to `True` (uses 5m TTL by default) or specify `'5m'` / `'1h'` directly\n1. **Cache All Messages**: Set AnthropicModelSettings.anthropic_cache_messages to `True` to automatically cache all messages\n\n### Example 1: Automatic Message Caching\n\nUse `anthropic_cache_messages` to automatically cache all messages up to and including the newest user message:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    system_prompt='You are a helpful assistant.',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_messages=True,  # Automatically caches the last message\n    ),\n)\n\n### The last message is automatically cached - no need for manual CachePoint\nresult1 = agent.run_sync('What is the capital of France?')\n\n### Subsequent calls with similar conversation benefit from cache\nresult2 = agent.run_sync('What is the capital of Germany?')\nprint(f'Cache write: {result1.usage().cache_write_tokens}')\nprint(f'Cache read: {result2.usage().cache_read_tokens}')\n\n```\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    system_prompt='You are a helpful assistant.',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_messages=True,  # Automatically caches the last message\n    ),\n)\n\n### The last message is automatically cached - no need for manual CachePoint\nresult1 = agent.run_sync('What is the capital of France?')\n\n### Subsequent calls with similar conversation benefit from cache\nresult2 = agent.run_sync('What is the capital of Germany?')\nprint(f'Cache write: {result1.usage().cache_write_tokens}')\nprint(f'Cache read: {result2.usage().cache_read_tokens}')\n\n```\n\n### Example 2: Comprehensive Caching Strategy\n\nCombine multiple cache settings for maximum savings:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    system_prompt='Detailed instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True,      # Cache system instructions\n        anthropic_cache_tool_definitions='1h',  # Cache tool definitions with 1h TTL\n        anthropic_cache_messages=True,          # Also cache the last message\n    ),\n)\n\n@agent.tool\ndef search_docs(ctx: RunContext, query: str) -> str:\n    \"\"\"Search documentation.\"\"\"\n    return f'Results for {query}'\n\n\nresult = agent.run_sync('Search for Python best practices')\nprint(result.output)\n\n```\n\n```python\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    system_prompt='Detailed instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True,      # Cache system instructions\n        anthropic_cache_tool_definitions='1h',  # Cache tool definitions with 1h TTL\n        anthropic_cache_messages=True,          # Also cache the last message\n    ),\n)\n\n@agent.tool\ndef search_docs(ctx: RunContext, query: str) -> str:\n    \"\"\"Search documentation.\"\"\"\n    return f'Results for {query}'\n\n\nresult = agent.run_sync('Search for Python best practices')\nprint(result.output)\n\n```\n\n### Example 3: Fine-Grained Control with CachePoint\n\nUse manual `CachePoint` markers to control cache locations precisely:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent, CachePoint\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    system_prompt='Instructions...',\n)\n\n### Manually control cache points for specific content blocks\nresult = agent.run_sync([\n    'Long context from documentation...',\n    CachePoint(),  # Cache everything up to this point\n    'First question'\n])\nprint(result.output)\n\n```\n\n```python\nfrom pydantic_ai import Agent, CachePoint\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    system_prompt='Instructions...',\n)\n\n### Manually control cache points for specific content blocks\nresult = agent.run_sync([\n    'Long context from documentation...',\n    CachePoint(),  # Cache everything up to this point\n    'First question'\n])\nprint(result.output)\n\n```\n\n### Accessing Cache Usage Statistics\n\nAccess cache usage statistics via `result.usage()`:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    system_prompt='Instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True  # Default 5m TTL\n    ),\n)\n\nresult = agent.run_sync('Your question')\nusage = result.usage()\nprint(f'Cache write tokens: {usage.cache_write_tokens}')\nprint(f'Cache read tokens: {usage.cache_read_tokens}')\n\n```\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    system_prompt='Instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True  # Default 5m TTL\n    ),\n)\n\nresult = agent.run_sync('Your question')\nusage = result.usage()\nprint(f'Cache write tokens: {usage.cache_write_tokens}')\nprint(f'Cache read tokens: {usage.cache_read_tokens}')\n\n```\n\n### Cache Point Limits\n\nAnthropic enforces a maximum of 4 cache points per request. Pydantic AI automatically manages this limit to ensure your requests always comply without errors.\n\n#### How Cache Points Are Allocated\n\nCache points can be placed in three locations:\n\n1. **System Prompt**: Via `anthropic_cache_instructions` setting (adds cache point to last system prompt block)\n1. **Tool Definitions**: Via `anthropic_cache_tool_definitions` setting (adds cache point to last tool definition)\n1. **Messages**: Via `CachePoint` markers or `anthropic_cache_messages` setting (adds cache points to message content)\n\nEach setting uses **at most 1 cache point**, but you can combine them.\n\n#### Example: Using All 3 Cache Point Sources\n\nDefine an agent with all cache settings enabled:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent, CachePoint\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    system_prompt='Detailed instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True,      # 1 cache point\n        anthropic_cache_tool_definitions=True,  # 1 cache point\n        anthropic_cache_messages=True,          # 1 cache point\n    ),\n)\n\n@agent.tool_plain\ndef my_tool() -> str:\n    return 'result'\n\n\n### This uses 3 cache points (instructions + tools + last message)\n### You can add 1 more CachePoint marker before hitting the limit\nresult = agent.run_sync([\n    'Context', CachePoint(),  # 4th cache point - OK\n    'Question'\n])\nprint(result.output)\nusage = result.usage()\nprint(f'Cache write tokens: {usage.cache_write_tokens}')\nprint(f'Cache read tokens: {usage.cache_read_tokens}')\n\n```\n\n```python\nfrom pydantic_ai import Agent, CachePoint\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    system_prompt='Detailed instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True,      # 1 cache point\n        anthropic_cache_tool_definitions=True,  # 1 cache point\n        anthropic_cache_messages=True,          # 1 cache point\n    ),\n)\n\n@agent.tool_plain\ndef my_tool() -> str:\n    return 'result'\n\n\n### This uses 3 cache points (instructions + tools + last message)\n### You can add 1 more CachePoint marker before hitting the limit\nresult = agent.run_sync([\n    'Context', CachePoint(),  # 4th cache point - OK\n    'Question'\n])\nprint(result.output)\nusage = result.usage()\nprint(f'Cache write tokens: {usage.cache_write_tokens}')\nprint(f'Cache read tokens: {usage.cache_read_tokens}')\n\n```\n\n#### Automatic Cache Point Limiting\n\nWhen cache points from all sources (settings + `CachePoint` markers) exceed 4, Pydantic AI automatically removes excess cache points from **older message content** (keeping the most recent ones).\n\nDefine an agent with 2 cache points from settings:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent, CachePoint\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'gateway/anthropic:claude-sonnet-4-5',\n    system_prompt='Instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True,      # 1 cache point\n        anthropic_cache_tool_definitions=True,  # 1 cache point\n    ),\n)\n\n@agent.tool_plain\ndef search() -> str:\n    return 'data'\n\n### Already using 2 cache points (instructions + tools)\n### Can add 2 more CachePoint markers (4 total limit)\nresult = agent.run_sync([\n    'Context 1', CachePoint(),  # Oldest - will be removed\n    'Context 2', CachePoint(),  # Will be kept (3rd point)\n    'Context 3', CachePoint(),  # Will be kept (4th point)\n    'Question'\n])\n### Final cache points: instructions + tools + Context 2 + Context 3 = 4\nprint(result.output)\nusage = result.usage()\nprint(f'Cache write tokens: {usage.cache_write_tokens}')\nprint(f'Cache read tokens: {usage.cache_read_tokens}')\n\n```\n\n```python\nfrom pydantic_ai import Agent, CachePoint\nfrom pydantic_ai.models.anthropic import AnthropicModelSettings\n\nagent = Agent(\n    'anthropic:claude-sonnet-4-5',\n    system_prompt='Instructions...',\n    model_settings=AnthropicModelSettings(\n        anthropic_cache_instructions=True,      # 1 cache point\n        anthropic_cache_tool_definitions=True,  # 1 cache point\n    ),\n)\n\n@agent.tool_plain\ndef search() -> str:\n    return 'data'\n\n### Already using 2 cache points (instructions + tools)\n### Can add 2 more CachePoint markers (4 total limit)\nresult = agent.run_sync([\n    'Context 1', CachePoint(),  # Oldest - will be removed\n    'Context 2', CachePoint(),  # Will be kept (3rd point)\n    'Context 3', CachePoint(),  # Will be kept (4th point)\n    'Question'\n])\n### Final cache points: instructions + tools + Context 2 + Context 3 = 4\nprint(result.output)\nusage = result.usage()\nprint(f'Cache write tokens: {usage.cache_write_tokens}')\nprint(f'Cache read tokens: {usage.cache_read_tokens}')\n\n```\n\n**Key Points**:\n\n- System and tool cache points are **always preserved**\n- The cache point created by `anthropic_cache_messages` is **always preserved** (as it's the newest message cache point)\n- Additional `CachePoint` markers in messages are removed from oldest to newest when the limit is exceeded\n- This ensures critical caching (instructions/tools) is maintained while still benefiting from message-level caching",
  "content_length": 13587
}