{
  "title": "`pydantic_ai.ag_ui`",
  "source_url": null,
  "content": "Provides an AG-UI protocol adapter for the Pydantic AI agent.\n\nThis package provides seamless integration between pydantic-ai agents and ag-ui for building interactive AI applications with streaming event-based communication.\n\n### SSE_CONTENT_TYPE\n\n```python\nSSE_CONTENT_TYPE = 'text/event-stream'\n\n```\n\nContent type header value for Server-Sent Events (SSE).\n\n### OnCompleteFunc\n\n```python\nOnCompleteFunc: TypeAlias = (\n    Callable[[AgentRunResult[Any]], None]\n    | Callable[[AgentRunResult[Any]], Awaitable[None]]\n    | Callable[[AgentRunResult[Any]], AsyncIterator[EventT]]\n)\n\n```\n\nCallback function type that receives the `AgentRunResult` of the completed run. Can be sync, async, or an async generator of protocol-specific events.\n\n### StateDeps\n\nBases: `Generic[StateT]`\n\nDependency type that holds state.\n\nThis class is used to manage the state of an agent run. It allows setting the state of the agent run with a specific type of state model, which must be a subclass of `BaseModel`.\n\nThe state is set using the `state` setter by the `Adapter` when the run starts.\n\nImplements the `StateHandler` protocol.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/_adapter.py`\n\n```python\n@dataclass\nclass StateDeps(Generic[StateT]):\n    \"\"\"Dependency type that holds state.\n\n    This class is used to manage the state of an agent run. It allows setting\n    the state of the agent run with a specific type of state model, which must\n    be a subclass of `BaseModel`.\n\n    The state is set using the `state` setter by the `Adapter` when the run starts.\n\n    Implements the `StateHandler` protocol.\n    \"\"\"\n\n    state: StateT\n\n```\n\n### StateHandler\n\nBases: `Protocol`\n\nProtocol for state handlers in agent runs. Requires the class to be a dataclass with a `state` field.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/_adapter.py`\n\n```python\n@runtime_checkable\nclass StateHandler(Protocol):\n    \"\"\"Protocol for state handlers in agent runs. Requires the class to be a dataclass with a `state` field.\"\"\"\n\n    # Has to be a dataclass so we can use `replace` to update the state.\n    # From https://github.com/python/typeshed/blob/9ab7fde0a0cd24ed7a72837fcb21093b811b80d8/stdlib/_typeshed/__init__.pyi#L352\n    __dataclass_fields__: ClassVar[dict[str, Field[Any]]]\n\n    @property\n    def state(self) -> Any:\n        \"\"\"Get the current state of the agent run.\"\"\"\n        ...\n\n    @state.setter\n    def state(self, state: Any) -> None:\n        \"\"\"Set the state of the agent run.\n\n        This method is called to update the state of the agent run with the\n        provided state.\n\n        Args:\n            state: The run state.\n        \"\"\"\n        ...\n\n```\n\n#### state\n\n```python\nstate: Any\n\n```\n\nGet the current state of the agent run.\n\n### AGUIApp\n\nBases: `Generic[AgentDepsT, OutputDataT]`, `Starlette`\n\nASGI application for running Pydantic AI agents with AG-UI protocol support.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py`\n\n```python\nclass AGUIApp(Generic[AgentDepsT, OutputDataT], Starlette):\n    \"\"\"ASGI application for running Pydantic AI agents with AG-UI protocol support.\"\"\"\n\n    def __init__(\n        self,\n        agent: AbstractAgent[AgentDepsT, OutputDataT],\n        *,\n        # AGUIAdapter.dispatch_request parameters\n        output_type: OutputSpec[Any] | None = None,\n        message_history: Sequence[ModelMessage] | None = None,\n        deferred_tool_results: DeferredToolResults | None = None,\n        model: Model | KnownModelName | str | None = None,\n        deps: AgentDepsT = None,\n        model_settings: ModelSettings | None = None,\n        usage_limits: UsageLimits | None = None,\n        usage: RunUsage | None = None,\n        infer_name: bool = True,\n        toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,\n        builtin_tools: Sequence[AbstractBuiltinTool] | None = None,\n        on_complete: OnCompleteFunc[Any] | None = None,\n        # Starlette parameters\n        debug: bool = False,\n        routes: Sequence[BaseRoute] | None = None,\n        middleware: Sequence[Middleware] | None = None,\n        exception_handlers: Mapping[Any, ExceptionHandler] | None = None,\n        on_startup: Sequence[Callable[[], Any]] | None = None,\n        on_shutdown: Sequence[Callable[[], Any]] | None = None,\n        lifespan: Lifespan[Self] | None = None,\n    ) -> None:\n        \"\"\"An ASGI application that handles every request by running the agent and streaming the response.\n\n        Note that the `deps` will be the same for each request, with the exception of the frontend state that's\n        injected into the `state` field of a `deps` object that implements the [`StateHandler`][pydantic_ai.ui.StateHandler] protocol.\n        To provide different `deps` for each request (e.g. based on the authenticated user),\n        use [`AGUIAdapter.run_stream()`][pydantic_ai.ui.ag_ui.AGUIAdapter.run_stream] or\n        [`AGUIAdapter.dispatch_request()`][pydantic_ai.ui.ag_ui.AGUIAdapter.dispatch_request] instead.\n\n        Args:\n            agent: The agent to run.\n\n            output_type: Custom output type to use for this run, `output_type` may only be used if the agent has\n                no output validators since output validators would expect an argument that matches the agent's\n                output type.\n            message_history: History of the conversation so far.\n            deferred_tool_results: Optional results for deferred tool calls in the message history.\n            model: Optional model to use for this run, required if `model` was not set when creating the agent.\n            deps: Optional dependencies to use for this run.\n            model_settings: Optional settings to use for this model's request.\n            usage_limits: Optional limits on model request count or token usage.\n            usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n            infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n            toolsets: Optional additional toolsets for this run.\n            builtin_tools: Optional additional builtin tools for this run.\n            on_complete: Optional callback function called when the agent run completes successfully.\n                The callback receives the completed [`AgentRunResult`][pydantic_ai.agent.AgentRunResult] and can access `all_messages()` and other result data.\n\n            debug: Boolean indicating if debug tracebacks should be returned on errors.\n            routes: A list of routes to serve incoming HTTP and WebSocket requests.\n            middleware: A list of middleware to run for every request. A starlette application will always\n                automatically include two middleware classes. `ServerErrorMiddleware` is added as the very\n                outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack.\n                `ExceptionMiddleware` is added as the very innermost middleware, to deal with handled\n                exception cases occurring in the routing or endpoints.\n            exception_handlers: A mapping of either integer status codes, or exception class types onto\n                callables which handle the exceptions. Exception handler callables should be of the form\n                `handler(request, exc) -> response` and may be either standard functions, or async functions.\n            on_startup: A list of callables to run on application startup. Startup handler callables do not\n                take any arguments, and may be either standard functions, or async functions.\n            on_shutdown: A list of callables to run on application shutdown. Shutdown handler callables do\n                not take any arguments, and may be either standard functions, or async functions.\n            lifespan: A lifespan context function, which can be used to perform startup and shutdown tasks.\n                This is a newer style that replaces the `on_startup` and `on_shutdown` handlers. Use one or\n                the other, not both.\n        \"\"\"\n        super().__init__(\n            debug=debug,\n            routes=routes,\n            middleware=middleware,\n            exception_handlers=exception_handlers,\n            on_startup=on_startup,\n            on_shutdown=on_shutdown,\n            lifespan=lifespan,\n        )\n\n        async def run_agent(request: Request) -> Response:\n            \"\"\"Endpoint to run the agent with the provided input data.\"\"\"\n            # `dispatch_request` will store the frontend state from the request on `deps.state` (if it implements the `StateHandler` protocol),\n            # so we need to copy the deps to avoid different requests mutating the same deps object.\n            nonlocal deps\n            if isinstance(deps, StateHandler):  # pragma: no branch\n                deps = replace(deps)\n\n            return await AGUIAdapter[AgentDepsT, OutputDataT].dispatch_request(\n                request,\n                agent=agent,\n                output_type=output_type,\n                message_history=message_history,\n                deferred_tool_results=deferred_tool_results,\n                model=model,\n                deps=deps,\n                model_settings=model_settings,\n                usage_limits=usage_limits,\n                usage=usage,\n                infer_name=infer_name,\n                toolsets=toolsets,\n                builtin_tools=builtin_tools,\n                on_complete=on_complete,\n            )\n\n        self.router.add_route('/', run_agent, methods=['POST'])\n\n```\n\n#### __init__\n\n```python\n__init__(\n    agent: AbstractAgent[AgentDepsT, OutputDataT],\n    *,\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: (\n        DeferredToolResults | None\n    ) = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: (\n        Sequence[AbstractToolset[AgentDepsT]] | None\n    ) = None,\n    builtin_tools: (\n        Sequence[AbstractBuiltinTool] | None\n    ) = None,\n    on_complete: OnCompleteFunc[Any] | None = None,\n    debug: bool = False,\n    routes: Sequence[BaseRoute] | None = None,\n    middleware: Sequence[Middleware] | None = None,\n    exception_handlers: (\n        Mapping[Any, ExceptionHandler] | None\n    ) = None,\n    on_startup: Sequence[Callable[[], Any]] | None = None,\n    on_shutdown: Sequence[Callable[[], Any]] | None = None,\n    lifespan: Lifespan[Self] | None = None\n) -> None\n\n```\n\nAn ASGI application that handles every request by running the agent and streaming the response.\n\nNote that the `deps` will be the same for each request, with the exception of the frontend state that's injected into the `state` field of a `deps` object that implements the StateHandler protocol. To provide different `deps` for each request (e.g. based on the authenticated user), use AGUIAdapter.run_stream() or AGUIAdapter.dispatch_request() instead.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `agent` | `AbstractAgent[AgentDepsT, OutputDataT]` | The agent to run. | *required* | | `output_type` | `OutputSpec[Any] | None` | Custom output type to use for this run, output_type may only be used if the agent has no output validators since output validators would expect an argument that matches the agent's output type. | `None` | | `message_history` | `Sequence[ModelMessage] | None` | History of the conversation so far. | `None` | | `deferred_tool_results` | `DeferredToolResults | None` | Optional results for deferred tool calls in the message history. | `None` | | `model` | `Model | KnownModelName | str | None` | Optional model to use for this run, required if model was not set when creating the agent. | `None` | | `deps` | `AgentDepsT` | Optional dependencies to use for this run. | `None` | | `model_settings` | `ModelSettings | None` | Optional settings to use for this model's request. | `None` | | `usage_limits` | `UsageLimits | None` | Optional limits on model request count or token usage. | `None` | | `usage` | `RunUsage | None` | Optional usage to start with, useful for resuming a conversation or agents used in tools. | `None` | | `infer_name` | `bool` | Whether to try to infer the agent name from the call frame if it's not set. | `True` | | `toolsets` | `Sequence[AbstractToolset[AgentDepsT]] | None` | Optional additional toolsets for this run. | `None` | | `builtin_tools` | `Sequence[AbstractBuiltinTool] | None` | Optional additional builtin tools for this run. | `None` | | `on_complete` | `OnCompleteFunc[Any] | None` | Optional callback function called when the agent run completes successfully. The callback receives the completed AgentRunResult and can access all_messages() and other result data. | `None` | | `debug` | `bool` | Boolean indicating if debug tracebacks should be returned on errors. | `False` | | `routes` | `Sequence[BaseRoute] | None` | A list of routes to serve incoming HTTP and WebSocket requests. | `None` | | `middleware` | `Sequence[Middleware] | None` | A list of middleware to run for every request. A starlette application will always automatically include two middleware classes. ServerErrorMiddleware is added as the very outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack. ExceptionMiddleware is added as the very innermost middleware, to deal with handled exception cases occurring in the routing or endpoints. | `None` | | `exception_handlers` | `Mapping[Any, ExceptionHandler] | None` | A mapping of either integer status codes, or exception class types onto callables which handle the exceptions. Exception handler callables should be of the form handler(request, exc) -> response and may be either standard functions, or async functions. | `None` | | `on_startup` | `Sequence[Callable[[], Any]] | None` | A list of callables to run on application startup. Startup handler callables do not take any arguments, and may be either standard functions, or async functions. | `None` | | `on_shutdown` | `Sequence[Callable[[], Any]] | None` | A list of callables to run on application shutdown. Shutdown handler callables do not take any arguments, and may be either standard functions, or async functions. | `None` | | `lifespan` | `Lifespan[Self] | None` | A lifespan context function, which can be used to perform startup and shutdown tasks. This is a newer style that replaces the on_startup and on_shutdown handlers. Use one or the other, not both. | `None` |\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py`\n\n```python\ndef __init__(\n    self,\n    agent: AbstractAgent[AgentDepsT, OutputDataT],\n    *,\n    # AGUIAdapter.dispatch_request parameters\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: DeferredToolResults | None = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,\n    builtin_tools: Sequence[AbstractBuiltinTool] | None = None,\n    on_complete: OnCompleteFunc[Any] | None = None,\n    # Starlette parameters\n    debug: bool = False,\n    routes: Sequence[BaseRoute] | None = None,\n    middleware: Sequence[Middleware] | None = None,\n    exception_handlers: Mapping[Any, ExceptionHandler] | None = None,\n    on_startup: Sequence[Callable[[], Any]] | None = None,\n    on_shutdown: Sequence[Callable[[], Any]] | None = None,\n    lifespan: Lifespan[Self] | None = None,\n) -> None:\n    \"\"\"An ASGI application that handles every request by running the agent and streaming the response.\n\n    Note that the `deps` will be the same for each request, with the exception of the frontend state that's\n    injected into the `state` field of a `deps` object that implements the [`StateHandler`][pydantic_ai.ui.StateHandler] protocol.\n    To provide different `deps` for each request (e.g. based on the authenticated user),\n    use [`AGUIAdapter.run_stream()`][pydantic_ai.ui.ag_ui.AGUIAdapter.run_stream] or\n    [`AGUIAdapter.dispatch_request()`][pydantic_ai.ui.ag_ui.AGUIAdapter.dispatch_request] instead.\n\n    Args:\n        agent: The agent to run.\n\n        output_type: Custom output type to use for this run, `output_type` may only be used if the agent has\n            no output validators since output validators would expect an argument that matches the agent's\n            output type.\n        message_history: History of the conversation so far.\n        deferred_tool_results: Optional results for deferred tool calls in the message history.\n        model: Optional model to use for this run, required if `model` was not set when creating the agent.\n        deps: Optional dependencies to use for this run.\n        model_settings: Optional settings to use for this model's request.\n        usage_limits: Optional limits on model request count or token usage.\n        usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n        infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n        toolsets: Optional additional toolsets for this run.\n        builtin_tools: Optional additional builtin tools for this run.\n        on_complete: Optional callback function called when the agent run completes successfully.\n            The callback receives the completed [`AgentRunResult`][pydantic_ai.agent.AgentRunResult] and can access `all_messages()` and other result data.\n\n        debug: Boolean indicating if debug tracebacks should be returned on errors.\n        routes: A list of routes to serve incoming HTTP and WebSocket requests.\n        middleware: A list of middleware to run for every request. A starlette application will always\n            automatically include two middleware classes. `ServerErrorMiddleware` is added as the very\n            outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack.\n            `ExceptionMiddleware` is added as the very innermost middleware, to deal with handled\n            exception cases occurring in the routing or endpoints.\n        exception_handlers: A mapping of either integer status codes, or exception class types onto\n            callables which handle the exceptions. Exception handler callables should be of the form\n            `handler(request, exc) -> response` and may be either standard functions, or async functions.\n        on_startup: A list of callables to run on application startup. Startup handler callables do not\n            take any arguments, and may be either standard functions, or async functions.\n        on_shutdown: A list of callables to run on application shutdown. Shutdown handler callables do\n            not take any arguments, and may be either standard functions, or async functions.\n        lifespan: A lifespan context function, which can be used to perform startup and shutdown tasks.\n            This is a newer style that replaces the `on_startup` and `on_shutdown` handlers. Use one or\n            the other, not both.\n    \"\"\"\n    super().__init__(\n        debug=debug,\n        routes=routes,\n        middleware=middleware,\n        exception_handlers=exception_handlers,\n        on_startup=on_startup,\n        on_shutdown=on_shutdown,\n        lifespan=lifespan,\n    )\n\n    async def run_agent(request: Request) -> Response:\n        \"\"\"Endpoint to run the agent with the provided input data.\"\"\"\n        # `dispatch_request` will store the frontend state from the request on `deps.state` (if it implements the `StateHandler` protocol),\n        # so we need to copy the deps to avoid different requests mutating the same deps object.\n        nonlocal deps\n        if isinstance(deps, StateHandler):  # pragma: no branch\n            deps = replace(deps)\n\n        return await AGUIAdapter[AgentDepsT, OutputDataT].dispatch_request(\n            request,\n            agent=agent,\n            output_type=output_type,\n            message_history=message_history,\n            deferred_tool_results=deferred_tool_results,\n            model=model,\n            deps=deps,\n            model_settings=model_settings,\n            usage_limits=usage_limits,\n            usage=usage,\n            infer_name=infer_name,\n            toolsets=toolsets,\n            builtin_tools=builtin_tools,\n            on_complete=on_complete,\n        )\n\n    self.router.add_route('/', run_agent, methods=['POST'])\n\n```\n\n### handle_ag_ui_request\n\n```python\nhandle_ag_ui_request(\n    agent: AbstractAgent[AgentDepsT, Any],\n    request: Request,\n    *,\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: (\n        DeferredToolResults | None\n    ) = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: (\n        Sequence[AbstractToolset[AgentDepsT]] | None\n    ) = None,\n    on_complete: OnCompleteFunc[BaseEvent] | None = None\n) -> Response\n\n```\n\nHandle an AG-UI request by running the agent and returning a streaming response.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `agent` | `AbstractAgent[AgentDepsT, Any]` | The agent to run. | *required* | | `request` | `Request` | The Starlette request (e.g. from FastAPI) containing the AG-UI run input. | *required* | | `output_type` | `OutputSpec[Any] | None` | Custom output type to use for this run, output_type may only be used if the agent has no output validators since output validators would expect an argument that matches the agent's output type. | `None` | | `message_history` | `Sequence[ModelMessage] | None` | History of the conversation so far. | `None` | | `deferred_tool_results` | `DeferredToolResults | None` | Optional results for deferred tool calls in the message history. | `None` | | `model` | `Model | KnownModelName | str | None` | Optional model to use for this run, required if model was not set when creating the agent. | `None` | | `deps` | `AgentDepsT` | Optional dependencies to use for this run. | `None` | | `model_settings` | `ModelSettings | None` | Optional settings to use for this model's request. | `None` | | `usage_limits` | `UsageLimits | None` | Optional limits on model request count or token usage. | `None` | | `usage` | `RunUsage | None` | Optional usage to start with, useful for resuming a conversation or agents used in tools. | `None` | | `infer_name` | `bool` | Whether to try to infer the agent name from the call frame if it's not set. | `True` | | `toolsets` | `Sequence[AbstractToolset[AgentDepsT]] | None` | Optional additional toolsets for this run. | `None` | | `on_complete` | `OnCompleteFunc[BaseEvent] | None` | Optional callback function called when the agent run completes successfully. The callback receives the completed AgentRunResult and can access all_messages() and other result data. | `None` |\n\nReturns:\n\n| Type | Description | | --- | --- | | `Response` | A streaming Starlette response with AG-UI protocol events. |\n\nSource code in `pydantic_ai_slim/pydantic_ai/ag_ui.py`\n\n```python\nasync def handle_ag_ui_request(\n    agent: AbstractAgent[AgentDepsT, Any],\n    request: Request,\n    *,\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: DeferredToolResults | None = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,\n    on_complete: OnCompleteFunc[BaseEvent] | None = None,\n) -> Response:\n    \"\"\"Handle an AG-UI request by running the agent and returning a streaming response.\n\n    Args:\n        agent: The agent to run.\n        request: The Starlette request (e.g. from FastAPI) containing the AG-UI run input.\n\n        output_type: Custom output type to use for this run, `output_type` may only be used if the agent has no\n            output validators since output validators would expect an argument that matches the agent's output type.\n        message_history: History of the conversation so far.\n        deferred_tool_results: Optional results for deferred tool calls in the message history.\n        model: Optional model to use for this run, required if `model` was not set when creating the agent.\n        deps: Optional dependencies to use for this run.\n        model_settings: Optional settings to use for this model's request.\n        usage_limits: Optional limits on model request count or token usage.\n        usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n        infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n        toolsets: Optional additional toolsets for this run.\n        on_complete: Optional callback function called when the agent run completes successfully.\n            The callback receives the completed [`AgentRunResult`][pydantic_ai.agent.AgentRunResult] and can access `all_messages()` and other result data.\n\n    Returns:\n        A streaming Starlette response with AG-UI protocol events.\n    \"\"\"\n    return await AGUIAdapter[AgentDepsT].dispatch_request(\n        request,\n        agent=agent,\n        deps=deps,\n        output_type=output_type,\n        message_history=message_history,\n        deferred_tool_results=deferred_tool_results,\n        model=model,\n        model_settings=model_settings,\n        usage_limits=usage_limits,\n        usage=usage,\n        infer_name=infer_name,\n        toolsets=toolsets,\n        on_complete=on_complete,\n    )\n\n```\n\n### run_ag_ui\n\n```python\nrun_ag_ui(\n    agent: AbstractAgent[AgentDepsT, Any],\n    run_input: RunAgentInput,\n    accept: str = SSE_CONTENT_TYPE,\n    *,\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: (\n        DeferredToolResults | None\n    ) = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: (\n        Sequence[AbstractToolset[AgentDepsT]] | None\n    ) = None,\n    on_complete: OnCompleteFunc[BaseEvent] | None = None\n) -> AsyncIterator[str]\n\n```\n\nRun the agent with the AG-UI run input and stream AG-UI protocol events.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `agent` | `AbstractAgent[AgentDepsT, Any]` | The agent to run. | *required* | | `run_input` | `RunAgentInput` | The AG-UI run input containing thread_id, run_id, messages, etc. | *required* | | `accept` | `str` | The accept header value for the run. | `SSE_CONTENT_TYPE` | | `output_type` | `OutputSpec[Any] | None` | Custom output type to use for this run, output_type may only be used if the agent has no output validators since output validators would expect an argument that matches the agent's output type. | `None` | | `message_history` | `Sequence[ModelMessage] | None` | History of the conversation so far. | `None` | | `deferred_tool_results` | `DeferredToolResults | None` | Optional results for deferred tool calls in the message history. | `None` | | `model` | `Model | KnownModelName | str | None` | Optional model to use for this run, required if model was not set when creating the agent. | `None` | | `deps` | `AgentDepsT` | Optional dependencies to use for this run. | `None` | | `model_settings` | `ModelSettings | None` | Optional settings to use for this model's request. | `None` | | `usage_limits` | `UsageLimits | None` | Optional limits on model request count or token usage. | `None` | | `usage` | `RunUsage | None` | Optional usage to start with, useful for resuming a conversation or agents used in tools. | `None` | | `infer_name` | `bool` | Whether to try to infer the agent name from the call frame if it's not set. | `True` | | `toolsets` | `Sequence[AbstractToolset[AgentDepsT]] | None` | Optional additional toolsets for this run. | `None` | | `on_complete` | `OnCompleteFunc[BaseEvent] | None` | Optional callback function called when the agent run completes successfully. The callback receives the completed AgentRunResult and can access all_messages() and other result data. | `None` |\n\nYields:\n\n| Type | Description | | --- | --- | | `AsyncIterator[str]` | Streaming event chunks encoded as strings according to the accept header value. |\n\nSource code in `pydantic_ai_slim/pydantic_ai/ag_ui.py`\n\n```python\ndef run_ag_ui(\n    agent: AbstractAgent[AgentDepsT, Any],\n    run_input: RunAgentInput,\n    accept: str = SSE_CONTENT_TYPE,\n    *,\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: DeferredToolResults | None = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,\n    on_complete: OnCompleteFunc[BaseEvent] | None = None,\n) -> AsyncIterator[str]:\n    \"\"\"Run the agent with the AG-UI run input and stream AG-UI protocol events.\n\n    Args:\n        agent: The agent to run.\n        run_input: The AG-UI run input containing thread_id, run_id, messages, etc.\n        accept: The accept header value for the run.\n\n        output_type: Custom output type to use for this run, `output_type` may only be used if the agent has no\n            output validators since output validators would expect an argument that matches the agent's output type.\n        message_history: History of the conversation so far.\n        deferred_tool_results: Optional results for deferred tool calls in the message history.\n        model: Optional model to use for this run, required if `model` was not set when creating the agent.\n        deps: Optional dependencies to use for this run.\n        model_settings: Optional settings to use for this model's request.\n        usage_limits: Optional limits on model request count or token usage.\n        usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n        infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n        toolsets: Optional additional toolsets for this run.\n        on_complete: Optional callback function called when the agent run completes successfully.\n            The callback receives the completed [`AgentRunResult`][pydantic_ai.agent.AgentRunResult] and can access `all_messages()` and other result data.\n\n    Yields:\n        Streaming event chunks encoded as strings according to the accept header value.\n    \"\"\"\n    adapter = AGUIAdapter(agent=agent, run_input=run_input, accept=accept)\n    return adapter.encode_stream(\n        adapter.run_stream(\n            output_type=output_type,\n            message_history=message_history,\n            deferred_tool_results=deferred_tool_results,\n            model=model,\n            deps=deps,\n            model_settings=model_settings,\n            usage_limits=usage_limits,\n            usage=usage,\n            infer_name=infer_name,\n            toolsets=toolsets,\n            on_complete=on_complete,\n        ),\n    )\n\n```",
  "content_length": 32007
}