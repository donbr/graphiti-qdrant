{
  "title": "Graphs",
  "source_url": null,
  "content": "Don't use a nail gun unless you need a nail gun\n\nIf Pydantic AI [agents](../agents/) are a hammer, and [multi-agent workflows](../multi-agent-applications/) are a sledgehammer, then graphs are a nail gun:\n\n- sure, nail guns look cooler than hammers\n- but nail guns take a lot more setup than hammers\n- and nail guns don't make you a better builder, they make you a builder with a nail gun\n- Lastly, (and at the risk of torturing this metaphor), if you're a fan of medieval tools like mallets and untyped Python, you probably won't like nail guns or our approach to graphs. (But then again, if you're not a fan of type hints in Python, you've probably already bounced off Pydantic AI to use one of the toy agent frameworks — good luck, and feel free to borrow my sledgehammer when you realize you need it)\n\nIn short, graphs are a powerful tool, but they're not the right tool for every job. Please consider other [multi-agent approaches](../multi-agent-applications/) before proceeding.\n\nIf you're not confident a graph-based approach is a good idea, it might be unnecessary.\n\nGraphs and finite state machines (FSMs) are a powerful abstraction to model, execute, control and visualize complex workflows.\n\nAlongside Pydantic AI, we've developed `pydantic-graph` — an async graph and state machine library for Python where nodes and edges are defined using type hints.\n\nWhile this library is developed as part of Pydantic AI; it has no dependency on `pydantic-ai` and can be considered as a pure graph-based state machine library. You may find it useful whether or not you're using Pydantic AI or even building with GenAI.\n\n`pydantic-graph` is designed for advanced users and makes heavy use of Python generics and type hints. It is not designed to be as beginner-friendly as Pydantic AI.\n\n## Installation\n\n`pydantic-graph` is a required dependency of `pydantic-ai`, and an optional dependency of `pydantic-ai-slim`, see [installation instructions](../install/#slim-install) for more information. You can also install it directly:\n\n```bash\npip install pydantic-graph\n\n```\n\n```bash\nuv add pydantic-graph\n\n```\n\n## Graph Types\n\n`pydantic-graph` is made up of a few key components:\n\n### GraphRunContext\n\nGraphRunContext — The context for the graph run, similar to Pydantic AI's RunContext. This holds the state of the graph and dependencies and is passed to nodes when they're run.\n\n`GraphRunContext` is generic in the state type of the graph it's used in, StateT.\n\n### End\n\nEnd — return value to indicate the graph run should end.\n\n`End` is generic in the graph return type of the graph it's used in, RunEndT.\n\n### Nodes\n\nSubclasses of BaseNode define nodes for execution in the graph.\n\nNodes, which are generally dataclasses, generally consist of:\n\n- fields containing any parameters required/optional when calling the node\n- the business logic to execute the node, in the run method\n- return annotations of the run method, which are read by `pydantic-graph` to determine the outgoing edges of the node\n\nNodes are generic in:\n\n- **state**, which must have the same type as the state of graphs they're included in, StateT has a default of `None`, so if you're not using state you can omit this generic parameter, see [stateful graphs](#stateful-graphs) for more information\n- **deps**, which must have the same type as the deps of the graph they're included in, DepsT has a default of `None`, so if you're not using deps you can omit this generic parameter, see [dependency injection](#dependency-injection) for more information\n- **graph return type** — this only applies if the node returns End. RunEndT has a default of Never so this generic parameter can be omitted if the node doesn't return `End`, but must be included if it does.\n\nHere's an example of a start or intermediate node in a graph — it can't end the run as it doesn't return End:\n\nintermediate_node.py\n\n```python\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, GraphRunContext\n\n\n@dataclass\nclass MyNode(BaseNode[MyState]):  # (1)!\n    foo: int  # (2)!\n\n    async def run(\n        self,\n        ctx: GraphRunContext[MyState],  # (3)!\n    ) -> AnotherNode:  # (4)!\n        ...\n        return AnotherNode()\n\n```\n\n1. State in this example is `MyState` (not shown), hence `BaseNode` is parameterized with `MyState`. This node can't end the run, so the `RunEndT` generic parameter is omitted and defaults to `Never`.\n1. `MyNode` is a dataclass and has a single field `foo`, an `int`.\n1. The `run` method takes a `GraphRunContext` parameter, again parameterized with state `MyState`.\n1. The return type of the `run` method is `AnotherNode` (not shown), this is used to determine the outgoing edges of the node.\n\nWe could extend `MyNode` to optionally end the run if `foo` is divisible by 5:\n\nintermediate_or_end_node.py\n\n```python\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, GraphRunContext\n\n\n@dataclass\nclass MyNode(BaseNode[MyState, None, int]):  # (1)!\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext[MyState],\n    ) -> AnotherNode | End[int]:  # (2)!\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return AnotherNode()\n\n```\n\n1. We parameterize the node with the return type (`int` in this case) as well as state. Because generic parameters are positional-only, we have to include `None` as the second parameter representing deps.\n1. The return type of the `run` method is now a union of `AnotherNode` and `End[int]`, this allows the node to end the run if `foo` is divisible by 5.\n\n### Graph\n\nGraph — this is the execution graph itself, made up of a set of [node classes](#nodes) (i.e., `BaseNode` subclasses).\n\n`Graph` is generic in:\n\n- **state** the state type of the graph, StateT\n- **deps** the deps type of the graph, DepsT\n- **graph return type** the return type of the graph run, RunEndT\n\nHere's an example of a simple graph:\n\ngraph_example.py\n\n```python\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass DivisibleBy5(BaseNode[None, None, int]):  # (1)!\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext,\n    ) -> Increment | End[int]:\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return Increment(self.foo)\n\n\n@dataclass\nclass Increment(BaseNode):  # (2)!\n    foo: int\n\n    async def run(self, ctx: GraphRunContext) -> DivisibleBy5:\n        return DivisibleBy5(self.foo + 1)\n\n\nfives_graph = Graph(nodes=[DivisibleBy5, Increment])  # (3)!\nresult = fives_graph.run_sync(DivisibleBy5(4))  # (4)!\nprint(result.output)\n#> 5\n\n```\n\n1. The `DivisibleBy5` node is parameterized with `None` for the state param and `None` for the deps param as this graph doesn't use state or deps, and `int` as it can end the run.\n1. The `Increment` node doesn't return `End`, so the `RunEndT` generic parameter is omitted, state can also be omitted as the graph doesn't use state.\n1. The graph is created with a sequence of nodes.\n1. The graph is run synchronously with run_sync. The initial node is `DivisibleBy5(4)`. Because the graph doesn't use external state or deps, we don't pass `state` or `deps`.\n\n*(This example is complete, it can be run \"as is\")*\n\nA [mermaid diagram](#mermaid-diagrams) for this graph can be generated with the following code:\n\ngraph_example_diagram.py\n\n```python\nfrom graph_example import DivisibleBy5, fives_graph\n\nfives_graph.mermaid_code(start_node=DivisibleBy5)\n\n```\n\n```\n---\ntitle: fives_graph\n---\nstateDiagram-v2\n  [*] --> DivisibleBy5\n  DivisibleBy5 --> Increment\n  DivisibleBy5 --> [*]\n  Increment --> DivisibleBy5\n```\n\nIn order to visualize a graph within a `jupyter-notebook`, `IPython.display` needs to be used:\n\njupyter_display_mermaid.py\n\n```python\nfrom graph_example import DivisibleBy5, fives_graph\nfrom IPython.display import Image, display\n\ndisplay(Image(fives_graph.mermaid_image(start_node=DivisibleBy5)))\n\n```\n\n## Stateful Graphs\n\nThe \"state\" concept in `pydantic-graph` provides an optional way to access and mutate an object (often a `dataclass` or Pydantic model) as nodes run in a graph. If you think of Graphs as a production line, then your state is the engine being passed along the line and built up by each node as the graph is run.\n\n`pydantic-graph` provides state persistence, with the state recorded after each node is run. (See [State Persistence](#state-persistence).)\n\nHere's an example of a graph which represents a vending machine where the user may insert coins and select a product to purchase.\n\nvending_machine.py\n\n```python\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom rich.prompt import Prompt\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass MachineState:  # (1)!\n    user_balance: float = 0.0\n    product: str | None = None\n\n\n@dataclass\nclass InsertCoin(BaseNode[MachineState]):  # (3)!\n    async def run(self, ctx: GraphRunContext[MachineState]) -> CoinsInserted:  # (16)!\n        return CoinsInserted(float(Prompt.ask('Insert coins')))  # (4)!\n\n\n@dataclass\nclass CoinsInserted(BaseNode[MachineState]):\n    amount: float  # (5)!\n\n    async def run(\n        self, ctx: GraphRunContext[MachineState]\n    ) -> SelectProduct | Purchase:  # (17)!\n        ctx.state.user_balance += self.amount  # (6)!\n        if ctx.state.product is not None:  # (7)!\n            return Purchase(ctx.state.product)\n        else:\n            return SelectProduct()\n\n\n@dataclass\nclass SelectProduct(BaseNode[MachineState]):\n    async def run(self, ctx: GraphRunContext[MachineState]) -> Purchase:\n        return Purchase(Prompt.ask('Select product'))\n\n\nPRODUCT_PRICES = {  # (2)!\n    'water': 1.25,\n    'soda': 1.50,\n    'crisps': 1.75,\n    'chocolate': 2.00,\n}\n\n\n@dataclass\nclass Purchase(BaseNode[MachineState, None, None]):  # (18)!\n    product: str\n\n    async def run(\n        self, ctx: GraphRunContext[MachineState]\n    ) -> End | InsertCoin | SelectProduct:\n        if price := PRODUCT_PRICES.get(self.product):  # (8)!\n            ctx.state.product = self.product  # (9)!\n            if ctx.state.user_balance >= price:  # (10)!\n                ctx.state.user_balance -= price\n                return End(None)\n            else:\n                diff = price - ctx.state.user_balance\n                print(f'Not enough money for {self.product}, need {diff:0.2f} more')\n                #> Not enough money for crisps, need 0.75 more\n                return InsertCoin()  # (11)!\n        else:\n            print(f'No such product: {self.product}, try again')\n            return SelectProduct()  # (12)!\n\n\nvending_machine_graph = Graph(  # (13)!\n    nodes=[InsertCoin, CoinsInserted, SelectProduct, Purchase]\n)\n\n\nasync def main():\n    state = MachineState()  # (14)!\n    await vending_machine_graph.run(InsertCoin(), state=state)  # (15)!\n    print(f'purchase successful item={state.product} change={state.user_balance:0.2f}')\n    #> purchase successful item=crisps change=0.25\n\n```\n\n1. The state of the vending machine is defined as a dataclass with the user's balance and the product they've selected, if any.\n1. A dictionary of products mapped to prices.\n1. The `InsertCoin` node, BaseNode is parameterized with `MachineState` as that's the state used in this graph.\n1. The `InsertCoin` node prompts the user to insert coins. We keep things simple by just entering a monetary amount as a float. Before you start thinking this is a toy too since it's using rich's Prompt.ask within nodes, see [below](#example-human-in-the-loop) for how control flow can be managed when nodes require external input.\n1. The `CoinsInserted` node; again this is a dataclass with one field `amount`.\n1. Update the user's balance with the amount inserted.\n1. If the user has already selected a product, go to `Purchase`, otherwise go to `SelectProduct`.\n1. In the `Purchase` node, look up the price of the product if the user entered a valid product.\n1. If the user did enter a valid product, set the product in the state so we don't revisit `SelectProduct`.\n1. If the balance is enough to purchase the product, adjust the balance to reflect the purchase and return End to end the graph. We're not using the run return type, so we call `End` with `None`.\n1. If the balance is insufficient, go to `InsertCoin` to prompt the user to insert more coins.\n1. If the product is invalid, go to `SelectProduct` to prompt the user to select a product again.\n1. The graph is created by passing a list of nodes to Graph. Order of nodes is not important, but it can affect how [diagrams](#mermaid-diagrams) are displayed.\n1. Initialize the state. This will be passed to the graph run and mutated as the graph runs.\n1. Run the graph with the initial state. Since the graph can be run from any node, we must pass the start node — in this case, `InsertCoin`. Graph.run returns a GraphRunResult that provides the final data and a history of the run.\n1. The return type of the node's run method is important as it is used to determine the outgoing edges of the node. This information in turn is used to render [mermaid diagrams](#mermaid-diagrams) and is enforced at runtime to detect misbehavior as soon as possible.\n1. The return type of `CoinsInserted`'s run method is a union, meaning multiple outgoing edges are possible.\n1. Unlike other nodes, `Purchase` can end the run, so the RunEndT generic parameter must be set. In this case it's `None` since the graph run return type is `None`.\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\nA [mermaid diagram](#mermaid-diagrams) for this graph can be generated with the following code:\n\nvending_machine_diagram.py\n\n```python\nfrom vending_machine import InsertCoin, vending_machine_graph\n\nvending_machine_graph.mermaid_code(start_node=InsertCoin)\n\n```\n\nThe diagram generated by the above code is:\n\n```\n---\ntitle: vending_machine_graph\n---\nstateDiagram-v2\n  [*] --> InsertCoin\n  InsertCoin --> CoinsInserted\n  CoinsInserted --> SelectProduct\n  CoinsInserted --> Purchase\n  SelectProduct --> Purchase\n  Purchase --> InsertCoin\n  Purchase --> SelectProduct\n  Purchase --> [*]\n```\n\nSee [below](#mermaid-diagrams) for more information on generating diagrams.\n\n## GenAI Example\n\nSo far we haven't shown an example of a Graph that actually uses Pydantic AI or GenAI at all.\n\nIn this example, one agent generates a welcome email to a user and the other agent provides feedback on the email.\n\nThis graph has a very simple structure:\n\n```\n---\ntitle: feedback_graph\n---\nstateDiagram-v2\n  [*] --> WriteEmail\n  WriteEmail --> Feedback\n  Feedback --> WriteEmail\n  Feedback --> [*]\n```\n\ngenai_email_feedback.py\n\n```python\nfrom __future__ import annotations as _annotations\n\nfrom dataclasses import dataclass, field\n\nfrom pydantic import BaseModel, EmailStr\n\nfrom pydantic_ai import Agent, ModelMessage, format_as_xml\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass User:\n    name: str\n    email: EmailStr\n    interests: list[str]\n\n\n@dataclass\nclass Email:\n    subject: str\n    body: str\n\n\n@dataclass\nclass State:\n    user: User\n    write_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n\nemail_writer_agent = Agent(\n    'google-gla:gemini-2.5-pro',\n    output_type=Email,\n    system_prompt='Write a welcome email to our tech blog.',\n)\n\n\n@dataclass\nclass WriteEmail(BaseNode[State]):\n    email_feedback: str | None = None\n\n    async def run(self, ctx: GraphRunContext[State]) -> Feedback:\n        if self.email_feedback:\n            prompt = (\n                f'Rewrite the email for the user:\\n'\n                f'{format_as_xml(ctx.state.user)}\\n'\n                f'Feedback: {self.email_feedback}'\n            )\n        else:\n            prompt = (\n                f'Write a welcome email for the user:\\n'\n                f'{format_as_xml(ctx.state.user)}'\n            )\n\n        result = await email_writer_agent.run(\n            prompt,\n            message_history=ctx.state.write_agent_messages,\n        )\n        ctx.state.write_agent_messages += result.new_messages()\n        return Feedback(result.output)\n\n\nclass EmailRequiresWrite(BaseModel):\n    feedback: str\n\n\nclass EmailOk(BaseModel):\n    pass\n\n\nfeedback_agent = Agent[None, EmailRequiresWrite | EmailOk](\n    'openai:gpt-5',\n    output_type=EmailRequiresWrite | EmailOk,  # type: ignore\n    system_prompt=(\n        'Review the email and provide feedback, email must reference the users specific interests.'\n    ),\n)\n\n\n@dataclass\nclass Feedback(BaseNode[State, None, Email]):\n    email: Email\n\n    async def run(\n        self,\n        ctx: GraphRunContext[State],\n    ) -> WriteEmail | End[Email]:\n        prompt = format_as_xml({'user': ctx.state.user, 'email': self.email})\n        result = await feedback_agent.run(prompt)\n        if isinstance(result.output, EmailRequiresWrite):\n            return WriteEmail(email_feedback=result.output.feedback)\n        else:\n            return End(self.email)\n\n\nasync def main():\n    user = User(\n        name='John Doe',\n        email='john.joe@example.com',\n        interests=['Haskel', 'Lisp', 'Fortran'],\n    )\n    state = State(user)\n    feedback_graph = Graph(nodes=(WriteEmail, Feedback))\n    result = await feedback_graph.run(WriteEmail(), state=state)\n    print(result.output)\n    \"\"\"\n    Email(\n        subject='Welcome to our tech blog!',\n        body='Hello John, Welcome to our tech blog! ...',\n    )\n    \"\"\"\n\n```\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\n## Iterating Over a Graph\n\n### Using `Graph.iter` for `async for` iteration\n\nSometimes you want direct control or insight into each node as the graph executes. The easiest way to do that is with the Graph.iter method, which returns a **context manager** that yields a GraphRun object. The `GraphRun` is an async-iterable over the nodes of your graph, allowing you to record or modify them as they execute.\n\nHere's an example:\n\ncount_down.py\n\n```python\nfrom __future__ import annotations as _annotations\n\nfrom dataclasses import dataclass\nfrom pydantic_graph import Graph, BaseNode, End, GraphRunContext\n\n\n@dataclass\nclass CountDownState:\n    counter: int\n\n\n@dataclass\nclass CountDown(BaseNode[CountDownState, None, int]):\n    async def run(self, ctx: GraphRunContext[CountDownState]) -> CountDown | End[int]:\n        if ctx.state.counter <= 0:\n            return End(ctx.state.counter)\n        ctx.state.counter -= 1\n        return CountDown()\n\n\ncount_down_graph = Graph(nodes=[CountDown])\n\n\nasync def main():\n    state = CountDownState(counter=3)\n    async with count_down_graph.iter(CountDown(), state=state) as run:  # (1)!\n        async for node in run:  # (2)!\n            print('Node:', node)\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: End(data=0)\n    print('Final output:', run.result.output)  # (3)!\n    #> Final output: 0\n\n```\n\n1. `Graph.iter(...)` returns a GraphRun.\n1. Here, we step through each node as it is executed.\n1. Once the graph returns an End, the loop ends, and `run.result` becomes a GraphRunResult containing the final outcome (`0` here).\n\n### Using `GraphRun.next(node)` manually\n\nAlternatively, you can drive iteration manually with the GraphRun.next method, which allows you to pass in whichever node you want to run next. You can modify or selectively skip nodes this way.\n\nBelow is a contrived example that stops whenever the counter is at 2, ignoring any node runs beyond that:\n\ncount_down_next.py\n\n```python\nfrom pydantic_graph import End, FullStatePersistence\nfrom count_down import CountDown, CountDownState, count_down_graph\n\n\nasync def main():\n    state = CountDownState(counter=5)\n    persistence = FullStatePersistence()  # (7)!\n    async with count_down_graph.iter(\n        CountDown(), state=state, persistence=persistence\n    ) as run:\n        node = run.next_node  # (1)!\n        while not isinstance(node, End):  # (2)!\n            print('Node:', node)\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            if state.counter == 2:\n                break  # (3)!\n            node = await run.next(node)  # (4)!\n\n        print(run.result)  # (5)!\n        #> None\n\n        for step in persistence.history:  # (6)!\n            print('History Step:', step.state, step.state)\n            #> History Step: CountDownState(counter=5) CountDownState(counter=5)\n            #> History Step: CountDownState(counter=4) CountDownState(counter=4)\n            #> History Step: CountDownState(counter=3) CountDownState(counter=3)\n            #> History Step: CountDownState(counter=2) CountDownState(counter=2)\n\n```\n\n1. We start by grabbing the first node that will be run in the agent's graph.\n1. The agent run is finished once an `End` node has been produced; instances of `End` cannot be passed to `next`.\n1. If the user decides to stop early, we break out of the loop. The graph run won't have a real final result in that case (`run.result` remains `None`).\n1. At each step, we call `await run.next(node)` to run it and get the next node (or an `End`).\n1. Because we did not continue the run until it finished, the `result` is not set.\n1. The run's history is still populated with the steps we executed so far.\n1. Use FullStatePersistence so we can show the history of the run, see [State Persistence](#state-persistence) below for more information.\n\n## State Persistence\n\nOne of the biggest benefits of finite state machine (FSM) graphs is how they simplify the handling of interrupted execution. This might happen for a variety of reasons:\n\n- the state machine logic might fundamentally need to be paused — e.g. the returns workflow for an e-commerce order needs to wait for the item to be posted to the returns center or because execution of the next node needs input from a user so needs to wait for a new http request,\n- the execution takes so long that the entire graph can't reliably be executed in a single continuous run — e.g. a deep research agent that might take hours to run,\n- you want to run multiple graph nodes in parallel in different processes / hardware instances (note: parallel node execution is not yet supported in `pydantic-graph`, see [#704](https://github.com/pydantic/pydantic-ai/issues/704)).\n\nTrying to make a conventional control flow (i.e., boolean logic and nested function calls) implementation compatible with these usage scenarios generally results in brittle and over-complicated spaghetti code, with the logic required to interrupt and resume execution dominating the implementation.\n\nTo allow graph runs to be interrupted and resumed, `pydantic-graph` provides state persistence — a system for snapshotting the state of a graph run before and after each node is run, allowing a graph run to be resumed from any point in the graph.\n\n`pydantic-graph` includes three state persistence implementations:\n\n- SimpleStatePersistence — Simple in memory state persistence that just hold the latest snapshot. If no state persistence implementation is provided when running a graph, this is used by default.\n- FullStatePersistence — In memory state persistence that hold a list of snapshots.\n- FileStatePersistence — File-based state persistence that saves snapshots to a JSON file.\n\nIn production applications, developers should implement their own state persistence by subclassing BaseStatePersistence abstract base class, which might persist runs in a relational database like PostgresQL.\n\nAt a high level the role of `StatePersistence` implementations is to store and retrieve NodeSnapshot and EndSnapshot objects.\n\ngraph.iter_from_persistence() may be used to run the graph based on the state stored in persistence.\n\nWe can run the `count_down_graph` from [above](#iterating-over-a-graph), using graph.iter_from_persistence() and FileStatePersistence.\n\nAs you can see in this code, `run_node` requires no external application state (apart from state persistence) to be run, meaning graphs can easily be executed by distributed execution and queueing systems.\n\ncount_down_from_persistence.py\n\n```python\nfrom pathlib import Path\n\nfrom pydantic_graph import End\nfrom pydantic_graph.persistence.file import FileStatePersistence\n\nfrom count_down import CountDown, CountDownState, count_down_graph\n\n\nasync def main():\n    run_id = 'run_abc123'\n    persistence = FileStatePersistence(Path(f'count_down_{run_id}.json'))  # (1)!\n    state = CountDownState(counter=5)\n    await count_down_graph.initialize(  # (2)!\n        CountDown(), state=state, persistence=persistence\n    )\n\n    done = False\n    while not done:\n        done = await run_node(run_id)\n\n\nasync def run_node(run_id: str) -> bool:  # (3)!\n    persistence = FileStatePersistence(Path(f'count_down_{run_id}.json'))\n    async with count_down_graph.iter_from_persistence(persistence) as run:  # (4)!\n        node_or_end = await run.next()  # (5)!\n\n    print('Node:', node_or_end)\n    #> Node: CountDown()\n    #> Node: CountDown()\n    #> Node: CountDown()\n    #> Node: CountDown()\n    #> Node: CountDown()\n    #> Node: End(data=0)\n    return isinstance(node_or_end, End)  # (6)!\n\n```\n\n1. Create a FileStatePersistence to use to start the graph.\n1. Call graph.initialize() to set the initial graph state in the persistence object.\n1. `run_node` is a pure function that doesn't need access to any other process state to run the next node of the graph, except the ID of the run.\n1. Call graph.iter_from_persistence() create a GraphRun object that will run the next node of the graph from the state stored in persistence. This will return either a node or an `End` object.\n1. graph.run() will return either a node or an End object.\n1. Check if the node is an End object, if it is, the graph run is complete.\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\n### Example: Human in the loop.\n\nAs noted above, state persistence allows graphs to be interrupted and resumed. One use case of this is to allow user input to continue.\n\nIn this example, an AI asks the user a question, the user provides an answer, the AI evaluates the answer and ends if the user got it right or asks another question if they got it wrong.\n\nInstead of running the entire graph in a single process invocation, we run the graph by running the process repeatedly, optionally providing an answer to the question as a command line argument.\n\n`ai_q_and_a_graph.py` — `question_graph` definition\n\n[Learn about Gateway](../gateway) ai_q_and_a_graph.py\n\n```python\nfrom __future__ import annotations as _annotations\n\nfrom typing import Annotated\nfrom pydantic_graph import Edge\nfrom dataclasses import dataclass, field\nfrom pydantic import BaseModel\nfrom pydantic_graph import (\n    BaseNode,\n    End,\n    Graph,\n    GraphRunContext,\n)\nfrom pydantic_ai import Agent, format_as_xml\nfrom pydantic_ai import ModelMessage\n\nask_agent = Agent('gateway/openai:gpt-5', output_type=str, instrument=True)\n\n\n@dataclass\nclass QuestionState:\n    question: str | None = None\n    ask_agent_messages: list[ModelMessage] = field(default_factory=list)\n    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n\n@dataclass\nclass Ask(BaseNode[QuestionState]):\n    \"\"\"Generate question using GPT-5.\"\"\"\n    docstring_notes = True\n    async def run(\n        self, ctx: GraphRunContext[QuestionState]\n    ) -> Annotated[Answer, Edge(label='Ask the question')]:\n        result = await ask_agent.run(\n            'Ask a simple question with a single correct answer.',\n            message_history=ctx.state.ask_agent_messages,\n        )\n        ctx.state.ask_agent_messages += result.new_messages()\n        ctx.state.question = result.output\n        return Answer(result.output)\n\n\n@dataclass\nclass Answer(BaseNode[QuestionState]):\n    question: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:\n        answer = input(f'{self.question}: ')\n        return Evaluate(answer)\n\n\nclass EvaluationResult(BaseModel, use_attribute_docstrings=True):\n    correct: bool\n    \"\"\"Whether the answer is correct.\"\"\"\n    comment: str\n    \"\"\"Comment on the answer, reprimand the user if the answer is wrong.\"\"\"\n\n\nevaluate_agent = Agent(\n    'gateway/openai:gpt-5',\n    output_type=EvaluationResult,\n    system_prompt='Given a question and answer, evaluate if the answer is correct.',\n)\n\n\n@dataclass\nclass Evaluate(BaseNode[QuestionState, None, str]):\n    answer: str\n\n    async def run(\n        self,\n        ctx: GraphRunContext[QuestionState],\n    ) -> Annotated[End[str], Edge(label='success')] | Reprimand:\n        assert ctx.state.question is not None\n        result = await evaluate_agent.run(\n            format_as_xml({'question': ctx.state.question, 'answer': self.answer}),\n            message_history=ctx.state.evaluate_agent_messages,\n        )\n        ctx.state.evaluate_agent_messages += result.new_messages()\n        if result.output.correct:\n            return End(result.output.comment)\n        else:\n            return Reprimand(result.output.comment)\n\n\n@dataclass\nclass Reprimand(BaseNode[QuestionState]):\n    comment: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:\n        print(f'Comment: {self.comment}')\n        ctx.state.question = None\n        return Ask()\n\n\nquestion_graph = Graph(\n    nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState\n)\n\n```\n\nai_q_and_a_graph.py\n\n```python\nfrom __future__ import annotations as _annotations\n\nfrom typing import Annotated\nfrom pydantic_graph import Edge\nfrom dataclasses import dataclass, field\nfrom pydantic import BaseModel\nfrom pydantic_graph import (\n    BaseNode,\n    End,\n    Graph,\n    GraphRunContext,\n)\nfrom pydantic_ai import Agent, format_as_xml\nfrom pydantic_ai import ModelMessage\n\nask_agent = Agent('openai:gpt-5', output_type=str, instrument=True)\n\n\n@dataclass\nclass QuestionState:\n    question: str | None = None\n    ask_agent_messages: list[ModelMessage] = field(default_factory=list)\n    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n\n@dataclass\nclass Ask(BaseNode[QuestionState]):\n    \"\"\"Generate question using GPT-5.\"\"\"\n    docstring_notes = True\n    async def run(\n        self, ctx: GraphRunContext[QuestionState]\n    ) -> Annotated[Answer, Edge(label='Ask the question')]:\n        result = await ask_agent.run(\n            'Ask a simple question with a single correct answer.',\n            message_history=ctx.state.ask_agent_messages,\n        )\n        ctx.state.ask_agent_messages += result.new_messages()\n        ctx.state.question = result.output\n        return Answer(result.output)\n\n\n@dataclass\nclass Answer(BaseNode[QuestionState]):\n    question: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:\n        answer = input(f'{self.question}: ')\n        return Evaluate(answer)\n\n\nclass EvaluationResult(BaseModel, use_attribute_docstrings=True):\n    correct: bool\n    \"\"\"Whether the answer is correct.\"\"\"\n    comment: str\n    \"\"\"Comment on the answer, reprimand the user if the answer is wrong.\"\"\"\n\n\nevaluate_agent = Agent(\n    'openai:gpt-5',\n    output_type=EvaluationResult,\n    system_prompt='Given a question and answer, evaluate if the answer is correct.',\n)\n\n\n@dataclass\nclass Evaluate(BaseNode[QuestionState, None, str]):\n    answer: str\n\n    async def run(\n        self,\n        ctx: GraphRunContext[QuestionState],\n    ) -> Annotated[End[str], Edge(label='success')] | Reprimand:\n        assert ctx.state.question is not None\n        result = await evaluate_agent.run(\n            format_as_xml({'question': ctx.state.question, 'answer': self.answer}),\n            message_history=ctx.state.evaluate_agent_messages,\n        )\n        ctx.state.evaluate_agent_messages += result.new_messages()\n        if result.output.correct:\n            return End(result.output.comment)\n        else:\n            return Reprimand(result.output.comment)\n\n\n@dataclass\nclass Reprimand(BaseNode[QuestionState]):\n    comment: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:\n        print(f'Comment: {self.comment}')\n        ctx.state.question = None\n        return Ask()\n\n\nquestion_graph = Graph(\n    nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState\n)\n\n```\n\n*(This example is complete, it can be run \"as is\")*\n\nai_q_and_a_run.py\n\n```python\nimport sys\nfrom pathlib import Path\n\nfrom pydantic_graph import End\nfrom pydantic_graph.persistence.file import FileStatePersistence\nfrom pydantic_ai import ModelMessage  # noqa: F401\n\nfrom ai_q_and_a_graph import Ask, question_graph, Evaluate, QuestionState, Answer\n\n\nasync def main():\n    answer: str | None = sys.argv[1] if len(sys.argv) > 1 else None  # (1)!\n    persistence = FileStatePersistence(Path('question_graph.json'))  # (2)!\n    persistence.set_graph_types(question_graph)  # (3)!\n\n    if snapshot := await persistence.load_next():  # (4)!\n        state = snapshot.state\n        assert answer is not None\n        node = Evaluate(answer)\n    else:\n        state = QuestionState()\n        node = Ask()  # (5)!\n\n    async with question_graph.iter(node, state=state, persistence=persistence) as run:\n        while True:\n            node = await run.next()  # (6)!\n            if isinstance(node, End):  # (7)!\n                print('END:', node.data)\n                history = await persistence.load_all()  # (8)!\n                print([e.node for e in history])\n                break\n            elif isinstance(node, Answer):  # (9)!\n                print(node.question)\n                #> What is the capital of France?\n                break\n            # otherwise just continue\n\n```\n\n1. Get the user's answer from the command line, if provided. See [question graph example](../examples/question-graph/) for a complete example.\n1. Create a state persistence instance the `'question_graph.json'` file may or may not already exist.\n1. Since we're using the persistence interface outside a graph, we need to call set_graph_types to set the graph generic types `StateT` and `RunEndT` for the persistence instance. This is necessary to allow the persistence instance to know how to serialize and deserialize graph nodes.\n1. If we're run the graph before, load_next will return a snapshot of the next node to run, here we use `state` from that snapshot, and create a new `Evaluate` node with the answer provided on the command line.\n1. If the graph hasn't been run before, we create a new `QuestionState` and start with the `Ask` node.\n1. Call GraphRun.next() to run the node. This will return either a node or an `End` object.\n1. If the node is an `End` object, the graph run is complete. The `data` field of the `End` object contains the comment returned by the `evaluate_agent` about the correct answer.\n1. To demonstrate the state persistence, we call load_all to get all the snapshots from the persistence instance. This will return a list of Snapshot objects.\n1. If the node is an `Answer` object, we print the question and break out of the loop to end the process and wait for user input.\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\nFor a complete example of this graph, see the [question graph example](../examples/question-graph/).\n\n## Dependency Injection\n\nAs with Pydantic AI, `pydantic-graph` supports dependency injection via a generic parameter on Graph and BaseNode, and the GraphRunContext.deps field.\n\nAs an example of dependency injection, let's modify the `DivisibleBy5` example [above](#graph) to use a ProcessPoolExecutor to run the compute load in a separate process (this is a contrived example, `ProcessPoolExecutor` wouldn't actually improve performance in this example):\n\ndeps_example.py\n\n```python\nfrom __future__ import annotations\n\nimport asyncio\nfrom concurrent.futures import ProcessPoolExecutor\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, FullStatePersistence, Graph, GraphRunContext\n\n\n@dataclass\nclass GraphDeps:\n    executor: ProcessPoolExecutor\n\n\n@dataclass\nclass DivisibleBy5(BaseNode[None, GraphDeps, int]):\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext[None, GraphDeps],\n    ) -> Increment | End[int]:\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return Increment(self.foo)\n\n\n@dataclass\nclass Increment(BaseNode[None, GraphDeps]):\n    foo: int\n\n    async def run(self, ctx: GraphRunContext[None, GraphDeps]) -> DivisibleBy5:\n        loop = asyncio.get_running_loop()\n        compute_result = await loop.run_in_executor(\n            ctx.deps.executor,\n            self.compute,\n        )\n        return DivisibleBy5(compute_result)\n\n    def compute(self) -> int:\n        return self.foo + 1\n\n\nfives_graph = Graph(nodes=[DivisibleBy5, Increment])\n\n\nasync def main():\n    with ProcessPoolExecutor() as executor:\n        deps = GraphDeps(executor)\n        result = await fives_graph.run(DivisibleBy5(3), deps=deps, persistence=FullStatePersistence())\n    print(result.output)\n    #> 5\n    # the full history is quite verbose (see below), so we'll just print the summary\n    print([item.node for item in result.persistence.history])\n    \"\"\"\n    [\n        DivisibleBy5(foo=3),\n        Increment(foo=3),\n        DivisibleBy5(foo=4),\n        Increment(foo=4),\n        DivisibleBy5(foo=5),\n        End(data=5),\n    ]\n    \"\"\"\n\n```\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\n## Mermaid Diagrams\n\nPydantic Graph can generate [mermaid](https://mermaid.js.org/) [`stateDiagram-v2`](https://mermaid.js.org/syntax/stateDiagram.html) diagrams for graphs, as shown above.\n\nThese diagrams can be generated with:\n\n- Graph.mermaid_code to generate the mermaid code for a graph\n- Graph.mermaid_image to generate an image of the graph using [mermaid.ink](https://mermaid.ink/)\n- Graph.mermaid_save to generate an image of the graph using [mermaid.ink](https://mermaid.ink/) and save it to a file\n\nBeyond the diagrams shown above, you can also customize mermaid diagrams with the following options:\n\n- Edge allows you to apply a label to an edge\n- BaseNode.docstring_notes and BaseNode.get_note allows you to add notes to nodes\n- The highlighted_nodes parameter allows you to highlight specific node(s) in the diagram\n\nPutting that together, we can edit the last [`ai_q_and_a_graph.py`](#example-human-in-the-loop) example to:\n\n- add labels to some edges\n- add a note to the `Ask` node\n- highlight the `Answer` node\n- save the diagram as a `PNG` image to file\n\n[Learn about Gateway](../gateway) ai_q_and_a_graph_extra.py\n\n```python\nfrom typing import Annotated\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext, Edge\nask_agent = Agent('gateway/openai:gpt-5', output_type=str, instrument=True)\n\n\n@dataclass\nclass QuestionState:\n    question: str | None = None\n    ask_agent_messages: list[ModelMessage] = field(default_factory=list)\n    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n@dataclass\nclass Ask(BaseNode[QuestionState]):\n    \"\"\"Generate question using GPT-5.\"\"\"\n    docstring_notes = True\n    async def run(\n        self, ctx: GraphRunContext[QuestionState]\n    ) -> Annotated[Answer, Edge(label='Ask the question')]:\n        result = await ask_agent.run(\n            'Ask a simple question with a single correct answer.',\n            message_history=ctx.state.ask_agent_messages,\n        )\n        ctx.state.ask_agent_messages += result.new_messages()\n        ctx.state.question = result.output\n        return Answer(result.output)\n\n\n@dataclass\nclass Answer(BaseNode[QuestionState]):\n    question: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:\n        answer = input(f'{self.question}: ')\n        return Evaluate(answer)\n\n\nclass EvaluationResult(BaseModel, use_attribute_docstrings=True):\n    correct: bool\n    \"\"\"Whether the answer is correct.\"\"\"\n    comment: str\n    \"\"\"Comment on the answer, reprimand the user if the answer is wrong.\"\"\"\n\n\nevaluate_agent = Agent(\n    'gateway/openai:gpt-5',\n    output_type=EvaluationResult,\n    system_prompt='Given a question and answer, evaluate if the answer is correct.',\n)\n\n\n@dataclass\nclass Evaluate(BaseNode[QuestionState, None, str]):\n    answer: str\n\n    async def run(\n        self,\n        ctx: GraphRunContext[QuestionState],\n    ) -> Annotated[End[str], Edge(label='success')] | Reprimand:\n        assert ctx.state.question is not None\n        result = await evaluate_agent.run(\n            format_as_xml({'question': ctx.state.question, 'answer': self.answer}),\n            message_history=ctx.state.evaluate_agent_messages,\n        )\n        ctx.state.evaluate_agent_messages += result.new_messages()\n        if result.output.correct:\n            return End(result.output.comment)\n        else:\n            return Reprimand(result.output.comment)\n\n\n@dataclass\nclass Reprimand(BaseNode[QuestionState]):\n    comment: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:\n        print(f'Comment: {self.comment}')\n        ctx.state.question = None\n        return Ask()\n\n\nquestion_graph = Graph(\n    nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState\n)\n\n```\n\nai_q_and_a_graph_extra.py\n\n```python\nfrom typing import Annotated\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext, Edge\nask_agent = Agent('openai:gpt-5', output_type=str, instrument=True)\n\n\n@dataclass\nclass QuestionState:\n    question: str | None = None\n    ask_agent_messages: list[ModelMessage] = field(default_factory=list)\n    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n@dataclass\nclass Ask(BaseNode[QuestionState]):\n    \"\"\"Generate question using GPT-5.\"\"\"\n    docstring_notes = True\n    async def run(\n        self, ctx: GraphRunContext[QuestionState]\n    ) -> Annotated[Answer, Edge(label='Ask the question')]:\n        result = await ask_agent.run(\n            'Ask a simple question with a single correct answer.',\n            message_history=ctx.state.ask_agent_messages,\n        )\n        ctx.state.ask_agent_messages += result.new_messages()\n        ctx.state.question = result.output\n        return Answer(result.output)\n\n\n@dataclass\nclass Answer(BaseNode[QuestionState]):\n    question: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:\n        answer = input(f'{self.question}: ')\n        return Evaluate(answer)\n\n\nclass EvaluationResult(BaseModel, use_attribute_docstrings=True):\n    correct: bool\n    \"\"\"Whether the answer is correct.\"\"\"\n    comment: str\n    \"\"\"Comment on the answer, reprimand the user if the answer is wrong.\"\"\"\n\n\nevaluate_agent = Agent(\n    'openai:gpt-5',\n    output_type=EvaluationResult,\n    system_prompt='Given a question and answer, evaluate if the answer is correct.',\n)\n\n\n@dataclass\nclass Evaluate(BaseNode[QuestionState, None, str]):\n    answer: str\n\n    async def run(\n        self,\n        ctx: GraphRunContext[QuestionState],\n    ) -> Annotated[End[str], Edge(label='success')] | Reprimand:\n        assert ctx.state.question is not None\n        result = await evaluate_agent.run(\n            format_as_xml({'question': ctx.state.question, 'answer': self.answer}),\n            message_history=ctx.state.evaluate_agent_messages,\n        )\n        ctx.state.evaluate_agent_messages += result.new_messages()\n        if result.output.correct:\n            return End(result.output.comment)\n        else:\n            return Reprimand(result.output.comment)\n\n\n@dataclass\nclass Reprimand(BaseNode[QuestionState]):\n    comment: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:\n        print(f'Comment: {self.comment}')\n        ctx.state.question = None\n        return Ask()\n\n\nquestion_graph = Graph(\n    nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState\n)\n\n```\n\n*(This example is not complete and cannot be run directly)*\n\nThis would generate an image that looks like this:\n\n```\n---\ntitle: question_graph\n---\nstateDiagram-v2\n  Ask --> Answer: Ask the question\n  note right of Ask\n    Judge the answer.\n    Decide on next step.\n  end note\n  Answer --> Evaluate\n  Evaluate --> Reprimand\n  Evaluate --> [*]: success\n  Reprimand --> Ask\n\nclassDef highlighted fill:#fdff32\nclass Answer highlighted\n```\n\n### Setting Direction of the State Diagram\n\nYou can specify the direction of the state diagram using one of the following values:\n\n- `'TB'`: Top to bottom, the diagram flows vertically from top to bottom.\n- `'LR'`: Left to right, the diagram flows horizontally from left to right.\n- `'RL'`: Right to left, the diagram flows horizontally from right to left.\n- `'BT'`: Bottom to top, the diagram flows vertically from bottom to top.\n\nHere is an example of how to do this using 'Left to Right' (LR) instead of the default 'Top to Bottom' (TB):\n\nvending_machine_diagram.py\n\n```python\nfrom vending_machine import InsertCoin, vending_machine_graph\n\nvending_machine_graph.mermaid_code(start_node=InsertCoin, direction='LR')\n\n```\n\n```\n---\ntitle: vending_machine_graph\n---\nstateDiagram-v2\n  direction LR\n  [*] --> InsertCoin\n  InsertCoin --> CoinsInserted\n  CoinsInserted --> SelectProduct\n  CoinsInserted --> Purchase\n  SelectProduct --> Purchase\n  Purchase --> InsertCoin\n  Purchase --> SelectProduct\n  Purchase --> [*]\n```",
  "content_length": 45487
}