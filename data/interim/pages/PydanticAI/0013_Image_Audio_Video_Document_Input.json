{
  "title": "Image, Audio, Video & Document Input",
  "source_url": null,
  "content": "Some LLMs are now capable of understanding audio, video, image and document content.\n\n## Image Input\n\nInfo\n\nSome models do not support image input. Please check the model's documentation to confirm whether it supports image input.\n\nIf you have a direct URL for the image, you can use ImageUrl:\n\n[Learn about Gateway](../gateway) image_input.py\n\n```python\nfrom pydantic_ai import Agent, ImageUrl\n\nagent = Agent(model='gateway/openai:gpt-5')\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        ImageUrl(url='https://iili.io/3Hs4FMg.png'),\n    ]\n)\nprint(result.output)\n#> This is the logo for Pydantic, a data validation and settings management library in Python.\n\n```\n\nimage_input.py\n\n```python\nfrom pydantic_ai import Agent, ImageUrl\n\nagent = Agent(model='openai:gpt-5')\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        ImageUrl(url='https://iili.io/3Hs4FMg.png'),\n    ]\n)\nprint(result.output)\n#> This is the logo for Pydantic, a data validation and settings management library in Python.\n\n```\n\nIf you have the image locally, you can also use BinaryContent:\n\n[Learn about Gateway](../gateway) local_image_input.py\n\n```python\nimport httpx\n\nfrom pydantic_ai import Agent, BinaryContent\n\nimage_response = httpx.get('https://iili.io/3Hs4FMg.png')  # Pydantic logo\n\nagent = Agent(model='gateway/openai:gpt-5')\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        BinaryContent(data=image_response.content, media_type='image/png'),  # (1)!\n    ]\n)\nprint(result.output)\n#> This is the logo for Pydantic, a data validation and settings management library in Python.\n\n```\n\n1. To ensure the example is runnable we download this image from the web, but you can also use `Path().read_bytes()` to read a local file's contents.\n\nlocal_image_input.py\n\n```python\nimport httpx\n\nfrom pydantic_ai import Agent, BinaryContent\n\nimage_response = httpx.get('https://iili.io/3Hs4FMg.png')  # Pydantic logo\n\nagent = Agent(model='openai:gpt-5')\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        BinaryContent(data=image_response.content, media_type='image/png'),  # (1)!\n    ]\n)\nprint(result.output)\n#> This is the logo for Pydantic, a data validation and settings management library in Python.\n\n```\n\n1. To ensure the example is runnable we download this image from the web, but you can also use `Path().read_bytes()` to read a local file's contents.\n\n## Audio Input\n\nInfo\n\nSome models do not support audio input. Please check the model's documentation to confirm whether it supports audio input.\n\nYou can provide audio input using either AudioUrl or BinaryContent. The process is analogous to the examples above.\n\n## Video Input\n\nInfo\n\nSome models do not support video input. Please check the model's documentation to confirm whether it supports video input.\n\nYou can provide video input using either VideoUrl or BinaryContent. The process is analogous to the examples above.\n\n## Document Input\n\nInfo\n\nSome models do not support document input. Please check the model's documentation to confirm whether it supports document input.\n\nYou can provide document input using either DocumentUrl or BinaryContent. The process is similar to the examples above.\n\nIf you have a direct URL for the document, you can use DocumentUrl:\n\n[Learn about Gateway](../gateway) document_input.py\n\n```python\nfrom pydantic_ai import Agent, DocumentUrl\n\nagent = Agent(model='gateway/anthropic:claude-sonnet-4-5')\nresult = agent.run_sync(\n    [\n        'What is the main content of this document?',\n        DocumentUrl(url='https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2403.05530.pdf'),\n    ]\n)\nprint(result.output)\n#> This document is the technical report introducing Gemini 1.5, Google's latest large language model...\n\n```\n\ndocument_input.py\n\n```python\nfrom pydantic_ai import Agent, DocumentUrl\n\nagent = Agent(model='anthropic:claude-sonnet-4-5')\nresult = agent.run_sync(\n    [\n        'What is the main content of this document?',\n        DocumentUrl(url='https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2403.05530.pdf'),\n    ]\n)\nprint(result.output)\n#> This document is the technical report introducing Gemini 1.5, Google's latest large language model...\n\n```\n\nThe supported document formats vary by model.\n\nYou can also use BinaryContent to pass document data directly:\n\n[Learn about Gateway](../gateway) binary_content_input.py\n\n```python\nfrom pathlib import Path\nfrom pydantic_ai import Agent, BinaryContent\n\npdf_path = Path('document.pdf')\nagent = Agent(model='gateway/anthropic:claude-sonnet-4-5')\nresult = agent.run_sync(\n    [\n        'What is the main content of this document?',\n        BinaryContent(data=pdf_path.read_bytes(), media_type='application/pdf'),\n    ]\n)\nprint(result.output)\n#> The document discusses...\n\n```\n\nbinary_content_input.py\n\n```python\nfrom pathlib import Path\nfrom pydantic_ai import Agent, BinaryContent\n\npdf_path = Path('document.pdf')\nagent = Agent(model='anthropic:claude-sonnet-4-5')\nresult = agent.run_sync(\n    [\n        'What is the main content of this document?',\n        BinaryContent(data=pdf_path.read_bytes(), media_type='application/pdf'),\n    ]\n)\nprint(result.output)\n#> The document discusses...\n\n```\n\n## User-side download vs. direct file URL\n\nWhen you provide a URL using any of `ImageUrl`, `AudioUrl`, `VideoUrl` or `DocumentUrl`, Pydantic AI will typically send the URL directly to the model API so that the download happens on their side.\n\nSome model APIs do not support file URLs at all or for specific file types. In the following cases, Pydantic AI will download the file content and send it as part of the API request instead:\n\n- OpenAIChatModel: `AudioUrl` and `DocumentUrl`\n- OpenAIResponsesModel: All URLs\n- AnthropicModel: `DocumentUrl` with media type `text/plain`\n- GoogleModel using GLA (Gemini Developer API): All URLs except YouTube video URLs and files uploaded to the [Files API](https://ai.google.dev/gemini-api/docs/files).\n- BedrockConverseModel: All URLs\n\nIf the model API supports file URLs but may not be able to download a file because of crawling or access restrictions, you can instruct Pydantic AI to download the file content and send that instead of the URL by enabling the `force_download` flag on the URL object. For example, GoogleModel on Vertex AI limits YouTube video URLs to one URL per request.\n\n## Uploaded Files\n\nSome model providers like Google's Gemini API support [uploading files](https://ai.google.dev/gemini-api/docs/files). You can upload a file to the model API using the client you can get from the provider and use the resulting URL as input:\n\nfile_upload.py\n\n```python\nfrom pydantic_ai import Agent, DocumentUrl\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\nprovider = GoogleProvider()\nfile = provider.client.files.upload(file='pydantic-ai-logo.png')\nassert file.uri is not None\n\nagent = Agent(GoogleModel('gemini-2.5-flash', provider=provider))\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        DocumentUrl(url=file.uri, media_type=file.mime_type),\n    ]\n)\nprint(result.output)\n\n```",
  "content_length": 7200
}