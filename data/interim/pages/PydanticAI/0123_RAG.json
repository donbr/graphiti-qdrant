{
  "title": "RAG",
  "source_url": null,
  "content": "RAG search example. This demo allows you to ask question of the [logfire](https://pydantic.dev/logfire) documentation.\n\nDemonstrates:\n\n- [tools](../../tools/)\n- [agent dependencies](../../dependencies/)\n- RAG search\n\nThis is done by creating a database containing each section of the markdown documentation, then registering the search tool with the Pydantic AI agent.\n\nLogic for extracting sections from markdown files and a JSON file with that data is available in [this gist](https://gist.github.com/samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992).\n\n[PostgreSQL with pgvector](https://github.com/pgvector/pgvector) is used as the search database, the easiest way to download and run pgvector is using Docker:\n\n```bash\nmkdir postgres-data\ndocker run --rm \\\n  -e POSTGRES_PASSWORD=postgres \\\n  -p 54320:5432 \\\n  -v `pwd`/postgres-data:/var/lib/postgresql/data \\\n  pgvector/pgvector:pg17\n\n```\n\nAs with the [SQL gen](../sql-gen/) example, we run postgres on port `54320` to avoid conflicts with any other postgres instances you may have running. We also mount the PostgreSQL `data` directory locally to persist the data if you need to stop and restart the container.\n\nWith that running and [dependencies installed and environment variables set](../setup/#usage), we can build the search database with (**WARNING**: this requires the `OPENAI_API_KEY` env variable and will calling the OpenAI embedding API around 300 times to generate embeddings for each section of the documentation):\n\n```bash\npython -m pydantic_ai_examples.rag build\n\n```\n\n```bash\nuv run -m pydantic_ai_examples.rag build\n\n```\n\n(Note building the database doesn't use Pydantic AI right now, instead it uses the OpenAI SDK directly.)\n\nYou can then ask the agent a question with:\n\n```bash\npython -m pydantic_ai_examples.rag search \"How do I configure logfire to work with FastAPI?\"\n\n```\n\n```bash\nuv run -m pydantic_ai_examples.rag search \"How do I configure logfire to work with FastAPI?\"\n\n```\n\n## Example Code\n\n[Learn about Gateway](../../gateway) [rag.py](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/rag.py)\n\n```python\n\"\"\"RAG example with pydantic-ai — using vector search to augment a chat agent.\n\nRun pgvector with:\n\n    mkdir postgres-data\n    docker run --rm -e POSTGRES_PASSWORD=postgres \\\n        -p 54320:5432 \\\n        -v `pwd`/postgres-data:/var/lib/postgresql/data \\\n        pgvector/pgvector:pg17\n\nBuild the search DB with:\n\n    uv run -m pydantic_ai_examples.rag build\n\nAsk the agent a question with:\n\n    uv run -m pydantic_ai_examples.rag search \"How do I configure logfire to work with FastAPI?\"\n\"\"\"\n\nfrom __future__ import annotations as _annotations\n\nimport asyncio\nimport re\nimport sys\nimport unicodedata\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass\n\nimport asyncpg\nimport httpx\nimport logfire\nimport pydantic_core\nfrom anyio import create_task_group\nfrom openai import AsyncOpenAI\nfrom pydantic import TypeAdapter\nfrom typing_extensions import AsyncGenerator\n\nfrom pydantic_ai import Agent, RunContext\n\n### 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured\nlogfire.configure(send_to_logfire='if-token-present')\nlogfire.instrument_asyncpg()\nlogfire.instrument_pydantic_ai()\n\n\n@dataclass\nclass Deps:\n    openai: AsyncOpenAI\n    pool: asyncpg.Pool\n\n\nagent = Agent('gateway/openai:gpt-5', deps_type=Deps)\n\n\n@agent.tool\nasync def retrieve(context: RunContext[Deps], search_query: str) -> str:\n    \"\"\"Retrieve documentation sections based on a search query.\n\n    Args:\n        context: The call context.\n        search_query: The search query.\n    \"\"\"\n    with logfire.span(\n        'create embedding for {search_query=}', search_query=search_query\n    ):\n        embedding = await context.deps.openai.embeddings.create(\n            input=search_query,\n            model='text-embedding-3-small',\n        )\n\n    assert len(embedding.data) == 1, (\n        f'Expected 1 embedding, got {len(embedding.data)}, doc query: {search_query!r}'\n    )\n    embedding = embedding.data[0].embedding\n    embedding_json = pydantic_core.to_json(embedding).decode()\n    rows = await context.deps.pool.fetch(\n        'SELECT url, title, content FROM doc_sections ORDER BY embedding <-> $1 LIMIT 8',\n        embedding_json,\n    )\n    return '\\n\\n'.join(\n        f'# {row[\"title\"]}\\nDocumentation URL:{row[\"url\"]}\\n\\n{row[\"content\"]}\\n'\n        for row in rows\n    )\n\n\nasync def run_agent(question: str):\n    \"\"\"Entry point to run the agent and perform RAG based question answering.\"\"\"\n    openai = AsyncOpenAI()\n    logfire.instrument_openai(openai)\n\n    logfire.info('Asking \"{question}\"', question=question)\n\n    async with database_connect(False) as pool:\n        deps = Deps(openai=openai, pool=pool)\n        answer = await agent.run(question, deps=deps)\n    print(answer.output)\n\n\n#######################################################\n### The rest of this file is dedicated to preparing the #\n### search database, and some utilities.                #\n#######################################################\n\n### JSON document from\n### https://gist.github.com/samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992\nDOCS_JSON = (\n    'https://gist.githubusercontent.com/'\n    'samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992/raw/'\n    '80c5925c42f1442c24963aaf5eb1a324d47afe95/logfire_docs.json'\n)\n\n\nasync def build_search_db():\n    \"\"\"Build the search database.\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(DOCS_JSON)\n        response.raise_for_status()\n    sections = sections_ta.validate_json(response.content)\n\n    openai = AsyncOpenAI()\n    logfire.instrument_openai(openai)\n\n    async with database_connect(True) as pool:\n        with logfire.span('create schema'):\n            async with pool.acquire() as conn:\n                async with conn.transaction():\n                    await conn.execute(DB_SCHEMA)\n\n        sem = asyncio.Semaphore(10)\n        async with create_task_group() as tg:\n            for section in sections:\n                tg.start_soon(insert_doc_section, sem, openai, pool, section)\n\n\nasync def insert_doc_section(\n    sem: asyncio.Semaphore,\n    openai: AsyncOpenAI,\n    pool: asyncpg.Pool,\n    section: DocsSection,\n) -> None:\n    async with sem:\n        url = section.url()\n        exists = await pool.fetchval('SELECT 1 FROM doc_sections WHERE url = $1', url)\n        if exists:\n            logfire.info('Skipping {url=}', url=url)\n            return\n\n        with logfire.span('create embedding for {url=}', url=url):\n            embedding = await openai.embeddings.create(\n                input=section.embedding_content(),\n                model='text-embedding-3-small',\n            )\n        assert len(embedding.data) == 1, (\n            f'Expected 1 embedding, got {len(embedding.data)}, doc section: {section}'\n        )\n        embedding = embedding.data[0].embedding\n        embedding_json = pydantic_core.to_json(embedding).decode()\n        await pool.execute(\n            'INSERT INTO doc_sections (url, title, content, embedding) VALUES ($1, $2, $3, $4)',\n            url,\n            section.title,\n            section.content,\n            embedding_json,\n        )\n\n\n@dataclass\nclass DocsSection:\n    id: int\n    parent: int | None\n    path: str\n    level: int\n    title: str\n    content: str\n\n    def url(self) -> str:\n        url_path = re.sub(r'\\.md$', '', self.path)\n        return (\n            f'https://logfire.pydantic.dev/docs/{url_path}/#{slugify(self.title, \"-\")}'\n        )\n\n    def embedding_content(self) -> str:\n        return '\\n\\n'.join((f'path: {self.path}', f'title: {self.title}', self.content))\n\n\nsections_ta = TypeAdapter(list[DocsSection])\n\n\n### pyright: reportUnknownMemberType=false\n### pyright: reportUnknownVariableType=false\n@asynccontextmanager\nasync def database_connect(\n    create_db: bool = False,\n) -> AsyncGenerator[asyncpg.Pool, None]:\n    server_dsn, database = (\n        'postgresql://postgres:postgres@localhost:54320',\n        'pydantic_ai_rag',\n    )\n    if create_db:\n        with logfire.span('check and create DB'):\n            conn = await asyncpg.connect(server_dsn)\n            try:\n                db_exists = await conn.fetchval(\n                    'SELECT 1 FROM pg_database WHERE datname = $1', database\n                )\n                if not db_exists:\n                    await conn.execute(f'CREATE DATABASE {database}')\n            finally:\n                await conn.close()\n\n    pool = await asyncpg.create_pool(f'{server_dsn}/{database}')\n    try:\n        yield pool\n    finally:\n        await pool.close()\n\n\nDB_SCHEMA = \"\"\"\nCREATE EXTENSION IF NOT EXISTS vector;\n\nCREATE TABLE IF NOT EXISTS doc_sections (\n    id serial PRIMARY KEY,\n    url text NOT NULL UNIQUE,\n    title text NOT NULL,\n    content text NOT NULL,\n    -- text-embedding-3-small returns a vector of 1536 floats\n    embedding vector(1536) NOT NULL\n);\nCREATE INDEX IF NOT EXISTS idx_doc_sections_embedding ON doc_sections USING hnsw (embedding vector_l2_ops);\n\"\"\"\n\n\ndef slugify(value: str, separator: str, unicode: bool = False) -> str:\n    \"\"\"Slugify a string, to make it URL friendly.\"\"\"\n    # Taken unchanged from https://github.com/Python-Markdown/markdown/blob/3.7/markdown/extensions/toc.py#L38\n    if not unicode:\n        # Replace Extended Latin characters with ASCII, i.e. `žlutý` => `zluty`\n        value = unicodedata.normalize('NFKD', value)\n        value = value.encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n    return re.sub(rf'[{separator}\\s]+', separator, value)\n\n\nif __name__ == '__main__':\n    action = sys.argv[1] if len(sys.argv) > 1 else None\n    if action == 'build':\n        asyncio.run(build_search_db())\n    elif action == 'search':\n        if len(sys.argv) == 3:\n            q = sys.argv[2]\n        else:\n            q = 'How do I configure logfire to work with FastAPI?'\n        asyncio.run(run_agent(q))\n    else:\n        print(\n            'uv run --extra examples -m pydantic_ai_examples.rag build|search',\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n```\n\n[rag.py](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/rag.py)\n\n```python\n\"\"\"RAG example with pydantic-ai — using vector search to augment a chat agent.\n\nRun pgvector with:\n\n    mkdir postgres-data\n    docker run --rm -e POSTGRES_PASSWORD=postgres \\\n        -p 54320:5432 \\\n        -v `pwd`/postgres-data:/var/lib/postgresql/data \\\n        pgvector/pgvector:pg17\n\nBuild the search DB with:\n\n    uv run -m pydantic_ai_examples.rag build\n\nAsk the agent a question with:\n\n    uv run -m pydantic_ai_examples.rag search \"How do I configure logfire to work with FastAPI?\"\n\"\"\"\n\nfrom __future__ import annotations as _annotations\n\nimport asyncio\nimport re\nimport sys\nimport unicodedata\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass\n\nimport asyncpg\nimport httpx\nimport logfire\nimport pydantic_core\nfrom anyio import create_task_group\nfrom openai import AsyncOpenAI\nfrom pydantic import TypeAdapter\nfrom typing_extensions import AsyncGenerator\n\nfrom pydantic_ai import Agent, RunContext\n\n### 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured\nlogfire.configure(send_to_logfire='if-token-present')\nlogfire.instrument_asyncpg()\nlogfire.instrument_pydantic_ai()\n\n\n@dataclass\nclass Deps:\n    openai: AsyncOpenAI\n    pool: asyncpg.Pool\n\n\nagent = Agent('openai:gpt-5', deps_type=Deps)\n\n\n@agent.tool\nasync def retrieve(context: RunContext[Deps], search_query: str) -> str:\n    \"\"\"Retrieve documentation sections based on a search query.\n\n    Args:\n        context: The call context.\n        search_query: The search query.\n    \"\"\"\n    with logfire.span(\n        'create embedding for {search_query=}', search_query=search_query\n    ):\n        embedding = await context.deps.openai.embeddings.create(\n            input=search_query,\n            model='text-embedding-3-small',\n        )\n\n    assert len(embedding.data) == 1, (\n        f'Expected 1 embedding, got {len(embedding.data)}, doc query: {search_query!r}'\n    )\n    embedding = embedding.data[0].embedding\n    embedding_json = pydantic_core.to_json(embedding).decode()\n    rows = await context.deps.pool.fetch(\n        'SELECT url, title, content FROM doc_sections ORDER BY embedding <-> $1 LIMIT 8',\n        embedding_json,\n    )\n    return '\\n\\n'.join(\n        f'# {row[\"title\"]}\\nDocumentation URL:{row[\"url\"]}\\n\\n{row[\"content\"]}\\n'\n        for row in rows\n    )\n\n\nasync def run_agent(question: str):\n    \"\"\"Entry point to run the agent and perform RAG based question answering.\"\"\"\n    openai = AsyncOpenAI()\n    logfire.instrument_openai(openai)\n\n    logfire.info('Asking \"{question}\"', question=question)\n\n    async with database_connect(False) as pool:\n        deps = Deps(openai=openai, pool=pool)\n        answer = await agent.run(question, deps=deps)\n    print(answer.output)\n\n\n#######################################################\n### The rest of this file is dedicated to preparing the #\n### search database, and some utilities.                #\n#######################################################\n\n### JSON document from\n### https://gist.github.com/samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992\nDOCS_JSON = (\n    'https://gist.githubusercontent.com/'\n    'samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992/raw/'\n    '80c5925c42f1442c24963aaf5eb1a324d47afe95/logfire_docs.json'\n)\n\n\nasync def build_search_db():\n    \"\"\"Build the search database.\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(DOCS_JSON)\n        response.raise_for_status()\n    sections = sections_ta.validate_json(response.content)\n\n    openai = AsyncOpenAI()\n    logfire.instrument_openai(openai)\n\n    async with database_connect(True) as pool:\n        with logfire.span('create schema'):\n            async with pool.acquire() as conn:\n                async with conn.transaction():\n                    await conn.execute(DB_SCHEMA)\n\n        sem = asyncio.Semaphore(10)\n        async with create_task_group() as tg:\n            for section in sections:\n                tg.start_soon(insert_doc_section, sem, openai, pool, section)\n\n\nasync def insert_doc_section(\n    sem: asyncio.Semaphore,\n    openai: AsyncOpenAI,\n    pool: asyncpg.Pool,\n    section: DocsSection,\n) -> None:\n    async with sem:\n        url = section.url()\n        exists = await pool.fetchval('SELECT 1 FROM doc_sections WHERE url = $1', url)\n        if exists:\n            logfire.info('Skipping {url=}', url=url)\n            return\n\n        with logfire.span('create embedding for {url=}', url=url):\n            embedding = await openai.embeddings.create(\n                input=section.embedding_content(),\n                model='text-embedding-3-small',\n            )\n        assert len(embedding.data) == 1, (\n            f'Expected 1 embedding, got {len(embedding.data)}, doc section: {section}'\n        )\n        embedding = embedding.data[0].embedding\n        embedding_json = pydantic_core.to_json(embedding).decode()\n        await pool.execute(\n            'INSERT INTO doc_sections (url, title, content, embedding) VALUES ($1, $2, $3, $4)',\n            url,\n            section.title,\n            section.content,\n            embedding_json,\n        )\n\n\n@dataclass\nclass DocsSection:\n    id: int\n    parent: int | None\n    path: str\n    level: int\n    title: str\n    content: str\n\n    def url(self) -> str:\n        url_path = re.sub(r'\\.md$', '', self.path)\n        return (\n            f'https://logfire.pydantic.dev/docs/{url_path}/#{slugify(self.title, \"-\")}'\n        )\n\n    def embedding_content(self) -> str:\n        return '\\n\\n'.join((f'path: {self.path}', f'title: {self.title}', self.content))\n\n\nsections_ta = TypeAdapter(list[DocsSection])\n\n\n### pyright: reportUnknownMemberType=false\n### pyright: reportUnknownVariableType=false\n@asynccontextmanager\nasync def database_connect(\n    create_db: bool = False,\n) -> AsyncGenerator[asyncpg.Pool, None]:\n    server_dsn, database = (\n        'postgresql://postgres:postgres@localhost:54320',\n        'pydantic_ai_rag',\n    )\n    if create_db:\n        with logfire.span('check and create DB'):\n            conn = await asyncpg.connect(server_dsn)\n            try:\n                db_exists = await conn.fetchval(\n                    'SELECT 1 FROM pg_database WHERE datname = $1', database\n                )\n                if not db_exists:\n                    await conn.execute(f'CREATE DATABASE {database}')\n            finally:\n                await conn.close()\n\n    pool = await asyncpg.create_pool(f'{server_dsn}/{database}')\n    try:\n        yield pool\n    finally:\n        await pool.close()\n\n\nDB_SCHEMA = \"\"\"\nCREATE EXTENSION IF NOT EXISTS vector;\n\nCREATE TABLE IF NOT EXISTS doc_sections (\n    id serial PRIMARY KEY,\n    url text NOT NULL UNIQUE,\n    title text NOT NULL,\n    content text NOT NULL,\n    -- text-embedding-3-small returns a vector of 1536 floats\n    embedding vector(1536) NOT NULL\n);\nCREATE INDEX IF NOT EXISTS idx_doc_sections_embedding ON doc_sections USING hnsw (embedding vector_l2_ops);\n\"\"\"\n\n\ndef slugify(value: str, separator: str, unicode: bool = False) -> str:\n    \"\"\"Slugify a string, to make it URL friendly.\"\"\"\n    # Taken unchanged from https://github.com/Python-Markdown/markdown/blob/3.7/markdown/extensions/toc.py#L38\n    if not unicode:\n        # Replace Extended Latin characters with ASCII, i.e. `žlutý` => `zluty`\n        value = unicodedata.normalize('NFKD', value)\n        value = value.encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n    return re.sub(rf'[{separator}\\s]+', separator, value)\n\n\nif __name__ == '__main__':\n    action = sys.argv[1] if len(sys.argv) > 1 else None\n    if action == 'build':\n        asyncio.run(build_search_db())\n    elif action == 'search':\n        if len(sys.argv) == 3:\n            q = sys.argv[2]\n        else:\n            q = 'How do I configure logfire to work with FastAPI?'\n        asyncio.run(run_agent(q))\n    else:\n        print(\n            'uv run --extra examples -m pydantic_ai_examples.rag build|search',\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n```",
  "content_length": 18287
}