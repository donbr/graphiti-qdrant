{
  "title": "`pydantic_ai.models.cohere`",
  "source_url": null,
  "content": "## Setup\n\nFor details on how to set up authentication with this model, see [model configuration for Cohere](../../../models/cohere/).\n\n### LatestCohereModelNames\n\n```python\nLatestCohereModelNames = Literal[\n    \"c4ai-aya-expanse-32b\",\n    \"c4ai-aya-expanse-8b\",\n    \"command-nightly\",\n    \"command-r-08-2024\",\n    \"command-r-plus-08-2024\",\n    \"command-r7b-12-2024\",\n]\n\n```\n\nLatest Cohere models.\n\n### CohereModelName\n\n```python\nCohereModelName = str | LatestCohereModelNames\n\n```\n\nPossible Cohere model names.\n\nSince Cohere supports a variety of date-stamped models, we explicitly list the latest models but allow any name in the type hints. See [Cohere's docs](https://docs.cohere.com/v2/docs/models) for a list of all available models.\n\n### CohereModelSettings\n\nBases: `ModelSettings`\n\nSettings used for a Cohere model request.\n\nSource code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`\n\n```python\nclass CohereModelSettings(ModelSettings, total=False):\n    \"\"\"Settings used for a Cohere model request.\"\"\"\n\n```\n\n### CohereModel\n\nBases: `Model`\n\nA model that uses the Cohere API.\n\nInternally, this uses the [Cohere Python client](https://github.com/cohere-ai/cohere-python) to interact with the API.\n\nApart from `__init__`, all methods are private or match those of the base class.\n\nSource code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`\n\n```python\n@dataclass(init=False)\nclass CohereModel(Model):\n    \"\"\"A model that uses the Cohere API.\n\n    Internally, this uses the [Cohere Python client](\n    https://github.com/cohere-ai/cohere-python) to interact with the API.\n\n    Apart from `__init__`, all methods are private or match those of the base class.\n    \"\"\"\n\n    client: AsyncClientV2 = field(repr=False)\n\n    _model_name: CohereModelName = field(repr=False)\n    _provider: Provider[AsyncClientV2] = field(repr=False)\n\n    def __init__(\n        self,\n        model_name: CohereModelName,\n        *,\n        provider: Literal['cohere'] | Provider[AsyncClientV2] = 'cohere',\n        profile: ModelProfileSpec | None = None,\n        settings: ModelSettings | None = None,\n    ):\n        \"\"\"Initialize an Cohere model.\n\n        Args:\n            model_name: The name of the Cohere model to use. List of model names\n                available [here](https://docs.cohere.com/docs/models#command).\n            provider: The provider to use for authentication and API access. Can be either the string\n                'cohere' or an instance of `Provider[AsyncClientV2]`. If not provided, a new provider will be\n                created using the other parameters.\n            profile: The model profile to use. Defaults to a profile picked by the provider based on the model name.\n            settings: Model-specific settings that will be used as defaults for this model.\n        \"\"\"\n        self._model_name = model_name\n\n        if isinstance(provider, str):\n            provider = infer_provider(provider)\n        self._provider = provider\n        self.client = provider.client\n\n        super().__init__(settings=settings, profile=profile or provider.model_profile)\n\n    @property\n    def base_url(self) -> str:\n        client_wrapper = self.client._client_wrapper  # type: ignore\n        return str(client_wrapper.get_base_url())\n\n    @property\n    def model_name(self) -> CohereModelName:\n        \"\"\"The model name.\"\"\"\n        return self._model_name\n\n    @property\n    def system(self) -> str:\n        \"\"\"The model provider.\"\"\"\n        return self._provider.name\n\n    async def request(\n        self,\n        messages: list[ModelMessage],\n        model_settings: ModelSettings | None,\n        model_request_parameters: ModelRequestParameters,\n    ) -> ModelResponse:\n        check_allow_model_requests()\n        model_settings, model_request_parameters = self.prepare_request(\n            model_settings,\n            model_request_parameters,\n        )\n        response = await self._chat(messages, cast(CohereModelSettings, model_settings or {}), model_request_parameters)\n        model_response = self._process_response(response)\n        return model_response\n\n    async def _chat(\n        self,\n        messages: list[ModelMessage],\n        model_settings: CohereModelSettings,\n        model_request_parameters: ModelRequestParameters,\n    ) -> V2ChatResponse:\n        tools = self._get_tools(model_request_parameters)\n\n        if model_request_parameters.builtin_tools:\n            raise UserError('Cohere does not support built-in tools')\n\n        cohere_messages = self._map_messages(messages, model_request_parameters)\n        try:\n            return await self.client.chat(\n                model=self._model_name,\n                messages=cohere_messages,\n                tools=tools or OMIT,\n                max_tokens=model_settings.get('max_tokens', OMIT),\n                stop_sequences=model_settings.get('stop_sequences', OMIT),\n                temperature=model_settings.get('temperature', OMIT),\n                p=model_settings.get('top_p', OMIT),\n                seed=model_settings.get('seed', OMIT),\n                presence_penalty=model_settings.get('presence_penalty', OMIT),\n                frequency_penalty=model_settings.get('frequency_penalty', OMIT),\n            )\n        except ApiError as e:\n            if (status_code := e.status_code) and status_code >= 400:\n                raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n            raise ModelAPIError(model_name=self.model_name, message=str(e)) from e\n\n    def _process_response(self, response: V2ChatResponse) -> ModelResponse:\n        \"\"\"Process a non-streamed response, and prepare a message to return.\"\"\"\n        parts: list[ModelResponsePart] = []\n        if response.message.content is not None:\n            for content in response.message.content:\n                if content.type == 'text':\n                    parts.append(TextPart(content=content.text))\n                elif content.type == 'thinking':  # pragma: no branch\n                    parts.append(ThinkingPart(content=content.thinking))\n        for c in response.message.tool_calls or []:\n            if c.function and c.function.name and c.function.arguments:  # pragma: no branch\n                parts.append(\n                    ToolCallPart(\n                        tool_name=c.function.name,\n                        args=c.function.arguments,\n                        tool_call_id=c.id or _generate_tool_call_id(),\n                    )\n                )\n\n        raw_finish_reason = response.finish_reason\n        provider_details = {'finish_reason': raw_finish_reason}\n        finish_reason = _FINISH_REASON_MAP.get(raw_finish_reason)\n\n        return ModelResponse(\n            parts=parts,\n            usage=_map_usage(response),\n            model_name=self._model_name,\n            provider_name=self._provider.name,\n            finish_reason=finish_reason,\n            provider_details=provider_details,\n        )\n\n    def _map_messages(\n        self, messages: list[ModelMessage], model_request_parameters: ModelRequestParameters\n    ) -> list[ChatMessageV2]:\n        \"\"\"Just maps a `pydantic_ai.Message` to a `cohere.ChatMessageV2`.\"\"\"\n        cohere_messages: list[ChatMessageV2] = []\n        for message in messages:\n            if isinstance(message, ModelRequest):\n                cohere_messages.extend(self._map_user_message(message))\n            elif isinstance(message, ModelResponse):\n                texts: list[str] = []\n                thinking: list[str] = []\n                tool_calls: list[ToolCallV2] = []\n                for item in message.parts:\n                    if isinstance(item, TextPart):\n                        texts.append(item.content)\n                    elif isinstance(item, ThinkingPart):\n                        thinking.append(item.content)\n                    elif isinstance(item, ToolCallPart):\n                        tool_calls.append(self._map_tool_call(item))\n                    elif isinstance(item, BuiltinToolCallPart | BuiltinToolReturnPart):  # pragma: no cover\n                        # This is currently never returned from cohere\n                        pass\n                    elif isinstance(item, FilePart):  # pragma: no cover\n                        # Files generated by models are not sent back to models that don't themselves generate files.\n                        pass\n                    else:\n                        assert_never(item)\n\n                message_param = AssistantChatMessageV2(role='assistant')\n                if texts or thinking:\n                    contents: list[AssistantMessageV2ContentItem] = []\n                    if thinking:\n                        contents.append(ThinkingAssistantMessageV2ContentItem(thinking='\\n\\n'.join(thinking)))\n                    if texts:  # pragma: no branch\n                        contents.append(TextAssistantMessageV2ContentItem(text='\\n\\n'.join(texts)))\n                    message_param.content = contents\n                if tool_calls:\n                    message_param.tool_calls = tool_calls\n                cohere_messages.append(message_param)\n            else:\n                assert_never(message)\n        if instructions := self._get_instructions(messages, model_request_parameters):\n            cohere_messages.insert(0, SystemChatMessageV2(role='system', content=instructions))\n        return cohere_messages\n\n    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[ToolV2]:\n        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]\n\n    @staticmethod\n    def _map_tool_call(t: ToolCallPart) -> ToolCallV2:\n        return ToolCallV2(\n            id=_guard_tool_call_id(t=t),\n            type='function',\n            function=ToolCallV2Function(\n                name=t.tool_name,\n                arguments=t.args_as_json_str(),\n            ),\n        )\n\n    @staticmethod\n    def _map_tool_definition(f: ToolDefinition) -> ToolV2:\n        return ToolV2(\n            type='function',\n            function=ToolV2Function(\n                name=f.name,\n                description=f.description,\n                parameters=f.parameters_json_schema,\n            ),\n        )\n\n    @classmethod\n    def _map_user_message(cls, message: ModelRequest) -> Iterable[ChatMessageV2]:\n        for part in message.parts:\n            if isinstance(part, SystemPromptPart):\n                yield SystemChatMessageV2(role='system', content=part.content)\n            elif isinstance(part, UserPromptPart):\n                if isinstance(part.content, str):\n                    yield UserChatMessageV2(role='user', content=part.content)\n                else:\n                    raise RuntimeError('Cohere does not yet support multi-modal inputs.')\n            elif isinstance(part, ToolReturnPart):\n                yield ToolChatMessageV2(\n                    role='tool',\n                    tool_call_id=_guard_tool_call_id(t=part),\n                    content=part.model_response_str(),\n                )\n            elif isinstance(part, RetryPromptPart):\n                if part.tool_name is None:\n                    yield UserChatMessageV2(role='user', content=part.model_response())  # pragma: no cover\n                else:\n                    yield ToolChatMessageV2(\n                        role='tool',\n                        tool_call_id=_guard_tool_call_id(t=part),\n                        content=part.model_response(),\n                    )\n            else:\n                assert_never(part)\n\n```\n\n#### __init__\n\n```python\n__init__(\n    model_name: CohereModelName,\n    *,\n    provider: (\n        Literal[\"cohere\"] | Provider[AsyncClientV2]\n    ) = \"cohere\",\n    profile: ModelProfileSpec | None = None,\n    settings: ModelSettings | None = None\n)\n\n```\n\nInitialize an Cohere model.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `model_name` | `CohereModelName` | The name of the Cohere model to use. List of model names available here. | *required* | | `provider` | `Literal['cohere'] | Provider[AsyncClientV2]` | The provider to use for authentication and API access. Can be either the string 'cohere' or an instance of Provider[AsyncClientV2]. If not provided, a new provider will be created using the other parameters. | `'cohere'` | | `profile` | `ModelProfileSpec | None` | The model profile to use. Defaults to a profile picked by the provider based on the model name. | `None` | | `settings` | `ModelSettings | None` | Model-specific settings that will be used as defaults for this model. | `None` |\n\nSource code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`\n\n```python\ndef __init__(\n    self,\n    model_name: CohereModelName,\n    *,\n    provider: Literal['cohere'] | Provider[AsyncClientV2] = 'cohere',\n    profile: ModelProfileSpec | None = None,\n    settings: ModelSettings | None = None,\n):\n    \"\"\"Initialize an Cohere model.\n\n    Args:\n        model_name: The name of the Cohere model to use. List of model names\n            available [here](https://docs.cohere.com/docs/models#command).\n        provider: The provider to use for authentication and API access. Can be either the string\n            'cohere' or an instance of `Provider[AsyncClientV2]`. If not provided, a new provider will be\n            created using the other parameters.\n        profile: The model profile to use. Defaults to a profile picked by the provider based on the model name.\n        settings: Model-specific settings that will be used as defaults for this model.\n    \"\"\"\n    self._model_name = model_name\n\n    if isinstance(provider, str):\n        provider = infer_provider(provider)\n    self._provider = provider\n    self.client = provider.client\n\n    super().__init__(settings=settings, profile=profile or provider.model_profile)\n\n```\n\n#### model_name\n\n```python\nmodel_name: CohereModelName\n\n```\n\nThe model name.\n\n#### system\n\n```python\nsystem: str\n\n```\n\nThe model provider.",
  "content_length": 13939
}