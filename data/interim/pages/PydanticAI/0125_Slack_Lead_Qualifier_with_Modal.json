{
  "title": "Slack Lead Qualifier with Modal",
  "source_url": null,
  "content": "In this example, we're going to build an agentic app that:\n\n- automatically researches each new member that joins a company's public Slack community to see how good of a fit they are for the company's commercial product,\n- sends this analysis into a (private) Slack channel, and\n- sends a daily summary of the top 5 leads from the previous 24 hours into a (different) Slack channel.\n\nWe'll be deploying the app on [Modal](https://modal.com), as it lets you use Python to define an app with web endpoints, scheduled functions, and background functions, and deploy them with a CLI, without needing to set up or manage any infrastructure. It's a great way to lower the barrier for people in your organization to start building and deploying AI agents to make their jobs easier.\n\nWe also add [Pydantic Logfire](https://pydantic.dev/logfire) to get observability into the app and agent as they're running in response to webhooks and the schedule\n\n## Screenshots\n\nThis is what the analysis sent into Slack will look like:\n\nThis is what the corresponding trace in [Logfire](https://pydantic.dev/logfire) will look like:\n\nAll of these entries can be clicked on to get more details about what happened at that step, including the full conversation with the LLM and HTTP requests and responses.\n\n## Prerequisites\n\nIf you just want to see the code without actually going through the effort of setting up the bits necessary to run it, feel free to [jump ahead](#the-code).\n\n### Slack app\n\nYou need to have a Slack workspace and the necessary permissions to create apps.\n\n2. Create a new Slack app using the instructions at <https://docs.slack.dev/quickstart>.\n\n   1. In step 2, \"Requesting scopes\", request the following scopes:\n      - [`users.read`](https://docs.slack.dev/reference/scopes/users.read)\n      - [`users.read.email`](https://docs.slack.dev/reference/scopes/users.read.email)\n      - [`users.profile.read`](https://docs.slack.dev/reference/scopes/users.profile.read)\n   1. In step 3, \"Installing and authorizing the app\", note down the Access Token as we're going to need to store it as a Secret in Modal.\n   1. You can skip steps 4 and 5. We're going to need to subscribe to the `team_join` event, but at this point you don't have a webhook URL yet.\n\n1. Create the channels the app will post into, and add the Slack app to them:\n\n   - `#new-slack-leads`\n   - `#daily-slack-leads-summary`\n\n   These names are hard-coded in the example. If you want to use different channels, you can clone the repo and change them in `examples/pydantic_examples/slack_lead_qualifier/functions.py`.\n\n### Logfire Write Token\n\n1. If you don't have a Logfire account yet, create one on <https://logfire-us.pydantic.dev/>.\n1. Create a new project named, for example, `slack-lead-qualifier`.\n1. Generate a new Write Token and note it down, as we're going to need to store it as a Secret in Modal.\n\n### OpenAI API Key\n\n1. If you don't have an OpenAI account yet, create one on <https://platform.openai.com/>.\n1. Create a new API Key in Settings and note it down, as we're going to need to store it as a Secret in Modal.\n\n### Modal account\n\n1. If you don't have a Modal account yet, create one on <https://modal.com/signup>.\n1. Create 3 Secrets of type \"Custom\" on <https://modal.com/secrets>:\n   - Name: `slack`, key: `SLACK_API_KEY`, value: the Slack Access Token you generated earlier\n   - Name: `logfire`, key: `LOGFIRE_TOKEN`, value: the Logfire Write Token you generated earlier\n   - Name: `openai`, key: `OPENAI_API_KEY`, value: the OpenAI API Key you generated earlier\n\n## Usage\n\n1. Make sure you have the [dependencies installed](../setup/#usage).\n\n1. Authenticate with Modal:\n\n   ```bash\n   python/uv-run -m modal setup\n\n   ```\n\n1. Run the example as an [ephemeral Modal app](https://modal.com/docs/guide/apps#ephemeral-apps), meaning it will only run until you quit it using Ctrl+C:\n\n   ```bash\n   python/uv-run -m modal serve -m pydantic_ai_examples.slack_lead_qualifier.modal\n\n   ```\n\n1. Note down the URL after `Created web function web_app =>`, this is your webhook endpoint URL.\n\n1. Go back to <https://docs.slack.dev/quickstart> and follow step 4, \"Configuring the app for event listening\", to subscribe to the `team_join` event with the webhook endpoint URL you noted down as the Request URL.\n\nNow when someone new (possibly you with a throwaway email) joins the Slack workspace, you'll see the webhook event being processed in the terminal where you ran `modal serve` and in the Logfire Live view, and after waiting a few seconds you should see the result appear in the `#new-slack-leads` Slack channel!\n\nFaking a Slack signup\n\nYou can also fake a Slack signup event and try out the agent like this, with any name or email you please:\n\n```bash\ncurl -X POST <webhook endpoint URL> \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"type\": \"event_callback\",\n    \"event\": {\n        \"type\": \"team_join\",\n        \"user\": {\n            \"profile\": {\n                \"email\": \"samuel@pydantic.dev\",\n                \"first_name\": \"Samuel\",\n                \"last_name\": \"Colvin\",\n                \"display_name\": \"Samuel Colvin\"\n            }\n        }\n    }\n}'\n\n```\n\nDeploying to production\n\nIf you'd like to deploy this app into your Modal workspace in a persistent fashion, you can use this command:\n\n```bash\npython/uv-run -m modal deploy -m pydantic_ai_examples.slack_lead_qualifier.modal\n\n```\n\nYou'll likely want to [download the code](https://github.com/pydantic/pydantic-ai/tree/main/examples/pydantic_ai_examples/slack_lead_qualifier) first, put it in a new repo, and then do [continuous deployment](https://modal.com/docs/guide/continuous-deployment#github-actions) using GitHub Actions.\n\nDon't forget to update the Slack event request URL to the new persistent URL! You'll also want to modify the [instructions for the agent](#agent) to your own situation.\n\n## The code\n\nWe're going to start with the basics, and then gradually build up into the full app.\n\n### Models\n\n#### `Profile`\n\nFirst, we define a [Pydantic](https://docs.pydantic.dev) model that represents a Slack user profile. These are the fields we get from the [`team_join`](https://docs.slack.dev/reference/events/team_join) event that's sent to the webhook endpoint that we'll define in a bit.\n\n[slack_lead_qualifier/models.py (L11-L15)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/models.py#L11-L15)\n\n```python\n...\n\nclass Profile(BaseModel):\n    first_name: str | None = None\n    last_name: str | None = None\n    display_name: str | None = None\n    email: str\n\n...\n\n```\n\nWe also define a `Profile.as_prompt()` helper method that uses format_as_xml to turn the profile into a string that can be sent to the model.\n\n[slack_lead_qualifier/models.py (L7-L19)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/models.py#L7-L19)\n\n```python\n...\n\nfrom pydantic_ai import format_as_xml\n\n...\n\nclass Profile(BaseModel):\n\n...\n\n    def as_prompt(self) -> str:\n        return format_as_xml(self, root_tag='profile')\n\n...\n\n```\n\n#### `Analysis`\n\nThe second model we'll need represents the result of the analysis that the agent will perform. We include docstrings to provide additional context to the model on what these fields should contain.\n\n[slack_lead_qualifier/models.py (L23-L31)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/models.py#L23-L31)\n\n```python\n...\n\nclass Analysis(BaseModel):\n    profile: Profile\n    organization_name: str\n    organization_domain: str\n    job_title: str\n    relevance: Annotated[int, Ge(1), Le(5)]\n    \"\"\"Estimated fit for Pydantic Logfire: 1 = low, 5 = high\"\"\"\n    summary: str\n    \"\"\"One-sentence welcome note summarising who they are and how we might help\"\"\"\n\n...\n\n```\n\nWe also define a `Analysis.as_slack_blocks()` helper method that turns the analysis into some [Slack blocks](https://api.slack.com/reference/block-kit/blocks) that can be sent to the Slack API to post a new message.\n\n[slack_lead_qualifier/models.py (L23-L46)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/models.py#L23-L46)\n\n```python\n...\n\nclass Analysis(BaseModel):\n\n...\n\n    def as_slack_blocks(self, include_relevance: bool = False) -> list[dict[str, Any]]:\n        profile = self.profile\n        relevance = f'({self.relevance}/5)' if include_relevance else ''\n        return [\n            {\n                'type': 'markdown',\n                'text': f'[{profile.display_name}](mailto:{profile.email}), {self.job_title} at [**{self.organization_name}**](https://{self.organization_domain}) {relevance}',\n            },\n            {\n                'type': 'markdown',\n                'text': self.summary,\n            },\n        ]\n\n```\n\n### Agent\n\nNow it's time to get into Pydantic AI and define the agent that will do the actual analysis!\n\nWe specify the model we'll use (`openai:gpt-5`), provide [instructions](../../agents/#instructions), give the agent access to the [DuckDuckGo search tool](../../common-tools/#duckduckgo-search-tool), and tell it to output either an `Analysis` or `None` using the [Native Output](../../output/#native-output) structured output mode.\n\nThe real meat of the app is in the instructions that tell the agent how to evaluate each new Slack member. If you plan to use this app yourself, you'll of course want to modify them to your own situation.\n\n[Learn about Gateway](../../gateway) [slack_lead_qualifier/agent.py (L7-L40)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/agent.py#L7-L40)\n\n```python\n...\n\nfrom pydantic_ai import Agent, NativeOutput\nfrom pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n\n...\n\nagent = Agent(\n    'gateway/openai:gpt-5',\n    instructions=dedent(\n        \"\"\"\n        When a new person joins our public Slack, please put together a brief snapshot so we can be most useful to them.\n\n        **What to include**\n\n        1. **Who they are:**  Any details about their professional role or projects (e.g. LinkedIn, GitHub, company bio).\n        2. **Where they work:**  Name of the organisation and its domain.\n        3. **How we can help:**  On a scale of 1–5, estimate how likely they are to benefit from **Pydantic Logfire**\n           (our paid observability tool) based on factors such as company size, product maturity, or AI usage.\n           *1 = probably not relevant, 5 = very strong fit.*\n\n        **Our products (for context only)**\n        • **Pydantic Validation** – Python data-validation (open source)\n        • **Pydantic AI** – Python agent framework (open source)\n        • **Pydantic Logfire** – Observability for traces, logs & metrics with first-class AI support (commercial)\n\n        **How to research**\n\n        • Use the provided DuckDuckGo search tool to research the person and the organization they work for, based on the email domain or what you find on e.g. LinkedIn and GitHub.\n        • If you can't find enough to form a reasonable view, return **None**.\n        \"\"\"\n    ),\n    tools=[duckduckgo_search_tool()],\n    output_type=NativeOutput([Analysis, NoneType]),\n)\n\n...\n\n```\n\n[slack_lead_qualifier/agent.py (L7-L40)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/agent.py#L7-L40)\n\n```python\n...\n\nfrom pydantic_ai import Agent, NativeOutput\nfrom pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n\n...\n\nagent = Agent(\n    'openai:gpt-5',\n    instructions=dedent(\n        \"\"\"\n        When a new person joins our public Slack, please put together a brief snapshot so we can be most useful to them.\n\n        **What to include**\n\n        1. **Who they are:**  Any details about their professional role or projects (e.g. LinkedIn, GitHub, company bio).\n        2. **Where they work:**  Name of the organisation and its domain.\n        3. **How we can help:**  On a scale of 1–5, estimate how likely they are to benefit from **Pydantic Logfire**\n           (our paid observability tool) based on factors such as company size, product maturity, or AI usage.\n           *1 = probably not relevant, 5 = very strong fit.*\n\n        **Our products (for context only)**\n        • **Pydantic Validation** – Python data-validation (open source)\n        • **Pydantic AI** – Python agent framework (open source)\n        • **Pydantic Logfire** – Observability for traces, logs & metrics with first-class AI support (commercial)\n\n        **How to research**\n\n        • Use the provided DuckDuckGo search tool to research the person and the organization they work for, based on the email domain or what you find on e.g. LinkedIn and GitHub.\n        • If you can't find enough to form a reasonable view, return **None**.\n        \"\"\"\n    ),\n    tools=[duckduckgo_search_tool()],\n    output_type=NativeOutput([Analysis, NoneType]),\n)\n\n...\n\n```\n\n#### `analyze_profile`\n\nWe also define a `analyze_profile` helper function that takes a `Profile`, runs the agent, and returns an `Analysis` (or `None`), and instrument it using [Logfire](../../logfire/).\n\n[slack_lead_qualifier/agent.py (L44-L47)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/agent.py#L44-L47)\n\n```python\n...\n\n@logfire.instrument('Analyze profile')\nasync def analyze_profile(profile: Profile) -> Analysis | None:\n    result = await agent.run(profile.as_prompt())\n    return result.output\n\n```\n\n### Analysis store\n\nThe next building block we'll need is a place to store all the analyses that have been done so that we can look them up when we send the daily summary.\n\nFortunately, Modal provides us with a convenient way to store some data that can be read back in a subsequent Modal run (webhook or scheduled): [`modal.Dict`](https://modal.com/docs/reference/modal.Dict).\n\nWe define some convenience methods to easily add, list, and clear analyses.\n\n[slack_lead_qualifier/store.py (L4-L31)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/store.py#L4-L31)\n\n```python\n...\n\nimport modal\n\n...\n\nclass AnalysisStore:\n    @classmethod\n    @logfire.instrument('Add analysis to store')\n    async def add(cls, analysis: Analysis):\n        await cls._get_store().put.aio(analysis.profile.email, analysis.model_dump())\n\n    @classmethod\n    @logfire.instrument('List analyses from store')\n    async def list(cls) -> list[Analysis]:\n        return [\n            Analysis.model_validate(analysis)\n            async for analysis in cls._get_store().values.aio()\n        ]\n\n    @classmethod\n    @logfire.instrument('Clear analyses from store')\n    async def clear(cls):\n        await cls._get_store().clear.aio()\n\n    @classmethod\n    def _get_store(cls) -> modal.Dict:\n        return modal.Dict.from_name('analyses', create_if_missing=True)  # type: ignore\n\n```\n\nNote\n\nNote that `# type: ignore` on the last line -- unfortunately `modal` does not fully define its types, so we need this to stop our static type checker `pyright`, which we run over all Pydantic AI code including examples, from complaining.\n\n### Send Slack message\n\nNext, we'll need a way to actually send a Slack message, so we define a simple function that uses Slack's [`chat.postMessage`](https://api.slack.com/methods/chat.postMessage) API.\n\n[slack_lead_qualifier/slack.py (L8-L30)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/slack.py#L8-L30)\n\n```python\n...\n\nAPI_KEY = os.getenv('SLACK_API_KEY')\nassert API_KEY, 'SLACK_API_KEY is not set'\n\n\n@logfire.instrument('Send Slack message')\nasync def send_slack_message(channel: str, blocks: list[dict[str, Any]]):\n    client = httpx.AsyncClient()\n    response = await client.post(\n        'https://slack.com/api/chat.postMessage',\n        json={\n            'channel': channel,\n            'blocks': blocks,\n        },\n        headers={\n            'Authorization': f'Bearer {API_KEY}',\n        },\n        timeout=5,\n    )\n    response.raise_for_status()\n    result = response.json()\n    if not result.get('ok', False):\n        error = result.get('error', 'Unknown error')\n        raise Exception(f'Failed to send to Slack: {error}')\n\n```\n\n### Features\n\nNow we can start putting these building blocks together to implement the actual features we want!\n\n#### `process_slack_member`\n\nThis function takes a [`Profile`](#profile), [analyzes](#analyze_profile) it using the agent, adds it to the [`AnalysisStore`](#analysis-store), and [sends](#send-slack-message) the analysis into the `#new-slack-leads` channel.\n\n[slack_lead_qualifier/functions.py (L4-L45)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/functions.py#L4-L45)\n\n```python\n...\n\nfrom .agent import analyze_profile\nfrom .models import Profile\n\nfrom .slack import send_slack_message\nfrom .store import AnalysisStore\n\n...\n\nNEW_LEAD_CHANNEL = '#new-slack-leads'\n\n...\n\n@logfire.instrument('Process Slack member')\nasync def process_slack_member(profile: Profile):\n    analysis = await analyze_profile(profile)\n    logfire.info('Analysis', analysis=analysis)\n\n    if analysis is None:\n        return\n\n    await AnalysisStore().add(analysis)\n\n    await send_slack_message(\n        NEW_LEAD_CHANNEL,\n        [\n            {\n                'type': 'header',\n                'text': {\n                    'type': 'plain_text',\n                    'text': f'New Slack member with score {analysis.relevance}/5',\n                },\n            },\n            {\n                'type': 'divider',\n            },\n            *analysis.as_slack_blocks(),\n        ],\n    )\n\n...\n\n```\n\n#### `send_daily_summary`\n\nThis function list all of the analyses in the [`AnalysisStore`](#analysis-store), takes the top 5 by relevance, [sends](#send-slack-message) them into the `#daily-slack-leads-summary` channel, and clears the `AnalysisStore` so that the next daily run won't process these analyses again.\n\n[slack_lead_qualifier/functions.py (L8-L85)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/functions.py#L8-L85)\n\n```python\n...\n\nfrom .slack import send_slack_message\nfrom .store import AnalysisStore\n\n...\n\nDAILY_SUMMARY_CHANNEL = '#daily-slack-leads-summary'\n\n...\n\n@logfire.instrument('Send daily summary')\nasync def send_daily_summary():\n    analyses = await AnalysisStore().list()\n    logfire.info('Analyses', analyses=analyses)\n\n    if len(analyses) == 0:\n        return\n\n    sorted_analyses = sorted(analyses, key=lambda x: x.relevance, reverse=True)\n    top_analyses = sorted_analyses[:5]\n\n    blocks = [\n        {\n            'type': 'header',\n            'text': {\n                'type': 'plain_text',\n                'text': f'Top {len(top_analyses)} new Slack members from the last 24 hours',\n            },\n        },\n    ]\n\n    for analysis in top_analyses:\n        blocks.extend(\n            [\n                {\n                    'type': 'divider',\n                },\n                *analysis.as_slack_blocks(include_relevance=True),\n            ]\n        )\n\n    await send_slack_message(\n        DAILY_SUMMARY_CHANNEL,\n        blocks,\n    )\n\n    await AnalysisStore().clear()\n\n```\n\n### Web app\n\nAs it stands, neither of these functions are actually being called from anywhere.\n\nLet's implement a [FastAPI](https://fastapi.tiangolo.com/) endpoint to handle the `team_join` Slack webhook (also known as the [Slack Events API](https://docs.slack.dev/apis/events-api)) and call the [`process_slack_member`](#process_slack_member) function we just defined. We also instrument FastAPI using Logfire for good measure.\n\n[slack_lead_qualifier/app.py (L20-L36)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/app.py#L20-L36)\n\n```python\n...\n\napp = FastAPI()\nlogfire.instrument_fastapi(app, capture_headers=True)\n\n\n@app.post('/')\nasync def process_webhook(payload: dict[str, Any]) -> dict[str, Any]:\n    if payload['type'] == 'url_verification':\n        return {'challenge': payload['challenge']}\n    elif (\n        payload['type'] == 'event_callback' and payload['event']['type'] == 'team_join'\n    ):\n        profile = Profile.model_validate(payload['event']['user']['profile'])\n\n        process_slack_member(profile)\n        return {'status': 'OK'}\n\n    raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY)\n\n```\n\n#### `process_slack_member` with Modal\n\nI was a little sneaky there -- we're not actually calling the [`process_slack_member`](#process_slack_member) function we defined in `functions.py` directly, as Slack requires webhooks to respond within 3 seconds, and we need a bit more time than that to talk to the LLM, do some web searches, and send the Slack message.\n\nInstead, we're calling the following function defined alongside the app, which uses Modal's [`modal.Function.spawn`](https://modal.com/docs/reference/modal.Function#spawn) feature to run a function in the background. (If you're curious what the Modal side of this function looks like, you can [jump ahead](#backgrounded-process_slack_member).)\n\nBecause `modal.py` (which we'll see in the next section) imports `app.py`, we import from `modal.py` inside the function definition because doing so at the top level would have resulted in a circular import error.\n\nWe also pass along the current Logfire context to get [Distributed Tracing](https://logfire.pydantic.dev/docs/how-to-guides/distributed-tracing/), meaning that the background function execution will show up nested under the webhook request trace, so that we have everything related to that request in one place.\n\n[slack_lead_qualifier/app.py (L11-L16)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/app.py#L11-L16)\n\n```python\n...\n\ndef process_slack_member(profile: Profile):\n    from .modal import process_slack_member as _process_slack_member\n\n    _process_slack_member.spawn(\n        profile.model_dump(), logfire_ctx=get_context()\n    )\n\n...\n\n```\n\n### Modal app\n\nNow let's see how easy Modal makes it to deploy all of this.\n\n#### Set up Modal\n\nThe first thing we do is define the Modal app, by specifying the base image to use (Debian with Python 3.13), all the Python packages it needs, and all of the secrets defined in the Modal interface that need to be made available during runtime.\n\n[slack_lead_qualifier/modal.py (L4-L21)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/modal.py#L4-L21)\n\n```python\n...\n\nimport modal\n\nimage = modal.Image.debian_slim(python_version='3.13').pip_install(\n    'pydantic',\n    'pydantic_ai_slim[openai,duckduckgo]',\n    'logfire[httpx,fastapi]',\n    'fastapi[standard]',\n    'httpx',\n)\napp = modal.App(\n    name='slack-lead-qualifier',\n    image=image,\n    secrets=[\n        modal.Secret.from_name('logfire'),\n        modal.Secret.from_name('openai'),\n        modal.Secret.from_name('slack'),\n    ],\n)\n\n...\n\n```\n\n#### Set up Logfire\n\nNext, we define a function to set up Logfire instrumentation for Pydantic AI and HTTPX.\n\nWe cannot do this at the top level of the file, as the requested packages (like `logfire`) will only be available within functions running on Modal (like the ones we'll define next). This file, `modal.py`, runs on your local machine and only has access to the `modal` package.\n\n[slack_lead_qualifier/modal.py (L25-L30)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/modal.py#L25-L30)\n\n```python\n...\n\ndef setup_logfire():\n    import logfire\n\n    logfire.configure(service_name=app.name)\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\n...\n\n```\n\n#### Web app\n\nTo deploy a [web endpoint](https://modal.com/docs/guide/webhooks) on Modal, we simply define a function that returns an ASGI app (like FastAPI) and decorate it with `@app.function()` and `@modal.asgi_app()`.\n\nThis `web_app` function will be run on Modal, so inside the function we can call the `setup_logfire` function that requires the `logfire` package, and import `app.py` which uses the other requested packages.\n\nBy default, Modal spins up a container to handle a function call (like a web request) on-demand, meaning there's a little bit of startup time to each request. However, Slack requires webhooks to respond within 3 seconds, so we specify `min_containers=1` to keep the web endpoint running and ready to answer requests at all times. This is a bit annoying and wasteful, but fortunately [Modal's pricing](https://modal.com/pricing) is pretty reasonable, you get $30 free monthly compute, and they offer up to $50k in free credits for startup and academic researchers.\n\n[slack_lead_qualifier/modal.py (L34-L41)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/modal.py#L34-L41)\n\n```python\n...\n\n@app.function(min_containers=1)\n@modal.asgi_app()  # type: ignore\ndef web_app():\n    setup_logfire()\n\n    from .app import app as _app\n\n    return _app\n\n...\n\n```\n\nNote\n\nNote that `# type: ignore` on the `@modal.asgi_app()` line -- unfortunately `modal` does not fully define its types, so we need this to stop our static type checker `pyright`, which we run over all Pydantic AI code including examples, from complaining.\n\n#### Scheduled `send_daily_summary`\n\nTo define a [scheduled function](https://modal.com/docs/guide/cron), we can use the `@app.function()` decorator with a `schedule` argument. This Modal function will call our imported [`send_daily_summary`](#send_daily_summary) function every day at 8 am UTC.\n\n[slack_lead_qualifier/modal.py (L60-L66)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/modal.py#L60-L66)\n\n```python\n...\n\n@app.function(schedule=modal.Cron('0 8 * * *'))  # Every day at 8am UTC\nasync def send_daily_summary():\n    setup_logfire()\n\n    from .functions import send_daily_summary as _send_daily_summary\n\n    await _send_daily_summary()\n\n```\n\n#### Backgrounded `process_slack_member`\n\nFinally, we define a Modal function that wraps our [`process_slack_member`](#process_slack_member) function, so that it can run in the background.\n\nAs you'll remember from when we [spawned this function from the web app](#process_slack_member-with-modal), we passed along the Logfire context to get [Distributed Tracing](https://logfire.pydantic.dev/docs/how-to-guides/distributed-tracing/), so we need to attach it here.\n\n[slack_lead_qualifier/modal.py (L45-L56)](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/slack_lead_qualifier/modal.py#L45-L56)\n\n```python\n...\n\n@app.function()\nasync def process_slack_member(profile_raw: dict[str, Any], logfire_ctx: Any):\n    setup_logfire()\n\n    from logfire.propagate import attach_context\n\n    from .functions import process_slack_member as _process_slack_member\n    from .models import Profile\n\n    with attach_context(logfire_ctx):\n        profile = Profile.model_validate(profile_raw)\n        await _process_slack_member(profile)\n\n...\n\n```\n\n## Conclusion\n\nAnd that's it! Now, assuming you've met the [prerequisites](#prerequisites), you can run or deploy the app using the commands under [usage](#usage).",
  "content_length": 27323
}