{
  "title": "Pydantic Model",
  "source_url": null,
  "content": "Simple example of using Pydantic AI to construct a Pydantic model from a text input.\n\nDemonstrates:\n\n- [structured `output_type`](../../output/#structured-output)\n\n## Running the Example\n\nWith [dependencies installed and environment variables set](../setup/#usage), run:\n\n```bash\npython -m pydantic_ai_examples.pydantic_model\n\n```\n\n```bash\nuv run -m pydantic_ai_examples.pydantic_model\n\n```\n\nThis examples uses `openai:gpt-5` by default, but it works well with other models, e.g. you can run it with Gemini using:\n\n```bash\nPYDANTIC_AI_MODEL=gemini-2.5-pro python -m pydantic_ai_examples.pydantic_model\n\n```\n\n```bash\nPYDANTIC_AI_MODEL=gemini-2.5-pro uv run -m pydantic_ai_examples.pydantic_model\n\n```\n\n(or `PYDANTIC_AI_MODEL=gemini-2.5-flash ...`)\n\n## Example Code\n\n[pydantic_model.py](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/pydantic_model.py)\n\n```python\n\"\"\"Simple example of using Pydantic AI to construct a Pydantic model from a text input.\n\nRun with:\n\n    uv run -m pydantic_ai_examples.pydantic_model\n\"\"\"\n\nimport os\n\nimport logfire\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent\n\n### 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured\nlogfire.configure(send_to_logfire='if-token-present')\nlogfire.instrument_pydantic_ai()\n\n\nclass MyModel(BaseModel):\n    city: str\n    country: str\n\n\nmodel = os.getenv('PYDANTIC_AI_MODEL', 'openai:gpt-5')\nprint(f'Using model: {model}')\nagent = Agent(model, output_type=MyModel)\n\nif __name__ == '__main__':\n    result = agent.run_sync('The windy city in the US of A.')\n    print(result.output)\n    print(result.usage())\n\n```",
  "content_length": 1675
}