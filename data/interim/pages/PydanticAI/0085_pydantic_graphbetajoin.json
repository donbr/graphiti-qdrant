{
  "title": "`pydantic_graph.beta.join`",
  "source_url": null,
  "content": "Join operations and reducers for graph execution.\n\nThis module provides the core components for joining parallel execution paths in a graph, including various reducer types that aggregate data from multiple sources into a single output.\n\n### JoinState\n\nThe state of a join during graph execution associated to a particular fork run.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\n@dataclass\nclass JoinState:\n    \"\"\"The state of a join during graph execution associated to a particular fork run.\"\"\"\n\n    current: Any\n    downstream_fork_stack: ForkStack\n    cancelled_sibling_tasks: bool = False\n\n```\n\n### ReducerContext\n\nBases: `Generic[StateT, DepsT]`\n\nContext information passed to reducer functions during graph execution.\n\nThe reducer context provides access to the current graph state and dependencies.\n\nType Parameters\n\nStateT: The type of the graph state DepsT: The type of the dependencies\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\n@dataclass(init=False)\nclass ReducerContext(Generic[StateT, DepsT]):\n    \"\"\"Context information passed to reducer functions during graph execution.\n\n    The reducer context provides access to the current graph state and dependencies.\n\n    Type Parameters:\n        StateT: The type of the graph state\n        DepsT: The type of the dependencies\n    \"\"\"\n\n    _state: StateT\n    \"\"\"The current graph state.\"\"\"\n    _deps: DepsT\n    \"\"\"The dependencies of the current graph run.\"\"\"\n    _join_state: JoinState\n    \"\"\"The JoinState for this reducer context.\"\"\"\n\n    def __init__(self, *, state: StateT, deps: DepsT, join_state: JoinState):\n        self._state = state\n        self._deps = deps\n        self._join_state = join_state\n\n    @property\n    def state(self) -> StateT:\n        \"\"\"The state of the graph run.\"\"\"\n        return self._state\n\n    @property\n    def deps(self) -> DepsT:\n        \"\"\"The deps for the graph run.\"\"\"\n        return self._deps\n\n    def cancel_sibling_tasks(self):\n        \"\"\"Cancel all sibling tasks created from the same fork.\n\n        You can call this if you want your join to have early-stopping behavior.\n        \"\"\"\n        self._join_state.cancelled_sibling_tasks = True\n\n```\n\n#### state\n\n```python\nstate: StateT\n\n```\n\nThe state of the graph run.\n\n#### deps\n\n```python\ndeps: DepsT\n\n```\n\nThe deps for the graph run.\n\n#### cancel_sibling_tasks\n\n```python\ncancel_sibling_tasks()\n\n```\n\nCancel all sibling tasks created from the same fork.\n\nYou can call this if you want your join to have early-stopping behavior.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef cancel_sibling_tasks(self):\n    \"\"\"Cancel all sibling tasks created from the same fork.\n\n    You can call this if you want your join to have early-stopping behavior.\n    \"\"\"\n    self._join_state.cancelled_sibling_tasks = True\n\n```\n\n### ReducerFunction\n\n```python\nReducerFunction = TypeAliasType(\n    \"ReducerFunction\",\n    ContextReducerFunction[StateT, DepsT, InputT, OutputT]\n    | PlainReducerFunction[InputT, OutputT],\n    type_params=(StateT, DepsT, InputT, OutputT),\n)\n\n```\n\nA function used for reducing inputs to a join node.\n\n### reduce_null\n\n```python\nreduce_null(current: None, inputs: Any) -> None\n\n```\n\nA reducer that discards all input data and returns None.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef reduce_null(current: None, inputs: Any) -> None:\n    \"\"\"A reducer that discards all input data and returns None.\"\"\"\n    return None\n\n```\n\n### reduce_list_append\n\n```python\nreduce_list_append(\n    current: list[T], inputs: T\n) -> list[T]\n\n```\n\nA reducer that appends to a list.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef reduce_list_append(current: list[T], inputs: T) -> list[T]:\n    \"\"\"A reducer that appends to a list.\"\"\"\n    current.append(inputs)\n    return current\n\n```\n\n### reduce_list_extend\n\n```python\nreduce_list_extend(\n    current: list[T], inputs: Iterable[T]\n) -> list[T]\n\n```\n\nA reducer that extends a list.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef reduce_list_extend(current: list[T], inputs: Iterable[T]) -> list[T]:\n    \"\"\"A reducer that extends a list.\"\"\"\n    current.extend(inputs)\n    return current\n\n```\n\n### reduce_dict_update\n\n```python\nreduce_dict_update(\n    current: dict[K, V], inputs: Mapping[K, V]\n) -> dict[K, V]\n\n```\n\nA reducer that updates a dict.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef reduce_dict_update(current: dict[K, V], inputs: Mapping[K, V]) -> dict[K, V]:\n    \"\"\"A reducer that updates a dict.\"\"\"\n    current.update(inputs)\n    return current\n\n```\n\n### SupportsSum\n\nBases: `Protocol`\n\nA protocol for a type that supports adding to itself.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\nclass SupportsSum(Protocol):\n    \"\"\"A protocol for a type that supports adding to itself.\"\"\"\n\n    @abstractmethod\n    def __add__(self, other: Self, /) -> Self:\n        pass\n\n```\n\n### reduce_sum\n\n```python\nreduce_sum(current: NumericT, inputs: NumericT) -> NumericT\n\n```\n\nA reducer that sums numbers.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef reduce_sum(current: NumericT, inputs: NumericT) -> NumericT:\n    \"\"\"A reducer that sums numbers.\"\"\"\n    return current + inputs\n\n```\n\n### ReduceFirstValue\n\nBases: `Generic[T]`\n\nA reducer that returns the first value it encounters, and cancels all other tasks.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\n@dataclass\nclass ReduceFirstValue(Generic[T]):\n    \"\"\"A reducer that returns the first value it encounters, and cancels all other tasks.\"\"\"\n\n    def __call__(self, ctx: ReducerContext[object, object], current: T, inputs: T) -> T:\n        \"\"\"The reducer function.\"\"\"\n        ctx.cancel_sibling_tasks()\n        return inputs\n\n```\n\n#### __call__\n\n```python\n__call__(\n    ctx: ReducerContext[object, object],\n    current: T,\n    inputs: T,\n) -> T\n\n```\n\nThe reducer function.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef __call__(self, ctx: ReducerContext[object, object], current: T, inputs: T) -> T:\n    \"\"\"The reducer function.\"\"\"\n    ctx.cancel_sibling_tasks()\n    return inputs\n\n```\n\n### Join\n\nBases: `Generic[StateT, DepsT, InputT, OutputT]`\n\nA join operation that synchronizes and aggregates parallel execution paths.\n\nA join defines how to combine outputs from multiple parallel execution paths using a ReducerFunction. It specifies which fork it joins (if any) and manages the initialization of reducers.\n\nType Parameters\n\nStateT: The type of the graph state DepsT: The type of the dependencies InputT: The type of input data to join OutputT: The type of the final joined output\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\n@dataclass(init=False)\nclass Join(Generic[StateT, DepsT, InputT, OutputT]):\n    \"\"\"A join operation that synchronizes and aggregates parallel execution paths.\n\n    A join defines how to combine outputs from multiple parallel execution paths\n    using a [`ReducerFunction`][pydantic_graph.beta.join.ReducerFunction]. It specifies which fork\n    it joins (if any) and manages the initialization of reducers.\n\n    Type Parameters:\n        StateT: The type of the graph state\n        DepsT: The type of the dependencies\n        InputT: The type of input data to join\n        OutputT: The type of the final joined output\n    \"\"\"\n\n    id: JoinID\n    _reducer: ReducerFunction[StateT, DepsT, InputT, OutputT]\n    _initial_factory: Callable[[], OutputT]\n    parent_fork_id: ForkID | None\n    preferred_parent_fork: Literal['closest', 'farthest']\n\n    def __init__(\n        self,\n        *,\n        id: JoinID,\n        reducer: ReducerFunction[StateT, DepsT, InputT, OutputT],\n        initial_factory: Callable[[], OutputT],\n        parent_fork_id: ForkID | None = None,\n        preferred_parent_fork: Literal['farthest', 'closest'] = 'farthest',\n    ):\n        self.id = id\n        self._reducer = reducer\n        self._initial_factory = initial_factory\n        self.parent_fork_id = parent_fork_id\n        self.preferred_parent_fork = preferred_parent_fork\n\n    @property\n    def reducer(self):\n        return self._reducer\n\n    @property\n    def initial_factory(self):\n        return self._initial_factory\n\n    def reduce(self, ctx: ReducerContext[StateT, DepsT], current: OutputT, inputs: InputT) -> OutputT:\n        n_parameters = len(inspect.signature(self.reducer).parameters)\n        if n_parameters == 2:\n            return cast(PlainReducerFunction[InputT, OutputT], self.reducer)(current, inputs)\n        else:\n            return cast(ContextReducerFunction[StateT, DepsT, InputT, OutputT], self.reducer)(ctx, current, inputs)\n\n    @overload\n    def as_node(self, inputs: None = None) -> JoinNode[StateT, DepsT]: ...\n\n    @overload\n    def as_node(self, inputs: InputT) -> JoinNode[StateT, DepsT]: ...\n\n    def as_node(self, inputs: InputT | None = None) -> JoinNode[StateT, DepsT]:\n        \"\"\"Create a step node with bound inputs.\n\n        Args:\n            inputs: The input data to bind to this step, or None\n\n        Returns:\n            A [`StepNode`][pydantic_graph.beta.step.StepNode] with this step and the bound inputs\n        \"\"\"\n        return JoinNode(self, inputs)\n\n```\n\n#### as_node\n\n```python\nas_node(inputs: None = None) -> JoinNode[StateT, DepsT]\n\n```\n\n```python\nas_node(inputs: InputT) -> JoinNode[StateT, DepsT]\n\n```\n\n```python\nas_node(\n    inputs: InputT | None = None,\n) -> JoinNode[StateT, DepsT]\n\n```\n\nCreate a step node with bound inputs.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `inputs` | `InputT | None` | The input data to bind to this step, or None | `None` |\n\nReturns:\n\n| Type | Description | | --- | --- | | `JoinNode[StateT, DepsT]` | A StepNode with this step and the bound inputs |\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\ndef as_node(self, inputs: InputT | None = None) -> JoinNode[StateT, DepsT]:\n    \"\"\"Create a step node with bound inputs.\n\n    Args:\n        inputs: The input data to bind to this step, or None\n\n    Returns:\n        A [`StepNode`][pydantic_graph.beta.step.StepNode] with this step and the bound inputs\n    \"\"\"\n    return JoinNode(self, inputs)\n\n```\n\n### JoinNode\n\nBases: `BaseNode[StateT, DepsT, Any]`\n\nA base node that represents a join item with bound inputs.\n\nJoinNode bridges between the v1 and v2 graph execution systems by wrapping a Join with bound inputs in a BaseNode interface. It is not meant to be run directly but rather used to indicate transitions to v2-style steps.\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\n@dataclass\nclass JoinNode(BaseNode[StateT, DepsT, Any]):\n    \"\"\"A base node that represents a join item with bound inputs.\n\n    JoinNode bridges between the v1 and v2 graph execution systems by wrapping\n    a [`Join`][pydantic_graph.beta.join.Join] with bound inputs in a BaseNode interface.\n    It is not meant to be run directly but rather used to indicate transitions\n    to v2-style steps.\n    \"\"\"\n\n    join: Join[StateT, DepsT, Any, Any]\n    \"\"\"The step to execute.\"\"\"\n\n    inputs: Any\n    \"\"\"The inputs bound to this step.\"\"\"\n\n    async def run(self, ctx: GraphRunContext[StateT, DepsT]) -> BaseNode[StateT, DepsT, Any] | End[Any]:\n        \"\"\"Attempt to run the join node.\n\n        Args:\n            ctx: The graph execution context\n\n        Returns:\n            The result of step execution\n\n        Raises:\n            NotImplementedError: Always raised as StepNode is not meant to be run directly\n        \"\"\"\n        raise NotImplementedError(\n            '`JoinNode` is not meant to be run directly, it is meant to be used in `BaseNode` subclasses to indicate a transition to v2-style steps.'\n        )\n\n```\n\n#### join\n\n```python\njoin: Join[StateT, DepsT, Any, Any]\n\n```\n\nThe step to execute.\n\n#### inputs\n\n```python\ninputs: Any\n\n```\n\nThe inputs bound to this step.\n\n#### run\n\n```python\nrun(\n    ctx: GraphRunContext[StateT, DepsT],\n) -> BaseNode[StateT, DepsT, Any] | End[Any]\n\n```\n\nAttempt to run the join node.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `ctx` | `GraphRunContext[StateT, DepsT]` | The graph execution context | *required* |\n\nReturns:\n\n| Type | Description | | --- | --- | | `BaseNode[StateT, DepsT, Any] | End[Any]` | The result of step execution |\n\nRaises:\n\n| Type | Description | | --- | --- | | `NotImplementedError` | Always raised as StepNode is not meant to be run directly |\n\nSource code in `pydantic_graph/pydantic_graph/beta/join.py`\n\n```python\nasync def run(self, ctx: GraphRunContext[StateT, DepsT]) -> BaseNode[StateT, DepsT, Any] | End[Any]:\n    \"\"\"Attempt to run the join node.\n\n    Args:\n        ctx: The graph execution context\n\n    Returns:\n        The result of step execution\n\n    Raises:\n        NotImplementedError: Always raised as StepNode is not meant to be run directly\n    \"\"\"\n    raise NotImplementedError(\n        '`JoinNode` is not meant to be run directly, it is meant to be used in `BaseNode` subclasses to indicate a transition to v2-style steps.'\n    )\n\n```",
  "content_length": 13154
}