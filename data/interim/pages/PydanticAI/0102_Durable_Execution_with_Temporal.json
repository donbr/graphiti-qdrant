{
  "title": "Durable Execution with Temporal",
  "source_url": null,
  "content": "[Temporal](https://temporal.io) is a popular [durable execution](https://docs.temporal.io/evaluate/understanding-temporal#durable-execution) platform that's natively supported by Pydantic AI.\n\n## Durable Execution\n\nIn Temporal's durable execution implementation, a program that crashes or encounters an exception while interacting with a model or API will retry until it can successfully complete.\n\nTemporal relies primarily on a replay mechanism to recover from failures. As the program makes progress, Temporal saves key inputs and decisions, allowing a re-started program to pick up right where it left off.\n\nThe key to making this work is to separate the application's repeatable (deterministic) and non-repeatable (non-deterministic) parts:\n\n1. Deterministic pieces, termed [**workflows**](https://docs.temporal.io/workflow-definition), execute the same way when re-run with the same inputs.\n1. Non-deterministic pieces, termed [**activities**](https://docs.temporal.io/activities), can run arbitrary code, performing I/O and any other operations.\n\nWorkflow code can run for extended periods and, if interrupted, resume exactly where it left off. Critically, workflow code generally *cannot* include any kind of I/O, over the network, disk, etc. Activity code faces no restrictions on I/O or external interactions, but if an activity fails part-way through it is restarted from the beginning.\n\nNote\n\nIf you are familiar with celery, it may be helpful to think of Temporal activities as similar to celery tasks, but where you wait for the task to complete and obtain its result before proceeding to the next step in the workflow. However, Temporal workflows and activities offer a great deal more flexibility and functionality than celery tasks.\n\nSee the [Temporal documentation](https://docs.temporal.io/evaluate/understanding-temporal#temporal-application-the-building-blocks) for more information\n\nIn the case of Pydantic AI agents, integration with Temporal means that [model requests](../../models/overview/), [tool calls](../../tools/) that may require I/O, and [MCP server communication](../../mcp/client/) all need to be offloaded to Temporal activities due to their I/O requirements, while the logic that coordinates them (i.e. the agent run) lives in the workflow. Code that handles a scheduled job or web request can then execute the workflow, which will in turn execute the activities as needed.\n\nThe diagram below shows the overall architecture of an agentic application in Temporal. The Temporal Server is responsible for tracking program execution and making sure the associated state is preserved reliably (i.e., stored to an internal database, and possibly replicated across cloud regions). Temporal Server manages data in encrypted form, so all data processing occurs on the Worker, which runs the workflow and activities.\n\n```text\n            +---------------------+\n            |   Temporal Server   |      (Stores workflow state,\n            +---------------------+       schedules activities,\n                     ^                    persists progress)\n                     |\n        Save state,  |   Schedule Tasks,\n        progress,    |   load state on resume\n        timeouts     |\n                     |\n+------------------------------------------------------+\n|                      Worker                          |\n|   +----------------------------------------------+   |\n|   |              Workflow Code                   |   |\n|   |       (Agent Run Loop)                       |   |\n|   +----------------------------------------------+   |\n|          |          |                |               |\n|          v          v                v               |\n|   +-----------+ +------------+ +-------------+       |\n|   | Activity  | | Activity   | |  Activity   |       |\n|   | (Tool)    | | (MCP Tool) | | (Model API) |       |\n|   +-----------+ +------------+ +-------------+       |\n|         |           |                |               |\n+------------------------------------------------------+\n          |           |                |\n          v           v                v\n      [External APIs, services, databases, etc.]\n\n```\n\nSee the [Temporal documentation](https://docs.temporal.io/evaluate/understanding-temporal#temporal-application-the-building-blocks) for more information.\n\n## Durable Agent\n\nAny agent can be wrapped in a TemporalAgent to get a durable agent that can be used inside a deterministic Temporal workflow, by automatically offloading all work that requires I/O (namely model requests, tool calls, and MCP server communication) to non-deterministic activities.\n\nAt the time of wrapping, the agent's [model](../../models/overview/) and [toolsets](../../toolsets/) (including function tools registered on the agent and MCP servers) are frozen, activities are dynamically created for each, and the original model and toolsets are wrapped to call on the worker to execute the corresponding activities instead of directly performing the actions inside the workflow. The original agent can still be used as normal outside the Temporal workflow, but any changes to its model or toolsets after wrapping will not be reflected in the durable agent.\n\nHere is a simple but complete example of wrapping an agent for durable execution, creating a Temporal workflow with durable execution logic, connecting to a Temporal server, and running the workflow from non-durable code. All it requires is a Temporal server to be [running locally](https://github.com/temporalio/temporal#download-and-start-temporal-server-locally):\n\n```sh\nbrew install temporal\ntemporal server start-dev\n\n```\n\ntemporal_agent.py\n\n```python\nimport uuid\n\nfrom temporalio import workflow\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.temporal import (\n    AgentPlugin,\n    PydanticAIPlugin,\n    TemporalAgent,\n)\n\nagent = Agent(\n    'gpt-5',\n    instructions=\"You're an expert in geography.\",\n    name='geography',  # (10)!\n)\n\ntemporal_agent = TemporalAgent(agent)  # (1)!\n\n\n@workflow.defn\nclass GeographyWorkflow:  # (2)!\n    @workflow.run\n    async def run(self, prompt: str) -> str:\n        result = await temporal_agent.run(prompt)  # (3)!\n        return result.output\n\n\nasync def main():\n    client = await Client.connect(  # (4)!\n        'localhost:7233',  # (5)!\n        plugins=[PydanticAIPlugin()],  # (6)!\n    )\n\n    async with Worker(  # (7)!\n        client,\n        task_queue='geography',\n        workflows=[GeographyWorkflow],\n        plugins=[AgentPlugin(temporal_agent)],  # (8)!\n    ):\n        output = await client.execute_workflow(  # (9)!\n            GeographyWorkflow.run,\n            args=['What is the capital of Mexico?'],\n            id=f'geography-{uuid.uuid4()}',\n            task_queue='geography',\n        )\n        print(output)\n        #> Mexico City (Ciudad de México, CDMX)\n\n```\n\n1. The original `Agent` cannot be used inside a deterministic Temporal workflow, but the `TemporalAgent` can.\n1. As explained above, the workflow represents a deterministic piece of code that can use non-deterministic activities for operations that require I/O.\n1. TemporalAgent.run() works just like Agent.run(), but it will automatically offload model requests, tool calls, and MCP server communication to Temporal activities.\n1. We connect to the Temporal server which keeps track of workflow and activity execution.\n1. This assumes the Temporal server is [running locally](https://github.com/temporalio/temporal#download-and-start-temporal-server-locally).\n1. The PydanticAIPlugin tells Temporal to use Pydantic for serialization and deserialization, and to treat UserError exceptions as non-retryable.\n1. We start the worker that will listen on the specified task queue and run workflows and activities. In a real world application, this might be run in a separate service.\n1. The AgentPlugin registers the `TemporalAgent`'s activities with the worker.\n1. We call on the server to execute the workflow on a worker that's listening on the specified task queue.\n1. The agent's `name` is used to uniquely identify its activities.\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\nIn a real world application, the agent, workflow, and worker are typically defined separately from the code that calls for a workflow to be executed. Because Temporal workflows need to be defined at the top level of the file and the `TemporalAgent` instance is needed inside the workflow and when starting the worker (to register the activities), it needs to be defined at the top level of the file as well.\n\nFor more information on how to use Temporal in Python applications, see their [Python SDK guide](https://docs.temporal.io/develop/python).\n\n## Temporal Integration Considerations\n\nThere are a few considerations specific to agents and toolsets when using Temporal for durable execution. These are important to understand to ensure that your agents and toolsets work correctly with Temporal's workflow and activity model.\n\n### Agent Names and Toolset IDs\n\nTo ensure that Temporal knows what code to run when an activity fails or is interrupted and then restarted, even if your code is changed in between, each activity needs to have a name that's stable and unique.\n\nWhen `TemporalAgent` dynamically creates activities for the wrapped agent's model requests and toolsets (specifically those that implement their own tool listing and calling, i.e. FunctionToolset and MCPServer), their names are derived from the agent's name and the toolsets' ids. These fields are normally optional, but are required to be set when using Temporal. They should not be changed once the durable agent has been deployed to production as this would break active workflows.\n\nOther than that, any agent and toolset will just work!\n\n### Instructions Functions, Output Functions, and History Processors\n\nPydantic AI runs non-async [instructions](../../agents/#instructions) and [system prompt](../../agents/#system-prompts) functions, [history processors](../../message-history/#processing-message-history), [output functions](../../output/#output-functions), and [output validators](../../output/#output-validator-functions) in threads, which are not supported inside Temporal workflows and require an activity. Ensure that these functions are async instead.\n\nSynchronous tool functions are supported, as tools are automatically run in activities unless this is [explicitly disabled](#activity-configuration). Still, it's recommended to make tool functions async as well to improve performance.\n\n### Agent Run Context and Dependencies\n\nAs workflows and activities run in separate processes, any values passed between them need to be serializable. As these payloads are stored in the workflow execution event history, Temporal limits their size to 2MB.\n\nTo account for these limitations, tool functions and the [event stream handler](#streaming) running inside activities receive a limited version of the agent's RunContext, and it's your responsibility to make sure that the [dependencies](../../dependencies/) object provided to TemporalAgent.run() can be serialized using Pydantic.\n\nSpecifically, only the `deps`, `run_id`, `retries`, `tool_call_id`, `tool_name`, `tool_call_approved`, `retry`, `max_retries`, `run_step`, `usage`, and `partial_output` fields are available by default, and trying to access `model`, `prompt`, `messages`, or `tracer` will raise an error. If you need one or more of these attributes to be available inside activities, you can create a TemporalRunContext subclass with custom `serialize_run_context` and `deserialize_run_context` class methods and pass it to TemporalAgent as `run_context_type`.\n\n### Streaming\n\nBecause Temporal activities cannot stream output directly to the activity call site, Agent.run_stream(), Agent.run_stream_events(), and Agent.iter() are not supported.\n\nInstead, you can implement streaming by setting an event_stream_handler on the `Agent` or `TemporalAgent` instance and using TemporalAgent.run() inside the workflow. The event stream handler function will receive the agent run context and an async iterable of events from the model's streaming response and the agent's execution of tools. For examples, see the [streaming docs](../../agents/#streaming-all-events).\n\nAs the streaming model request activity, workflow, and workflow execution call all take place in separate processes, passing data between them requires some care:\n\n- To get data from the workflow call site or workflow to the event stream handler, you can use a [dependencies object](#agent-run-context-and-dependencies).\n- To get data from the event stream handler to the workflow, workflow call site, or a frontend, you need to use an external system that the event stream handler can write to and the event consumer can read from, like a message queue. You can use the dependency object to make sure the same connection string or other unique ID is available in all the places that need it.\n\n## Activity Configuration\n\nTemporal activity configuration, like timeouts and retry policies, can be customized by passing [`temporalio.workflow.ActivityConfig`](https://python.temporal.io/temporalio.workflow.ActivityConfig.html) objects to the `TemporalAgent` constructor:\n\n- `activity_config`: The base Temporal activity config to use for all activities. If no config is provided, a `start_to_close_timeout` of 60 seconds is used.\n\n- `model_activity_config`: The Temporal activity config to use for model request activities. This is merged with the base activity config.\n\n- `toolset_activity_config`: The Temporal activity config to use for get-tools and call-tool activities for specific toolsets identified by ID. This is merged with the base activity config.\n\n- `tool_activity_config`: The Temporal activity config to use for specific tool call activities identified by toolset ID and tool name. This is merged with the base and toolset-specific activity configs.\n\n  If a tool does not use I/O, you can specify `False` to disable using an activity. Note that the tool is required to be defined as an `async` function as non-async tools are run in threads which are non-deterministic and thus not supported outside of activities.\n\n## Activity Retries\n\nOn top of the automatic retries for request failures that Temporal will perform, Pydantic AI and various provider API clients also have their own request retry logic. Enabling these at the same time may cause the request to be retried more often than expected, with improper `Retry-After` handling.\n\nWhen using Temporal, it's recommended to not use [HTTP Request Retries](../../retries/) and to turn off your provider API client's own retry logic, for example by setting `max_retries=0` on a [custom `OpenAIProvider` API client](../../models/openai/#custom-openai-client).\n\nYou can customize Temporal's retry policy using [activity configuration](#activity-configuration).\n\n## Observability with Logfire\n\nTemporal generates telemetry events and metrics for each workflow and activity execution, and Pydantic AI generates events for each agent run, model request and tool call. These can be sent to [Pydantic Logfire](../../logfire/) to get a complete picture of what's happening in your application.\n\nTo use Logfire with Temporal, you need to pass a LogfirePlugin object to Temporal's `Client.connect()`:\n\nlogfire_plugin.py\n\n```python\nfrom temporalio.client import Client\n\nfrom pydantic_ai.durable_exec.temporal import LogfirePlugin, PydanticAIPlugin\n\n\nasync def main():\n    client = await Client.connect(\n        'localhost:7233',\n        plugins=[PydanticAIPlugin(), LogfirePlugin()],\n    )\n\n```\n\nBy default, the `LogfirePlugin` will instrument Temporal (including metrics) and Pydantic AI and send all data to Logfire. To customize Logfire configuration and instrumentation, you can pass a `logfire_setup` function to the `LogfirePlugin` constructor and return a custom `Logfire` instance (i.e. the result of `logfire.configure()`). To disable sending Temporal metrics to Logfire, you can pass `metrics=False` to the `LogfirePlugin` constructor.\n\n## Known Issues\n\n### Pandas\n\nWhen `logfire.info` is used inside an activity and the `pandas` package is among your project's dependencies, you may encounter the following error which seems to be the result of an import race condition:\n\n```text\nAttributeError: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)\n\n```\n\nTo fix this, you can use the [`temporalio.workflow.unsafe.imports_passed_through()`](https://python.temporal.io/temporalio.workflow.unsafe.html#imports_passed_through) context manager to proactively import the package and not have it be reloaded in the workflow sandbox:\n\ntemporal_activity.py\n\n```python\nfrom temporalio import workflow\n\nwith workflow.unsafe.imports_passed_through():\n    import pandas\n\n```",
  "content_length": 16961
}