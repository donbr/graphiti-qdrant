{
  "title": "Durable Execution with Prefect",
  "source_url": null,
  "content": "[Prefect](https://www.prefect.io/) is a workflow orchestration framework for building resilient data pipelines in Python, natively integrated with Pydantic AI.\n\n## Durable Execution\n\nPrefect 3.0 brings [transactional semantics](https://www.prefect.io/blog/transactional-ml-pipelines-with-prefect-3-0) to your Python workflows, allowing you to group tasks into atomic units and define failure modes. If any part of a transaction fails, the entire transaction can be rolled back to a clean state.\n\n- **Flows** are the top-level entry points for your workflow. They can contain tasks and other flows.\n- **Tasks** are individual units of work that can be retried, cached, and monitored independently.\n\nPrefect 3.0's approach to transactional orchestration makes your workflows automatically **idempotent**: rerunnable without duplication or inconsistency across any environment. Every task is executed within a transaction that governs when and where the task's result record is persisted. If the task runs again under an identical context, it will not re-execute but instead load its previous result.\n\nThe diagram below shows the overall architecture of an agentic application with Prefect. Prefect uses client-side task orchestration by default, with optional server connectivity for advanced features like scheduling and monitoring.\n\n```text\n            +---------------------+\n            |   Prefect Server    |      (Monitoring,\n            |      or Cloud       |       scheduling, UI,\n            +---------------------+       orchestration)\n                     ^\n                     |\n        Flow state,  |   Schedule flows,\n        metadata,    |   track execution\n        logs         |\n                     |\n+------------------------------------------------------+\n|               Application Process                    |\n|   +----------------------------------------------+   |\n|   |              Flow (Agent.run)                |   |\n|   +----------------------------------------------+   |\n|          |          |                |               |\n|          v          v                v               |\n|   +-----------+ +------------+ +-------------+       |\n|   |   Task    | |    Task    | |    Task     |       |\n|   |  (Tool)   | | (MCP Tool) | | (Model API) |       |\n|   +-----------+ +------------+ +-------------+       |\n|         |           |                |               |\n|       Cache &     Cache &          Cache &           |\n|       persist     persist          persist           |\n|         to           to               to             |\n|         v            v                v              |\n|   +----------------------------------------------+   |\n|   |     Result Storage (Local FS, S3, etc.)     |    |\n|   +----------------------------------------------+   |\n+------------------------------------------------------+\n          |           |                |\n          v           v                v\n      [External APIs, services, databases, etc.]\n\n```\n\nSee the [Prefect documentation](https://docs.prefect.io/) for more information.\n\n## Durable Agent\n\nAny agent can be wrapped in a PrefectAgent to get durable execution. `PrefectAgent` automatically:\n\n- Wraps Agent.run and Agent.run_sync as Prefect flows.\n- Wraps [model requests](../../models/overview/) as Prefect tasks.\n- Wraps [tool calls](../../tools/) as Prefect tasks (configurable per-tool).\n- Wraps [MCP communication](../../mcp/client/) as Prefect tasks.\n\nEvent stream handlers are **automatically wrapped** by Prefect when running inside a Prefect flow. Each event from the stream is processed in a separate Prefect task for durability. You can customize the task behavior using the `event_stream_handler_task_config` parameter when creating the `PrefectAgent`. Do **not** manually decorate event stream handlers with `@task`. For examples, see the [streaming docs](../../agents/#streaming-all-events)\n\nThe original agent, model, and MCP server can still be used as normal outside the Prefect flow.\n\nHere is a simple but complete example of wrapping an agent for durable execution. All it requires is to install Pydantic AI with Prefect:\n\n```bash\npip install pydantic-ai[prefect]\n\n```\n\n```bash\nuv add pydantic-ai[prefect]\n\n```\n\nOr if you're using the slim package, you can install it with the `prefect` optional group:\n\n```bash\npip install pydantic-ai-slim[prefect]\n\n```\n\n```bash\nuv add pydantic-ai-slim[prefect]\n\n```\n\nprefect_agent.py\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.prefect import PrefectAgent\n\nagent = Agent(\n    'gpt-5',\n    instructions=\"You're an expert in geography.\",\n    name='geography',  # (1)!\n)\n\nprefect_agent = PrefectAgent(agent)  # (2)!\n\nasync def main():\n    result = await prefect_agent.run('What is the capital of Mexico?')  # (3)!\n    print(result.output)\n    #> Mexico City (Ciudad de México, CDMX)\n\n```\n\n1. The agent's `name` is used to uniquely identify its flows and tasks.\n1. Wrapping the agent with `PrefectAgent` enables durable execution for all agent runs.\n1. PrefectAgent.run() works like Agent.run(), but runs as a Prefect flow and executes model requests, decorated tool calls, and MCP communication as Prefect tasks.\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\nFor more information on how to use Prefect in Python applications, see their [Python documentation](https://docs.prefect.io/v3/how-to-guides/workflows/write-and-run).\n\n## Prefect Integration Considerations\n\nWhen using Prefect with Pydantic AI agents, there are a few important considerations to ensure workflows behave correctly.\n\n### Agent Requirements\n\nEach agent instance must have a unique `name` so Prefect can correctly identify and track its flows and tasks.\n\n### Tool Wrapping\n\nAgent tools are automatically wrapped as Prefect tasks, which means they benefit from:\n\n- **Retry logic**: Failed tool calls can be retried automatically\n- **Caching**: Tool results are cached based on their inputs\n- **Observability**: Tool execution is tracked in the Prefect UI\n\nYou can customize tool task behavior using `tool_task_config` (applies to all tools) or `tool_task_config_by_name` (per-tool configuration):\n\nprefect_agent_config.py\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.prefect import PrefectAgent, TaskConfig\n\nagent = Agent('gpt-5', name='my_agent')\n\n@agent.tool_plain\ndef fetch_data(url: str) -> str:\n    # This tool will be wrapped as a Prefect task\n    ...\n\nprefect_agent = PrefectAgent(\n    agent,\n    tool_task_config=TaskConfig(retries=3),  # Default for all tools\n    tool_task_config_by_name={\n        'fetch_data': TaskConfig(timeout_seconds=10.0),  # Specific to fetch_data\n        'simple_tool': None,  # Disable task wrapping for simple_tool\n    },\n)\n\n```\n\nSet a tool's config to `None` in `tool_task_config_by_name` to disable task wrapping for that specific tool.\n\n### Streaming\n\nWhen running inside a Prefect flow, Agent.run_stream() works but doesn't provide real-time streaming because Prefect tasks consume their entire execution before returning results. The method will execute fully and return the complete result at once.\n\nFor real-time streaming behavior inside Prefect flows, you can set an event_stream_handler on the `Agent` or `PrefectAgent` instance and use PrefectAgent.run().\n\n**Note**: Event stream handlers behave differently when running inside a Prefect flow versus outside:\n\n- **Outside a flow**: The handler receives events as they stream from the model\n- **Inside a flow**: Each event is wrapped as a Prefect task for durability, which may affect timing but ensures reliability\n\nThe event stream handler function will receive the agent run context and an async iterable of events from the model's streaming response and the agent's execution of tools. For examples, see the [streaming docs](../../agents/#streaming-all-events).\n\n## Task Configuration\n\nYou can customize Prefect task behavior, such as retries and timeouts, by passing TaskConfig objects to the `PrefectAgent` constructor:\n\n- `mcp_task_config`: Configuration for MCP server communication tasks\n- `model_task_config`: Configuration for model request tasks\n- `tool_task_config`: Default configuration for all tool calls\n- `tool_task_config_by_name`: Per-tool task configuration (overrides `tool_task_config`)\n- `event_stream_handler_task_config`: Configuration for event stream handler tasks (applies when running inside a Prefect flow)\n\nAvailable `TaskConfig` options:\n\n- `retries`: Maximum number of retries for the task (default: `0`)\n- `retry_delay_seconds`: Delay between retries in seconds (can be a single value or list for exponential backoff, default: `1.0`)\n- `timeout_seconds`: Maximum time in seconds for the task to complete\n- `cache_policy`: Custom Prefect cache policy for the task\n- `persist_result`: Whether to persist the task result\n- `result_storage`: Prefect result storage for the task (e.g., `'s3-bucket/my-storage'` or a `WritableFileSystem` block)\n- `log_prints`: Whether to log print statements from the task (default: `False`)\n\nExample:\n\nprefect_agent_config.py\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.prefect import PrefectAgent, TaskConfig\n\nagent = Agent(\n    'gpt-5',\n    instructions=\"You're an expert in geography.\",\n    name='geography',\n)\n\nprefect_agent = PrefectAgent(\n    agent,\n    model_task_config=TaskConfig(\n        retries=3,\n        retry_delay_seconds=[1.0, 2.0, 4.0],  # Exponential backoff\n        timeout_seconds=30.0,\n    ),\n)\n\nasync def main():\n    result = await prefect_agent.run('What is the capital of France?')\n    print(result.output)\n    #> Paris\n\n```\n\n*(This example is complete, it can be run \"as is\" — you'll need to add `asyncio.run(main())` to run `main`)*\n\n### Retry Considerations\n\nPydantic AI and provider API clients have their own retry logic. When using Prefect, you may want to:\n\n- Disable [HTTP Request Retries](../../retries/) in Pydantic AI\n- Turn off your provider API client's retry logic (e.g., `max_retries=0` on a [custom OpenAI client](../../models/openai/#custom-openai-client))\n- Rely on Prefect's task-level retry configuration for consistency\n\nThis prevents requests from being retried multiple times at different layers.\n\n## Caching and Idempotency\n\nPrefect 3.0 provides built-in caching and transactional semantics. Tasks with identical inputs will not re-execute if their results are already cached, making workflows naturally idempotent and resilient to failures.\n\n- **Task inputs**: Messages, settings, parameters, tool arguments, and serializable dependencies\n\n**Note**: For user dependencies to be included in cache keys, they must be serializable (e.g., Pydantic models or basic Python types). Non-serializable dependencies are automatically excluded from cache computation.\n\n## Observability with Prefect and Logfire\n\nPrefect provides a built-in UI for monitoring flow runs, task executions, and failures. You can:\n\n- View real-time flow run status\n- Debug failures with full stack traces\n- Set up alerts and notifications\n\nTo access the Prefect UI, you can either:\n\n1. Use [Prefect Cloud](https://www.prefect.io/cloud) (managed service)\n1. Run a local [Prefect server](https://docs.prefect.io/v3/how-to-guides/self-hosted/server-cli) with `prefect server start`\n\nYou can also use [Pydantic Logfire](../../logfire/) for detailed observability. When using both Prefect and Logfire, you'll get complementary views:\n\n- **Prefect**: Workflow-level orchestration, task status, and retry history\n- **Logfire**: Fine-grained tracing of agent runs, model requests, and tool invocations\n\nWhen using Logfire with Prefect, you can enable distributed tracing to see spans for your Prefect runs included with your agent runs, model requests, and tool invocations.\n\nFor more information about Prefect monitoring, see the [Prefect documentation](https://docs.prefect.io/).\n\n## Deployments and Scheduling\n\nTo deploy and schedule a `PrefectAgent`, wrap it in a Prefect flow and use the flow's [`serve()`](https://docs.prefect.io/v3/how-to-guides/deployments/create-deployments#create-a-deployment-with-serve) or [`deploy()`](https://docs.prefect.io/v3/how-to-guides/deployments/deploy-via-python) methods:\n\n[Learn about Gateway](../../gateway) serve_agent.py\n\n```python\nfrom prefect import flow\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.prefect import PrefectAgent\n\n\n@flow\nasync def daily_report_flow(user_prompt: str):\n    \"\"\"Generate a daily report using the agent.\"\"\"\n    agent = Agent(  # (1)!\n        'gateway/openai:gpt-5',\n        name='daily_report_agent',\n        instructions='Generate a daily summary report.',\n    )\n\n    prefect_agent = PrefectAgent(agent)\n\n    result = await prefect_agent.run(user_prompt)\n    return result.output\n\n\n\n### Serve the flow with a daily schedule\nif __name__ == 'gateway/__main__':\n    daily_report_flow.serve(\n        name='daily-report-deployment',\n        cron='0 9 * * *',  # Run daily at 9am\n        parameters={'user_prompt': \"Generate today's report\"},\n        tags=['production', 'reports'],\n    )\n\n```\n\n1. Each flow run executes in an isolated process, and all inputs and dependencies must be serializable. Because Agent instances cannot be serialized, instantiate the agent inside the flow rather than at the module level.\n\nserve_agent.py\n\n```python\nfrom prefect import flow\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.prefect import PrefectAgent\n\n\n@flow\nasync def daily_report_flow(user_prompt: str):\n    \"\"\"Generate a daily report using the agent.\"\"\"\n    agent = Agent(  # (1)!\n        'openai:gpt-5',\n        name='daily_report_agent',\n        instructions='Generate a daily summary report.',\n    )\n\n    prefect_agent = PrefectAgent(agent)\n\n    result = await prefect_agent.run(user_prompt)\n    return result.output\n\n\n\n### Serve the flow with a daily schedule\nif __name__ == '__main__':\n    daily_report_flow.serve(\n        name='daily-report-deployment',\n        cron='0 9 * * *',  # Run daily at 9am\n        parameters={'user_prompt': \"Generate today's report\"},\n        tags=['production', 'reports'],\n    )\n\n```\n\n1. Each flow run executes in an isolated process, and all inputs and dependencies must be serializable. Because Agent instances cannot be serialized, instantiate the agent inside the flow rather than at the module level.\n\nThe `serve()` method accepts scheduling options:\n\n- **`cron`**: Cron schedule string (e.g., `'0 9 * * *'` for daily at 9am)\n- **`interval`**: Schedule interval in seconds or as a timedelta\n- **`rrule`**: iCalendar RRule schedule string\n\nFor production deployments with Docker, Kubernetes, or other infrastructure, use the flow's [`deploy()`](https://docs.prefect.io/v3/how-to-guides/deployments/deploy-via-python) method. See the [Prefect deployment documentation](https://docs.prefect.io/v3/how-to-guides/deployments/create-deploymentsy) for more information.",
  "content_length": 14935
}