{
  "title": "`pydantic_ai.ui.ag_ui`",
  "source_url": null,
  "content": "AG-UI protocol integration for Pydantic AI agents.\n\n### AGUIAdapter\n\nBases: `UIAdapter[RunAgentInput, Message, BaseEvent, AgentDepsT, OutputDataT]`\n\nUI adapter for the Agent-User Interaction (AG-UI) protocol.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py`\n\n```python\nclass AGUIAdapter(UIAdapter[RunAgentInput, Message, BaseEvent, AgentDepsT, OutputDataT]):\n    \"\"\"UI adapter for the Agent-User Interaction (AG-UI) protocol.\"\"\"\n\n    @classmethod\n    def build_run_input(cls, body: bytes) -> RunAgentInput:\n        \"\"\"Build an AG-UI run input object from the request body.\"\"\"\n        return RunAgentInput.model_validate_json(body)\n\n    def build_event_stream(self) -> UIEventStream[RunAgentInput, BaseEvent, AgentDepsT, OutputDataT]:\n        \"\"\"Build an AG-UI event stream transformer.\"\"\"\n        return AGUIEventStream(self.run_input, accept=self.accept)\n\n    @cached_property\n    def messages(self) -> list[ModelMessage]:\n        \"\"\"Pydantic AI messages from the AG-UI run input.\"\"\"\n        return self.load_messages(self.run_input.messages)\n\n    @cached_property\n    def toolset(self) -> AbstractToolset[AgentDepsT] | None:\n        \"\"\"Toolset representing frontend tools from the AG-UI run input.\"\"\"\n        if self.run_input.tools:\n            return _AGUIFrontendToolset[AgentDepsT](self.run_input.tools)\n        return None\n\n    @cached_property\n    def state(self) -> dict[str, Any] | None:\n        \"\"\"Frontend state from the AG-UI run input.\"\"\"\n        state = self.run_input.state\n        if state is None:\n            return None\n\n        if isinstance(state, Mapping) and not state:\n            return None\n\n        return cast('dict[str, Any]', state)\n\n    @classmethod\n    def load_messages(cls, messages: Sequence[Message]) -> list[ModelMessage]:\n        \"\"\"Transform AG-UI messages into Pydantic AI messages.\"\"\"\n        builder = MessagesBuilder()\n        tool_calls: dict[str, str] = {}  # Tool call ID to tool name mapping.\n\n        for msg in messages:\n            if isinstance(msg, UserMessage | SystemMessage | DeveloperMessage) or (\n                isinstance(msg, ToolMessage) and not msg.tool_call_id.startswith(BUILTIN_TOOL_CALL_ID_PREFIX)\n            ):\n                if isinstance(msg, UserMessage):\n                    builder.add(UserPromptPart(content=msg.content))\n                elif isinstance(msg, SystemMessage | DeveloperMessage):\n                    builder.add(SystemPromptPart(content=msg.content))\n                else:\n                    tool_call_id = msg.tool_call_id\n                    tool_name = tool_calls.get(tool_call_id)\n                    if tool_name is None:  # pragma: no cover\n                        raise ValueError(f'Tool call with ID {tool_call_id} not found in the history.')\n\n                    builder.add(\n                        ToolReturnPart(\n                            tool_name=tool_name,\n                            content=msg.content,\n                            tool_call_id=tool_call_id,\n                        )\n                    )\n\n            elif isinstance(msg, AssistantMessage) or (  # pragma: no branch\n                isinstance(msg, ToolMessage) and msg.tool_call_id.startswith(BUILTIN_TOOL_CALL_ID_PREFIX)\n            ):\n                if isinstance(msg, AssistantMessage):\n                    if msg.content:\n                        builder.add(TextPart(content=msg.content))\n\n                    if msg.tool_calls:\n                        for tool_call in msg.tool_calls:\n                            tool_call_id = tool_call.id\n                            tool_name = tool_call.function.name\n                            tool_calls[tool_call_id] = tool_name\n\n                            if tool_call_id.startswith(BUILTIN_TOOL_CALL_ID_PREFIX):\n                                _, provider_name, tool_call_id = tool_call_id.split('|', 2)\n                                builder.add(\n                                    BuiltinToolCallPart(\n                                        tool_name=tool_name,\n                                        args=tool_call.function.arguments,\n                                        tool_call_id=tool_call_id,\n                                        provider_name=provider_name,\n                                    )\n                                )\n                            else:\n                                builder.add(\n                                    ToolCallPart(\n                                        tool_name=tool_name,\n                                        tool_call_id=tool_call_id,\n                                        args=tool_call.function.arguments,\n                                    )\n                                )\n                else:\n                    tool_call_id = msg.tool_call_id\n                    tool_name = tool_calls.get(tool_call_id)\n                    if tool_name is None:  # pragma: no cover\n                        raise ValueError(f'Tool call with ID {tool_call_id} not found in the history.')\n                    _, provider_name, tool_call_id = tool_call_id.split('|', 2)\n\n                    builder.add(\n                        BuiltinToolReturnPart(\n                            tool_name=tool_name,\n                            content=msg.content,\n                            tool_call_id=tool_call_id,\n                            provider_name=provider_name,\n                        )\n                    )\n\n        return builder.messages\n\n```\n\n#### build_run_input\n\n```python\nbuild_run_input(body: bytes) -> RunAgentInput\n\n```\n\nBuild an AG-UI run input object from the request body.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py`\n\n```python\n@classmethod\ndef build_run_input(cls, body: bytes) -> RunAgentInput:\n    \"\"\"Build an AG-UI run input object from the request body.\"\"\"\n    return RunAgentInput.model_validate_json(body)\n\n```\n\n#### build_event_stream\n\n```python\nbuild_event_stream() -> (\n    UIEventStream[\n        RunAgentInput, BaseEvent, AgentDepsT, OutputDataT\n    ]\n)\n\n```\n\nBuild an AG-UI event stream transformer.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py`\n\n```python\ndef build_event_stream(self) -> UIEventStream[RunAgentInput, BaseEvent, AgentDepsT, OutputDataT]:\n    \"\"\"Build an AG-UI event stream transformer.\"\"\"\n    return AGUIEventStream(self.run_input, accept=self.accept)\n\n```\n\n#### messages\n\n```python\nmessages: list[ModelMessage]\n\n```\n\nPydantic AI messages from the AG-UI run input.\n\n#### toolset\n\n```python\ntoolset: AbstractToolset[AgentDepsT] | None\n\n```\n\nToolset representing frontend tools from the AG-UI run input.\n\n#### state\n\n```python\nstate: dict[str, Any] | None\n\n```\n\nFrontend state from the AG-UI run input.\n\n#### load_messages\n\n```python\nload_messages(\n    messages: Sequence[Message],\n) -> list[ModelMessage]\n\n```\n\nTransform AG-UI messages into Pydantic AI messages.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py`\n\n```python\n@classmethod\ndef load_messages(cls, messages: Sequence[Message]) -> list[ModelMessage]:\n    \"\"\"Transform AG-UI messages into Pydantic AI messages.\"\"\"\n    builder = MessagesBuilder()\n    tool_calls: dict[str, str] = {}  # Tool call ID to tool name mapping.\n\n    for msg in messages:\n        if isinstance(msg, UserMessage | SystemMessage | DeveloperMessage) or (\n            isinstance(msg, ToolMessage) and not msg.tool_call_id.startswith(BUILTIN_TOOL_CALL_ID_PREFIX)\n        ):\n            if isinstance(msg, UserMessage):\n                builder.add(UserPromptPart(content=msg.content))\n            elif isinstance(msg, SystemMessage | DeveloperMessage):\n                builder.add(SystemPromptPart(content=msg.content))\n            else:\n                tool_call_id = msg.tool_call_id\n                tool_name = tool_calls.get(tool_call_id)\n                if tool_name is None:  # pragma: no cover\n                    raise ValueError(f'Tool call with ID {tool_call_id} not found in the history.')\n\n                builder.add(\n                    ToolReturnPart(\n                        tool_name=tool_name,\n                        content=msg.content,\n                        tool_call_id=tool_call_id,\n                    )\n                )\n\n        elif isinstance(msg, AssistantMessage) or (  # pragma: no branch\n            isinstance(msg, ToolMessage) and msg.tool_call_id.startswith(BUILTIN_TOOL_CALL_ID_PREFIX)\n        ):\n            if isinstance(msg, AssistantMessage):\n                if msg.content:\n                    builder.add(TextPart(content=msg.content))\n\n                if msg.tool_calls:\n                    for tool_call in msg.tool_calls:\n                        tool_call_id = tool_call.id\n                        tool_name = tool_call.function.name\n                        tool_calls[tool_call_id] = tool_name\n\n                        if tool_call_id.startswith(BUILTIN_TOOL_CALL_ID_PREFIX):\n                            _, provider_name, tool_call_id = tool_call_id.split('|', 2)\n                            builder.add(\n                                BuiltinToolCallPart(\n                                    tool_name=tool_name,\n                                    args=tool_call.function.arguments,\n                                    tool_call_id=tool_call_id,\n                                    provider_name=provider_name,\n                                )\n                            )\n                        else:\n                            builder.add(\n                                ToolCallPart(\n                                    tool_name=tool_name,\n                                    tool_call_id=tool_call_id,\n                                    args=tool_call.function.arguments,\n                                )\n                            )\n            else:\n                tool_call_id = msg.tool_call_id\n                tool_name = tool_calls.get(tool_call_id)\n                if tool_name is None:  # pragma: no cover\n                    raise ValueError(f'Tool call with ID {tool_call_id} not found in the history.')\n                _, provider_name, tool_call_id = tool_call_id.split('|', 2)\n\n                builder.add(\n                    BuiltinToolReturnPart(\n                        tool_name=tool_name,\n                        content=msg.content,\n                        tool_call_id=tool_call_id,\n                        provider_name=provider_name,\n                    )\n                )\n\n    return builder.messages\n\n```\n\n### AGUIEventStream\n\nBases: `UIEventStream[RunAgentInput, BaseEvent, AgentDepsT, OutputDataT]`\n\nUI event stream transformer for the Agent-User Interaction (AG-UI) protocol.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py`\n\n```python\n@dataclass\nclass AGUIEventStream(UIEventStream[RunAgentInput, BaseEvent, AgentDepsT, OutputDataT]):\n    \"\"\"UI event stream transformer for the Agent-User Interaction (AG-UI) protocol.\"\"\"\n\n    _thinking_text: bool = False\n    _builtin_tool_call_ids: dict[str, str] = field(default_factory=dict)\n    _error: bool = False\n\n    @property\n    def _event_encoder(self) -> EventEncoder:\n        return EventEncoder(accept=self.accept or SSE_CONTENT_TYPE)\n\n    @property\n    def content_type(self) -> str:\n        return self._event_encoder.get_content_type()\n\n    def encode_event(self, event: BaseEvent) -> str:\n        return self._event_encoder.encode(event)\n\n    async def before_stream(self) -> AsyncIterator[BaseEvent]:\n        yield RunStartedEvent(\n            thread_id=self.run_input.thread_id,\n            run_id=self.run_input.run_id,\n        )\n\n    async def before_response(self) -> AsyncIterator[BaseEvent]:\n        # Prevent parts from a subsequent response being tied to parts from an earlier response.\n        # See https://github.com/pydantic/pydantic-ai/issues/3316\n        self.new_message_id()\n        return\n        yield  # Make this an async generator\n\n    async def after_stream(self) -> AsyncIterator[BaseEvent]:\n        if not self._error:\n            yield RunFinishedEvent(\n                thread_id=self.run_input.thread_id,\n                run_id=self.run_input.run_id,\n            )\n\n    async def on_error(self, error: Exception) -> AsyncIterator[BaseEvent]:\n        self._error = True\n        yield RunErrorEvent(message=str(error))\n\n    async def handle_text_start(self, part: TextPart, follows_text: bool = False) -> AsyncIterator[BaseEvent]:\n        if follows_text:\n            message_id = self.message_id\n        else:\n            message_id = self.new_message_id()\n            yield TextMessageStartEvent(message_id=message_id)\n\n        if part.content:  # pragma: no branch\n            yield TextMessageContentEvent(message_id=message_id, delta=part.content)\n\n    async def handle_text_delta(self, delta: TextPartDelta) -> AsyncIterator[BaseEvent]:\n        if delta.content_delta:  # pragma: no branch\n            yield TextMessageContentEvent(message_id=self.message_id, delta=delta.content_delta)\n\n    async def handle_text_end(self, part: TextPart, followed_by_text: bool = False) -> AsyncIterator[BaseEvent]:\n        if not followed_by_text:\n            yield TextMessageEndEvent(message_id=self.message_id)\n\n    async def handle_thinking_start(\n        self, part: ThinkingPart, follows_thinking: bool = False\n    ) -> AsyncIterator[BaseEvent]:\n        if not follows_thinking:\n            yield ThinkingStartEvent(type=EventType.THINKING_START)\n\n        if part.content:\n            yield ThinkingTextMessageStartEvent(type=EventType.THINKING_TEXT_MESSAGE_START)\n            yield ThinkingTextMessageContentEvent(type=EventType.THINKING_TEXT_MESSAGE_CONTENT, delta=part.content)\n            self._thinking_text = True\n\n    async def handle_thinking_delta(self, delta: ThinkingPartDelta) -> AsyncIterator[BaseEvent]:\n        if not delta.content_delta:\n            return  # pragma: no cover\n\n        if not self._thinking_text:\n            yield ThinkingTextMessageStartEvent(type=EventType.THINKING_TEXT_MESSAGE_START)\n            self._thinking_text = True\n\n        yield ThinkingTextMessageContentEvent(type=EventType.THINKING_TEXT_MESSAGE_CONTENT, delta=delta.content_delta)\n\n    async def handle_thinking_end(\n        self, part: ThinkingPart, followed_by_thinking: bool = False\n    ) -> AsyncIterator[BaseEvent]:\n        if self._thinking_text:\n            yield ThinkingTextMessageEndEvent(type=EventType.THINKING_TEXT_MESSAGE_END)\n            self._thinking_text = False\n\n        if not followed_by_thinking:\n            yield ThinkingEndEvent(type=EventType.THINKING_END)\n\n    def handle_tool_call_start(self, part: ToolCallPart | BuiltinToolCallPart) -> AsyncIterator[BaseEvent]:\n        return self._handle_tool_call_start(part)\n\n    def handle_builtin_tool_call_start(self, part: BuiltinToolCallPart) -> AsyncIterator[BaseEvent]:\n        tool_call_id = part.tool_call_id\n        builtin_tool_call_id = '|'.join([BUILTIN_TOOL_CALL_ID_PREFIX, part.provider_name or '', tool_call_id])\n        self._builtin_tool_call_ids[tool_call_id] = builtin_tool_call_id\n        tool_call_id = builtin_tool_call_id\n\n        return self._handle_tool_call_start(part, tool_call_id)\n\n    async def _handle_tool_call_start(\n        self, part: ToolCallPart | BuiltinToolCallPart, tool_call_id: str | None = None\n    ) -> AsyncIterator[BaseEvent]:\n        tool_call_id = tool_call_id or part.tool_call_id\n        parent_message_id = self.message_id\n\n        yield ToolCallStartEvent(\n            tool_call_id=tool_call_id, tool_call_name=part.tool_name, parent_message_id=parent_message_id\n        )\n        if part.args:\n            yield ToolCallArgsEvent(tool_call_id=tool_call_id, delta=part.args_as_json_str())\n\n    async def handle_tool_call_delta(self, delta: ToolCallPartDelta) -> AsyncIterator[BaseEvent]:\n        tool_call_id = delta.tool_call_id\n        assert tool_call_id, '`ToolCallPartDelta.tool_call_id` must be set'\n        if tool_call_id in self._builtin_tool_call_ids:\n            tool_call_id = self._builtin_tool_call_ids[tool_call_id]\n        yield ToolCallArgsEvent(\n            tool_call_id=tool_call_id,\n            delta=delta.args_delta if isinstance(delta.args_delta, str) else json.dumps(delta.args_delta),\n        )\n\n    async def handle_tool_call_end(self, part: ToolCallPart) -> AsyncIterator[BaseEvent]:\n        yield ToolCallEndEvent(tool_call_id=part.tool_call_id)\n\n    async def handle_builtin_tool_call_end(self, part: BuiltinToolCallPart) -> AsyncIterator[BaseEvent]:\n        yield ToolCallEndEvent(tool_call_id=self._builtin_tool_call_ids[part.tool_call_id])\n\n    async def handle_builtin_tool_return(self, part: BuiltinToolReturnPart) -> AsyncIterator[BaseEvent]:\n        tool_call_id = self._builtin_tool_call_ids[part.tool_call_id]\n        yield ToolCallResultEvent(\n            message_id=self.new_message_id(),\n            type=EventType.TOOL_CALL_RESULT,\n            role='tool',\n            tool_call_id=tool_call_id,\n            content=part.model_response_str(),\n        )\n\n    async def handle_function_tool_result(self, event: FunctionToolResultEvent) -> AsyncIterator[BaseEvent]:\n        result = event.result\n        output = result.model_response() if isinstance(result, RetryPromptPart) else result.model_response_str()\n\n        yield ToolCallResultEvent(\n            message_id=self.new_message_id(),\n            type=EventType.TOOL_CALL_RESULT,\n            role='tool',\n            tool_call_id=result.tool_call_id,\n            content=output,\n        )\n\n        # ToolCallResultEvent.content may hold user parts (e.g. text, images) that AG-UI does not currently have events for\n\n        if isinstance(result, ToolReturnPart):\n            # Check for AG-UI events returned by tool calls.\n            possible_event = result.metadata or result.content\n            if isinstance(possible_event, BaseEvent):\n                yield possible_event\n            elif isinstance(possible_event, str | bytes):  # pragma: no branch\n                # Avoid iterable check for strings and bytes.\n                pass\n            elif isinstance(possible_event, Iterable):  # pragma: no branch\n                for item in possible_event:  # type: ignore[reportUnknownMemberType]\n                    if isinstance(item, BaseEvent):  # pragma: no branch\n                        yield item\n\n```\n\nAG-UI protocol integration for Pydantic AI agents.\n\n### AGUIApp\n\nBases: `Generic[AgentDepsT, OutputDataT]`, `Starlette`\n\nASGI application for running Pydantic AI agents with AG-UI protocol support.\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py`\n\n```python\nclass AGUIApp(Generic[AgentDepsT, OutputDataT], Starlette):\n    \"\"\"ASGI application for running Pydantic AI agents with AG-UI protocol support.\"\"\"\n\n    def __init__(\n        self,\n        agent: AbstractAgent[AgentDepsT, OutputDataT],\n        *,\n        # AGUIAdapter.dispatch_request parameters\n        output_type: OutputSpec[Any] | None = None,\n        message_history: Sequence[ModelMessage] | None = None,\n        deferred_tool_results: DeferredToolResults | None = None,\n        model: Model | KnownModelName | str | None = None,\n        deps: AgentDepsT = None,\n        model_settings: ModelSettings | None = None,\n        usage_limits: UsageLimits | None = None,\n        usage: RunUsage | None = None,\n        infer_name: bool = True,\n        toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,\n        builtin_tools: Sequence[AbstractBuiltinTool] | None = None,\n        on_complete: OnCompleteFunc[Any] | None = None,\n        # Starlette parameters\n        debug: bool = False,\n        routes: Sequence[BaseRoute] | None = None,\n        middleware: Sequence[Middleware] | None = None,\n        exception_handlers: Mapping[Any, ExceptionHandler] | None = None,\n        on_startup: Sequence[Callable[[], Any]] | None = None,\n        on_shutdown: Sequence[Callable[[], Any]] | None = None,\n        lifespan: Lifespan[Self] | None = None,\n    ) -> None:\n        \"\"\"An ASGI application that handles every request by running the agent and streaming the response.\n\n        Note that the `deps` will be the same for each request, with the exception of the frontend state that's\n        injected into the `state` field of a `deps` object that implements the [`StateHandler`][pydantic_ai.ui.StateHandler] protocol.\n        To provide different `deps` for each request (e.g. based on the authenticated user),\n        use [`AGUIAdapter.run_stream()`][pydantic_ai.ui.ag_ui.AGUIAdapter.run_stream] or\n        [`AGUIAdapter.dispatch_request()`][pydantic_ai.ui.ag_ui.AGUIAdapter.dispatch_request] instead.\n\n        Args:\n            agent: The agent to run.\n\n            output_type: Custom output type to use for this run, `output_type` may only be used if the agent has\n                no output validators since output validators would expect an argument that matches the agent's\n                output type.\n            message_history: History of the conversation so far.\n            deferred_tool_results: Optional results for deferred tool calls in the message history.\n            model: Optional model to use for this run, required if `model` was not set when creating the agent.\n            deps: Optional dependencies to use for this run.\n            model_settings: Optional settings to use for this model's request.\n            usage_limits: Optional limits on model request count or token usage.\n            usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n            infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n            toolsets: Optional additional toolsets for this run.\n            builtin_tools: Optional additional builtin tools for this run.\n            on_complete: Optional callback function called when the agent run completes successfully.\n                The callback receives the completed [`AgentRunResult`][pydantic_ai.agent.AgentRunResult] and can access `all_messages()` and other result data.\n\n            debug: Boolean indicating if debug tracebacks should be returned on errors.\n            routes: A list of routes to serve incoming HTTP and WebSocket requests.\n            middleware: A list of middleware to run for every request. A starlette application will always\n                automatically include two middleware classes. `ServerErrorMiddleware` is added as the very\n                outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack.\n                `ExceptionMiddleware` is added as the very innermost middleware, to deal with handled\n                exception cases occurring in the routing or endpoints.\n            exception_handlers: A mapping of either integer status codes, or exception class types onto\n                callables which handle the exceptions. Exception handler callables should be of the form\n                `handler(request, exc) -> response` and may be either standard functions, or async functions.\n            on_startup: A list of callables to run on application startup. Startup handler callables do not\n                take any arguments, and may be either standard functions, or async functions.\n            on_shutdown: A list of callables to run on application shutdown. Shutdown handler callables do\n                not take any arguments, and may be either standard functions, or async functions.\n            lifespan: A lifespan context function, which can be used to perform startup and shutdown tasks.\n                This is a newer style that replaces the `on_startup` and `on_shutdown` handlers. Use one or\n                the other, not both.\n        \"\"\"\n        super().__init__(\n            debug=debug,\n            routes=routes,\n            middleware=middleware,\n            exception_handlers=exception_handlers,\n            on_startup=on_startup,\n            on_shutdown=on_shutdown,\n            lifespan=lifespan,\n        )\n\n        async def run_agent(request: Request) -> Response:\n            \"\"\"Endpoint to run the agent with the provided input data.\"\"\"\n            # `dispatch_request` will store the frontend state from the request on `deps.state` (if it implements the `StateHandler` protocol),\n            # so we need to copy the deps to avoid different requests mutating the same deps object.\n            nonlocal deps\n            if isinstance(deps, StateHandler):  # pragma: no branch\n                deps = replace(deps)\n\n            return await AGUIAdapter[AgentDepsT, OutputDataT].dispatch_request(\n                request,\n                agent=agent,\n                output_type=output_type,\n                message_history=message_history,\n                deferred_tool_results=deferred_tool_results,\n                model=model,\n                deps=deps,\n                model_settings=model_settings,\n                usage_limits=usage_limits,\n                usage=usage,\n                infer_name=infer_name,\n                toolsets=toolsets,\n                builtin_tools=builtin_tools,\n                on_complete=on_complete,\n            )\n\n        self.router.add_route('/', run_agent, methods=['POST'])\n\n```\n\n#### __init__\n\n```python\n__init__(\n    agent: AbstractAgent[AgentDepsT, OutputDataT],\n    *,\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: (\n        DeferredToolResults | None\n    ) = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: (\n        Sequence[AbstractToolset[AgentDepsT]] | None\n    ) = None,\n    builtin_tools: (\n        Sequence[AbstractBuiltinTool] | None\n    ) = None,\n    on_complete: OnCompleteFunc[Any] | None = None,\n    debug: bool = False,\n    routes: Sequence[BaseRoute] | None = None,\n    middleware: Sequence[Middleware] | None = None,\n    exception_handlers: (\n        Mapping[Any, ExceptionHandler] | None\n    ) = None,\n    on_startup: Sequence[Callable[[], Any]] | None = None,\n    on_shutdown: Sequence[Callable[[], Any]] | None = None,\n    lifespan: Lifespan[Self] | None = None\n) -> None\n\n```\n\nAn ASGI application that handles every request by running the agent and streaming the response.\n\nNote that the `deps` will be the same for each request, with the exception of the frontend state that's injected into the `state` field of a `deps` object that implements the StateHandler protocol. To provide different `deps` for each request (e.g. based on the authenticated user), use AGUIAdapter.run_stream() or AGUIAdapter.dispatch_request() instead.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `agent` | `AbstractAgent[AgentDepsT, OutputDataT]` | The agent to run. | *required* | | `output_type` | `OutputSpec[Any] | None` | Custom output type to use for this run, output_type may only be used if the agent has no output validators since output validators would expect an argument that matches the agent's output type. | `None` | | `message_history` | `Sequence[ModelMessage] | None` | History of the conversation so far. | `None` | | `deferred_tool_results` | `DeferredToolResults | None` | Optional results for deferred tool calls in the message history. | `None` | | `model` | `Model | KnownModelName | str | None` | Optional model to use for this run, required if model was not set when creating the agent. | `None` | | `deps` | `AgentDepsT` | Optional dependencies to use for this run. | `None` | | `model_settings` | `ModelSettings | None` | Optional settings to use for this model's request. | `None` | | `usage_limits` | `UsageLimits | None` | Optional limits on model request count or token usage. | `None` | | `usage` | `RunUsage | None` | Optional usage to start with, useful for resuming a conversation or agents used in tools. | `None` | | `infer_name` | `bool` | Whether to try to infer the agent name from the call frame if it's not set. | `True` | | `toolsets` | `Sequence[AbstractToolset[AgentDepsT]] | None` | Optional additional toolsets for this run. | `None` | | `builtin_tools` | `Sequence[AbstractBuiltinTool] | None` | Optional additional builtin tools for this run. | `None` | | `on_complete` | `OnCompleteFunc[Any] | None` | Optional callback function called when the agent run completes successfully. The callback receives the completed AgentRunResult and can access all_messages() and other result data. | `None` | | `debug` | `bool` | Boolean indicating if debug tracebacks should be returned on errors. | `False` | | `routes` | `Sequence[BaseRoute] | None` | A list of routes to serve incoming HTTP and WebSocket requests. | `None` | | `middleware` | `Sequence[Middleware] | None` | A list of middleware to run for every request. A starlette application will always automatically include two middleware classes. ServerErrorMiddleware is added as the very outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack. ExceptionMiddleware is added as the very innermost middleware, to deal with handled exception cases occurring in the routing or endpoints. | `None` | | `exception_handlers` | `Mapping[Any, ExceptionHandler] | None` | A mapping of either integer status codes, or exception class types onto callables which handle the exceptions. Exception handler callables should be of the form handler(request, exc) -> response and may be either standard functions, or async functions. | `None` | | `on_startup` | `Sequence[Callable[[], Any]] | None` | A list of callables to run on application startup. Startup handler callables do not take any arguments, and may be either standard functions, or async functions. | `None` | | `on_shutdown` | `Sequence[Callable[[], Any]] | None` | A list of callables to run on application shutdown. Shutdown handler callables do not take any arguments, and may be either standard functions, or async functions. | `None` | | `lifespan` | `Lifespan[Self] | None` | A lifespan context function, which can be used to perform startup and shutdown tasks. This is a newer style that replaces the on_startup and on_shutdown handlers. Use one or the other, not both. | `None` |\n\nSource code in `pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py`\n\n```python\ndef __init__(\n    self,\n    agent: AbstractAgent[AgentDepsT, OutputDataT],\n    *,\n    # AGUIAdapter.dispatch_request parameters\n    output_type: OutputSpec[Any] | None = None,\n    message_history: Sequence[ModelMessage] | None = None,\n    deferred_tool_results: DeferredToolResults | None = None,\n    model: Model | KnownModelName | str | None = None,\n    deps: AgentDepsT = None,\n    model_settings: ModelSettings | None = None,\n    usage_limits: UsageLimits | None = None,\n    usage: RunUsage | None = None,\n    infer_name: bool = True,\n    toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,\n    builtin_tools: Sequence[AbstractBuiltinTool] | None = None,\n    on_complete: OnCompleteFunc[Any] | None = None,\n    # Starlette parameters\n    debug: bool = False,\n    routes: Sequence[BaseRoute] | None = None,\n    middleware: Sequence[Middleware] | None = None,\n    exception_handlers: Mapping[Any, ExceptionHandler] | None = None,\n    on_startup: Sequence[Callable[[], Any]] | None = None,\n    on_shutdown: Sequence[Callable[[], Any]] | None = None,\n    lifespan: Lifespan[Self] | None = None,\n) -> None:\n    \"\"\"An ASGI application that handles every request by running the agent and streaming the response.\n\n    Note that the `deps` will be the same for each request, with the exception of the frontend state that's\n    injected into the `state` field of a `deps` object that implements the [`StateHandler`][pydantic_ai.ui.StateHandler] protocol.\n    To provide different `deps` for each request (e.g. based on the authenticated user),\n    use [`AGUIAdapter.run_stream()`][pydantic_ai.ui.ag_ui.AGUIAdapter.run_stream] or\n    [`AGUIAdapter.dispatch_request()`][pydantic_ai.ui.ag_ui.AGUIAdapter.dispatch_request] instead.\n\n    Args:\n        agent: The agent to run.\n\n        output_type: Custom output type to use for this run, `output_type` may only be used if the agent has\n            no output validators since output validators would expect an argument that matches the agent's\n            output type.\n        message_history: History of the conversation so far.\n        deferred_tool_results: Optional results for deferred tool calls in the message history.\n        model: Optional model to use for this run, required if `model` was not set when creating the agent.\n        deps: Optional dependencies to use for this run.\n        model_settings: Optional settings to use for this model's request.\n        usage_limits: Optional limits on model request count or token usage.\n        usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n        infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n        toolsets: Optional additional toolsets for this run.\n        builtin_tools: Optional additional builtin tools for this run.\n        on_complete: Optional callback function called when the agent run completes successfully.\n            The callback receives the completed [`AgentRunResult`][pydantic_ai.agent.AgentRunResult] and can access `all_messages()` and other result data.\n\n        debug: Boolean indicating if debug tracebacks should be returned on errors.\n        routes: A list of routes to serve incoming HTTP and WebSocket requests.\n        middleware: A list of middleware to run for every request. A starlette application will always\n            automatically include two middleware classes. `ServerErrorMiddleware` is added as the very\n            outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack.\n            `ExceptionMiddleware` is added as the very innermost middleware, to deal with handled\n            exception cases occurring in the routing or endpoints.\n        exception_handlers: A mapping of either integer status codes, or exception class types onto\n            callables which handle the exceptions. Exception handler callables should be of the form\n            `handler(request, exc) -> response` and may be either standard functions, or async functions.\n        on_startup: A list of callables to run on application startup. Startup handler callables do not\n            take any arguments, and may be either standard functions, or async functions.\n        on_shutdown: A list of callables to run on application shutdown. Shutdown handler callables do\n            not take any arguments, and may be either standard functions, or async functions.\n        lifespan: A lifespan context function, which can be used to perform startup and shutdown tasks.\n            This is a newer style that replaces the `on_startup` and `on_shutdown` handlers. Use one or\n            the other, not both.\n    \"\"\"\n    super().__init__(\n        debug=debug,\n        routes=routes,\n        middleware=middleware,\n        exception_handlers=exception_handlers,\n        on_startup=on_startup,\n        on_shutdown=on_shutdown,\n        lifespan=lifespan,\n    )\n\n    async def run_agent(request: Request) -> Response:\n        \"\"\"Endpoint to run the agent with the provided input data.\"\"\"\n        # `dispatch_request` will store the frontend state from the request on `deps.state` (if it implements the `StateHandler` protocol),\n        # so we need to copy the deps to avoid different requests mutating the same deps object.\n        nonlocal deps\n        if isinstance(deps, StateHandler):  # pragma: no branch\n            deps = replace(deps)\n\n        return await AGUIAdapter[AgentDepsT, OutputDataT].dispatch_request(\n            request,\n            agent=agent,\n            output_type=output_type,\n            message_history=message_history,\n            deferred_tool_results=deferred_tool_results,\n            model=model,\n            deps=deps,\n            model_settings=model_settings,\n            usage_limits=usage_limits,\n            usage=usage,\n            infer_name=infer_name,\n            toolsets=toolsets,\n            builtin_tools=builtin_tools,\n            on_complete=on_complete,\n        )\n\n    self.router.add_route('/', run_agent, methods=['POST'])\n\n```",
  "content_length": 36347
}