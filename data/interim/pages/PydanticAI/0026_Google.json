{
  "title": "Google",
  "source_url": null,
  "content": "The `GoogleModel` is a model that uses the [`google-genai`](https://pypi.org/project/google-genai/) package under the hood to access Google's Gemini models via both the Generative Language API and Vertex AI.\n\n## Install\n\nTo use `GoogleModel`, you need to either install `pydantic-ai`, or install `pydantic-ai-slim` with the `google` optional group:\n\n```bash\npip install \"pydantic-ai-slim[google]\"\n\n```\n\n```bash\nuv add \"pydantic-ai-slim[google]\"\n\n```\n\n## Configuration\n\n`GoogleModel` lets you use Google's Gemini models through their [Generative Language API](https://ai.google.dev/api/all-methods) (`generativelanguage.googleapis.com`) or [Vertex AI API](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) (`*-aiplatform.googleapis.com`).\n\n### API Key (Generative Language API)\n\nTo use Gemini via the Generative Language API, go to [aistudio.google.com](https://aistudio.google.com/apikey) and create an API key.\n\nOnce you have the API key, set it as an environment variable:\n\n```bash\nexport GOOGLE_API_KEY=your-api-key\n\n```\n\nYou can then use `GoogleModel` by name (where GLA stands for Generative Language API):\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('google-gla:gemini-2.5-pro')\n...\n\n```\n\nOr you can explicitly create the provider:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\nprovider = GoogleProvider(api_key='your-api-key')\nmodel = GoogleModel('gemini-2.5-pro', provider=provider)\nagent = Agent(model)\n...\n\n```\n\n### Vertex AI (Enterprise/Cloud)\n\nIf you are an enterprise user, you can also use `GoogleModel` to access Gemini via Vertex AI.\n\nThis interface has a number of advantages over the Generative Language API:\n\n1. The VertexAI API comes with more enterprise readiness guarantees.\n1. You can [purchase provisioned throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput#purchase-provisioned-throughput) with Vertex AI to guarantee capacity.\n1. If you're running Pydantic AI inside GCP, you don't need to set up authentication, it should \"just work\".\n1. You can decide which region to use, which might be important from a regulatory perspective, and might improve latency.\n\nYou can authenticate using [application default credentials](https://cloud.google.com/docs/authentication/application-default-credentials), a service account, or an [API key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/api-keys?usertype=expressmode).\n\nWhichever way you authenticate, you'll need to have Vertex AI enabled in your GCP account.\n\n#### Application Default Credentials\n\nIf you have the [`gcloud` CLI](https://cloud.google.com/sdk/gcloud) installed and configured, you can use `GoogleProvider` in Vertex AI mode by name:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('gateway/google-vertex:gemini-2.5-pro')\n...\n\n```\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('google-vertex:gemini-2.5-pro')\n...\n\n```\n\nOr you can explicitly create the provider and model:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\nprovider = GoogleProvider(vertexai=True)\nmodel = GoogleModel('gemini-2.5-pro', provider=provider)\nagent = Agent(model)\n...\n\n```\n\n#### Service Account\n\nTo use a service account JSON file, explicitly create the provider and model:\n\ngoogle_model_service_account.py\n\n```python\nfrom google.oauth2 import service_account\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\ncredentials = service_account.Credentials.from_service_account_file(\n    'path/to/service-account.json',\n    scopes=['https://www.googleapis.com/auth/cloud-platform'],\n)\nprovider = GoogleProvider(credentials=credentials, project='your-project-id')\nmodel = GoogleModel('gemini-2.5-flash', provider=provider)\nagent = Agent(model)\n...\n\n```\n\n#### API Key\n\nTo use Vertex AI with an API key, [create a key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/api-keys?usertype=expressmode) and set it as an environment variable:\n\n```bash\nexport GOOGLE_API_KEY=your-api-key\n\n```\n\nYou can then use `GoogleModel` in Vertex AI mode by name:\n\n[Learn about Gateway](../../gateway)\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('gateway/google-vertex:gemini-2.5-pro')\n...\n\n```\n\n```python\nfrom pydantic_ai import Agent\n\nagent = Agent('google-vertex:gemini-2.5-pro')\n...\n\n```\n\nOr you can explicitly create the provider and model:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\nprovider = GoogleProvider(vertexai=True, api_key='your-api-key')\nmodel = GoogleModel('gemini-2.5-pro', provider=provider)\nagent = Agent(model)\n...\n\n```\n\n#### Customizing Location or Project\n\nYou can specify the location and/or project when using Vertex AI:\n\ngoogle_model_location.py\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\nprovider = GoogleProvider(vertexai=True, location='asia-east1', project='your-gcp-project-id')\nmodel = GoogleModel('gemini-2.5-pro', provider=provider)\nagent = Agent(model)\n...\n\n```\n\n#### Model Garden\n\nYou can access models from the [Model Garden](https://cloud.google.com/model-garden?hl=en) that support the `generateContent` API and are available under your GCP project, including but not limited to Gemini, using one of the following `model_name` patterns:\n\n- `{model_id}` for Gemini models\n- `{publisher}/{model_id}`\n- `publishers/{publisher}/models/{model_id}`\n- `projects/{project}/locations/{location}/publishers/{publisher}/models/{model_id}`\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\nprovider = GoogleProvider(\n    project='your-gcp-project-id',\n    location='us-central1',  # the region where the model is available\n)\nmodel = GoogleModel('meta/llama-3.3-70b-instruct-maas', provider=provider)\nagent = Agent(model)\n...\n\n```\n\n## Custom HTTP Client\n\nYou can customize the `GoogleProvider` with a custom `httpx.AsyncClient`:\n\n```python\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel\nfrom pydantic_ai.providers.google import GoogleProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = GoogleModel(\n    'gemini-2.5-pro',\n    provider=GoogleProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n\n```\n\n## Document, Image, Audio, and Video Input\n\n`GoogleModel` supports multi-modal input, including documents, images, audio, and video. See the [input documentation](../../input/) for details and examples.\n\n## Model settings\n\nYou can customize model behavior using GoogleModelSettings:\n\n```python\nfrom google.genai.types import HarmBlockThreshold, HarmCategory\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel, GoogleModelSettings\n\nsettings = GoogleModelSettings(\n    temperature=0.2,\n    max_tokens=1024,\n    google_thinking_config={'thinking_level': 'low'},\n    google_safety_settings=[\n        {\n            'category': HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n            'threshold': HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n        }\n    ]\n)\nmodel = GoogleModel('gemini-2.5-pro')\nagent = Agent(model, model_settings=settings)\n...\n\n```\n\n### Disable thinking\n\nOn models older than Gemini 2.5 Pro, you can disable thinking by setting the `thinking_budget` to `0` on the `google_thinking_config`:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel, GoogleModelSettings\n\nmodel_settings = GoogleModelSettings(google_thinking_config={'thinking_budget': 0})\nmodel = GoogleModel('gemini-2.5-flash')\nagent = Agent(model, model_settings=model_settings)\n...\n\n```\n\nCheck out the [Gemini API docs](https://ai.google.dev/gemini-api/docs/thinking) for more on thinking.\n\n### Safety settings\n\nYou can customize the safety settings by setting the `google_safety_settings` field.\n\n```python\nfrom google.genai.types import HarmBlockThreshold, HarmCategory\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.google import GoogleModel, GoogleModelSettings\n\nmodel_settings = GoogleModelSettings(\n    google_safety_settings=[\n        {\n            'category': HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n            'threshold': HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n        }\n    ]\n)\nmodel = GoogleModel('gemini-2.5-flash')\nagent = Agent(model, model_settings=model_settings)\n...\n\n```\n\nSee the [Gemini API docs](https://ai.google.dev/gemini-api/docs/safety-settings) for more on safety settings.",
  "content_length": 8879
}