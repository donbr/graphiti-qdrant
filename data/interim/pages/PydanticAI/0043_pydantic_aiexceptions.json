{
  "title": "`pydantic_ai.exceptions`",
  "source_url": null,
  "content": "### ModelRetry\n\nBases: `Exception`\n\nException to raise when a tool function should be retried.\n\nThe agent will return the message to the model and ask it to try calling the function/tool again.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass ModelRetry(Exception):\n    \"\"\"Exception to raise when a tool function should be retried.\n\n    The agent will return the message to the model and ask it to try calling the function/tool again.\n    \"\"\"\n\n    message: str\n    \"\"\"The message to return to the model.\"\"\"\n\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(message)\n\n    def __eq__(self, other: Any) -> bool:\n        return isinstance(other, self.__class__) and other.message == self.message\n\n    def __hash__(self) -> int:\n        return hash((self.__class__, self.message))\n\n    @classmethod\n    def __get_pydantic_core_schema__(cls, _: Any, __: Any) -> core_schema.CoreSchema:\n        \"\"\"Pydantic core schema to allow `ModelRetry` to be (de)serialized.\"\"\"\n        schema = core_schema.typed_dict_schema(\n            {\n                'message': core_schema.typed_dict_field(core_schema.str_schema()),\n                'kind': core_schema.typed_dict_field(core_schema.literal_schema(['model-retry'])),\n            }\n        )\n        return core_schema.no_info_after_validator_function(\n            lambda dct: ModelRetry(dct['message']),\n            schema,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                lambda x: {'message': x.message, 'kind': 'model-retry'},\n                return_schema=schema,\n            ),\n        )\n\n```\n\n#### message\n\n```python\nmessage: str = message\n\n```\n\nThe message to return to the model.\n\n#### __get_pydantic_core_schema__\n\n```python\n__get_pydantic_core_schema__(_: Any, __: Any) -> CoreSchema\n\n```\n\nPydantic core schema to allow `ModelRetry` to be (de)serialized.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\n@classmethod\ndef __get_pydantic_core_schema__(cls, _: Any, __: Any) -> core_schema.CoreSchema:\n    \"\"\"Pydantic core schema to allow `ModelRetry` to be (de)serialized.\"\"\"\n    schema = core_schema.typed_dict_schema(\n        {\n            'message': core_schema.typed_dict_field(core_schema.str_schema()),\n            'kind': core_schema.typed_dict_field(core_schema.literal_schema(['model-retry'])),\n        }\n    )\n    return core_schema.no_info_after_validator_function(\n        lambda dct: ModelRetry(dct['message']),\n        schema,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            lambda x: {'message': x.message, 'kind': 'model-retry'},\n            return_schema=schema,\n        ),\n    )\n\n```\n\n### CallDeferred\n\nBases: `Exception`\n\nException to raise when a tool call should be deferred.\n\nSee [tools docs](../../deferred-tools/#deferred-tools) for more information.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `metadata` | `dict[str, Any] | None` | Optional dictionary of metadata to attach to the deferred tool call. This metadata will be available in DeferredToolRequests.metadata keyed by tool_call_id. | `None` |\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass CallDeferred(Exception):\n    \"\"\"Exception to raise when a tool call should be deferred.\n\n    See [tools docs](../deferred-tools.md#deferred-tools) for more information.\n\n    Args:\n        metadata: Optional dictionary of metadata to attach to the deferred tool call.\n            This metadata will be available in `DeferredToolRequests.metadata` keyed by `tool_call_id`.\n    \"\"\"\n\n    def __init__(self, metadata: dict[str, Any] | None = None):\n        self.metadata = metadata\n        super().__init__()\n\n```\n\n### ApprovalRequired\n\nBases: `Exception`\n\nException to raise when a tool call requires human-in-the-loop approval.\n\nSee [tools docs](../../deferred-tools/#human-in-the-loop-tool-approval) for more information.\n\nParameters:\n\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `metadata` | `dict[str, Any] | None` | Optional dictionary of metadata to attach to the deferred tool call. This metadata will be available in DeferredToolRequests.metadata keyed by tool_call_id. | `None` |\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass ApprovalRequired(Exception):\n    \"\"\"Exception to raise when a tool call requires human-in-the-loop approval.\n\n    See [tools docs](../deferred-tools.md#human-in-the-loop-tool-approval) for more information.\n\n    Args:\n        metadata: Optional dictionary of metadata to attach to the deferred tool call.\n            This metadata will be available in `DeferredToolRequests.metadata` keyed by `tool_call_id`.\n    \"\"\"\n\n    def __init__(self, metadata: dict[str, Any] | None = None):\n        self.metadata = metadata\n        super().__init__()\n\n```\n\n### UserError\n\nBases: `RuntimeError`\n\nError caused by a usage mistake by the application developer — You!\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass UserError(RuntimeError):\n    \"\"\"Error caused by a usage mistake by the application developer — You!\"\"\"\n\n    message: str\n    \"\"\"Description of the mistake.\"\"\"\n\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(message)\n\n```\n\n#### message\n\n```python\nmessage: str = message\n\n```\n\nDescription of the mistake.\n\n### AgentRunError\n\nBases: `RuntimeError`\n\nBase class for errors occurring during an agent run.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass AgentRunError(RuntimeError):\n    \"\"\"Base class for errors occurring during an agent run.\"\"\"\n\n    message: str\n    \"\"\"The error message.\"\"\"\n\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(message)\n\n    def __str__(self) -> str:\n        return self.message\n\n```\n\n#### message\n\n```python\nmessage: str = message\n\n```\n\nThe error message.\n\n### UsageLimitExceeded\n\nBases: `AgentRunError`\n\nError raised when a Model's usage exceeds the specified limits.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass UsageLimitExceeded(AgentRunError):\n    \"\"\"Error raised when a Model's usage exceeds the specified limits.\"\"\"\n\n```\n\n### UnexpectedModelBehavior\n\nBases: `AgentRunError`\n\nError caused by unexpected Model behavior, e.g. an unexpected response code.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass UnexpectedModelBehavior(AgentRunError):\n    \"\"\"Error caused by unexpected Model behavior, e.g. an unexpected response code.\"\"\"\n\n    message: str\n    \"\"\"Description of the unexpected behavior.\"\"\"\n    body: str | None\n    \"\"\"The body of the response, if available.\"\"\"\n\n    def __init__(self, message: str, body: str | None = None):\n        self.message = message\n        if body is None:\n            self.body: str | None = None\n        else:\n            try:\n                self.body = json.dumps(json.loads(body), indent=2)\n            except ValueError:\n                self.body = body\n        super().__init__(message)\n\n    def __str__(self) -> str:\n        if self.body:\n            return f'{self.message}, body:\\n{self.body}'\n        else:\n            return self.message\n\n```\n\n#### message\n\n```python\nmessage: str = message\n\n```\n\nDescription of the unexpected behavior.\n\n#### body\n\n```python\nbody: str | None = dumps(loads(body), indent=2)\n\n```\n\nThe body of the response, if available.\n\n### ModelAPIError\n\nBases: `AgentRunError`\n\nRaised when a model provider API request fails.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass ModelAPIError(AgentRunError):\n    \"\"\"Raised when a model provider API request fails.\"\"\"\n\n    model_name: str\n    \"\"\"The name of the model associated with the error.\"\"\"\n\n    def __init__(self, model_name: str, message: str):\n        self.model_name = model_name\n        super().__init__(message)\n\n```\n\n#### model_name\n\n```python\nmodel_name: str = model_name\n\n```\n\nThe name of the model associated with the error.\n\n### ModelHTTPError\n\nBases: `ModelAPIError`\n\nRaised when an model provider response has a status code of 4xx or 5xx.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass ModelHTTPError(ModelAPIError):\n    \"\"\"Raised when an model provider response has a status code of 4xx or 5xx.\"\"\"\n\n    status_code: int\n    \"\"\"The HTTP status code returned by the API.\"\"\"\n\n    body: object | None\n    \"\"\"The body of the response, if available.\"\"\"\n\n    def __init__(self, status_code: int, model_name: str, body: object | None = None):\n        self.status_code = status_code\n        self.body = body\n        message = f'status_code: {status_code}, model_name: {model_name}, body: {body}'\n        super().__init__(model_name=model_name, message=message)\n\n```\n\n#### status_code\n\n```python\nstatus_code: int = status_code\n\n```\n\nThe HTTP status code returned by the API.\n\n#### body\n\n```python\nbody: object | None = body\n\n```\n\nThe body of the response, if available.\n\n### FallbackExceptionGroup\n\nBases: `ExceptionGroup[Any]`\n\nA group of exceptions that can be raised when all fallback models fail.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass FallbackExceptionGroup(ExceptionGroup[Any]):\n    \"\"\"A group of exceptions that can be raised when all fallback models fail.\"\"\"\n\n```\n\n### IncompleteToolCall\n\nBases: `UnexpectedModelBehavior`\n\nError raised when a model stops due to token limit while emitting a tool call.\n\nSource code in `pydantic_ai_slim/pydantic_ai/exceptions.py`\n\n```python\nclass IncompleteToolCall(UnexpectedModelBehavior):\n    \"\"\"Error raised when a model stops due to token limit while emitting a tool call.\"\"\"\n\n```",
  "content_length": 9740
}