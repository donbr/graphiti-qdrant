{
  "title": "Outlines",
  "source_url": null,
  "content": "## Install\n\nAs Outlines is a library allowing you to run models from various different providers, it does not include the necessary dependencies for any provider by default. As a result, to use the OutlinesModel, you must install `pydantic-ai-slim` with an optional group composed of outlines, a dash, and the name of the specific model provider you would use through Outlines. For instance:\n\n```bash\npip install \"pydantic-ai-slim[outlines-transformers]\"\n\n```\n\n```bash\nuv add \"pydantic-ai-slim[outlines-transformers]\"\n\n```\n\nOr\n\n```bash\npip install \"pydantic-ai-slim[outlines-mlxlm]\"\n\n```\n\n```bash\nuv add \"pydantic-ai-slim[outlines-mlxlm]\"\n\n```\n\nThere are 5 optional groups for the 5 model providers supported through Outlines:\n\n- `outlines-transformers`\n- `outlines-llamacpp`\n- `outlines-mlxlm`\n- `outlines-sglang`\n- `outlines-vllm-offline`\n\n## Model Initialization\n\nAs Outlines is not an inference provider, but instead a library allowing you to run both local and API-based models, instantiating the model is a bit different from the other models available on Pydantic AI.\n\nTo initialize the `OutlinesModel` through the `__init__` method, the first argument you must provide has to be an `outlines.Model` or an `outlines.AsyncModel` instance.\n\nFor instance:\n\n```python\nimport outlines\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom pydantic_ai.models.outlines import OutlinesModel\n\noutlines_model = outlines.from_transformers(\n    AutoModelForCausalLM.from_pretrained('erwanf/gpt2-mini'),\n    AutoTokenizer.from_pretrained('erwanf/gpt2-mini')\n)\nmodel = OutlinesModel(outlines_model)\n\n```\n\nAs you already providing an Outlines model instance, there is no need to provide an `OutlinesProvider` yourself.\n\n### Model Loading Methods\n\nAlternatively, you can use some `OutlinesModel` class methods made to load a specific type of Outlines model directly. To do so, you must provide as arguments the same arguments you would have given to the associated Outlines model loading function (except in the case of SGLang).\n\nThere are methods for the 5 Outlines models that are officially supported in the integration into Pydantic AI:\n\n- from_transformers\n- from_llamacpp\n- from_mlxlm\n- from_sglang\n- from_vllm_offline\n\n#### Transformers\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom pydantic_ai.models.outlines import OutlinesModel\n\nmodel = OutlinesModel.from_transformers(\n    AutoModelForCausalLM.from_pretrained('microsoft/Phi-3-mini-4k-instruct'),\n    AutoTokenizer.from_pretrained('microsoft/Phi-3-mini-4k-instruct')\n)\n\n```\n\n#### LlamaCpp\n\n```python\nfrom llama_cpp import Llama\n\nfrom pydantic_ai.models.outlines import OutlinesModel\n\nmodel = OutlinesModel.from_llamacpp(\n    Llama.from_pretrained(\n        repo_id='TheBloke/Mistral-7B-Instruct-v0.2-GGUF',\n        filename='mistral-7b-instruct-v0.2.Q5_K_M.gguf',\n    )\n)\n\n```\n\n#### MLXLM\n\n```python\nfrom mlx_lm import load\n\nfrom pydantic_ai.models.outlines import OutlinesModel\n\nmodel = OutlinesModel.from_mlxlm(\n    *load('mlx-community/TinyLlama-1.1B-Chat-v1.0-4bit')\n)\n\n```\n\n#### SGLang\n\n```python\nfrom pydantic_ai.models.outlines import OutlinesModel\n\nmodel = OutlinesModel.from_sglang(\n    'http://localhost:11434',\n    'api_key',\n    'meta-llama/Llama-3.1-8B'\n)\n\n```\n\n#### vLLM Offline\n\n```python\nfrom vllm import LLM\n\nfrom pydantic_ai.models.outlines import OutlinesModel\n\nmodel = OutlinesModel.from_vllm_offline(\n    LLM('microsoft/Phi-3-mini-4k-instruct')\n)\n\n```\n\n## Running the model\n\nOnce you have initialized an `OutlinesModel`, you can use it with an Agent as with all other Pydantic AI models.\n\nAs Outlines is focused on structured output, this provider supports the `output_type` component through the NativeOutput format. There is not need to include information on the required output format in your prompt, instructions based on the `output_type` will be included automatically.\n\n```python\nfrom pydantic import BaseModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.outlines import OutlinesModel\nfrom pydantic_ai.settings import ModelSettings\n\n\nclass Box(BaseModel):\n    \"\"\"Class representing a box\"\"\"\n    width: int\n    height: int\n    depth: int\n    units: str\n\nmodel = OutlinesModel.from_transformers(\n    AutoModelForCausalLM.from_pretrained('microsoft/Phi-3-mini-4k-instruct'),\n    AutoTokenizer.from_pretrained('microsoft/Phi-3-mini-4k-instruct')\n)\nagent = Agent(model, output_type=Box)\n\nresult = agent.run_sync(\n    'Give me the dimensions of a box',\n    model_settings=ModelSettings(extra_body={'max_new_tokens': 100})\n)\nprint(result.output) # width=20 height=30 depth=40 units='cm'\n\n```\n\nOutlines does not support tools yet, but support for that feature will be added in the near future.\n\n## Multimodal models\n\nIf the model you are running through Outlines and the provider selected supports it, you can include images in your prompts using ImageUrl or BinaryImage. In that case, the prompt you provide when running the agent should be a list containing a string and one or several images. See the [input documentation](../../input/) for details and examples on using assets in model inputs.\n\nThis feature is supported in Outlines for the `SGLang` and `Transformers` models. If you want to run a multimodal model through `transformers`, you must provide a processor instead of a tokenizer as the second argument when initializing the model with the `OutlinesModel.from_transformers` method.\n\n```python\nfrom datetime import date\nfrom typing import Literal\n\nimport torch\nfrom pydantic import BaseModel\nfrom transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n\nfrom pydantic_ai import Agent, ModelSettings\nfrom pydantic_ai.messages import ImageUrl\nfrom pydantic_ai.models.outlines import OutlinesModel\n\nMODEL_NAME = 'Qwen/Qwen2-VL-7B-Instruct'\n\nclass Item(BaseModel):\n    name: str\n    quantity: int | None\n    price_per_unit: float | None\n    total_price: float | None\n\nclass ReceiptSummary(BaseModel):\n    store_name: str\n    store_address: str\n    store_number: int | None\n    items: list[Item]\n    tax: float | None\n    total: float | None\n    date: date\n    payment_method: Literal['cash', 'credit', 'debit', 'check', 'other']\n\ntf_model = Qwen2VLForConditionalGeneration.from_pretrained(\n    MODEL_NAME,\n    device_map='auto',\n    dtype=torch.bfloat16\n)\ntf_processor = AutoProcessor.from_pretrained(\n    MODEL_NAME,\n    device_map='auto'\n)\nmodel = OutlinesModel.from_transformers(tf_model, tf_processor)\n\nagent = Agent(model, output_type=ReceiptSummary)\n\nresult = agent.run_sync(\n    [\n        'You are an expert at extracting information from receipts. Please extract the information from the receipt. Be as detailed as possible, do not miss any information',\n        ImageUrl('https://raw.githubusercontent.com/dottxt-ai/outlines/refs/heads/main/docs/examples/images/trader-joes-receipt.jpg')\n    ],\n    model_settings=ModelSettings(extra_body={'max_new_tokens': 1000})\n)\nprint(result.output)\n### store_name=\"Trader Joe's\"\n### store_address='401 Bay Street, San Francisco, CA 94133'\n### store_number=0\n### items=[\n###   Item(name='BANANA EACH', quantity=7, price_per_unit=0.23, total_price=1.61),\n###   Item(name='BAREBELLS CHOCOLATE DOUG',quantity=1, price_per_unit=2.29, total_price=2.29),\n###   Item(name='BAREBELLS CREAMY CRISP', quantity=1, price_per_unit=2.29, total_price=2.29),\n###   Item(name='BAREBELLS CHOCOLATE DOUG', quantity=1, price_per_unit=2.29, total_price=2.29),\n###   Item(name='BAREBELLS CARAMEL CASHEW', quantity=2, price_per_unit=2.29, total_price=4.58),\n###   Item(name='BAREBELLS CREAMY CRISP', quantity=1, price_per_unit=2.29, total_price=2.29),\n###   Item(name='T SPINDRIFT ORANGE MANGO 8', quantity=1, price_per_unit=7.49, total_price=7.49),\n###   Item(name='T Bottle Deposit', quantity=8, price_per_unit=0.05, total_price=0.4),\n###   Item(name='MILK ORGANIC GALLON WHOL', quantity=1, price_per_unit=6.79, total_price=6.79),\n###   Item(name='CLASSIC GREEK SALAD', quantity=1, price_per_unit=3.49, total_price=3.49),\n###   Item(name='COBB SALAD', quantity=1, price_per_unit=5.99, total_price=5.99),\n###   Item(name='PEPPER BELL RED XL EACH', quantity=1, price_per_unit=1.29, total_price=1.29),\n###   Item(name='BAG FEE.', quantity=1, price_per_unit=0.25, total_price=0.25),\n###   Item(name='BAG FEE.', quantity=1, price_per_unit=0.25, total_price=0.25)]\n### tax=7.89\n### total=41.98\n### date='2023-04-01'\n### payment_method='credit'\n\n```",
  "content_length": 8479
}