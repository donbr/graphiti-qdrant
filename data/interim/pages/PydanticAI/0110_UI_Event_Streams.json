{
  "title": "UI Event Streams",
  "source_url": null,
  "content": "If you're building a chat app or other interactive frontend for an AI agent, your backend will need to receive agent run input (like a chat message or complete [message history](../../message-history/)) from the frontend, and will need to stream the [agent's events](../../agents/#streaming-all-events) (like text, thinking, and tool calls) to the frontend so that the user knows what's happening in real time.\n\nWhile your frontend could use Pydantic AI's ModelRequest and AgentStreamEvent directly, you'll typically want to use a UI event stream protocol that's natively supported by your frontend framework.\n\nPydantic AI natively supports two UI event stream protocols:\n\n- [Agent-User Interaction (AG-UI) Protocol](../ag-ui/)\n- [Vercel AI Data Stream Protocol](../vercel-ai/)\n\nThese integrations are implemented as subclasses of the abstract UIAdapter class, so they also serve as a reference for integrating with other UI event stream protocols.\n\n## Usage\n\nThe protocol-specific UIAdapter subclass (i.e. AGUIAdapter or VercelAIAdapter) is responsible for transforming agent run input received from the frontend into arguments for [`Agent.run_stream_events()`](../../agents/#running-agents), running the agent, and then transforming Pydantic AI events into protocol-specific events. The event stream transformation is handled by a protocol-specific UIEventStream subclass, but you typically won't use this directly.\n\nIf you're using a Starlette-based web framework like FastAPI, you can use the UIAdapter.dispatch_request() class method from an endpoint function to directly handle a request and return a streaming response of protocol-specific events. This is demonstrated in the next section.\n\nIf you're using a web framework not based on Starlette (e.g. Django or Flask) or need fine-grained control over the input or output, you can create a `UIAdapter` instance and directly use its methods. This is demonstrated in \"Advanced Usage\" section below.\n\n### Usage with Starlette/FastAPI\n\nBesides the request, UIAdapter.dispatch_request() takes the agent, the same optional arguments as [`Agent.run_stream_events()`](../../agents/#running-agents), and an optional `on_complete` callback function that receives the completed AgentRunResult and can optionally yield additional protocol-specific events.\n\nNote\n\nThese examples use the `VercelAIAdapter`, but the same patterns apply to all `UIAdapter` subclasses.\n\n[Learn about Gateway](../../gateway) dispatch_request.py\n\n```python\nfrom fastapi import FastAPI\nfrom starlette.requests import Request\nfrom starlette.responses import Response\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.ui.vercel_ai import VercelAIAdapter\n\nagent = Agent('gateway/openai:gpt-5')\n\napp = FastAPI()\n\n@app.post('/chat')\nasync def chat(request: Request) -> Response:\n    return await VercelAIAdapter.dispatch_request(request, agent=agent)\n\n```\n\ndispatch_request.py\n\n```python\nfrom fastapi import FastAPI\nfrom starlette.requests import Request\nfrom starlette.responses import Response\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.ui.vercel_ai import VercelAIAdapter\n\nagent = Agent('openai:gpt-5')\n\napp = FastAPI()\n\n@app.post('/chat')\nasync def chat(request: Request) -> Response:\n    return await VercelAIAdapter.dispatch_request(request, agent=agent)\n\n```\n\n### Advanced Usage\n\nIf you're using a web framework not based on Starlette (e.g. Django or Flask) or need fine-grained control over the input or output, you can create a `UIAdapter` instance and directly use its methods, which can be chained to accomplish the same thing as the `UIAdapter.dispatch_request()` class method shown above:\n\n1. The UIAdapter.build_run_input() class method takes the request body as bytes and returns a protocol-specific run input object, which you can then pass to the UIAdapter() constructor along with the agent.\n   - You can also use the UIAdapter.from_request() class method to build an adapter directly from a Starlette/FastAPI request.\n1. The UIAdapter.run_stream() method runs the agent and returns a stream of protocol-specific events. It supports the same optional arguments as [`Agent.run_stream_events()`](../../agents/#running-agents) and an optional `on_complete` callback function that receives the completed AgentRunResult and can optionally yield additional protocol-specific events.\n   - You can also use UIAdapter.run_stream_native() to run the agent and return a stream of Pydantic AI events instead, which can then be transformed into protocol-specific events using UIAdapter.transform_stream().\n1. The UIAdapter.encode_stream() method encodes the stream of protocol-specific events as SSE (HTTP Server-Sent Events) strings, which you can then return as a streaming response.\n   - You can also use UIAdapter.streaming_response() to generate a Starlette/FastAPI streaming response directly from the protocol-specific event stream returned by `run_stream()`.\n\nNote\n\nThis example uses FastAPI, but can be modified to work with any web framework.\n\n[Learn about Gateway](../../gateway) run_stream.py\n\n```python\nimport json\nfrom http import HTTPStatus\n\nfrom fastapi import FastAPI\nfrom fastapi.requests import Request\nfrom fastapi.responses import Response, StreamingResponse\nfrom pydantic import ValidationError\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.ui import SSE_CONTENT_TYPE\nfrom pydantic_ai.ui.vercel_ai import VercelAIAdapter\n\nagent = Agent('gateway/openai:gpt-5')\n\napp = FastAPI()\n\n\n@app.post('/chat')\nasync def chat(request: Request) -> Response:\n    accept = request.headers.get('accept', SSE_CONTENT_TYPE)\n    try:\n        run_input = VercelAIAdapter.build_run_input(await request.body())\n    except ValidationError as e:\n        return Response(\n            content=json.dumps(e.json()),\n            media_type='application/json',\n            status_code=HTTPStatus.UNPROCESSABLE_ENTITY,\n        )\n\n    adapter = VercelAIAdapter(agent=agent, run_input=run_input, accept=accept)\n    event_stream = adapter.run_stream()\n\n    sse_event_stream = adapter.encode_stream(event_stream)\n    return StreamingResponse(sse_event_stream, media_type=accept)\n\n```\n\nrun_stream.py\n\n```python\nimport json\nfrom http import HTTPStatus\n\nfrom fastapi import FastAPI\nfrom fastapi.requests import Request\nfrom fastapi.responses import Response, StreamingResponse\nfrom pydantic import ValidationError\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.ui import SSE_CONTENT_TYPE\nfrom pydantic_ai.ui.vercel_ai import VercelAIAdapter\n\nagent = Agent('openai:gpt-5')\n\napp = FastAPI()\n\n\n@app.post('/chat')\nasync def chat(request: Request) -> Response:\n    accept = request.headers.get('accept', SSE_CONTENT_TYPE)\n    try:\n        run_input = VercelAIAdapter.build_run_input(await request.body())\n    except ValidationError as e:\n        return Response(\n            content=json.dumps(e.json()),\n            media_type='application/json',\n            status_code=HTTPStatus.UNPROCESSABLE_ENTITY,\n        )\n\n    adapter = VercelAIAdapter(agent=agent, run_input=run_input, accept=accept)\n    event_stream = adapter.run_stream()\n\n    sse_event_stream = adapter.encode_stream(event_stream)\n    return StreamingResponse(sse_event_stream, media_type=accept)\n\n```",
  "content_length": 7171
}