{
  "title": "MCP Middleware",
  "source_url": "https://gofastmcp.com/servers/middleware",
  "content": "Add cross-cutting functionality to your MCP server with middleware that can inspect, modify, and respond to all MCP requests and responses.\n\nexport const VersionBadge = ({version}) => {\n  return <code className=\"version-badge-container\">\n            <p className=\"version-badge\">\n                <span className=\"version-badge-label\">New in version:</span> \n                <code className=\"version-badge-version\">{version}</code>\n            </p>\n        </code>;\n};\n\n<VersionBadge version=\"2.9.0\" />\n\nMCP middleware is a powerful concept that allows you to add cross-cutting functionality to your FastMCP server. Unlike traditional web middleware, MCP middleware is designed specifically for the Model Context Protocol, providing hooks for different types of MCP operations like tool calls, resource reads, and prompt requests.\n\n<Tip>\n  MCP middleware is a FastMCP-specific concept and is not part of the official MCP protocol specification. This middleware system is designed to work with FastMCP servers and may not be compatible with other MCP implementations.\n</Tip>\n\n<Warning>\n  MCP middleware is a brand new concept and may be subject to breaking changes in future versions.\n</Warning>\n\n## What is MCP Middleware?\n\nMCP middleware lets you intercept and modify MCP requests and responses as they flow through your server. Think of it as a pipeline where each piece of middleware can inspect what's happening, make changes, and then pass control to the next middleware in the chain.\n\nCommon use cases for MCP middleware include:\n\n* **Authentication and Authorization**: Verify client permissions before executing operations\n* **Logging and Monitoring**: Track usage patterns and performance metrics\n* **Rate Limiting**: Control request frequency per client or operation type\n* **Request/Response Transformation**: Modify data before it reaches tools or after it leaves\n* **Caching**: Store frequently requested data to improve performance\n* **Error Handling**: Provide consistent error responses across your server\n\n## How Middleware Works\n\nFastMCP middleware operates on a pipeline model. When a request comes in, it flows through your middleware in the order they were added to the server. Each middleware can:\n\n1. **Inspect the incoming request** and its context\n2. **Modify the request** before passing it to the next middleware or handler\n3. **Execute the next middleware/handler** in the chain by calling `call_next()`\n4. **Inspect and modify the response** before returning it\n5. **Handle errors** that occur during processing\n\nThe key insight is that middleware forms a chain where each piece decides whether to continue processing or stop the chain entirely.\n\nIf you're familiar with ASGI middleware, the basic structure of FastMCP middleware will feel familiar. At its core, middleware is a callable class that receives a context object containing information about the current JSON-RPC message and a handler function to continue the middleware chain.\n\nIt's important to understand that MCP operates on the [JSON-RPC specification](https://spec.modelcontextprotocol.io/specification/basic/transports/). While FastMCP presents requests and responses in a familiar way, these are fundamentally JSON-RPC messages, not HTTP request/response pairs like you might be used to in web applications. FastMCP middleware works with all [transport types](/clients/transports), including local stdio transport and HTTP transports, though not all middleware implementations are compatible across all transports (e.g., middleware that inspects HTTP headers won't work with stdio transport).\n\nThe most fundamental way to implement middleware is by overriding the `__call__` method on the `Middleware` base class:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass RawMiddleware(Middleware):\n    async def __call__(self, context: MiddlewareContext, call_next):\n        # This method receives ALL messages regardless of type\n        print(f\"Raw middleware processing: {context.method}\")\n        result = await call_next(context)\n        print(f\"Raw middleware completed: {context.method}\")\n        return result\n```\n\nThis gives you complete control over every message that flows through your server, but requires you to handle all message types manually.\n\n## Middleware Hooks\n\nTo make it easier for users to target specific types of messages, FastMCP middleware provides a variety of specialized hooks. Instead of implementing the raw `__call__` method, you can override specific hook methods that are called only for certain types of operations, allowing you to target exactly the level of specificity you need for your middleware logic.\n\n### Hook Hierarchy and Execution Order\n\nFastMCP provides multiple hooks that are called with varying levels of specificity. Understanding this hierarchy is crucial for effective middleware design.\n\nWhen a request comes in, **multiple hooks may be called for the same request**, going from general to specific:\n\n1. **`on_message`** - Called for ALL MCP messages (both requests and notifications)\n2. **`on_request` or `on_notification`** - Called based on the message type\n3. **Operation-specific hooks** - Called for specific MCP operations like `on_call_tool`\n\nFor example, when a client calls a tool, your middleware will receive **multiple hook calls**:\n\n1. `on_message` and `on_request` for any initial tool discovery operations (list\\_tools)\n2. `on_message` (because it's any MCP message) for the tool call itself\n3. `on_request` (because tool calls expect responses) for the tool call itself\n4. `on_call_tool` (because it's specifically a tool execution) for the tool call itself\n\nNote that the MCP SDK may perform additional operations like listing tools for caching purposes, which will trigger additional middleware calls beyond just the direct tool execution.\n\nThis hierarchy allows you to target your middleware logic with the right level of specificity. Use `on_message` for broad concerns like logging, `on_request` for authentication, and `on_call_tool` for tool-specific logic like performance monitoring.\n\n### Available Hooks\n\n<VersionBadge version=\"2.9.0\" />\n\n* `on_message`: Called for all MCP messages (requests and notifications)\n\n* `on_request`: Called specifically for MCP requests (that expect responses)\n\n* `on_notification`: Called specifically for MCP notifications (fire-and-forget)\n\n* `on_call_tool`: Called when tools are being executed\n\n* `on_read_resource`: Called when resources are being read\n\n* `on_get_prompt`: Called when prompts are being retrieved\n\n* `on_list_tools`: Called when listing available tools\n\n* `on_list_resources`: Called when listing available resources\n\n* `on_list_resource_templates`: Called when listing resource templates\n\n* `on_list_prompts`: Called when listing available prompts\n\n<VersionBadge version=\"2.13.0\" />\n\n* `on_initialize`: Called when a client connects and initializes the session (returns `None`)\n\n<Note>\n  The `on_initialize` hook receives the client's initialization request but **returns `None`** rather than a result. The initialization response is handled internally by the MCP protocol and cannot be modified by middleware. This hook is useful for client detection, logging connections, or initializing session state, but not for modifying the initialization handshake itself.\n</Note>\n\n### MCP Session Availability in Middleware\n\n<VersionBadge version=\"2.13.1\" />\n\nThe MCP session and request context are not available during certain phases like initialization. When middleware runs during these phases, `context.fastmcp_context.request_context` returns `None` rather than the full MCP request context.\n\nThis typically occurs when:\n\n* The `on_request` hook fires during client initialization\n* The MCP handshake hasn't completed yet\n\nTo handle this in middleware, check if the MCP request context is available before accessing MCP-specific attributes. Note that the MCP request context is distinct from the HTTP request - for HTTP transports, you can use HTTP helpers to access request data even when the MCP session is not available:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass SessionAwareMiddleware(Middleware):\n    async def on_request(self, context: MiddlewareContext, call_next):\n        ctx = context.fastmcp_context\n\n        if ctx.request_context:\n            # MCP session available - can access session-specific attributes\n            session_id = ctx.session_id\n            request_id = ctx.request_id\n        else:\n            # MCP session not available yet - use HTTP helpers for request data (if using HTTP transport)\n            from fastmcp.server.dependencies import get_http_headers\n            headers = get_http_headers()\n            # Access HTTP data for auth, logging, etc.\n\n        return await call_next(context)\n```\n\nFor HTTP request data (headers, client IP, etc.) when using HTTP transports, use `get_http_request()` or `get_http_headers()` from `fastmcp.server.dependencies`, which work regardless of MCP session availability. See [HTTP Requests](/servers/context#http-requests) for details.\n\n## Component Access in Middleware\n\nUnderstanding how to access component information (tools, resources, prompts) in middleware is crucial for building powerful middleware functionality. The access patterns differ significantly between listing operations and execution operations.\n\n### Listing Operations vs Execution Operations\n\nFastMCP middleware handles two types of operations differently:\n\n**Listing Operations** (`on_list_tools`, `on_list_resources`, `on_list_prompts`, etc.):\n\n* Middleware receives **FastMCP component objects** with full metadata\n* These objects include FastMCP-specific properties like `tags` that can be accessed directly from the component\n* The result contains complete component information before it's converted to MCP format\n* Tags are included in the component's `meta` field in the listing response returned to MCP clients\n\n**Execution Operations** (`on_call_tool`, `on_read_resource`, `on_get_prompt`):\n\n* Middleware runs **before** the component is executed\n* The middleware result is either the execution result or an error if the component wasn't found\n* Component metadata isn't directly available in the hook parameters\n\n### Accessing Component Metadata During Execution\n\nIf you need to check component properties (like tags) during execution operations, use the FastMCP server instance available through the context:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\nfrom fastmcp.exceptions import ToolError\n\nclass TagBasedMiddleware(Middleware):\n    async def on_call_tool(self, context: MiddlewareContext, call_next):\n        # Access the tool object to check its metadata\n        if context.fastmcp_context:\n            try:\n                tool = await context.fastmcp_context.fastmcp.get_tool(context.message.name)\n                \n                # Check if this tool has a \"private\" tag\n                if \"private\" in tool.tags:\n                    raise ToolError(\"Access denied: private tool\")\n                    \n                # Check if tool is enabled\n                if not tool.enabled:\n                    raise ToolError(\"Tool is currently disabled\")\n                    \n            except Exception:\n                # Tool not found or other error - let execution continue\n                # and handle the error naturally\n                pass\n        \n        return await call_next(context)\n```\n\nThe same pattern works for resources and prompts:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\nfrom fastmcp.exceptions import ResourceError, PromptError\n\nclass ComponentAccessMiddleware(Middleware):\n    async def on_read_resource(self, context: MiddlewareContext, call_next):\n        if context.fastmcp_context:\n            try:\n                resource = await context.fastmcp_context.fastmcp.get_resource(context.message.uri)\n                if \"restricted\" in resource.tags:\n                    raise ResourceError(\"Access denied: restricted resource\")\n            except Exception:\n                pass\n        return await call_next(context)\n    \n    async def on_get_prompt(self, context: MiddlewareContext, call_next):\n        if context.fastmcp_context:\n            try:\n                prompt = await context.fastmcp_context.fastmcp.get_prompt(context.message.name)\n                if not prompt.enabled:\n                    raise PromptError(\"Prompt is currently disabled\")\n            except Exception:\n                pass\n        return await call_next(context)\n```\n\n### Working with Listing Results\n\nFor listing operations, the middleware `call_next` function returns a list of FastMCP components prior to being converted to MCP format. You can filter or modify this list and return it to the client. For example:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass ListingFilterMiddleware(Middleware):\n    async def on_list_tools(self, context: MiddlewareContext, call_next):\n        result = await call_next(context)\n        \n        # Filter out tools with \"private\" tag\n        filtered_tools = [\n            tool for tool in result \n            if \"private\" not in tool.tags\n        ]\n        \n        # Return modified list\n        return filtered_tools\n```\n\nThis filtering happens before the components are converted to MCP format and returned to the client. Tags are accessible both during filtering and are included in the component's `meta` field in the final listing response.\n\n<Tip>\n  When filtering components in listing operations, ensure you also prevent execution of filtered components in the corresponding execution hooks (`on_call_tool`, `on_read_resource`, `on_get_prompt`) to maintain consistency.\n</Tip>\n\n### Tool Call Denial\n\nYou can deny access to specific tools by raising a `ToolError` in your middleware. This is the correct way to block tool execution, as it integrates properly with the FastMCP error handling system.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\nfrom fastmcp.exceptions import ToolError\n\nclass AuthMiddleware(Middleware):\n    async def on_call_tool(self, context: MiddlewareContext, call_next):\n        tool_name = context.message.name\n        \n        # Deny access to restricted tools\n        if tool_name.lower() in [\"delete\", \"admin_config\"]:\n            raise ToolError(\"Access denied: tool requires admin privileges\")\n        \n        # Allow other tools to proceed\n        return await call_next(context)\n```\n\n<Warning>\n  When denying tool calls, always raise `ToolError` rather than returning `ToolResult` objects or other values. `ToolError` ensures proper error propagation through the middleware chain and converts to the correct MCP error response format.\n</Warning>\n\n### Tool Call Modification\n\nFor execution operations like tool calls, you can modify arguments before execution or transform results afterward:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass ToolCallMiddleware(Middleware):\n    async def on_call_tool(self, context: MiddlewareContext, call_next):\n        # Modify arguments before execution\n        if context.message.name == \"calculate\":\n            # Ensure positive inputs\n            if context.message.arguments.get(\"value\", 0) < 0:\n                context.message.arguments[\"value\"] = abs(context.message.arguments[\"value\"])\n        \n        result = await call_next(context)\n        \n        # Transform result after execution\n        if context.message.name == \"get_data\":\n            # Add metadata to result\n            if result.structured_content:\n                result.structured_content[\"processed_at\"] = \"2024-01-01T00:00:00Z\"\n        \n        return result\n```\n\n<Tip>\n  For more complex tool rewriting scenarios, consider using [Tool Transformation](/patterns/tool-transformation) patterns which provide a more structured approach to creating modified tool variants.\n</Tip>\n\n### Anatomy of a Hook\n\nEvery middleware hook follows the same pattern. Let's examine the `on_message` hook to understand the structure:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nasync def on_message(self, context: MiddlewareContext, call_next):\n    # 1. Pre-processing: Inspect and optionally modify the request\n    print(f\"Processing {context.method}\")\n    \n    # 2. Chain continuation: Call the next middleware/handler\n    result = await call_next(context)\n    \n    # 3. Post-processing: Inspect and optionally modify the response\n    print(f\"Completed {context.method}\")\n    \n    # 4. Return the result (potentially modified)\n    return result\n```\n\n### Hook Parameters\n\nEvery hook receives two parameters:\n\n1. **`context: MiddlewareContext`** - Contains information about the current request:\n   * `context.method` - The MCP method name (e.g., \"tools/call\")\n   * `context.source` - Where the request came from (\"client\" or \"server\")\n   * `context.type` - Message type (\"request\" or \"notification\")\n   * `context.message` - The MCP message data\n   * `context.timestamp` - When the request was received\n   * `context.fastmcp_context` - FastMCP Context object (if available)\n\n2. **`call_next`** - A function that continues the middleware chain. You **must** call this to proceed, unless you want to stop processing entirely.\n\n### Control Flow\n\nYou have complete control over the request flow:\n\n* **Continue processing**: Call `await call_next(context)` to proceed\n* **Modify the request**: Change the context before calling `call_next`\n* **Modify the response**: Change the result after calling `call_next`\n* **Stop the chain**: Don't call `call_next` (rarely needed)\n* **Handle errors**: Wrap `call_next` in try/catch blocks\n\n#### State Management\n\n<VersionBadge version=\"2.11.0\" />\n\nIn addition to modifying the request and response, you can also store state data that your tools can (optionally) access later. To do so, use the FastMCP Context to either `set_state` or `get_state` as appropriate. For more information, see the [Context State Management](/servers/context#state-management) docs.\n\n## Creating Middleware\n\nFastMCP middleware is implemented by subclassing the `Middleware` base class and overriding the hooks you need. You only need to implement the hooks that are relevant to your use case.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass LoggingMiddleware(Middleware):\n    \"\"\"Middleware that logs all MCP operations.\"\"\"\n    \n    async def on_message(self, context: MiddlewareContext, call_next):\n        \"\"\"Called for all MCP messages.\"\"\"\n        print(f\"Processing {context.method} from {context.source}\")\n        \n        result = await call_next(context)\n        \n        print(f\"Completed {context.method}\")\n        return result\n\n# Add middleware to your server\nmcp = FastMCP(\"MyServer\")\nmcp.add_middleware(LoggingMiddleware())\n```\n\nThis creates a basic logging middleware that will print information about every request that flows through your server.\n\n## Adding Middleware to Your Server\n\n### Single Middleware\n\nAdding middleware to your server is straightforward:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nmcp = FastMCP(\"MyServer\")\nmcp.add_middleware(LoggingMiddleware())\n```\n\n### Multiple Middleware\n\nMiddleware executes in the order it's added to the server. The first middleware added runs first on the way in, and last on the way out:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nmcp = FastMCP(\"MyServer\")\n\nmcp.add_middleware(AuthenticationMiddleware(\"secret-token\"))\nmcp.add_middleware(PerformanceMiddleware())\nmcp.add_middleware(LoggingMiddleware())\n```\n\nThis creates the following execution flow:\n\n1. AuthenticationMiddleware (pre-processing)\n2. PerformanceMiddleware (pre-processing)\n3. LoggingMiddleware (pre-processing)\n4. Actual tool/resource handler\n5. LoggingMiddleware (post-processing)\n6. PerformanceMiddleware (post-processing)\n7. AuthenticationMiddleware (post-processing)\n\n## Server Composition and Middleware\n\nWhen using [Server Composition](/servers/composition) with `mount` or `import_server`, middleware behavior follows these rules:\n\n1. **Parent server middleware** runs for all requests, including those routed to mounted servers\n2. **Mounted server middleware** only runs for requests handled by that specific server\n3. **Middleware order** is preserved within each server\n\nThis allows you to create layered middleware architectures where parent servers handle cross-cutting concerns like authentication, while child servers focus on domain-specific middleware.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n# Parent server with middleware\nparent = FastMCP(\"Parent\")\nparent.add_middleware(AuthenticationMiddleware(\"token\"))\n\n# Child server with its own middleware  \nchild = FastMCP(\"Child\")\nchild.add_middleware(LoggingMiddleware())\n\n@child.tool\ndef child_tool() -> str:\n    return \"from child\"\n\n# Mount the child server\nparent.mount(child, prefix=\"child\")\n```\n\nWhen a client calls \"child\\_tool\", the request will flow through the parent's authentication middleware first, then route to the child server where it will go through the child's logging middleware.\n\n## Built-in Middleware Examples\n\nFastMCP includes several middleware implementations that demonstrate best practices and provide immediately useful functionality. Let's explore how each type works by building simplified versions, then see how to use the full implementations.\n\n### Timing Middleware\n\nPerformance monitoring is essential for understanding your server's behavior and identifying bottlenecks. FastMCP includes timing middleware at `fastmcp.server.middleware.timing`.\n\nHere's an example of how it works:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nimport time\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass SimpleTimingMiddleware(Middleware):\n    async def on_request(self, context: MiddlewareContext, call_next):\n        start_time = time.perf_counter()\n        \n        try:\n            result = await call_next(context)\n            duration_ms = (time.perf_counter() - start_time) * 1000\n            print(f\"Request {context.method} completed in {duration_ms:.2f}ms\")\n            return result\n        except Exception as e:\n            duration_ms = (time.perf_counter() - start_time) * 1000\n            print(f\"Request {context.method} failed after {duration_ms:.2f}ms: {e}\")\n            raise\n```\n\nTo use the full version with proper logging and configuration:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.timing import (\n    TimingMiddleware, \n    DetailedTimingMiddleware\n)\n\n# Basic timing for all requests\nmcp.add_middleware(TimingMiddleware())\n\n# Detailed per-operation timing (tools, resources, prompts)\nmcp.add_middleware(DetailedTimingMiddleware())\n```\n\nThe built-in versions include custom logger support, proper formatting, and **DetailedTimingMiddleware** provides operation-specific hooks like `on_call_tool` and `on_read_resource` for granular timing.\n\n### Tool Injection Middleware\n\nTool injection middleware is a middleware that injects tools into the server during the request lifecycle:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.tool_injection import ToolInjectionMiddleware\n\ndef my_tool_fn(a: int, b: int) -> int:\n    return a + b\n\nmy_tool = Tool.from_function(fn=my_tool_fn, name=\"my_tool\")\n\nmcp.add_middleware(ToolInjectionMiddleware(tools=[my_tool]))\n```\n\n### Prompt Tool Middleware\n\nPrompt tool middleware is a compatibility middleware for clients that are unable to list or get prompts. It provides two tools: `list_prompts` and `get_prompt` which allow clients to list and get prompts respectively using only tool calls.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.tool_injection import PromptToolMiddleware\n\nmcp.add_middleware(PromptToolMiddleware())\n```\n\n### Resource Tool Middleware\n\nResource tool middleware is a compatibility middleware for clients that are unable to list or read resources. It provides two tools: `list_resources` and `read_resource` which allow clients to list and read resources respectively using only tool calls.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.tool_injection import ResourceToolMiddleware\n\nmcp.add_middleware(ResourceToolMiddleware())\n```\n\n### Caching Middleware\n\nCaching middleware is essential for improving performance and reducing server load. FastMCP provides caching middleware at `fastmcp.server.middleware.caching`.\n\nHere's how to use the full version:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.caching import ResponseCachingMiddleware\n\nmcp.add_middleware(ResponseCachingMiddleware())\n```\n\nOut of the box, it caches call/list tool, resources, and prompts to an in-memory cache with TTL-based expiration. Cache entries expire based on their TTL; there is no event-based cache invalidation. List calls are stored under global keys—when sharing a storage backend across multiple servers, consider namespacing collections to prevent conflicts. See [Storage Backends](/servers/storage-backends) for advanced configuration options.\n\nEach method can be configured individually, for example, caching list tools for 30 seconds, limiting caching to specific tools, and disabling caching for resource reads:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.caching import ResponseCachingMiddleware, CallToolSettings, ListToolsSettings, ReadResourceSettings\n\nmcp.add_middleware(ResponseCachingMiddleware(\n    list_tools_settings=ListToolsSettings(\n        ttl=30,\n    ),\n    call_tool_settings=CallToolSettings(\n        included_tools=[\"tool1\"],\n    ),\n    read_resource_settings=ReadResourceSettings(\n        enabled=False\n    )\n))\n```\n\n#### Storage Backends\n\nBy default, caching uses in-memory storage, which is fast but doesn't persist across restarts. For production or persistent caching across server restarts, configure a different storage backend. See [Storage Backends](/servers/storage-backends) for complete options including disk, Redis, DynamoDB, and custom implementations.\n\nDisk-based caching example:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.caching import ResponseCachingMiddleware\nfrom key_value.aio.stores.disk import DiskStore\n\nmcp.add_middleware(ResponseCachingMiddleware(\n    cache_storage=DiskStore(directory=\"cache\"),\n))\n```\n\nRedis for distributed deployments:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.caching import ResponseCachingMiddleware\nfrom key_value.aio.stores.redis import RedisStore\n\nmcp.add_middleware(ResponseCachingMiddleware(\n    cache_storage=RedisStore(host=\"redis.example.com\", port=6379),\n))\n```\n\n#### Cache Statistics\n\nThe caching middleware collects operation statistics (hits, misses, etc.) through the underlying storage layer. Access statistics from the middleware instance:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.caching import ResponseCachingMiddleware\n\nmiddleware = ResponseCachingMiddleware()\nmcp.add_middleware(middleware)\n\n# Later, retrieve statistics\nstats = middleware.statistics()\nprint(f\"Total cache operations: {stats}\")\n```\n\n### Logging Middleware\n\nRequest and response logging is crucial for debugging, monitoring, and understanding usage patterns in your MCP server. FastMCP provides comprehensive logging middleware at `fastmcp.server.middleware.logging`.\n\nHere's an example of how it works:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass SimpleLoggingMiddleware(Middleware):\n    async def on_message(self, context: MiddlewareContext, call_next):\n        print(f\"Processing {context.method} from {context.source}\")\n        \n        try:\n            result = await call_next(context)\n            print(f\"Completed {context.method}\")\n            return result\n        except Exception as e:\n            print(f\"Failed {context.method}: {e}\")\n            raise\n```\n\nTo use the full versions with advanced features:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.logging import (\n    LoggingMiddleware, \n    StructuredLoggingMiddleware\n)\n\n# Human-readable logging with payload support\nmcp.add_middleware(LoggingMiddleware(\n    include_payloads=True,\n    max_payload_length=1000\n))\n\n# JSON-structured logging for log aggregation tools\nmcp.add_middleware(StructuredLoggingMiddleware(include_payloads=True))\n```\n\nThe built-in versions include payload logging, structured JSON output, custom logger support, payload size limits, and operation-specific hooks for granular control.\n\n### Rate Limiting Middleware\n\nRate limiting is essential for protecting your server from abuse, ensuring fair resource usage, and maintaining performance under load. FastMCP includes sophisticated rate limiting middleware at `fastmcp.server.middleware.rate_limiting`.\n\nHere's an example of how it works:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nimport time\nfrom collections import defaultdict\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\nfrom mcp import McpError\nfrom mcp.types import ErrorData\n\nclass SimpleRateLimitMiddleware(Middleware):\n    def __init__(self, requests_per_minute: int = 60):\n        self.requests_per_minute = requests_per_minute\n        self.client_requests = defaultdict(list)\n    \n    async def on_request(self, context: MiddlewareContext, call_next):\n        current_time = time.time()\n        client_id = \"default\"  # In practice, extract from headers or context\n        \n        # Clean old requests and check limit\n        cutoff_time = current_time - 60\n        self.client_requests[client_id] = [\n            req_time for req_time in self.client_requests[client_id]\n            if req_time > cutoff_time\n        ]\n        \n        if len(self.client_requests[client_id]) >= self.requests_per_minute:\n            raise McpError(ErrorData(code=-32000, message=\"Rate limit exceeded\"))\n        \n        self.client_requests[client_id].append(current_time)\n        return await call_next(context)\n```\n\nTo use the full versions with advanced algorithms:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.rate_limiting import (\n    RateLimitingMiddleware, \n    SlidingWindowRateLimitingMiddleware\n)\n\n# Token bucket rate limiting (allows controlled bursts)\nmcp.add_middleware(RateLimitingMiddleware(\n    max_requests_per_second=10.0,\n    burst_capacity=20\n))\n\n# Sliding window rate limiting (precise time-based control)\nmcp.add_middleware(SlidingWindowRateLimitingMiddleware(\n    max_requests=100,\n    window_minutes=1\n))\n```\n\nThe built-in versions include token bucket algorithms, per-client identification, global rate limiting, and async-safe implementations with configurable client identification functions.\n\n### Error Handling Middleware\n\nConsistent error handling and recovery is critical for robust MCP servers. FastMCP provides comprehensive error handling middleware at `fastmcp.server.middleware.error_handling`.\n\nHere's an example of how it works:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nimport logging\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass SimpleErrorHandlingMiddleware(Middleware):\n    def __init__(self):\n        self.logger = logging.getLogger(\"errors\")\n        self.error_counts = {}\n    \n    async def on_message(self, context: MiddlewareContext, call_next):\n        try:\n            return await call_next(context)\n        except Exception as error:\n            # Log the error and track statistics\n            error_key = f\"{type(error).__name__}:{context.method}\"\n            self.error_counts[error_key] = self.error_counts.get(error_key, 0) + 1\n            \n            self.logger.error(f\"Error in {context.method}: {type(error).__name__}: {error}\")\n            raise\n```\n\nTo use the full versions with advanced features:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware.error_handling import (\n    ErrorHandlingMiddleware, \n    RetryMiddleware\n)\n\n# Comprehensive error logging and transformation\nmcp.add_middleware(ErrorHandlingMiddleware(\n    include_traceback=True,\n    transform_errors=True,\n    error_callback=my_error_callback\n))\n\n# Automatic retry with exponential backoff\nmcp.add_middleware(RetryMiddleware(\n    max_retries=3,\n    retry_exceptions=(ConnectionError, TimeoutError)\n))\n```\n\nThe built-in versions include error transformation, custom callbacks, configurable retry logic, and proper MCP error formatting.\n\n### Combining Middleware\n\nThese middleware work together seamlessly:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom fastmcp.server.middleware.timing import TimingMiddleware\nfrom fastmcp.server.middleware.logging import LoggingMiddleware\nfrom fastmcp.server.middleware.rate_limiting import RateLimitingMiddleware\nfrom fastmcp.server.middleware.error_handling import ErrorHandlingMiddleware\n\nmcp = FastMCP(\"Production Server\")\n\n# Add middleware in logical order\nmcp.add_middleware(ErrorHandlingMiddleware())  # Handle errors first\nmcp.add_middleware(RateLimitingMiddleware(max_requests_per_second=50))\nmcp.add_middleware(TimingMiddleware())  # Time actual execution\nmcp.add_middleware(LoggingMiddleware())  # Log everything\n\n@mcp.tool\ndef my_tool(data: str) -> str:\n    return f\"Processed: {data}\"\n```\n\nThis configuration provides comprehensive monitoring, protection, and observability for your MCP server.\n\n### Custom Middleware Example\n\nYou can also create custom middleware by extending the base class:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.server.middleware import Middleware, MiddlewareContext\n\nclass CustomHeaderMiddleware(Middleware):\n    async def on_request(self, context: MiddlewareContext, call_next):\n        # Add custom logic here\n        print(f\"Processing {context.method}\")\n        \n        result = await call_next(context)\n        \n        print(f\"Completed {context.method}\")\n        return result\n\nmcp.add_middleware(CustomHeaderMiddleware())\n```",
  "content_length": 35242
}