{
  "title": "Prompts",
  "source_url": "https://gofastmcp.com/servers/prompts",
  "content": "Create reusable, parameterized prompt templates for MCP clients.\n\nexport const VersionBadge = ({version}) => {\n  return <code className=\"version-badge-container\">\n            <p className=\"version-badge\">\n                <span className=\"version-badge-label\">New in version:</span>Â \n                <code className=\"version-badge-version\">{version}</code>\n            </p>\n        </code>;\n};\n\nPrompts are reusable message templates that help LLMs generate structured, purposeful responses. FastMCP simplifies defining these templates, primarily using the `@mcp.prompt` decorator.\n\n## What Are Prompts?\n\nPrompts provide parameterized message templates for LLMs. When a client requests a prompt:\n\n1. FastMCP finds the corresponding prompt definition.\n2. If it has parameters, they are validated against your function signature.\n3. Your function executes with the validated inputs.\n4. The generated message(s) are returned to the LLM to guide its response.\n\nThis allows you to define consistent, reusable templates that LLMs can use across different clients and contexts.\n\n## Prompts\n\n### The `@prompt` Decorator\n\nThe most common way to define a prompt is by decorating a Python function. The decorator uses the function name as the prompt's identifier.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom fastmcp.prompts.prompt import Message, PromptMessage, TextContent\n\nmcp = FastMCP(name=\"PromptServer\")\n\n# Basic prompt returning a string (converted to user message automatically)\n@mcp.prompt\ndef ask_about_topic(topic: str) -> str:\n    \"\"\"Generates a user message asking for an explanation of a topic.\"\"\"\n    return f\"Can you please explain the concept of '{topic}'?\"\n\n# Prompt returning a specific message type\n@mcp.prompt\ndef generate_code_request(language: str, task_description: str) -> PromptMessage:\n    \"\"\"Generates a user message requesting code generation.\"\"\"\n    content = f\"Write a {language} function that performs the following task: {task_description}\"\n    return PromptMessage(role=\"user\", content=TextContent(type=\"text\", text=content))\n```\n\n**Key Concepts:**\n\n* **Name:** By default, the prompt name is taken from the function name.\n* **Parameters:** The function parameters define the inputs needed to generate the prompt.\n* **Inferred Metadata:** By default:\n  * Prompt Name: Taken from the function name (`ask_about_topic`).\n  * Prompt Description: Taken from the function's docstring.\n\n<Tip>\n  Functions with `*args` or `**kwargs` are not supported as prompts. This restriction exists because FastMCP needs to generate a complete parameter schema for the MCP protocol, which isn't possible with variable argument lists.\n</Tip>\n\n#### Decorator Arguments\n\nWhile FastMCP infers the name and description from your function, you can override these and add additional metadata using arguments to the `@mcp.prompt` decorator:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n@mcp.prompt(\n    name=\"analyze_data_request\",          # Custom prompt name\n    description=\"Creates a request to analyze data with specific parameters\",  # Custom description\n    tags={\"analysis\", \"data\"},            # Optional categorization tags\n    meta={\"version\": \"1.1\", \"author\": \"data-team\"}  # Custom metadata\n)\ndef data_analysis_prompt(\n    data_uri: str = Field(description=\"The URI of the resource containing the data.\"),\n    analysis_type: str = Field(default=\"summary\", description=\"Type of analysis.\")\n) -> str:\n    \"\"\"This docstring is ignored when description is provided.\"\"\"\n    return f\"Please perform a '{analysis_type}' analysis on the data found at {data_uri}.\"\n```\n\n<Card icon=\"code\" title=\"@prompt Decorator Arguments\">\n  <ParamField body=\"name\" type=\"str | None\">\n    Sets the explicit prompt name exposed via MCP. If not provided, uses the function name\n  </ParamField>\n\n  <ParamField body=\"title\" type=\"str | None\">\n    A human-readable title for the prompt\n  </ParamField>\n\n  <ParamField body=\"description\" type=\"str | None\">\n    Provides the description exposed via MCP. If set, the function's docstring is ignored for this purpose\n  </ParamField>\n\n  <ParamField body=\"tags\" type=\"set[str] | None\">\n    A set of strings used to categorize the prompt. These can be used by the server and, in some cases, by clients to filter or group available prompts.\n  </ParamField>\n\n  <ParamField body=\"enabled\" type=\"bool\" default=\"True\">\n    A boolean to enable or disable the prompt. See [Disabling Prompts](#disabling-prompts) for more information\n  </ParamField>\n\n  <ParamField body=\"icons\" type=\"list[Icon] | None\">\n    <VersionBadge version=\"2.14.0\" />\n\n    Optional list of icon representations for this prompt. See [Icons](/servers/icons) for detailed examples\n  </ParamField>\n\n  <ParamField body=\"meta\" type=\"dict[str, Any] | None\">\n    <VersionBadge version=\"2.11.0\" />\n\n    Optional meta information about the prompt. This data is passed through to the MCP client as the `_meta` field of the client-side prompt object and can be used for custom metadata, versioning, or other application-specific purposes.\n  </ParamField>\n</Card>\n\n### Argument Types\n\n<VersionBadge version=\"2.9.0\" />\n\nThe MCP specification requires that all prompt arguments be passed as strings, but FastMCP allows you to use typed annotations for better developer experience. When you use complex types like `list[int]` or `dict[str, str]`, FastMCP:\n\n1. **Automatically converts** string arguments from MCP clients to the expected types\n2. **Generates helpful descriptions** showing the exact JSON string format needed\n3. **Preserves direct usage** - you can still call prompts with properly typed arguments\n\nSince the MCP specification only allows string arguments, clients need to know what string format to use for complex types. FastMCP solves this by automatically enhancing the argument descriptions with JSON schema information, making it clear to both humans and LLMs how to format their arguments.\n\n<CodeGroup>\n  ```python Python Code theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n  @mcp.prompt\n  def analyze_data(\n      numbers: list[int],\n      metadata: dict[str, str], \n      threshold: float\n  ) -> str:\n      \"\"\"Analyze numerical data.\"\"\"\n      avg = sum(numbers) / len(numbers)\n      return f\"Average: {avg}, above threshold: {avg > threshold}\"\n  ```\n\n  ```json Resulting MCP Prompt theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n  {\n    \"name\": \"analyze_data\",\n    \"description\": \"Analyze numerical data.\",\n    \"arguments\": [\n      {\n        \"name\": \"numbers\",\n        \"description\": \"Provide as a JSON string matching the following schema: {\\\"items\\\":{\\\"type\\\":\\\"integer\\\"},\\\"type\\\":\\\"array\\\"}\",\n        \"required\": true\n      },\n      {\n        \"name\": \"metadata\", \n        \"description\": \"Provide as a JSON string matching the following schema: {\\\"additionalProperties\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"object\\\"}\",\n        \"required\": true\n      },\n      {\n        \"name\": \"threshold\",\n        \"description\": \"Provide as a JSON string matching the following schema: {\\\"type\\\":\\\"number\\\"}\",\n        \"required\": true\n      }\n    ]\n  }\n  ```\n</CodeGroup>\n\n**MCP clients will call this prompt with string arguments:**\n\n```json  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n{\n  \"numbers\": \"[1, 2, 3, 4, 5]\",\n  \"metadata\": \"{\\\"source\\\": \\\"api\\\", \\\"version\\\": \\\"1.0\\\"}\",\n  \"threshold\": \"2.5\"\n}\n```\n\n**But you can still call it directly with proper types:**\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n# This also works for direct calls\nresult = await prompt.render({\n    \"numbers\": [1, 2, 3, 4, 5],\n    \"metadata\": {\"source\": \"api\", \"version\": \"1.0\"}, \n    \"threshold\": 2.5\n})\n```\n\n<Warning>\n  Keep your type annotations simple when using this feature. Complex nested types or custom classes may not convert reliably from JSON strings. The automatically generated schema descriptions are the only guidance users receive about the expected format.\n\n  Good choices: `list[int]`, `dict[str, str]`, `float`, `bool`\n  Avoid: Complex Pydantic models, deeply nested structures, custom classes\n</Warning>\n\n### Return Values\n\nFastMCP intelligently handles different return types from your prompt function:\n\n* **`str`**: Automatically converted to a single `PromptMessage`.\n* **`PromptMessage`**: Used directly as provided. (Note a more user-friendly `Message` constructor is available that can accept raw strings instead of `TextContent` objects.)\n* **`list[PromptMessage | str]`**: Used as a sequence of messages (a conversation).\n* **`Any`**: If the return type is not one of the above, the return value is attempted to be converted to a string and used as a `PromptMessage`.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp.prompts.prompt import Message, PromptResult\n\n@mcp.prompt\ndef roleplay_scenario(character: str, situation: str) -> PromptResult:\n    \"\"\"Sets up a roleplaying scenario with initial messages.\"\"\"\n    return [\n        Message(f\"Let's roleplay. You are {character}. The situation is: {situation}\"),\n        Message(\"Okay, I understand. I am ready. What happens next?\", role=\"assistant\")\n    ]\n```\n\n### Required vs. Optional Parameters\n\nParameters in your function signature are considered **required** unless they have a default value.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n@mcp.prompt\ndef data_analysis_prompt(\n    data_uri: str,                        # Required - no default value\n    analysis_type: str = \"summary\",       # Optional - has default value\n    include_charts: bool = False          # Optional - has default value\n) -> str:\n    \"\"\"Creates a request to analyze data with specific parameters.\"\"\"\n    prompt = f\"Please perform a '{analysis_type}' analysis on the data found at {data_uri}.\"\n    if include_charts:\n        prompt += \" Include relevant charts and visualizations.\"\n    return prompt\n```\n\nIn this example, the client *must* provide `data_uri`. If `analysis_type` or `include_charts` are omitted, their default values will be used.\n\n### Disabling Prompts\n\n<VersionBadge version=\"2.8.0\" />\n\nYou can control the visibility and availability of prompts by enabling or disabling them. Disabled prompts will not appear in the list of available prompts, and attempting to call a disabled prompt will result in an \"Unknown prompt\" error.\n\nBy default, all prompts are enabled. You can disable a prompt upon creation using the `enabled` parameter in the decorator:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n@mcp.prompt(enabled=False)\ndef experimental_prompt():\n    \"\"\"This prompt is not ready for use.\"\"\"\n    return \"This is an experimental prompt.\"\n```\n\nYou can also toggle a prompt's state programmatically after it has been created:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n@mcp.prompt\ndef seasonal_prompt(): return \"Happy Holidays!\"\n\n# Disable and re-enable the prompt\nseasonal_prompt.disable()\nseasonal_prompt.enable()\n```\n\n### Async Prompts\n\nFastMCP seamlessly supports both standard (`def`) and asynchronous (`async def`) functions as prompts.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n# Synchronous prompt\n@mcp.prompt\ndef simple_question(question: str) -> str:\n    \"\"\"Generates a simple question to ask the LLM.\"\"\"\n    return f\"Question: {question}\"\n\n# Asynchronous prompt\n@mcp.prompt\nasync def data_based_prompt(data_id: str) -> str:\n    \"\"\"Generates a prompt based on data that needs to be fetched.\"\"\"\n    # In a real scenario, you might fetch data from a database or API\n    async with aiohttp.ClientSession() as session:\n        async with session.get(f\"https://api.example.com/data/{data_id}\") as response:\n            data = await response.json()\n            return f\"Analyze this data: {data['content']}\"\n```\n\nUse `async def` when your prompt function performs I/O operations like network requests, database queries, file I/O, or external service calls.\n\n### Accessing MCP Context\n\n<VersionBadge version=\"2.2.5\" />\n\nPrompts can access additional MCP information and features through the `Context` object. To access it, add a parameter to your prompt function with a type annotation of `Context`:\n\n```python {6} theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP, Context\n\nmcp = FastMCP(name=\"PromptServer\")\n\n@mcp.prompt\nasync def generate_report_request(report_type: str, ctx: Context) -> str:\n    \"\"\"Generates a request for a report.\"\"\"\n    return f\"Please create a {report_type} report. Request ID: {ctx.request_id}\"\n```\n\nFor full documentation on the Context object and all its capabilities, see the [Context documentation](/servers/context).\n\n### Notifications\n\n<VersionBadge version=\"2.9.1\" />\n\nFastMCP automatically sends `notifications/prompts/list_changed` notifications to connected clients when prompts are added, enabled, or disabled. This allows clients to stay up-to-date with the current prompt set without manually polling for changes.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n@mcp.prompt\ndef example_prompt() -> str:\n    return \"Hello!\"\n\n# These operations trigger notifications:\nmcp.add_prompt(example_prompt)  # Sends prompts/list_changed notification\nexample_prompt.disable()        # Sends prompts/list_changed notification  \nexample_prompt.enable()         # Sends prompts/list_changed notification\n```\n\nNotifications are only sent when these operations occur within an active MCP request context (e.g., when called from within a tool or other MCP operation). Operations performed during server initialization do not trigger notifications.\n\nClients can handle these notifications using a [message handler](/clients/messages) to automatically refresh their prompt lists or update their interfaces.\n\n## Server Behavior\n\n### Duplicate Prompts\n\n<VersionBadge version=\"2.1.0\" />\n\nYou can configure how the FastMCP server handles attempts to register multiple prompts with the same name. Use the `on_duplicate_prompts` setting during `FastMCP` initialization.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\n    name=\"PromptServer\",\n    on_duplicate_prompts=\"error\"  # Raise an error if a prompt name is duplicated\n)\n\n@mcp.prompt\ndef greeting(): return \"Hello, how can I help you today?\"\n\n# This registration attempt will raise a ValueError because\n# \"greeting\" is already registered and the behavior is \"error\".\n# @mcp.prompt\n# def greeting(): return \"Hi there! What can I do for you?\"\n```\n\nThe duplicate behavior options are:\n\n* `\"warn\"` (default): Logs a warning, and the new prompt replaces the old one.\n* `\"error\"`: Raises a `ValueError`, preventing the duplicate registration.\n* `\"replace\"`: Silently replaces the existing prompt with the new one.\n* `\"ignore\"`: Keeps the original prompt and ignores the new registration attempt.",
  "content_length": 14937
}