{
  "title": "HTTP Deployment",
  "source_url": "https://gofastmcp.com/deployment/http",
  "content": "Deploy your FastMCP server over HTTP for remote access\n\nexport const VersionBadge = ({version}) => {\n  return <code className=\"version-badge-container\">\n            <p className=\"version-badge\">\n                <span className=\"version-badge-label\">New in version:</span> \n                <code className=\"version-badge-version\">{version}</code>\n            </p>\n        </code>;\n};\n\n<Tip>\n  STDIO transport is perfect for local development and desktop applications. But to unlock the full potential of MCP—centralized services, multi-client access, and network availability—you need remote HTTP deployment.\n</Tip>\n\nThis guide walks you through deploying your FastMCP server as a remote MCP service that's accessible via a URL. Once deployed, your MCP server will be available over the network, allowing multiple clients to connect simultaneously and enabling integration with cloud-based LLM applications. This guide focuses specifically on remote MCP deployment, not local STDIO servers.\n\n## Choosing Your Approach\n\nFastMCP provides two ways to deploy your server as an HTTP service. Understanding the trade-offs helps you choose the right approach for your needs.\n\nThe **direct HTTP server** approach is simpler and perfect for getting started quickly. You modify your server's `run()` method to use HTTP transport, and FastMCP handles all the web server configuration. This approach works well for standalone deployments where you want your MCP server to be the only service running on a port.\n\nThe **ASGI application** approach gives you more control and flexibility. Instead of running the server directly, you create an ASGI application that can be served by Uvicorn. This approach is better when you need advanced server features like multiple workers, custom middleware, or when you're integrating with existing web applications.\n\n### Direct HTTP Server\n\nThe simplest way to get your MCP server online is to use the built-in `run()` method with HTTP transport. This approach handles all the server configuration for you and is ideal when you want a standalone MCP server without additional complexity.\n\n```python server.py theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"My Server\")\n\n@mcp.tool\ndef process_data(input: str) -> str:\n    \"\"\"Process data on the server\"\"\"\n    return f\"Processed: {input}\"\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"http\", host=\"0.0.0.0\", port=8000)\n```\n\nRun your server with a simple Python command:\n\n```bash  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\npython server.py\n```\n\nYour server is now accessible at `http://localhost:8000/mcp` (or use your server's actual IP address for remote access).\n\nThis approach is ideal when you want to get online quickly with minimal configuration. It's perfect for internal tools, development environments, or simple deployments where you don't need advanced server features. The built-in server handles all the HTTP details, letting you focus on your MCP implementation.\n\n### ASGI Application\n\nFor production deployments, you'll often want more control over how your server runs. FastMCP can create a standard ASGI application that works with any ASGI server like Uvicorn, Gunicorn, or Hypercorn. This approach is particularly useful when you need to configure advanced server options, run multiple workers, or integrate with existing infrastructure.\n\n```python app.py theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"My Server\")\n\n@mcp.tool\ndef process_data(input: str) -> str:\n    \"\"\"Process data on the server\"\"\"\n    return f\"Processed: {input}\"\n\n# Create ASGI application\napp = mcp.http_app()\n```\n\nRun with any ASGI server - here's an example with Uvicorn:\n\n```bash  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nuvicorn app:app --host 0.0.0.0 --port 8000\n```\n\nYour server is accessible at the same URL: `http://localhost:8000/mcp` (or use your server's actual IP address for remote access).\n\nThe ASGI approach shines in production environments where you need reliability and performance. You can run multiple worker processes to handle concurrent requests, add custom middleware for logging or monitoring, integrate with existing deployment pipelines, or mount your MCP server as part of a larger application.\n\n## Configuring Your Server\n\n### Custom Path\n\nBy default, your MCP server is accessible at `/mcp/` on your domain. You can customize this path to fit your URL structure or avoid conflicts with existing endpoints. This is particularly useful when integrating MCP into an existing application or following specific API conventions.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n# Option 1: With mcp.run()\nmcp.run(transport=\"http\", host=\"0.0.0.0\", port=8000, path=\"/api/mcp/\")\n\n# Option 2: With ASGI app\napp = mcp.http_app(path=\"/api/mcp/\")\n```\n\nNow your server is accessible at `http://localhost:8000/api/mcp/`.\n\n### Authentication\n\n<Warning>\n  Authentication is **highly recommended** for remote MCP servers. Some LLM clients require authentication for remote servers and will refuse to connect without it.\n</Warning>\n\nFastMCP supports multiple authentication methods to secure your remote server. See the [Authentication Overview](/servers/auth/authentication) for complete configuration options including Bearer tokens, JWT, and OAuth.\n\nIf you're mounting an authenticated server under a path prefix, see [Mounting Authenticated Servers](#mounting-authenticated-servers) below for important routing considerations.\n\n### Health Checks\n\nHealth check endpoints are essential for monitoring your deployed server and ensuring it's responding correctly. FastMCP allows you to add custom routes alongside your MCP endpoints, making it easy to implement health checks that work with both deployment approaches.\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom starlette.responses import JSONResponse\n\n@mcp.custom_route(\"/health\", methods=[\"GET\"])\nasync def health_check(request):\n    return JSONResponse({\"status\": \"healthy\", \"service\": \"mcp-server\"})\n```\n\nThis health endpoint will be available at `http://localhost:8000/health` and can be used by load balancers, monitoring systems, or deployment platforms to verify your server is running.\n\n### Custom Middleware\n\n<VersionBadge version=\"2.3.2\" />\n\nAdd custom Starlette middleware to your FastMCP ASGI apps:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.cors import CORSMiddleware\n\n# Create your FastMCP server\nmcp = FastMCP(\"MyServer\")\n\n# Define middleware\nmiddleware = [\n    Middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n]\n\n# Create ASGI app with middleware\nhttp_app = mcp.http_app(middleware=middleware)\n```\n\n### CORS for Browser-Based Clients\n\n<Tip>\n  Most MCP clients, including those that you access through a browser like ChatGPT or Claude, don't need CORS configuration. Only enable CORS if you're working with an MCP client that connects directly from a browser, such as debugging tools or inspectors.\n</Tip>\n\nCORS (Cross-Origin Resource Sharing) is needed when JavaScript running in a web browser connects directly to your MCP server. This is different from using an LLM through a browser—in that case, the browser connects to the LLM service, and the LLM service connects to your MCP server (no CORS needed).\n\nBrowser-based MCP clients that need CORS include:\n\n* **MCP Inspector** - Browser-based debugging tool for testing MCP servers\n* **Custom browser-based MCP clients** - If you're building a web app that directly connects to MCP servers\n\nFor these scenarios, add CORS middleware with the specific headers required for MCP protocol:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.cors import CORSMiddleware\n\nmcp = FastMCP(\"MyServer\")\n\n# Configure CORS for browser-based clients\nmiddleware = [\n    Middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],  # Allow all origins; use specific origins for security\n        allow_methods=[\"GET\", \"POST\", \"DELETE\", \"OPTIONS\"],\n        allow_headers=[\n            \"mcp-protocol-version\",\n            \"mcp-session-id\",\n            \"Authorization\",\n            \"Content-Type\",\n        ],\n        expose_headers=[\"mcp-session-id\"],\n    )\n]\n\napp = mcp.http_app(middleware=middleware)\n```\n\n**Key configuration details:**\n\n* **`allow_origins`**: Specify exact origins (e.g., `[\"http://localhost:3000\"]`) rather than `[\"*\"]` for production deployments\n* **`allow_headers`**: Must include `mcp-protocol-version`, `mcp-session-id`, and `Authorization` (for authenticated servers)\n* **`expose_headers`**: Must include `mcp-session-id` so JavaScript can read the session ID from responses and send it in subsequent requests\n\nWithout `expose_headers=[\"mcp-session-id\"]`, browsers will receive the session ID but JavaScript won't be able to access it, causing session management to fail.\n\n<Warning>\n  **Production Security**: Never use `allow_origins=[\"*\"]` in production. Specify the exact origins of your browser-based clients. Using wildcards exposes your server to unauthorized access from any website.\n</Warning>\n\n## Integration with Web Frameworks\n\nIf you already have a web application running, you can add MCP capabilities by mounting a FastMCP server as a sub-application. This allows you to expose MCP tools alongside your existing API endpoints, sharing the same domain and infrastructure. The MCP server becomes just another route in your application, making it easy to manage and deploy.\n\n### Mounting in Starlette\n\nMount your FastMCP server in a Starlette application:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\n\n# Create your FastMCP server\nmcp = FastMCP(\"MyServer\")\n\n@mcp.tool\ndef analyze(data: str) -> dict:\n    return {\"result\": f\"Analyzed: {data}\"}\n\n# Create the ASGI app\nmcp_app = mcp.http_app(path='/mcp')\n\n# Create a Starlette app and mount the MCP server\napp = Starlette(\n    routes=[\n        Mount(\"/mcp-server\", app=mcp_app),\n        # Add other routes as needed\n    ],\n    lifespan=mcp_app.lifespan,\n)\n```\n\nThe MCP endpoint will be available at `/mcp-server/mcp/` of the resulting Starlette app.\n\n<Warning>\n  For Streamable HTTP transport, you **must** pass the lifespan context from the FastMCP app to the resulting Starlette app, as nested lifespans are not recognized. Otherwise, the FastMCP server's session manager will not be properly initialized.\n</Warning>\n\n#### Nested Mounts\n\nYou can create complex routing structures by nesting mounts:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\n\n# Create your FastMCP server\nmcp = FastMCP(\"MyServer\")\n\n# Create the ASGI app\nmcp_app = mcp.http_app(path='/mcp')\n\n# Create nested application structure\ninner_app = Starlette(routes=[Mount(\"/inner\", app=mcp_app)])\napp = Starlette(\n    routes=[Mount(\"/outer\", app=inner_app)],\n    lifespan=mcp_app.lifespan,\n)\n```\n\nIn this setup, the MCP server is accessible at the `/outer/inner/mcp/` path.\n\n### FastAPI Integration\n\nFor FastAPI-specific integration patterns including both mounting MCP servers into FastAPI apps and generating MCP servers from FastAPI apps, see the [FastAPI Integration guide](/integrations/fastapi).\n\nHere's a quick example showing how to add MCP to an existing FastAPI application:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastapi import FastAPI\nfrom fastmcp import FastMCP\n\n# Your existing API\napi = FastAPI()\n\n@api.get(\"/api/status\")\ndef status():\n    return {\"status\": \"ok\"}\n\n# Create your MCP server\nmcp = FastMCP(\"API Tools\")\n\n@mcp.tool\ndef query_database(query: str) -> dict:\n    \"\"\"Run a database query\"\"\"\n    return {\"result\": \"data\"}\n\n# Mount MCP at /mcp\napi.mount(\"/mcp\", mcp.http_app())\n\n# Run with: uvicorn app:api --host 0.0.0.0 --port 8000\n```\n\nYour existing API remains at `http://localhost:8000/api` while MCP is available at `http://localhost:8000/mcp`.\n\n## Mounting Authenticated Servers\n\n<VersionBadge version=\"2.13.0\" />\n\n<Tip>\n  This section only applies if you're **mounting an OAuth-protected FastMCP server under a path prefix** (like `/api`) inside another application using `Mount()`.\n\n  If you're deploying your FastMCP server at root level without any `Mount()` prefix, the well-known routes are automatically included in `mcp.http_app()` and you don't need to do anything special.\n</Tip>\n\nOAuth specifications (RFC 8414 and RFC 9728) require discovery metadata to be accessible at well-known paths under the root level of your domain. When you mount an OAuth-protected FastMCP server under a path prefix like `/api`, this creates a routing challenge: your operational OAuth endpoints move under the prefix, but discovery endpoints must remain at the root.\n\n<Warning>\n  **Common Mistakes to Avoid:**\n\n  1. **Forgetting to mount `.well-known` routes at root** - FastMCP cannot do this automatically when your server is mounted under a path prefix. You must explicitly mount well-known routes at the root level.\n\n  2. **Including mount prefix in both base\\_url AND mcp\\_path** - The mount prefix (like `/api`) should only be in `base_url`, not in `mcp_path`. Otherwise you'll get double paths.\n\n     ✅ **Correct:**\n\n     ```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n     base_url = \"http://localhost:8000/api\"\n     mcp_path = \"/mcp\"\n     # Result: /api/mcp\n     ```\n\n     ❌ **Wrong:**\n\n     ```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n     base_url = \"http://localhost:8000/api\"\n     mcp_path = \"/api/mcp\"\n     # Result: /api/api/mcp (double prefix!)\n     ```\n\n  3. **Not setting issuer\\_url when mounting** - Without `issuer_url` set to root level, OAuth discovery will attempt path-scoped discovery first (which will 404), adding unnecessary error logs.\n\n  Follow the configuration instructions below to set up mounting correctly.\n</Warning>\n\n<Warning>\n  **CORS Middleware Conflicts:**\n\n  If you're integrating FastMCP into an existing application with its own CORS middleware, be aware that layering CORS middleware can cause conflicts (such as 404 errors on `.well-known` routes or OPTIONS requests).\n\n  FastMCP and the MCP SDK already handle CORS for OAuth routes. If you need CORS on your own application routes, consider using the sub-app pattern: mount FastMCP and your routes as separate apps, each with their own middleware, rather than adding application-wide CORS middleware.\n</Warning>\n\n### Route Types\n\nOAuth-protected MCP servers expose two categories of routes:\n\n**Operational routes** handle the OAuth flow and MCP protocol:\n\n* `/authorize` - OAuth authorization endpoint\n* `/token` - Token exchange endpoint\n* `/auth/callback` - OAuth callback handler\n* `/mcp` - MCP protocol endpoint\n\n**Discovery routes** provide metadata for OAuth clients:\n\n* `/.well-known/oauth-authorization-server` - Authorization server metadata\n* `/.well-known/oauth-protected-resource/*` - Protected resource metadata\n\nWhen you mount your MCP app under a prefix, operational routes move with it, but discovery routes must stay at root level for RFC compliance.\n\n### Configuration Parameters\n\nThree parameters control where routes are located and how they combine:\n\n**`base_url`** tells clients where to find operational endpoints. This includes any Starlette `Mount()` path prefix (e.g., `/api`):\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nbase_url=\"http://localhost:8000/api\"  # Includes mount prefix\n```\n\n**`mcp_path`** is the internal FastMCP endpoint path, which gets appended to `base_url`:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nmcp_path=\"/mcp\"  # Internal MCP path, NOT the mount prefix\n```\n\n**`issuer_url`** tells clients where to find discovery metadata. This should point to the root level of your server where well-known routes are mounted:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nissuer_url=\"http://localhost:8000\"  # Root level, no prefix\n```\n\n**Key Invariant:** `base_url + mcp_path = actual externally-accessible MCP URL`\n\nExample:\n\n* `base_url`: `http://localhost:8000/api` (mount prefix `/api`)\n* `mcp_path`: `/mcp` (internal path)\n* Result: `http://localhost:8000/api/mcp` (final MCP endpoint)\n\nNote that the mount prefix (`/api` from `Mount(\"/api\", ...)`) goes in `base_url`, while `mcp_path` is just the internal MCP route. Don't include the mount prefix in both places or you'll get `/api/api/mcp`.\n\n### Mounting Strategy\n\nWhen mounting an OAuth-protected server under a path prefix, declare your URLs upfront to make the relationships clear:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom fastmcp.server.auth.providers.github import GitHubProvider\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\n\n# Define the routing structure\nROOT_URL = \"http://localhost:8000\"\nMOUNT_PREFIX = \"/api\"\nMCP_PATH = \"/mcp\"\n```\n\nCreate the auth provider with both `issuer_url` and `base_url`:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nauth = GitHubProvider(\n    client_id=\"your-client-id\",\n    client_secret=\"your-client-secret\",\n    issuer_url=ROOT_URL,  # Discovery metadata at root\n    base_url=f\"{ROOT_URL}{MOUNT_PREFIX}\",  # Operational endpoints under prefix\n)\n```\n\nCreate the MCP app, which generates operational routes at the specified path:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nmcp = FastMCP(\"Protected Server\", auth=auth)\nmcp_app = mcp.http_app(path=MCP_PATH)\n```\n\nRetrieve the discovery routes from the auth provider. The `mcp_path` argument should match the path used when creating the MCP app:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nwell_known_routes = auth.get_well_known_routes(mcp_path=MCP_PATH)\n```\n\nFinally, mount everything in the Starlette app with discovery routes at root and the MCP app under the prefix:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\napp = Starlette(\n    routes=[\n        *well_known_routes,  # Discovery routes at root level\n        Mount(MOUNT_PREFIX, app=mcp_app),  # Operational routes under prefix\n    ],\n    lifespan=mcp_app.lifespan,\n)\n```\n\nThis configuration produces the following URL structure:\n\n* MCP endpoint: `http://localhost:8000/api/mcp`\n* OAuth authorization: `http://localhost:8000/api/authorize`\n* OAuth callback: `http://localhost:8000/api/auth/callback`\n* Authorization server metadata: `http://localhost:8000/.well-known/oauth-authorization-server`\n* Protected resource metadata: `http://localhost:8000/.well-known/oauth-protected-resource/api/mcp`\n\n### Complete Example\n\nHere's a complete working example showing all the pieces together:\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom fastmcp import FastMCP\nfrom fastmcp.server.auth.providers.github import GitHubProvider\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\nimport uvicorn\n\n# Define routing structure\nROOT_URL = \"http://localhost:8000\"\nMOUNT_PREFIX = \"/api\"\nMCP_PATH = \"/mcp\"\n\n# Create OAuth provider\nauth = GitHubProvider(\n    client_id=\"your-client-id\",\n    client_secret=\"your-client-secret\",\n    issuer_url=ROOT_URL,\n    base_url=f\"{ROOT_URL}{MOUNT_PREFIX}\",\n)\n\n# Create MCP server\nmcp = FastMCP(\"Protected Server\", auth=auth)\n\n@mcp.tool\ndef analyze(data: str) -> dict:\n    return {\"result\": f\"Analyzed: {data}\"}\n\n# Create MCP app\nmcp_app = mcp.http_app(path=MCP_PATH)\n\n# Get discovery routes for root level\nwell_known_routes = auth.get_well_known_routes(mcp_path=MCP_PATH)\n\n# Assemble the application\napp = Starlette(\n    routes=[\n        *well_known_routes,\n        Mount(MOUNT_PREFIX, app=mcp_app),\n    ],\n    lifespan=mcp_app.lifespan,\n)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\nFor more details on OAuth authentication, see the [Authentication guide](/servers/auth).\n\n## Production Deployment\n\n### Running with Uvicorn\n\nWhen deploying to production, you'll want to optimize your server for performance and reliability. Uvicorn provides several options to improve your server's capabilities:\n\n```bash  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\n# Run with basic configuration\nuvicorn app:app --host 0.0.0.0 --port 8000\n\n# Ensure stateless HTTP mode is enabled (stateless_http=True)\n# Run with multiple workers for production\nuvicorn app:app --host 0.0.0.0 --port 8000 --workers 4\n```\n\n### Environment Variables\n\nProduction deployments should never hardcode sensitive information like API keys or authentication tokens. Instead, use environment variables to configure your server at runtime. This keeps your code secure and makes it easy to deploy the same code to different environments with different configurations.\n\nHere's an example using bearer token authentication (though OAuth is recommended for production):\n\n```python  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nimport os\nfrom fastmcp import FastMCP\nfrom fastmcp.server.auth import BearerTokenAuth\n\n# Read configuration from environment\nauth_token = os.environ.get(\"MCP_AUTH_TOKEN\")\nif auth_token:\n    auth = BearerTokenAuth(token=auth_token)\n    mcp = FastMCP(\"Production Server\", auth=auth)\nelse:\n    mcp = FastMCP(\"Production Server\")\n\napp = mcp.http_app()\n```\n\nDeploy with your secrets safely stored in environment variables:\n\n```bash  theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nMCP_AUTH_TOKEN=secret uvicorn app:app --host 0.0.0.0 --port 8000\n```\n\n### OAuth Token Security\n\n<VersionBadge version=\"2.13.0\" />\n\nIf you're using the [OAuth Proxy](/servers/auth/oauth-proxy), FastMCP issues its own JWT tokens to clients instead of forwarding upstream provider tokens. This maintains proper OAuth 2.0 token boundaries.\n\n**Default Behavior (Development Only):**\n\nBy default, FastMCP automatically manages cryptographic keys:\n\n* **Mac/Windows**: Keys are generated and stored in your system keyring, surviving server restarts. Suitable **only** for development and local testing.\n* **Linux**: Keys are ephemeral (random salt at startup), so tokens are invalidated on restart.\n\nThis automatic approach is convenient for development but not suitable for production deployments.\n\n**For Production:**\n\nProduction requires explicit key management to ensure tokens survive restarts and can be shared across multiple server instances. This requires the following two things working together:\n\n1. **Explicit JWT signing key** for signing tokens issued to clients\n2. **Persistent network-accessible storage** for upstream tokens (wrapped in `FernetEncryptionWrapper` to encrypt sensitive data at rest)\n\n**Configuration:**\n\nAdd two parameters to your auth provider:\n\n```python {8-12} theme={\"theme\":{\"light\":\"snazzy-light\",\"dark\":\"dark-plus\"}}\nfrom key_value.aio.stores.redis import RedisStore\nfrom key_value.aio.wrappers.encryption import FernetEncryptionWrapper\nfrom cryptography.fernet import Fernet\n\nauth = GitHubProvider(\n    client_id=os.environ[\"GITHUB_CLIENT_ID\"],\n    client_secret=os.environ[\"GITHUB_CLIENT_SECRET\"],\n    jwt_signing_key=os.environ[\"JWT_SIGNING_KEY\"],\n    client_storage=FernetEncryptionWrapper(\n        key_value=RedisStore(host=\"redis.example.com\", port=6379),\n        fernet=Fernet(os.environ[\"STORAGE_ENCRYPTION_KEY\"])\n    ),\n    base_url=\"https://your-server.com\"  # use HTTPS\n)\n```\n\nBoth parameters are required for production. Without an explicit signing key, keys are signed using a key derived from the client\\_secret, which will cause invalidation upon rotation of the client secret. Without persistent storage, tokens are local to the server and won't be trusted across hosts. **Wrap your storage backend in `FernetEncryptionWrapper` to encrypt sensitive OAuth tokens at rest** - without encryption, tokens are stored in plaintext.\n\nFor more details on the token architecture and key management, see [OAuth Proxy Key and Storage Management](/servers/auth/oauth-proxy#key-and-storage-management).\n\n## Testing Your Deployment\n\nOnce your server is deployed, you'll need to verify it's accessible and functioning correctly. For comprehensive testing strategies including connectivity tests, client testing, and authentication testing, see the [Testing Your Server](/development/tests) guide.\n\n## Hosting Your Server\n\nThis guide has shown you how to create an HTTP-accessible MCP server, but you'll still need a hosting provider to make it available on the internet. Your FastMCP server can run anywhere that supports Python web applications:\n\n* **Cloud VMs** (AWS EC2, Google Compute Engine, Azure VMs)\n* **Container platforms** (Cloud Run, Container Instances, ECS)\n* **Platform-as-a-Service** (Railway, Render, Vercel)\n* **Edge platforms** (Cloudflare Workers)\n* **Kubernetes clusters** (self-managed or managed)\n\nThe key requirements are Python 3.10+ support and the ability to expose an HTTP port. Most providers will require you to package your server (requirements.txt, Dockerfile, etc.) according to their deployment format. For managed, zero-configuration deployment, see [FastMCP Cloud](/deployment/fastmcp-cloud).",
  "content_length": 25645
}