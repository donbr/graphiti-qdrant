{
  "title": "Run a LangGraph app locally",
  "source_url": "https://docs.langchain.com/langsmith/local-server",
  "content": "This quickstart shows you how to set up a LangGraph application locally for testing and development.\n\n## Prerequisites\n\nBefore you begin, ensure you have an API key for [LangSmith](https://smith.langchain.com/settings) (free to sign up).\n\n## 1. Install the LangGraph CLI\n\n<Tabs>\n  <Tab title=\"Python server\">\n    ```shell  theme={null}\n    # Python >= 3.11 is required.\n\n    pip install -U \"langgraph-cli[inmem]\"\n    ```\n  </Tab>\n\n  <Tab title=\"Node server\">\n    ```shell  theme={null}\n    npx @langchain/langgraph-cli\n    ```\n  </Tab>\n</Tabs>\n\n## 2. Create a LangGraph app ðŸŒ±\n\nCreate a new app from the [`new-langgraph-project-python` template](https://github.com/langchain-ai/new-langgraph-project) or [`new-langgraph-project-js` template](https://github.com/langchain-ai/new-langgraphjs-project). This template demonstrates a single-node application you can extend with your own logic.\n\n<Tabs>\n  <Tab title=\"Python server\">\n    ```shell  theme={null}\n    langgraph new path/to/your/app --template new-langgraph-project-python\n    ```\n  </Tab>\n\n  <Tab title=\"Node server\">\n    ```shell  theme={null}\n    langgraph new path/to/your/app --template new-langgraph-project-js\n    ```\n  </Tab>\n</Tabs>\n\n<Tip>\n  **Additional templates**<br />\n  If you use [`langgraph new`](/langsmith/cli) without specifying a template, you will be presented with an interactive menu that will allow you to choose from a list of available templates.\n</Tip>\n\n## 3. Install dependencies\n\nIn the root of your new LangGraph app, install the dependencies in `edit` mode so your local changes are used by the server:\n\n<Tabs>\n  <Tab title=\"Python server\">\n    ```shell  theme={null}\n    cd path/to/your/app\n    pip install -e .\n    ```\n  </Tab>\n\n  <Tab title=\"Node server\">\n    ```shell  theme={null}\n    cd path/to/your/app\n    yarn install\n    ```\n  </Tab>\n</Tabs>\n\n## 4. Create a `.env` file\n\nYou will find a [`.env.example`](/langsmith/application-structure#configuration-file) in the root of your new LangGraph app. Create a `.env` file in the root of your new LangGraph app and copy the contents of the `.env.example` file into it, filling in the necessary API keys:\n\n```bash  theme={null}\nLANGSMITH_API_KEY=lsv2...\n```\n\n## 5. Launch Agent Server ðŸš€\n\nStart the Agent Server locally:\n\n<Tabs>\n  <Tab title=\"Python server\">\n    ```shell  theme={null}\n    langgraph dev\n    ```\n  </Tab>\n\n  <Tab title=\"Node server\">\n    ```shell  theme={null}\n    npx @langchain/langgraph-cli dev\n    ```\n  </Tab>\n</Tabs>\n\nSample output:\n\n```\n>    Ready!\n>\n>    - API: [http://localhost:2024](http://localhost:2024/)\n>\n>    - Docs: http://localhost:2024/docs\n>\n>    - Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n```\n\nThe [`langgraph dev`](/langsmith/cli) command starts [Agent Server](/langsmith/agent-server) in an in-memory mode. This mode is suitable for development and testing purposes.\n\n<Tip>\n  For production use, deploy Agent Server with a persistent storage backend. For more information, refer to the LangSmith [platform options](/langsmith/platform-setup).\n</Tip>\n\n## 6. Test the API\n\n<Tabs>\n  <Tab title=\"Python SDK (async)\">\n    1. Install the LangGraph Python SDK:\n\n    ```shell  theme={null}\n    pip install langgraph-sdk\n    ```\n\n    2. Send a message to the assistant (threadless run):\n\n    ```python  theme={null}\n    from langgraph_sdk import get_client\n    import asyncio\n\n    client = get_client(url=\"http://localhost:2024\")\n\n    async def main():\n        async for chunk in client.runs.stream(\n            None,  # Threadless run\n            \"agent\", # Name of assistant. Defined in langgraph.json.\n            input={\n            \"messages\": [{\n                \"role\": \"human\",\n                \"content\": \"What is LangGraph?\",\n                }],\n            },\n        ):\n            print(f\"Receiving new event of type: {chunk.event}...\")\n            print(chunk.data)\n            print(\"\\n\\n\")\n\n    asyncio.run(main())\n    ```\n  </Tab>\n\n  <Tab title=\"Python SDK (sync)\">\n    1. Install the LangGraph Python SDK:\n\n    ```shell  theme={null}\n    pip install langgraph-sdk\n    ```\n\n    2. Send a message to the assistant (threadless run):\n\n    ```python  theme={null}\n    from langgraph_sdk import get_sync_client\n\n    client = get_sync_client(url=\"http://localhost:2024\")\n\n    for chunk in client.runs.stream(\n        None,  # Threadless run\n        \"agent\", # Name of assistant. Defined in langgraph.json.\n        input={\n            \"messages\": [{\n                \"role\": \"human\",\n                \"content\": \"What is LangGraph?\",\n            }],\n        },\n        stream_mode=\"messages-tuple\",\n    ):\n        print(f\"Receiving new event of type: {chunk.event}...\")\n        print(chunk.data)\n        print(\"\\n\\n\")\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript SDK\">\n    1. Install the LangGraph JS SDK:\n\n    ```shell  theme={null}\n    npm install @langchain/langgraph-sdk\n    ```\n\n    2. Send a message to the assistant (threadless run):\n\n    ```js  theme={null}\n    const { Client } = await import(\"@langchain/langgraph-sdk\");\n\n    // only set the apiUrl if you changed the default port when calling langgraph dev\n    const client = new Client({ apiUrl: \"http://localhost:2024\"});\n\n    const streamResponse = client.runs.stream(\n        null, // Threadless run\n        \"agent\", // Assistant ID\n        {\n            input: {\n                \"messages\": [\n                    { \"role\": \"user\", \"content\": \"What is LangGraph?\"}\n                ]\n            },\n            streamMode: \"messages-tuple\",\n        }\n    );\n\n    for await (const chunk of streamResponse) {\n        console.log(`Receiving new event of type: ${chunk.event}...`);\n        console.log(JSON.stringify(chunk.data));\n        console.log(\"\\n\\n\");\n    }\n    ```\n  </Tab>\n\n  <Tab title=\"Rest API\">\n    ```bash  theme={null}\n    curl -s --request POST \\\n        --url \"http://localhost:2024/runs/stream\" \\\n        --header 'Content-Type: application/json' \\\n        --data \"{\n            \\\"assistant_id\\\": \\\"agent\\\",\n            \\\"input\\\": {\n                \\\"messages\\\": [\n                    {\n                        \\\"role\\\": \\\"human\\\",\n                        \\\"content\\\": \\\"What is LangGraph?\\\"\n                    }\n                ]\n            },\n            \\\"stream_mode\\\": \\\"messages-tuple\\\"\n        }\"\n    ```\n  </Tab>\n</Tabs>\n\n## Next steps\n\nNow that you have a LangGraph app running locally, you're ready to deploy it:\n\n**Choose a hosting option for LangSmith:**\n\n* [**Cloud**](/langsmith/cloud): Fastest setup, fully managed (recommended).\n* [**Hybrid**](/langsmith/hybrid): <Tooltip tip=\"The runtime environment where your Agent Servers and agents execute.\">Data plane</Tooltip> in your cloud, <Tooltip tip=\"The LangSmith UI and APIs for managing deployments.\">control plane</Tooltip> managed by LangChain.\n* [**Self-hosted**](/langsmith/self-hosted): Full control in your infrastructure.\n\nFor more details, refer to the [Platform setup comparison](/langsmith/platform-setup).\n\n**Then deploy your app:**\n\n* [Deploy to Cloud quickstart](/langsmith/deployment-quickstart): Quick setup guide.\n* [Full Cloud setup guide](/langsmith/deploy-to-cloud): Comprehensive deployment documentation.\n\n**Explore features:**\n\n* **[Studio](/langsmith/studio)**: Visualize, interact with, and debug your application with the Studio UI. Try the [Studio quickstart](/langsmith/quick-start-studio).\n* **API References**: [LangSmith Deployment API](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref/), [Python SDK](/langsmith/langgraph-python-sdk), [JS/TS SDK](/langsmith/langgraph-js-ts-sdk)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/local-server.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 7943
}