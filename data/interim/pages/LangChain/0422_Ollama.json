{
  "title": "Ollama",
  "source_url": "https://docs.langchain.com/oss/python/integrations/providers/ollama",
  "content": "This page covers all LangChain integrations with [Ollama](https://ollama.com/).\n\nOllama allows you to run open-source models (like [`gpt-oss`](https://ollama.com/library/gpt-oss)) locally.\n\nFor a complete list of supported models and variants, see the [Ollama model library](https://ollama.ai/library).\n\n## Model interfaces\n\n<Columns cols={2}>\n  <Card title=\"ChatOllama\" href=\"/oss/python/integrations/chat/ollama\" cta=\"Get started\" icon=\"message\" arrow>\n    Ollama chat models.\n  </Card>\n\n  <Card title=\"OllamaLLM\" href=\"/oss/python/integrations/llms/ollama\" cta=\"Get started\" icon=\"i-cursor\" arrow>\n    (Legacy) Ollama text completion models.\n  </Card>\n\n  <Card title=\"OllamaEmbeddings\" href=\"/oss/python/integrations/text_embedding/ollama\" cta=\"Get started\" icon=\"microsoft\" arrow>\n    Ollama embedding models.\n  </Card>\n</Columns>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/ollama.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 1207
}