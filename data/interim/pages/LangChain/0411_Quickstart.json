{
  "title": "Quickstart",
  "source_url": "https://docs.langchain.com/oss/python/deepagents/quickstart",
  "content": "Build your first deep agent in minutes\n\nThis guide walks you through creating your first deep agent with planning, file system tools, and subagent capabilities. You'll build a research agent that can conduct research and write reports.\n\n## Prerequisites\n\nBefore you begin, make sure you have an API key from a model provider (e.g., Anthropic, OpenAI).\n\n### Step 1: Install dependencies\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install deepagents tavily-python\n  ```\n\n  ```bash uv theme={null}\n  uv add deepagents tavily-python\n  ```\n\n  ```bash poetry theme={null}\n  poetry add deepagents tavily-python\n  ```\n</CodeGroup>\n\n### Step 2: Set up your API keys\n\n```bash  theme={null}\nexport ANTHROPIC_API_KEY=\"your-api-key\"\nexport TAVILY_API_KEY=\"your-tavily-api-key\"\n```\n\n### Step 3: Create a search tool\n\n```python  theme={null}\nimport os\nfrom typing import Literal\nfrom tavily import TavilyClient\nfrom deepagents import create_deep_agent\n\ntavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n\ndef internet_search(\n    query: str,\n    max_results: int = 5,\n    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n    include_raw_content: bool = False,\n):\n    \"\"\"Run a web search\"\"\"\n    return tavily_client.search(\n        query,\n        max_results=max_results,\n        include_raw_content=include_raw_content,\n        topic=topic,\n    )\n```\n\n### Step 4: Create a deep agent\n\n```python  theme={null}\n# System prompt to steer the agent to be an expert researcher\nresearch_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research and then write a polished report.\n\nYou have access to an internet search tool as your primary means of gathering information.\n\n## `internet_search`\n\nUse this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n\"\"\"\n\nagent = create_deep_agent(\n    tools=[internet_search],\n    system_prompt=research_instructions\n)\n```\n\n### Step 5: Run the agent\n\n```python  theme={null}\nresult = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langgraph?\"}]})\n\n# Print the agent's response\nprint(result[\"messages\"][-1].content)\n```\n\n## What happened?\n\nYour deep agent automatically:\n\n1. **Planned its approach**: Used the built-in `write_todos` tool to break down the research task\n2. **Conducted research**: Called the `internet_search` tool to gather information\n3. **Managed context**: Used file system tools (`write_file`, `read_file`) to offload large search results\n4. **Spawned subagents** (if needed): Delegated complex subtasks to specialized subagents\n5. **Synthesized a report**: Compiled findings into a coherent response\n\n## Next steps\n\nNow that you've built your first deep agent:\n\n* **Customize your agent**: Learn about [customization options](/oss/python/deepagents/customization), including custom system prompts, tools, and subagents.\n* **Understand middleware**: Dive into the [middleware architecture](/oss/python/deepagents/middleware) that powers deep agents.\n* **Add long-term memory**: Enable [persistent memory](/oss/python/deepagents/long-term-memory) across conversations.\n* **Deploy to production**: Learn about [deployment options](/oss/python/langgraph/deploy) for LangGraph applications.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/deepagents/quickstart.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 3658
}