{
  "title": "Test a ReAct agent with Pytest/Vitest and LangSmith",
  "source_url": "https://docs.langchain.com/langsmith/test-react-agent-pytest",
  "content": "This tutorial will show you how to use LangSmith's integrations with popular testing tools (Pytest, Vitest, and Jest) to evaluate your LLM application. We will create a ReAct agent that answers questions about publicly traded stocks and write a comprehensive test suite for it.\n\n## Setup\n\nThis tutorial uses [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/) for agent orchestration, [OpenAI's GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [Tavily](https://tavily.com/) for search, [E2B's](https://e2b.dev/) code interpreter, and [Polygon](https://polygon.io/stocks) to retrieve stock data but it can be adapted for other frameworks, models and tools with minor modifications. Tavily, E2B and Polygon are free to sign up for.\n\n### Installation\n\nFirst, install the packages required for making the agent:\n\n<CodeGroup>\n  ```bash Python theme={null}\n  pip install -U langgraph langchain[openai] langchain-community e2b-code-interpreter\n  ```\n\n  ```bash TypeScript theme={null}\n  yarn add @langchain/openai @langchain/community @langchain/langgraph @langchain/core @e2b/code-interpreter @polygon.io/client-js openai zod\n  ```\n</CodeGroup>\n\nNext, install the testing framework:\n\n<CodeGroup>\n  ```bash Pytest theme={null}\n  # Make sure you have langsmith>=0.3.1\n  pip install -U \"langsmith[pytest]\"\n  ```\n\n  ```bash Vitest theme={null}\n  yarn add -D langsmith vitest\n  ```\n\n  ```bash Jest theme={null}\n  yarn add -D langsmith jest\n  ```\n</CodeGroup>\n\n### Environment variables\n\nSet the following environment variables:\n\n```bash  theme={null}\nexport LANGSMITH_TRACING=true\nexport LANGSMITH_API_KEY=<YOUR_LANGSMITH_API_KEY>\nexport OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>\nexport TAVILY_API_KEY=<YOUR_TAVILY_API_KEY>\nexport E2B_API_KEY=<YOUR_E2B_API_KEY>\nexport POLYGON_API_KEY=<YOUR_POLYGON_API_KEY>\n```\n\n## Create your app\n\nTo define our React agent, we will use LangGraph/LangGraph.js for the orchestation and LangChain for the LLM and tools.\n\n### Define tools\n\nFirst we are going to define the tools we are going to use in our agent. There are going to be 3 tools:\n\n* A search tool using Tavily\n* A code interpreter tool using E2B\n* A stock information tool using Polygon\n\n<CodeGroup>\n  ```python Python theme={null}\n  from langchain_community.tools import TavilySearchResults\n  from e2b_code_interpreter import Sandbox\n  from langchain_community.tools.polygon.aggregates import PolygonAggregates\n  from langchain_community.utilities.polygon import PolygonAPIWrapper\n  from typing_extensions import Annotated, TypedDict, Optional, Literal\n\n  # Define search tool\n  search_tool = TavilySearchResults(\n    max_results=5,\n    include_raw_content=True,\n  )\n\n  # Define code tool\n  def code_tool(code: str) -> str:\n    \"\"\"Execute python code and return the result.\"\"\"\n    sbx = Sandbox()\n    execution = sbx.run_code(code)\n\n    if execution.error:\n        return f\"Error: {execution.error}\"\n    return f\"Results: {execution.results}, Logs: {execution.logs}\"\n\n  # Define input schema for stock ticker tool\n  class TickerToolInput(TypedDict):\n    \"\"\"Input format for the ticker tool.\n      The tool will pull data in aggregate blocks (timespan_multiplier * timespan) from the from_date to the to_date\n    \"\"\"\n    ticker: Annotated[str, ..., \"The ticker symbol of the stock\"]\n    timespan: Annotated[Literal[\"minute\", \"hour\", \"day\", \"week\", \"month\", \"quarter\", \"year\"], ..., \"The size of the time window.\"]\n    timespan_multiplier: Annotated[int, ..., \"The multiplier for the time window\"]\n    from_date: Annotated[str, ..., \"The date to start pulling data from, YYYY-MM-DD format - ONLY include the year month and day\"]\n    to_date: Annotated[str, ..., \"The date to stop pulling data, YYYY-MM-DD format - ONLY include the year month and day\"]\n\n  api_wrapper = PolygonAPIWrapper()\n  polygon_aggregate = PolygonAggregates(api_wrapper=api_wrapper)\n\n  # Define stock ticker tool\n  def ticker_tool(query: TickerToolInput) -> str:\n    \"\"\"Pull data for the ticker.\"\"\"\n    return polygon_aggregate.invoke(query)\n  ```\n\n  ```typescript TypeScript theme={null}\n  import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n  import { Sandbox } from \"@e2b/code-interpreter\";\n  import { tool } from \"@langchain/core/tools\";\n  import { z } from \"zod\";\n  import { restClient } from \"@polygon.io/client-js\";\n\n  // Define search tool\n  const searchTool = new TavilySearchResults({\n    maxResults: 5,\n  });\n\n  // Define code tool\n  const codeTool = tool(async (input) => {\n    const sbx = await Sandbox.create();\n    const execution = await sbx.runCode(input.code);\n    if (execution.error) {\n      return `Error: ${execution.error}`;\n    }\n    return `Results: ${execution.results}, Logs: ${execution.logs}`;\n  }, {\n    name: \"code\",\n    description: \"Execute python code and return the result.\",\n    schema: z.object({\n      code: z.string().describe(\"The python code to execute\"),\n    }),\n  });\n\n  // Define input schema for stock ticker tool\n  const TickerToolInputSchema = z.object({\n    ticker: z.string().describe(\"The ticker symbol of the stock\"),\n    timespan: z.enum([\"minute\", \"hour\", \"day\", \"week\", \"month\", \"quarter\", \"year\"]).describe(\"The size of the time window.\"),\n    timespan_multiplier: z.number().describe(\"The multiplier for the time window\"),\n    from_date: z\n      .string()\n      .describe(\"The date to start pulling data from, YYYY-MM-DD format - ONLY include the year, month, and day\"),\n    to_date: z\n      .string()\n      .describe(\"The date to stop pulling data, YYYY-MM-DD format - ONLY include the year, month, and day\"),\n  });\n\n  const rest = restClient(process.env.POLYGON_API_KEY);\n\n  // Define stock ticker tool\n  const tickerTool = tool(async (query) => {\n    const parsed = TickerToolInputSchema.parse(query);\n    const result = await rest.stocks.aggregates(\n        parsed.ticker,\n        parsed.timespan_multiplier,\n        parsed.timespan,\n        parsed.from_date,\n        parsed.to_date\n    );\n    return JSON.stringify(result);\n  }, {\n    name: \"ticker\",\n    description: \"Pull data for the ticker\",\n    schema: TickerToolInputSchema,\n  });\n  ```\n</CodeGroup>\n\n### Define agent\n\nNow that we have defined all of our tools, we can use [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) to create our agent.\n\n<CodeGroup>\n  ```python Python theme={null}\n  from typing_extensions import Annotated, TypedDict\n  from langchain.agents import create_agent\n\n\n  class AgentOutputFormat(TypedDict):\n      numeric_answer: Annotated[float | None, ..., \"The numeric answer, if the user asked for one\"]\n      text_answer: Annotated[str | None, ..., \"The text answer, if the user asked for one\"]\n      reasoning: Annotated[str, ..., \"The reasoning behind the answer\"]\n\n  agent = create_agent(\n      model=\"gpt-4o-mini\",\n      tools=[code_tool, search_tool, polygon_aggregates],\n      response_format=AgentOutputFormat,\n      system_prompt=\"You are a financial expert. Respond to the users query accurately\",\n  )\n  ```\n\n  ```typescript TypeScript theme={null}\n  import { z } from \"zod\";\n  import { ChatOpenAI } from \"@langchain/openai\";\n  import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\n  const AgentOutputFormatSchema = z.object({\n    numeric_answer: z.number().optional().describe(\"The numeric answer, if the user asked for one\"),\n    text_answer: z.string().optional().describe(\"The text answer, if the user asked for one\"),\n    reasoning: z.string().describe(\"The reasoning behind the answer\"),\n  })\n\n  const tools = [codeTool, searchTool, tickerTool];\n\n  const agent = createReactAgent({\n    llm: new ChatOpenAI({ model: \"gpt-4o\" }),\n    tools: tools,\n    responseFormat: AgentOutputFormatSchema,\n    stateModifier: \"You are a financial expert. Respond to the users query accurately\",\n  });\n\n  export default agent;\n  ```\n</CodeGroup>\n\n## Write tests\n\nNow that we have defined our agent, let's write a few tests to ensure basic functionality. In this tutorial we are going to test whether the agent's tool calling abilities are working, whether the agent knows to ignore irrelevant questions, and whether it is able to answer complex questions that involve using all of the tools.\n\nWe need to first set up a test file and add the imports needed at the top of the file.\n\n<CodeGroup>\n  ```python Pytest theme={null}\n  Create a `tests/test_agent.py` file.\n\n  from app import agent, polygon_aggregates, search_tool # import from wherever your agent is defined\n  import pytest\n  from langsmith import testing as t\n  ```\n\n  ```typescript Vitest theme={null}\n  Name your test file `agent.vitest.eval.ts`\n\n  import { expect } from \"vitest\";\n  import * as ls from \"langsmith/vitest\";\n  import agent from \"../agent\"; // import from wherever your agent is defined\n\n  // Optional, but recommended to group tests together\n  ls.describe(\"Agent Tests\", () => {\n    // PLACE TESTS Here\n  });\n  ```\n\n  ```typescript Jest theme={null}\n  Name your test file `agent.jest.eval.ts`\n\n  import { expect } from \"@jest/globals\";\n  import * as ls from \"langsmith/jest\";\n  import agent from \"../agent\"; // import from wherever your agent is defined\n\n  // Optional, but recommended to group tests together\n  ls.describe(\"Agent Tests\", () => {\n    // PLACE TESTS Here\n  });\n  ```\n</CodeGroup>\n\n### Test 1: Handle off-topic questions\n\nThe first test will be a simple check that the agent does not use tools on irrelevant queries.\n\n<CodeGroup>\n  ```python Pytest theme={null}\n  @pytest.mark.langsmith\n  @pytest.mark.parametrize(\n    # <-- Can still use all normal pytest markers\n    \"query\",\n    [\"Hello!\", \"How are you doing?\"],\n  )\n  def test_no_tools_on_offtopic_query(query: str) -> None:\n    \"\"\"Test that the agent does not use tools on offtopic queries.\"\"\"\n    # Log the test example\n    t.log_inputs({\"query\": query})\n    expected = []\n    t.log_reference_outputs({\"tool_calls\": expected})\n    # Call the agent's model node directly instead of running the ReACT loop.\n    result = agent.nodes[\"agent\"].invoke(\n        {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n    )\n    actual = result[\"messages\"][0].tool_calls\n    t.log_outputs({\"tool_calls\": actual})\n    # Check that no tool calls were made.\n    assert actual == expected\n  ```\n\n  ```typescript Vitest theme={null}\n  ls.test.each([\n    { inputs: { query: \"Hello!\" }, expected: { numMessages: 2 } },\n    { inputs: { query: \"How are you doing?\" }, expected: { numMessages: 2 } },\n  ])(\n    \"should not use tools on offtopic query: %s\",\n    async ({ inputs: { query }, expected: { numMessages } }) => {\n      const result = await agent.invoke({ messages: [{ role: \"user\", content: query }] });\n      ls.logOutputs(result);\n\n      // Check that the flow was HUMAN -> AI FINAL RESPONSE (no tools called)\n      expect(result.messages).toHaveLength(numMessages);\n    }\n  );\n  ```\n\n  ```typescript Jest theme={null}\n  ls.test.each([\n    { inputs: { query: \"Hello!\" }, expected: { numMessages: 2 } },\n    { inputs: { query: \"How are you doing?\" }, expected: { numMessages: 2 } },\n  ])(\n    \"should not use tools on offtopic query: %s\",\n    async ({ inputs: { query }, expected: { numMessages } }) => {\n      const result = await agent.invoke({ messages: [{ role: \"user\", content: query }] });\n      ls.logOutputs(result);\n\n      // Check that the flow was HUMAN -> AI FINAL RESPONSE (no tools called)\n      expect(result.messages).toHaveLength(numMessages);\n    }\n  );\n  ```\n</CodeGroup>\n\n### Test 2: Simple tool calling\n\nFor tool calling, we are going to verify that the agent calls the correct tool with the correct parameters.\n\n<CodeGroup>\n  ```python Pytest theme={null}\n  @pytest.mark.langsmith\n  def test_searches_for_correct_ticker() -> None:\n    \"\"\"Test that the model looks up the correct ticker on simple query.\"\"\"\n    # Log the test example\n    query = \"What is the price of Apple?\"\n    t.log_inputs({\"query\": query})\n    expected = \"AAPL\"\n    t.log_reference_outputs({\"ticker\": expected})\n    # Call the agent's model node directly instead of running the full ReACT loop.\n    result = agent.nodes[\"agent\"].invoke(\n        {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n    )\n    tool_calls = result[\"messages\"][0].tool_calls\n    if tool_calls[0][\"name\"] == polygon_aggregates.name:\n        actual = tool_calls[0][\"args\"][\"ticker\"]\n    else:\n        actual = None\n    t.log_outputs({\"ticker\": actual})\n    # Check that the right ticker was queried\n    assert actual == expected\n  ```\n\n  ```typescript Vitest theme={null}\n  ls.test(\n    \"should search for correct ticker\",\n    {\n      inputs: { query: \"What is the price of Apple?\" },\n      expected: { numMessages: 4 },\n    },\n    async ({ inputs: { query }, expected: { numMessages } }) => {\n      const result = await agent.invoke({\n        messages: [{ role: \"user\", content: query }],\n      });\n\n      ls.logOutputs(result);\n\n      // The agent should have made a single tool call to the ticker tool\n      const toolCalls = (result.messages[1] as AIMessage).tool_calls || [];\n      const tickerQuery = JSON.parse(toolCalls[0].function.arguments).query.ticker;\n      // Check that the right ticker was queried\n      expect(tickerQuery).toBe(\"AAPL\");\n\n      // Check that the flow was HUMAN -> AI -> TOOL -> AI FINAL RESPONSE\n      expect(result.messages).toHaveLength(numMessages);\n    }\n  );\n  ```\n\n  ```typescript Jest theme={null}\n  ls.test(\n    \"should search for correct ticker\",\n    {\n      inputs: { query: \"What is the price of Apple?\" },\n      expected: { numMessages: 4 },\n    },\n    async ({ inputs: { query }, expected: { numMessages } }) => {\n      const result = await agent.invoke({\n        messages: [{ role: \"user\", content: query }],\n      });\n\n      ls.logOutputs(result);\n\n      // The agent should have made a single tool call to the ticker tool\n      const toolCalls = (result.messages[1] as AIMessage).tool_calls || [];\n      const tickerQuery = JSON.parse(toolCalls[0].function.arguments).query.ticker;\n      // Check that the right ticker was queried\n      expect(tickerQuery).toBe(\"AAPL\");\n\n      // Check that the flow was HUMAN -> AI -> TOOL -> AI FINAL RESPONSE\n      expect(result.messages).toHaveLength(numMessages);\n    }\n  );\n  ```\n</CodeGroup>\n\n### Test 3: Complex tool calling\n\nSome tool calls are easier to test than others. With the ticker lookup, we can assert that the correct ticker is searched. With the coding tool, the inputs and outputs of the tool are much less constrained, and there are lots of ways to get to the right answer. In this case, it's simpler to test that the tool is used correctly by running the full agent and asserting that it both calls the coding tool and that it ends up with the right answer.\n\n<CodeGroup>\n  ```python Pytest theme={null}\n  @pytest.mark.langsmith\n  def test_executes_code_when_needed() -> None:\n    query = (\n        \"In the past year Facebook stock went up by 66.76%, \"\n        \"Apple by 25.24%, Google by 37.11%, Amazon by 47.52%, \"\n        \"Netflix by 78.31%. Whats the avg return in the past \"\n        \"year of the FAANG stocks, expressed as a percentage?\"\n    )\n    t.log_inputs({\"query\": query})\n    expected = 50.988\n    t.log_reference_outputs({\"response\": expected})\n    # Test that the agent executes code when needed\n    result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n    t.log_outputs({\"result\": result[\"structured_response\"].get(\"numeric_answer\")})\n    # Grab all the tool calls made by the LLM\n    tool_calls = [\n        tc[\"name\"]\n        for msg in result[\"messages\"]\n        for tc in getattr(msg, \"tool_calls\", [])\n    ]\n    # This will log the number of steps taken by the agent, which is useful for\n    # determining how efficiently the agent gets to an answer.\n    t.log_feedback(key=\"num_steps\", score=len(result[\"messages\"]) - 1)\n    # Assert that the code tool was used\n    assert \"code_tool\" in tool_calls\n    # Assert that a numeric answer was provided:\n    assert result[\"structured_response\"].get(\"numeric_answer\") is not None\n    # Assert that the answer is correct\n    assert abs(result[\"structured_response\"][\"numeric_answer\"] - expected) <= 0.01\n  ```\n\n  ```typescript Vitest theme={null}\n  ls.test(\n    \"should execute code when needed\",\n    {\n      inputs: { query: \"What was the average return rate for FAANG stock in 2024?\" },\n      expected: { answer: 53 },\n    },\n    async ({ inputs: { query }, expected: { answer } }) => {\n      const result = await agent.invoke({\n        messages: [{ role: \"user\", content: query }],\n      });\n\n      ls.logOutputs(result);\n\n      // Grab all the tool calls made by the LLM\n      const toolCalls = result.messages\n        .filter(m => (m as AIMessage).tool_calls)\n        .flatMap(m => (m as AIMessage).tool_calls?.map(tc => tc.name));\n      // This will log the number of steps taken by the LLM, which we can track over time to measure performance\n      ls.logFeedback({\n        key: \"num_steps\",\n        score: result.messages.length - 1, // The first message is the user message\n      });\n      // Assert that the tool calls include the \"code_tool\" function\n      expect(toolCalls).toContain(\"code_tool\");\n      // Assert that the answer is within 1 of the expected answer\n      expect(Math.abs(result.structured_response.numeric_answer - answer)).toBeLessThanOrEqual(1);\n    }\n  );\n  ```\n\n  ```typescript Jest theme={null}\n  ls.test(\n    \"should execute code when needed\",\n    {\n      inputs: { query: \"What was the average return rate for FAANG stock in 2024?\" },\n      expected: { answer: 53 },\n    },\n    async ({ inputs: { query }, expected: { answer } }) => {\n      const result = await agent.invoke({\n        messages: [{ role: \"user\", content: query }],\n      });\n\n      ls.logOutputs(result);\n      // Grab all the tool calls made by the LLM\n      const toolCalls = result.messages\n        .filter(m => (m as AIMessage).tool_calls)\n        .flatMap(m => (m as AIMessage).tool_calls?.map(tc => tc.name));\n      // This will log the number of steps taken by the LLM, which we can track over time to measure performance\n      ls.logFeedback({\n        key: \"num_steps\",\n        score: result.messages.length - 1, // The first message is the user message\n      });\n      // Assert that the tool calls include the \"code_tool\" function\n      expect(toolCalls).toContain(\"code_tool\");\n      // Assert that the answer is within 1 of the expected answer\n      expect(Math.abs(result.structured_response.numeric_answer - answer)).toBeLessThanOrEqual(1);\n    }\n  );\n  ```\n</CodeGroup>\n\n### Test 4: LLM-as-a-judge\n\nWe are going to ensure that the agent's answer is grounded in the search results by running an LLM-as-a-judge evaluation. In order to trace the LLM as a judge call separately from our agent, we will use the LangSmith provided `trace_feedback` context manager in Python and `wrapEvaluator` function in JS/TS.\n\n<CodeGroup>\n  ```python Pytest theme={null}\n  from typing_extensions import Annotated, TypedDict\n  from langchain.chat_models import init_chat_model\n\n  class Grade(TypedDict):\n    \"\"\"Evaluate the groundedness of an answer in source documents.\"\"\"\n    score: Annotated[\n        bool,\n        ...,\n        \"Return True if the answer is fully grounded in the source documents, otherwise False.\",\n    ]\n\n  judge_llm = init_chat_model(\"gpt-4o\").with_structured_output(Grade)\n\n  @pytest.mark.langsmith\n  def test_grounded_in_source_info() -> None:\n    \"\"\"Test that response is grounded in the tool outputs.\"\"\"\n    query = \"How did Nvidia stock do in 2024 according to analysts?\"\n    t.log_inputs({\"query\": query})\n    result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n    # Grab all the search calls made by the LLM\n    search_results = \"\\n\\n\".join(\n        msg.content\n        for msg in result[\"messages\"]\n        if msg.type == \"tool\" and msg.name == search_tool.name\n    )\n    t.log_outputs(\n        {\n            \"response\": result[\"structured_response\"].get(\"text_answer\"),\n            \"search_results\": search_results,\n        }\n    )\n    # Trace the feedback LLM run separately from the agent run.\n    with t.trace_feedback():\n        # Instructions for the LLM judge\n        instructions = (\n            \"Grade the following ANSWER. \"\n            \"The ANSWER should be fully grounded in (i.e. supported by) the source DOCUMENTS. \"\n            \"Return True if the ANSWER is fully grounded in the DOCUMENTS. \"\n            \"Return False if the ANSWER is not grounded in the DOCUMENTS.\"\n        )\n        answer_and_docs = (\n            f\"ANSWER: {result['structured_response'].get('text_answer', '')}\\n\"\n            f\"DOCUMENTS:\\n{search_results}\"\n        )\n        # Run the judge LLM\n        grade = judge_llm.invoke(\n            [\n                {\"role\": \"system\", \"content\": instructions},\n                {\"role\": \"user\", \"content\": answer_and_docs},\n            ]\n        )\n        t.log_feedback(key=\"groundedness\", score=grade[\"score\"])\n    assert grade['score']\n  ```\n\n  ```typescript Vitest theme={null}\n  // THIS CODE GOES OUTSIDE THE TEST - IT IS JUST A HELPER FUNCTION\n  const judgeLLM = new ChatOpenAI({ model: \"gpt-4o\" });\n  const groundedEvaluator = async (params: {\n    answer: string;\n    referenceDocuments: string,\n  }) => {\n    // Instructions for the LLM judge\n    const instructions = [\n      \"Return 1 if the ANSWER is grounded in the DOCUMENTS\",\n      \"Return 0 if the ANSWER is not grounded in the DOCUMENTS\",\n    ].join(\"\\n\");\n\n    // Run the judge LLM\n    const grade = await judgeLLM.invoke([\n      { role: \"system\", content: instructions },\n      { role: \"user\", content: `ANSWER: ${params.answer}\\nDOCUMENTS: ${params.referenceDocuments}` },\n    ]);\n    const score = parseInt(grade.content.toString());\n    return { key: \"groundedness\", score };\n  };\n\n  // THIS CODE GOES INSIDE THE TEST\n  ls.test(\n    \"grounded in the source\",\n    {\n      inputs: { query: \"How did Nvidia stock do in 2024 according to analysts?\" },\n    },\n    async ({ inputs: { query } }) => {\n      const result = await agent.invoke({\n        messages: [{ role: \"user\", content: query }],\n      });\n      const wrappedEvaluator = ls.wrapEvaluator(groundedEvaluator);\n      await wrappedEvaluator({\n        answer: result.structuredResponse.text_answer ?? \"\",\n        referenceDocuments: result.structuredResponse.reasoning,\n      })\n      ls.logOutputs(result);\n    }\n  );\n  ```\n\n  ```typescript Jest theme={null}\n  // THIS CODE GOES OUTSIDE THE TEST - IT IS JUST A HELPER FUNCTION\n  const judgeLLM = new ChatOpenAI({ model: \"gpt-4o\" });\n  const groundedEvaluator = async (params: {\n    answer: string;\n    referenceDocuments: string,\n  }) => {\n    // Instructions for the LLM judge\n    const instructions = [\n      \"Return 1 if the ANSWER is grounded in the DOCUMENTS\",\n      \"Return 0 if the ANSWER is not grounded in the DOCUMENTS\",\n    ].join(\"\\n\");\n\n    // Run the judge LLM\n    const grade = await judgeLLM.invoke([\n      { role: \"system\", content: instructions },\n      { role: \"user\", content: `ANSWER: ${params.answer}\\nDOCUMENTS: ${params.referenceDocuments}` },\n    ]);\n    const score = parseInt(grade.content.toString());\n    return { key: \"groundedness\", score };\n  };\n\n  // THIS CODE GOES INSIDE THE TEST\n  ls.test(\n    \"grounded in the source\",\n    {\n      inputs: { query: \"How did Nvidia stock do in 2024 according to analysts?\" },\n    },\n    async ({ inputs: { query } }) => {\n      const result = await agent.invoke({\n        messages: [{ role: \"user\", content: query }],\n      });\n      const wrappedEvaluator = ls.wrapEvaluator(groundedEvaluator);\n      await wrappedEvaluator({\n        answer: result.structuredResponse.text_answer ?? \"\",\n        referenceDocuments: result.structuredResponse.reasoning,\n      })\n      ls.logOutputs(result);\n    }\n  );\n  ```\n</CodeGroup>\n\n## Run tests\n\nOnce you have setup your config files (if you are using Vitest or Jest), you can run your tests using the following commands:\n\n<Accordion title=\"Config files for Vitest/Jest\">\n  <CodeGroup>\n    ```typescript Vitest theme={null}\n    Create a `ls.vitest.config.ts` file:\n\n    import { defineConfig } from \"vitest/config\";\n\n    export default defineConfig({\n      test: {\n        include: [\"**/*.eval.?(c|m)[jt]s\"],\n        reporters: [\"langsmith/vitest/reporter\"],\n        setupFiles: [\"dotenv/config\"],\n      },\n    });\n    ```\n\n    ```javascript Jest theme={null}\n    Create a `ls.jest.config.ts` file:\n\n    require('dotenv').config();\n\n    module.exports = {\n      preset: 'ts-jest',\n      testEnvironment: 'node',\n      testMatch: [\n        '<rootDir>/tests/jest/**/*.jest.eval.ts'\n      ],\n      testPathIgnorePatterns: [\n        '<rootDir>/tests/vitest/.*.vitest.eval.ts$'\n      ],\n      reporters: [\"langsmith/jest/reporter\"],\n    };\n    ```\n  </CodeGroup>\n</Accordion>\n\n<CodeGroup>\n  ```bash Pytest theme={null}\n  pytest --langsmith-output tests\n  ```\n\n  ```bash Vitest theme={null}\n  yarn vitest --config ls.vitest.config.ts\n  ```\n\n  ```bash Jest theme={null}\n  yarn jest --config ls.jest.config.ts\n  ```\n</CodeGroup>\n\n## Reference code\n\nRemember to also add the config files for [Vitest](#config-files-for-vitestjest) and [Jest](#config-files-for-vitestjest) to your project.\n\n### Agent\n\n<Accordion title=\"Agent code\">\n  <CodeGroup>\n    ```python Python theme={null}\n    from e2b_code_interpreter import Sandbox\n    from langchain_community.tools import PolygonAggregates, TavilySearchResults\n    from langchain_community.utilities.polygon import PolygonAPIWrapper\n    from langchain.agents import create_agent\n    from typing_extensions import Annotated, TypedDict\n\n\n    search_tool = TavilySearchResults(\n        max_results=5,\n        include_raw_content=True,\n    )\n\n    def code_tool(code: str) -> str:\n        \"\"\"Execute python code and return the result.\"\"\"\n        sbx = Sandbox()\n        execution = sbx.run_code(code)\n\n        if execution.error:\n            return f\"Error: {execution.error}\"\n        return f\"Results: {execution.results}, Logs: {execution.logs}\"\n\n    polygon_aggregates = PolygonAggregates(api_wrapper=PolygonAPIWrapper())\n\n    class AgentOutputFormat(TypedDict):\n        numeric_answer: Annotated[\n            float | None, ..., \"The numeric answer, if the user asked for one\"\n        ]\n        text_answer: Annotated[\n            str | None, ..., \"The text answer, if the user asked for one\"\n        ]\n        reasoning: Annotated[str, ..., \"The reasoning behind the answer\"]\n\n    agent = create_agent(\n        model=\"gpt-4o-mini\",\n        tools=[code_tool, search_tool, polygon_aggregates],\n        response_format=AgentOutputFormat,\n        system_prompt=\"You are a financial expert. Respond to the users query accurately\",\n    )\n    ```\n\n    ```typescript TypeScript theme={null}\n    import { ChatOpenAI } from \"@langchain/openai\";\n    import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n    import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n    import { Sandbox } from '@e2b/code-interpreter'\n    import { restClient } from '@polygon.io/client-js';\n    import { tool } from \"@langchain/core/tools\";\n    import { z } from \"zod\";\n\n    const codeTool = tool(async (input) => {\n        const sbx = await Sandbox.create();\n        const execution = await sbx.runCode(input.code);\n        if (execution.error) {\n        return `Error: ${execution.error}`;\n        }\n        return `Results: ${execution.results}, Logs: ${execution.logs}`;\n    }, {\n        name: \"code\",\n        description: \"Execute python code and return the result.\",\n        schema: z.object({\n        code: z.string().describe(\"The python code to execute\"),\n        }),\n    });\n\n    const TickerToolInputSchema = z.object({\n        ticker: z.string().describe(\"The ticker symbol of the stock\"),\n        timespan: z.enum([\"minute\", \"hour\", \"day\", \"week\", \"month\", \"quarter\", \"year\"]).describe(\"The size of the time window.\"),\n        timespan_multiplier: z.number().describe(\"The multiplier for the time window\"),\n        from_date: z\n        .string()\n        .describe(\"The date to start pulling data from, YYYY-MM-DD format - ONLY include the year, month, and day\"),\n        to_date: z\n        .string()\n        .describe(\"The date to stop pulling data, YYYY-MM-DD format - ONLY include the year, month, and day\"),\n    });\n\n    const rest = restClient(process.env.POLYGON_API_KEY);\n\n    const tickerTool = tool(async (query) => {\n        const parsed = TickerToolInputSchema.parse(query);\n        const result = await rest.stocks.aggregates(\n        parsed.ticker,\n        parsed.timespan_multiplier,\n        parsed.timespan,\n        parsed.from_date,\n        parsed.to_date\n        );\n        return JSON.stringify(result);\n    }, {\n        name: \"ticker\",\n        description: \"Pull data for the ticker\",\n        schema: TickerToolInputSchema,\n    });\n\n    const searchTool = new TavilySearchResults({\n        maxResults: 5,\n    });\n\n    const AgentOutputFormatSchema = z.object({\n        numeric_answer: z.number().optional().describe(\"The numeric answer, if the user asked for one\"),\n        text_answer: z.string().optional().describe(\"The text answer, if the user asked for one\"),\n        reasoning: z.string().describe(\"The reasoning behind the answer\"),\n    })\n\n    const tools = [codeTool, searchTool, tickerTool];\n\n    const agent = createReactAgent({\n        llm: new ChatOpenAI({ model: \"gpt-4o\" }),\n        tools: tools,\n        responseFormat: AgentOutputFormatSchema,\n        stateModifier: \"You are a financial expert. Respond to the users query accurately\",\n    });\n\n    export default agent;\n    ```\n  </CodeGroup>\n</Accordion>\n\n### Tests\n\n<Accordion title=\"Test code\">\n  <CodeGroup>\n    ```python Pytest theme={null}\n    # from app import agent, polygon_aggregates, search_tool # import from wherever your agent is defined\n    import pytest\n    from langchain.chat_models import init_chat_model\n    from langsmith import testing as t\n    from typing_extensions import Annotated, TypedDict\n\n    @pytest.mark.langsmith\n    @pytest.mark.parametrize(\n      # <-- Can still use all normal pytest markers\n      \"query\",\n      [\"Hello!\", \"How are you doing?\"],\n    )\n    def test_no_tools_on_offtopic_query(query: str) -> None:\n      \"\"\"Test that the agent does not use tools on offtopic queries.\"\"\"\n      # Log the test example\n      t.log_inputs({\"query\": query})\n      expected = []\n      t.log_reference_outputs({\"tool_calls\": expected})\n      # Call the agent's model node directly instead of running the ReACT loop.\n      result = agent.nodes[\"agent\"].invoke(\n          {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n      )\n      actual = result[\"messages\"][0].tool_calls\n      t.log_outputs({\"tool_calls\": actual})\n      # Check that no tool calls were made.\n      assert actual == expected\n\n    @pytest.mark.langsmith\n    def test_searches_for_correct_ticker() -> None:\n      \"\"\"Test that the model looks up the correct ticker on simple query.\"\"\"\n      # Log the test example\n      query = \"What is the price of Apple?\"\n      t.log_inputs({\"query\": query})\n      expected = \"AAPL\"\n      t.log_reference_outputs({\"ticker\": expected})\n      # Call the agent's model node directly instead of running the full ReACT loop.\n      result = agent.nodes[\"agent\"].invoke(\n          {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n      )\n      tool_calls = result[\"messages\"][0].tool_calls\n      if tool_calls[0][\"name\"] == polygon_aggregates.name:\n          actual = tool_calls[0][\"args\"][\"ticker\"]\n      else:\n          actual = None\n      t.log_outputs({\"ticker\": actual})\n      # Check that the right ticker was queried\n      assert actual == expected\n\n    @pytest.mark.langsmith\n    def test_executes_code_when_needed() -> None:\n      query = (\n          \"In the past year Facebook stock went up by 66.76%, \"\n          \"Apple by 25.24%, Google by 37.11%, Amazon by 47.52%, \"\n          \"Netflix by 78.31%. Whats the avg return in the past \"\n          \"year of the FAANG stocks, expressed as a percentage?\"\n      )\n      t.log_inputs({\"query\": query})\n      expected = 50.988\n      t.log_reference_outputs({\"response\": expected})\n      # Test that the agent executes code when needed\n      result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n      t.log_outputs({\"result\": result[\"structured_response\"].get(\"numeric_answer\")})\n      # Grab all the tool calls made by the LLM\n      tool_calls = [\n          tc[\"name\"]\n          for msg in result[\"messages\"]\n          for tc in getattr(msg, \"tool_calls\", [])\n      ]\n      # This will log the number of steps taken by the agent, which is useful for\n      # determining how efficiently the agent gets to an answer.\n      t.log_feedback(key=\"num_steps\", score=len(result[\"messages\"]) - 1)\n      # Assert that the code tool was used\n      assert \"code_tool\" in tool_calls\n      # Assert that a numeric answer was provided:\n      assert result[\"structured_response\"].get(\"numeric_answer\") is not None\n      # Assert that the answer is correct\n      assert abs(result[\"structured_response\"][\"numeric_answer\"] - expected) <= 0.01\n\n    class Grade(TypedDict):\n      \"\"\"Evaluate the groundedness of an answer in source documents.\"\"\"\n      score: Annotated[\n          bool,\n          ...,\n          \"Return True if the answer is fully grounded in the source documents, otherwise False.\",\n      ]\n\n    judge_llm = init_chat_model(\"gpt-4o\").with_structured_output(Grade)\n\n    @pytest.mark.langsmith\n    def test_grounded_in_source_info() -> None:\n      \"\"\"Test that response is grounded in the tool outputs.\"\"\"\n      query = \"How did Nvidia stock do in 2024 according to analysts?\"\n      t.log_inputs({\"query\": query})\n      result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n      # Grab all the search calls made by the LLM\n      search_results = \"\\n\\n\".join(\n          msg.content\n          for msg in result[\"messages\"]\n          if msg.type == \"tool\" and msg.name == search_tool.name\n      )\n      t.log_outputs(\n          {\n              \"response\": result[\"structured_response\"].get(\"text_answer\"),\n              \"search_results\": search_results,\n          }\n      )\n      # Trace the feedback LLM run separately from the agent run.\n      with t.trace_feedback():\n          # Instructions for the LLM judge\n          instructions = (\n              \"Grade the following ANSWER. \"\n              \"The ANSWER should be fully grounded in (i.e. supported by) the source DOCUMENTS. \"\n              \"Return True if the ANSWER is fully grounded in the DOCUMENTS. \"\n              \"Return False if the ANSWER is not grounded in the DOCUMENTS.\"\n          )\n          answer_and_docs = (\n              f\"ANSWER: {result['structured_response'].get('text_answer', '')}\\n\"\n              f\"DOCUMENTS:\\n{search_results}\"\n          )\n          # Run the judge LLM\n          grade = judge_llm.invoke(\n              [\n                  {\"role\": \"system\", \"content\": instructions},\n                  {\"role\": \"user\", \"content\": answer_and_docs},\n              ]\n          )\n          t.log_feedback(key=\"groundedness\", score=grade[\"score\"])\n      assert grade[\"score\"]\n    ```\n\n    ```typescript Vitest theme={null}\n    import { expect } from \"vitest\";\n    import * as ls from \"langsmith/vitest\";\n    import agent from \"../agent\";\n    import { AIMessage, ToolMessage } from \"@langchain/core/messages\";\n    import { ChatOpenAI } from \"@langchain/openai\";\n\n    const judgeLLM = new ChatOpenAI({ model: \"gpt-4o\" });\n\n    const groundedEvaluator = async (params: {\n      answer: string;\n      referenceDocuments: string,\n    }) => {\n      const instructions = [\n        \"Return 1 if the ANSWER is grounded in the DOCUMENTS\",\n        \"Return 0 if the ANSWER is not grounded in the DOCUMENTS\",\n      ].join(\"\\n\");\n\n      const grade = await judgeLLM.invoke([\n        { role: \"system\", content: instructions },\n        { role: \"user\", content: `ANSWER: ${params.answer}\\nDOCUMENTS: ${params.referenceDocuments}` },\n      ]);\n      const score = parseInt(grade.content.toString());\n      return { key: \"groundedness\", score };\n    };\n\n    ls.describe(\"Agent Tests\", () => {\n      ls.test.each([\n        { inputs: { query: \"Hello!\" }, referenceOutputs: { numMessages: 2 } },\n        { inputs: { query: \"How are you doing?\" }, referenceOutputs: { numMessages: 2 } },\n      ])(\n        \"should not use tools on offtopic query: %s\",\n        async ({ inputs: { query }, referenceOutputs: { numMessages } }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          ls.logOutputs(result);\n          expect(result.messages).toHaveLength(numMessages);\n        }\n      );\n\n      ls.test(\n        \"should search for correct ticker\",\n        {\n          inputs: { query: \"What is the price of Apple?\" },\n          referenceOutputs: { numMessages: 4 },\n        },\n        async ({ inputs: { query }, referenceOutputs: { numMessages } }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          const toolCalls = (result.messages[1] as AIMessage).tool_calls || [];\n          const tickerQuery = toolCalls[0].args.ticker;\n          ls.logOutputs(result);\n          expect(tickerQuery).toBe(\"AAPL\");\n          expect(result.messages).toHaveLength(numMessages);\n        }\n      );\n\n      ls.test(\n        \"should execute code when needed\",\n        {\n          inputs: { query: \"What was the average return rate for FAANG stock in 2024?\" },\n          referenceOutputs: { answer: 53 },\n        },\n        async ({ inputs: { query }, referenceOutputs: { answer } }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n\n          const toolCalls = result.messages\n            .filter(m => (m as AIMessage).tool_calls)\n            .flatMap(m => (m as AIMessage).tool_calls?.map(tc => tc.name));\n          ls.logFeedback({\n            key: \"num_steps\",\n            score: result.messages.length - 1,\n          });\n          ls.logOutputs(result);\n          expect(toolCalls).toContain(\"code_tool\");\n          expect(Math.abs((result.structuredResponse.numeric_answer ?? 0) - answer)).toBeLessThanOrEqual(1);\n        }\n      );\n\n      ls.test(\n        \"grounded in the source\",\n        {\n          inputs: { query: \"How did Nvidia stock do in 2024?\" },\n          referenceOutputs: {},\n        },\n        async ({ inputs: { query }, referenceOutputs: {} }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          const referenceDocuments = result.messages\n            .filter((m): m is ToolMessage => m.name?.includes('tavily_search_results_json') ?? false)\n            .map(m => m.content)\n            .join('\\n');\n          const wrappedEvaluator = ls.wrapEvaluator(groundedEvaluator);\n          await wrappedEvaluator({\n            answer: result.structuredResponse.text_answer ?? \"\",\n            referenceDocuments: referenceDocuments,\n          })\n          ls.logOutputs(result);\n        }\n      );\n    });\n    ```\n\n    ```typescript Jest theme={null}\n    import { expect } from \"@jest/globals\";\n    import * as ls from \"langsmith/jest\";\n    import agent from \"../agent\";\n    import { AIMessage } from \"@langchain/core/messages\";\n    import { ChatOpenAI } from \"@langchain/openai\";\n\n    const judgeLLM = new ChatOpenAI({ model: \"gpt-4o\" });\n\n    const groundedEvaluator = async (params: {\n      answer: string;\n      referenceDocuments: string,\n    }) => {\n      const instructions = [\n        \"Return 1 if the ANSWER is grounded in the DOCUMENTS\",\n        \"Return 0 if the ANSWER is not grounded in the DOCUMENTS\",\n      ].join(\"\\n\");\n\n      const grade = await judgeLLM.invoke([\n        { role: \"system\", content: instructions },\n        { role: \"user\", content: `ANSWER: ${params.answer}\\nDOCUMENTS: ${params.referenceDocuments}` },\n      ]);\n      const score = parseInt(grade.content.toString());\n      return { key: \"groundedness\", score };\n    };\n\n    ls.describe(\"Agent Tests\", () => {\n      ls.test.each([\n        { inputs: { query: \"Hello!\" }, referenceOutputs: { numMessages: 2 } },\n        { inputs: { query: \"How are you doing?\" }, referenceOutputs: { numMessages: 2 } },\n      ])(\n        \"should not use tools on offtopic query: %s\",\n        async ({ inputs: { query }, referenceOutputs: { numMessages } }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          ls.logOutputs(result);\n          expect(result.messages).toHaveLength(numMessages);\n        }\n      );\n\n      ls.test(\n        \"should search for correct ticker\",\n        {\n          inputs: { query: \"What is the price of Apple?\" },\n          referenceOutputs: { numMessages: 4 },\n        },\n        async ({ inputs: { query }, referenceOutputs: { numMessages } }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          const toolCalls = (result.messages[1] as AIMessage).tool_calls || [];\n          const tickerQuery = toolCalls[0].args.ticker;\n          ls.logOutputs(result);\n          expect(tickerQuery).toBe(\"AAPL\");\n          expect(result.messages).toHaveLength(numMessages);\n        }\n      );\n\n      ls.test(\n        \"should execute code when needed\",\n        {\n          inputs: { query: \"What was the average return rate for FAANG stock in 2024?\" },\n          referenceOutputs: { answer: 53 },\n        },\n        async ({ inputs: { query }, referenceOutputs: { answer } }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          const toolCalls = result.messages\n            .filter(m => (m as AIMessage).tool_calls)\n            .flatMap(m => (m as AIMessage).tool_calls?.map(tc => tc.name));\n          ls.logFeedback({\n            key: \"num_steps\",\n            score: result.messages.length - 1,\n          });\n          ls.logOutputs(result);\n          expect(toolCalls).toContain(\"code_tool\");\n          expect(Math.abs((result.structuredResponse.numeric_answer ?? 0) - answer)).toBeLessThanOrEqual(1);\n        }\n      );\n\n      ls.test(\n        \"grounded in the source\",\n        {\n          inputs: { query: \"How did Nvidia stock do in 2024 according to analysts?\" },\n          referenceOutputs: {},\n        },\n        async ({ inputs: { query }, referenceOutputs: {} }) => {\n          const result = await agent.invoke({\n            messages: [{ role: \"user\", content: query }],\n          });\n          const wrappedEvaluator = ls.wrapEvaluator(groundedEvaluator);\n          await wrappedEvaluator({\n            answer: result.structuredResponse.text_answer ?? \"\",\n            referenceDocuments: result.structuredResponse.reasoning,\n          })\n          ls.logOutputs(result);\n        }\n      );\n    });\n    ```\n  </CodeGroup>\n</Accordion>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/test-react-agent-pytest.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 43321
}