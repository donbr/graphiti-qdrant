{
  "title": "Use the graph API",
  "source_url": "https://docs.langchain.com/oss/javascript/langgraph/use-graph-api",
  "content": "This guide demonstrates the basics of LangGraph's Graph API. It walks through [state](#define-and-update-state), as well as composing common graph structures such as [sequences](#create-a-sequence-of-steps), [branches](#create-branches), and [loops](#create-and-control-loops). It also covers LangGraph's control features, including the [Send API](#map-reduce-and-the-send-api) for map-reduce workflows and the [Command API](#combine-control-flow-and-state-updates-with-command) for combining state updates with \"hops\" across nodes.\n\n## Setup\n\nInstall `langgraph`:\n\n```bash  theme={null}\nnpm install @langchain/langgraph\n```\n\n<Tip>\n  **Set up LangSmith for better debugging**\n\n  Sign up for [LangSmith](https://smith.langchain.com) to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started in the [docs](/langsmith/observability).\n</Tip>\n\n## Define and update state\n\nHere we show how to define and update [state](/oss/javascript/langgraph/graph-api#state) in LangGraph. We will demonstrate:\n\n1. How to use state to define a graph's [schema](/oss/javascript/langgraph/graph-api#schema)\n2. How to use [reducers](/oss/javascript/langgraph/graph-api#reducers) to control how state updates are processed.\n\n### Define state\n\n[State](/oss/javascript/langgraph/graph-api#state) in LangGraph can be defined using Zod schemas. Below we will use Zod. See [this section](#alternative-state-definitions) for detail on using alternative approaches.\n\nBy default, graphs will have the same input and output schema, and the state determines that schema. See [this section](#define-input-and-output-schemas) for how to define distinct input and output schemas.\n\nLet's consider a simple example using [messages](/oss/javascript/langgraph/graph-api#messagesstate). This represents a versatile formulation of state for many LLM applications. See our [concepts page](/oss/javascript/langgraph/graph-api#working-with-messages-in-graph-state) for more detail.\n\n```typescript  theme={null}\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { MessagesZodMeta } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  messages: z.array(z.custom<BaseMessage>()).register(registry, MessagesZodMeta),\n  extraField: z.number(),\n});\n```\n\nThis state tracks a list of [message](https://js.langchain.com/docs/concepts/messages/) objects, as well as an extra integer field.\n\n### Update state\n\nLet's build an example graph with a single node. Our [node](/oss/javascript/langgraph/graph-api#nodes) is just a TypeScript function that reads our graph's state and makes updates to it. The first argument to this function will always be the state:\n\n```typescript  theme={null}\nimport { AIMessage } from \"@langchain/core/messages\";\n\nconst node = (state: z.infer<typeof State>) => {\n  const messages = state.messages;\n  const newMessage = new AIMessage(\"Hello!\");\n  return { messages: messages.concat([newMessage]), extraField: 10 };\n};\n```\n\nThis node simply appends a message to our message list, and populates an extra field.\n\n<Warning>\n  Nodes should return updates to the state directly, instead of mutating the state.\n</Warning>\n\nLet's next define a simple graph containing this node. We use [`StateGraph`](/oss/javascript/langgraph/graph-api#stategraph) to define a graph that operates on this state. We then use [`addNode`](/oss/javascript/langgraph/graph-api#nodes) populate our graph.\n\n```typescript  theme={null}\nimport { StateGraph } from \"@langchain/langgraph\";\n\nconst graph = new StateGraph(State)\n  .addNode(\"node\", node)\n  .addEdge(\"__start__\", \"node\")\n  .compile();\n```\n\nLangGraph provides built-in utilities for visualizing your graph. Let's inspect our graph. See [this section](#visualize-your-graph) for detail on visualization.\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\nIn this case, our graph just executes a single node. Let's proceed with a simple invocation:\n\n```typescript  theme={null}\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst result = await graph.invoke({ messages: [new HumanMessage(\"Hi\")], extraField: 0 });\nconsole.log(result);\n```\n\n```\n{ messages: [HumanMessage { content: 'Hi' }, AIMessage { content: 'Hello!' }], extraField: 10 }\n```\n\nNote that:\n\n* We kicked off invocation by updating a single key of the state.\n* We receive the entire state in the invocation result.\n\nFor convenience, we frequently inspect the content of [message objects](https://js.langchain.com/docs/concepts/messages/) via logging:\n\n```typescript  theme={null}\nfor (const message of result.messages) {\n  console.log(`${message.getType()}: ${message.content}`);\n}\n```\n\n```\nhuman: Hi\nai: Hello!\n```\n\n### Process state updates with reducers\n\nEach key in the state can have its own independent [reducer](/oss/javascript/langgraph/graph-api#reducers) function, which controls how updates from nodes are applied. If no reducer function is explicitly specified then it is assumed that all updates to the key should override it.\n\nFor Zod state schemas, we can define reducers by using the special `.langgraph.reducer()` method on the schema field.\n\nIn the earlier example, our node updated the `\"messages\"` key in the state by appending a message to it. Below, we add a reducer to this key, such that updates are automatically appended:\n\n```typescript  theme={null}\nimport \"@langchain/langgraph/zod\";\n\nconst State = z.object({\n  messages: z.array(z.custom<BaseMessage>()).langgraph.reducer((x, y) => x.concat(y)),  // [!code highlight]\n  extraField: z.number(),\n});\n```\n\nNow our node can be simplified:\n\n```typescript  theme={null}\nconst node = (state: z.infer<typeof State>) => {\n  const newMessage = new AIMessage(\"Hello!\");\n  return { messages: [newMessage], extraField: 10 };  // [!code highlight]\n};\n```\n\n```typescript  theme={null}\nimport { START } from \"@langchain/langgraph\";\n\nconst graph = new StateGraph(State)\n  .addNode(\"node\", node)\n  .addEdge(START, \"node\")\n  .compile();\n\nconst result = await graph.invoke({ messages: [new HumanMessage(\"Hi\")] });\n\nfor (const message of result.messages) {\n  console.log(`${message.getType()}: ${message.content}`);\n}\n```\n\n```\nhuman: Hi\nai: Hello!\n```\n\n#### MessagesState\n\nIn practice, there are additional considerations for updating lists of messages:\n\n* We may wish to update an existing message in the state.\n* We may want to accept short-hands for [message formats](/oss/javascript/langgraph/graph-api#using-messages-in-your-graph), such as [OpenAI format](https://python.langchain.com/docs/concepts/messages/#openai-format).\n\nLangGraph includes a built-in `MessagesZodMeta` that handles these considerations:\n\n```typescript  theme={null}\nimport { MessagesZodMeta } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({  // [!code highlight]\n  messages: z\n    .array(z.custom<BaseMessage>())\n    .register(registry, MessagesZodMeta),\n  extraField: z.number(),\n});\n\nconst graph = new StateGraph(State)\n  .addNode(\"node\", (state) => {\n    const newMessage = new AIMessage(\"Hello!\");\n    return { messages: [newMessage], extraField: 10 };\n  })\n  .addEdge(START, \"node\")\n  .compile();\n```\n\n```typescript  theme={null}\nconst inputMessage = { role: \"user\", content: \"Hi\" };  // [!code highlight]\n\nconst result = await graph.invoke({ messages: [inputMessage] });\n\nfor (const message of result.messages) {\n  console.log(`${message.getType()}: ${message.content}`);\n}\n```\n\n```\nhuman: Hi\nai: Hello!\n```\n\nThis is a versatile representation of state for applications involving [chat models](https://js.langchain.com/docs/concepts/chat_models/). LangGraph includes this pre-built `MessagesZodMeta` for convenience, so that we can have:\n\n```typescript  theme={null}\nimport { MessagesZodMeta } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  messages: z\n    .array(z.custom<BaseMessage>())\n    .register(registry, MessagesZodMeta),\n  extraField: z.number(),\n});\n```\n\n### Define input and output schemas\n\nBy default, `StateGraph` operates with a single schema, and all nodes are expected to communicate using that schema. However, it's also possible to define distinct input and output schemas for a graph.\n\nWhen distinct schemas are specified, an internal schema will still be used for communication between nodes. The input schema ensures that the provided input matches the expected structure, while the output schema filters the internal data to return only the relevant information according to the defined output schema.\n\nBelow, we'll see how to define distinct input and output schema.\n\n```typescript  theme={null}\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport * as z from \"zod\";\n\n// Define the schema for the input\nconst InputState = z.object({\n  question: z.string(),\n});\n\n// Define the schema for the output\nconst OutputState = z.object({\n  answer: z.string(),\n});\n\n// Define the overall schema, combining both input and output\nconst OverallState = InputState.merge(OutputState);\n\n// Build the graph with input and output schemas specified\nconst graph = new StateGraph({\n  input: InputState,\n  output: OutputState,\n  state: OverallState,\n})\n  .addNode(\"answerNode\", (state) => {\n    // Example answer and an extra key\n    return { answer: \"bye\", question: state.question };\n  })\n  .addEdge(START, \"answerNode\")\n  .addEdge(\"answerNode\", END)\n  .compile();\n\n// Invoke the graph with an input and print the result\nconsole.log(await graph.invoke({ question: \"hi\" }));\n```\n\n```\n{ answer: 'bye' }\n```\n\nNotice that the output of invoke only includes the output schema.\n\n### Pass private state between nodes\n\nIn some cases, you may want nodes to exchange information that is crucial for intermediate logic but doesn't need to be part of the main schema of the graph. This private data is not relevant to the overall input/output of the graph and should only be shared between certain nodes.\n\nBelow, we'll create an example sequential graph consisting of three nodes (node\\_1, node\\_2 and node\\_3), where private data is passed between the first two steps (node\\_1 and node\\_2), while the third step (node\\_3) only has access to the public overall state.\n\n```typescript  theme={null}\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport * as z from \"zod\";\n\n// The overall state of the graph (this is the public state shared across nodes)\nconst OverallState = z.object({\n  a: z.string(),\n});\n\n// Output from node1 contains private data that is not part of the overall state\nconst Node1Output = z.object({\n  privateData: z.string(),\n});\n\n// The private data is only shared between node1 and node2\nconst node1 = (state: z.infer<typeof OverallState>): z.infer<typeof Node1Output> => {\n  const output = { privateData: \"set by node1\" };\n  console.log(`Entered node 'node1':\\n\\tInput: ${JSON.stringify(state)}.\\n\\tReturned: ${JSON.stringify(output)}`);\n  return output;\n};\n\n// Node 2 input only requests the private data available after node1\nconst Node2Input = z.object({\n  privateData: z.string(),\n});\n\nconst node2 = (state: z.infer<typeof Node2Input>): z.infer<typeof OverallState> => {\n  const output = { a: \"set by node2\" };\n  console.log(`Entered node 'node2':\\n\\tInput: ${JSON.stringify(state)}.\\n\\tReturned: ${JSON.stringify(output)}`);\n  return output;\n};\n\n// Node 3 only has access to the overall state (no access to private data from node1)\nconst node3 = (state: z.infer<typeof OverallState>): z.infer<typeof OverallState> => {\n  const output = { a: \"set by node3\" };\n  console.log(`Entered node 'node3':\\n\\tInput: ${JSON.stringify(state)}.\\n\\tReturned: ${JSON.stringify(output)}`);\n  return output;\n};\n\n// Connect nodes in a sequence\n// node2 accepts private data from node1, whereas\n// node3 does not see the private data.\nconst graph = new StateGraph({\n  state: OverallState,\n  nodes: {\n    node1: { action: node1, output: Node1Output },\n    node2: { action: node2, input: Node2Input },\n    node3: { action: node3 },\n  }\n})\n  .addEdge(START, \"node1\")\n  .addEdge(\"node1\", \"node2\")\n  .addEdge(\"node2\", \"node3\")\n  .addEdge(\"node3\", END)\n  .compile();\n\n// Invoke the graph with the initial state\nconst response = await graph.invoke({ a: \"set at start\" });\n\nconsole.log(`\\nOutput of graph invocation: ${JSON.stringify(response)}`);\n```\n\n```\nEntered node 'node1':\n    ut: {\"a\":\"set at start\"}.\n    urned: {\"privateData\":\"set by node1\"}\nEntered node 'node2':\n    ut: {\"privateData\":\"set by node1\"}.\n    urned: {\"a\":\"set by node2\"}\nEntered node 'node3':\n    ut: {\"a\":\"set by node2\"}.\n    urned: {\"a\":\"set by node3\"}\n\nOutput of graph invocation: {\"a\":\"set by node3\"}\n```\n\n### Alternative state definitions\n\nWhile Zod schemas are the recommended approach, LangGraph also supports other ways to define state schemas:\n\n```typescript  theme={null}\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { StateGraph } from \"@langchain/langgraph\";\n\ninterface WorkflowChannelsState {\n  messages: BaseMessage[];\n  question: string;\n  answer: string;\n}\n\nconst workflowWithChannels = new StateGraph<WorkflowChannelsState>({\n  channels: {\n    messages: {\n      reducer: (currentState, updateValue) => currentState.concat(updateValue),\n      default: () => [],\n    },\n    question: null,\n    answer: null,\n  },\n});\n```\n\n## Add runtime configuration\n\nSometimes you want to be able to configure your graph when calling it. For example, you might want to be able to specify what LLM or system prompt to use at runtime, *without polluting the graph state with these parameters*.\n\nTo add runtime configuration:\n\n1. Specify a schema for your configuration\n2. Add the configuration to the function signature for nodes or conditional edges\n3. Pass the configuration into the graph.\n\nSee below for a simple example:\n\n```typescript  theme={null}\nimport { StateGraph, END, START } from \"@langchain/langgraph\";\nimport * as z from \"zod\";\n\n// 1. Specify config schema\nconst ContextSchema = z.object({\n  myRuntimeValue: z.string(),\n});\n\n// 2. Define a graph that accesses the config in a node\nconst StateSchema = z.object({\n  myStateValue: z.number(),\n});\n\nconst graph = new StateGraph(StateSchema, ContextSchema)\n  .addNode(\"node\", (state, runtime) => {\n    if (runtime?.context?.myRuntimeValue === \"a\") {  // [!code highlight]\n      return { myStateValue: 1 };\n    } else if (runtime?.context?.myRuntimeValue === \"b\") {  // [!code highlight]\n      return { myStateValue: 2 };\n    } else {\n      throw new Error(\"Unknown values.\");\n    }\n  })\n  .addEdge(START, \"node\")\n  .addEdge(\"node\", END)\n  .compile();\n\n// 3. Pass in configuration at runtime:\nconsole.log(await graph.invoke({}, { context: { myRuntimeValue: \"a\" } }));  // [!code highlight]\nconsole.log(await graph.invoke({}, { context: { myRuntimeValue: \"b\" } }));  // [!code highlight]\n```\n\n```\n{ myStateValue: 1 }\n{ myStateValue: 2 }\n```\n\n<Accordion title=\"Extended example: specifying LLM at runtime\">\n  Below we demonstrate a practical example in which we configure what LLM to use at runtime. We will use both OpenAI and Anthropic models.\n\n  ```typescript  theme={null}\n  import { ChatOpenAI } from \"@langchain/openai\";\n  import { ChatAnthropic } from \"@langchain/anthropic\";\n  import { BaseMessage } from \"@langchain/core/messages\";\n  import { MessagesZodMeta, StateGraph, START, END } from \"@langchain/langgraph\";\n  import { registry } from \"@langchain/langgraph/zod\";\n  import { RunnableConfig } from \"@langchain/core/runnables\";\n  import * as z from \"zod\";\n\n  const ConfigSchema = z.object({\n    modelProvider: z.string().default(\"anthropic\"),\n  });\n\n  const MessagesZodState = z.object({\n    messages: z\n      .array(z.custom<BaseMessage>())\n      .register(registry, MessagesZodMeta),\n  });\n\n  const MODELS = {\n    anthropic: new ChatAnthropic({ model: \"claude-haiku-4-5-20251001\" }),\n    openai: new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n  };\n\n  const graph = new StateGraph(MessagesZodState, ConfigSchema)\n    .addNode(\"model\", async (state, config) => {\n      const modelProvider = config?.configurable?.modelProvider || \"anthropic\";\n      const model = MODELS[modelProvider as keyof typeof MODELS];\n      const response = await model.invoke(state.messages);\n      return { messages: [response] };\n    })\n    .addEdge(START, \"model\")\n    .addEdge(\"model\", END)\n    .compile();\n\n  // Usage\n  const inputMessage = { role: \"user\", content: \"hi\" };\n  // With no configuration, uses default (Anthropic)\n  const response1 = await graph.invoke({ messages: [inputMessage] });\n  // Or, can set OpenAI\n  const response2 = await graph.invoke(\n    { messages: [inputMessage] },\n    { configurable: { modelProvider: \"openai\" } },\n  );\n\n  console.log(response1.messages.at(-1)?.response_metadata?.model);\n  console.log(response2.messages.at(-1)?.response_metadata?.model);\n  ```\n\n  ```\n  claude-haiku-4-5-20251001\n  gpt-4o-mini-2024-07-18\n  ```\n</Accordion>\n\n<Accordion title=\"Extended example: specifying model and system message at runtime\">\n  Below we demonstrate a practical example in which we configure two parameters: the LLM and system message to use at runtime.\n\n  ```typescript  theme={null}\n  import { ChatOpenAI } from \"@langchain/openai\";\n  import { ChatAnthropic } from \"@langchain/anthropic\";\n  import { SystemMessage, BaseMessage } from \"@langchain/core/messages\";\n  import { MessagesZodMeta, StateGraph, START, END } from \"@langchain/langgraph\";\n  import { registry } from \"@langchain/langgraph/zod\";\n  import * as z from \"zod\";\n\n  const ConfigSchema = z.object({\n    modelProvider: z.string().default(\"anthropic\"),\n    systemMessage: z.string().optional(),\n  });\n\n  const MessagesZodState = z.object({\n    messages: z\n      .array(z.custom<BaseMessage>())\n      .register(registry, MessagesZodMeta),\n  });\n\n  const MODELS = {\n    anthropic: new ChatAnthropic({ model: \"claude-haiku-4-5-20251001\" }),\n    openai: new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n  };\n\n  const graph = new StateGraph(MessagesZodState, ConfigSchema)\n    .addNode(\"model\", async (state, config) => {\n      const modelProvider = config?.configurable?.modelProvider || \"anthropic\";\n      const systemMessage = config?.configurable?.systemMessage;\n\n      const model = MODELS[modelProvider as keyof typeof MODELS];\n      let messages = state.messages;\n\n      if (systemMessage) {\n        messages = [new SystemMessage(systemMessage), ...messages];\n      }\n\n      const response = await model.invoke(messages);\n      return { messages: [response] };\n    })\n    .addEdge(START, \"model\")\n    .addEdge(\"model\", END)\n    .compile();\n\n  // Usage\n  const inputMessage = { role: \"user\", content: \"hi\" };\n  const response = await graph.invoke(\n    { messages: [inputMessage] },\n    {\n      configurable: {\n        modelProvider: \"openai\",\n        systemMessage: \"Respond in Italian.\"\n      }\n    }\n  );\n\n  for (const message of response.messages) {\n    console.log(`${message.getType()}: ${message.content}`);\n  }\n  ```\n\n  ```\n  human: hi\n  ai: Ciao! Come posso aiutarti oggi?\n  ```\n</Accordion>\n\n## Add retry policies\n\nThere are many use cases where you may wish for your node to have a custom retry policy, for example if you are calling an API, querying a database, or calling an LLM, etc. LangGraph lets you add retry policies to nodes.\n\nTo configure a retry policy, pass the `retryPolicy` parameter to the [`addNode`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.Graph.html#addnode). The `retryPolicy` parameter takes in a `RetryPolicy` object. Below we instantiate a `RetryPolicy` object with the default parameters and associate it with a node:\n\n```typescript  theme={null}\nimport { RetryPolicy } from \"@langchain/langgraph\";\n\nconst graph = new StateGraph(State)\n  .addNode(\"nodeName\", nodeFunction, { retryPolicy: {} })\n  .compile();\n```\n\nBy default, the retry policy retries on any exception except for the following:\n\n* `TypeError`\n* `SyntaxError`\n* `ReferenceError`\n\n<Accordion title=\"Extended example: customizing retry policies\">\n  Consider an example in which we are reading from a SQL database. Below we pass two different retry policies to nodes:\n\n  ```typescript  theme={null}\n  import Database from \"better-sqlite3\";\n  import { ChatAnthropic } from \"@langchain/anthropic\";\n  import { StateGraph, START, END, MessagesZodMeta } from \"@langchain/langgraph\";\n  import { registry } from \"@langchain/langgraph/zod\";\n  import { AIMessage, BaseMessage } from \"@langchain/core/messages\";\n  import * as z from \"zod\";\n\n  const MessagesZodState = z.object({\n    messages: z\n      .array(z.custom<BaseMessage>())\n      .register(registry, MessagesZodMeta),\n  });\n\n  // Create an in-memory database\n  const db: typeof Database.prototype = new Database(\":memory:\");\n\n  const model = new ChatAnthropic({ model: \"claude-3-5-sonnet-20240620\" });\n\n  const callModel = async (state: z.infer<typeof MessagesZodState>) => {\n    const response = await model.invoke(state.messages);\n    return { messages: [response] };\n  };\n\n  const queryDatabase = async (state: z.infer<typeof MessagesZodState>) => {\n    const queryResult: string = JSON.stringify(\n      db.prepare(\"SELECT * FROM Artist LIMIT 10;\").all(),\n    );\n\n    return { messages: [new AIMessage({ content: \"queryResult\" })] };\n  };\n\n  const workflow = new StateGraph(MessagesZodState)\n    // Define the two nodes we will cycle between\n    .addNode(\"call_model\", callModel, { retryPolicy: { maxAttempts: 5 } })\n    .addNode(\"query_database\", queryDatabase, {\n      retryPolicy: {\n        retryOn: (e: any): boolean => {\n          if (e instanceof Database.SqliteError) {\n            // Retry on \"SQLITE_BUSY\" error\n            return e.code === \"SQLITE_BUSY\";\n          }\n          return false; // Don't retry on other errors\n        },\n      },\n    })\n    .addEdge(START, \"call_model\")\n    .addEdge(\"call_model\", \"query_database\")\n    .addEdge(\"query_database\", END);\n\n  const graph = workflow.compile();\n  ```\n</Accordion>\n\n## Create a sequence of steps\n\n<Info>\n  **Prerequisites**\n  This guide assumes familiarity with the above section on [state](#define-and-update-state).\n</Info>\n\nHere we demonstrate how to construct a simple sequence of steps. We will show:\n\n1. How to build a sequential graph\n2. Built-in short-hand for constructing similar graphs.\n\nTo add a sequence of nodes, we use the `.addNode` and `.addEdge` methods of our [graph](/oss/javascript/langgraph/graph-api#stategraph):\n\n```typescript  theme={null}\nimport { START, StateGraph } from \"@langchain/langgraph\";\n\nconst builder = new StateGraph(State)\n  .addNode(\"step1\", step1)\n  .addNode(\"step2\", step2)\n  .addNode(\"step3\", step3)\n  .addEdge(START, \"step1\")\n  .addEdge(\"step1\", \"step2\")\n  .addEdge(\"step2\", \"step3\");\n```\n\n<Accordion title=\"Why split application steps into a sequence with LangGraph?\">\n  LangGraph makes it easy to add an underlying persistence layer to your application.\n  This allows state to be checkpointed in between the execution of nodes, so your LangGraph nodes govern:\n\n  * How state updates are [checkpointed](/oss/javascript/langgraph/persistence)\n  * How interruptions are resumed in [human-in-the-loop](/oss/javascript/langgraph/interrupts) workflows\n  * How we can \"rewind\" and branch-off executions using LangGraph's [time travel](/oss/javascript/langgraph/use-time-travel) features\n\n  They also determine how execution steps are [streamed](/oss/javascript/langgraph/streaming), and how your application is visualized and debugged using [Studio](/langsmith/studio).\n\n  Let's demonstrate an end-to-end example. We will create a sequence of three steps:\n\n  1. Populate a value in a key of the state\n  2. Update the same value\n  3. Populate a different value\n\n  Let's first define our [state](/oss/javascript/langgraph/graph-api#state). This governs the [schema of the graph](/oss/javascript/langgraph/graph-api#schema), and can also specify how to apply updates. See [this section](#process-state-updates-with-reducers) for more detail.\n\n  In our case, we will just keep track of two values:\n\n  ```typescript  theme={null}\n  import * as z from \"zod\";\n\n  const State = z.object({\n    value1: z.string(),\n    value2: z.number(),\n  });\n  ```\n\n  Our [nodes](/oss/javascript/langgraph/graph-api#nodes) are just TypeScript functions that read our graph's state and make updates to it. The first argument to this function will always be the state:\n\n  ```typescript  theme={null}\n  const step1 = (state: z.infer<typeof State>) => {\n    return { value1: \"a\" };\n  };\n\n  const step2 = (state: z.infer<typeof State>) => {\n    const currentValue1 = state.value1;\n    return { value1: `${currentValue1} b` };\n  };\n\n  const step3 = (state: z.infer<typeof State>) => {\n    return { value2: 10 };\n  };\n  ```\n\n  <Note>\n    Note that when issuing updates to the state, each node can just specify the value of the key it wishes to update.\n\n    By default, this will **overwrite** the value of the corresponding key. You can also use [reducers](/oss/javascript/langgraph/graph-api#reducers) to control how updates are processed— for example, you can append successive updates to a key instead. See [this section](#process-state-updates-with-reducers) for more detail.\n  </Note>\n\n  Finally, we define the graph. We use [StateGraph](/oss/javascript/langgraph/graph-api#stategraph) to define a graph that operates on this state.\n\n  We will then use [addNode](/oss/javascript/langgraph/graph-api#nodes) and [addEdge](/oss/javascript/langgraph/graph-api#edges) to populate our graph and define its control flow.\n\n  ```typescript  theme={null}\n  import { START, StateGraph } from \"@langchain/langgraph\";\n\n  const graph = new StateGraph(State)\n    .addNode(\"step1\", step1)\n    .addNode(\"step2\", step2)\n    .addNode(\"step3\", step3)\n    .addEdge(START, \"step1\")\n    .addEdge(\"step1\", \"step2\")\n    .addEdge(\"step2\", \"step3\")\n    .compile();\n  ```\n\n  <Tip>\n    **Specifying custom names**\n    You can specify custom names for nodes using `.addNode`:\n\n    ```typescript  theme={null}\n    const graph = new StateGraph(State)\n    .addNode(\"myNode\", step1)\n    .compile();\n    ```\n  </Tip>\n\n  Note that:\n\n  * `.addEdge` takes the names of nodes, which for functions defaults to `node.name`.\n  * We must specify the entry point of the graph. For this we add an edge with the [START node](/oss/javascript/langgraph/graph-api#start-node).\n  * The graph halts when there are no more nodes to execute.\n\n  We next [compile](/oss/javascript/langgraph/graph-api#compiling-your-graph) our graph. This provides a few basic checks on the structure of the graph (e.g., identifying orphaned nodes). If we were adding persistence to our application via a [checkpointer](/oss/javascript/langgraph/persistence), it would also be passed in here.\n\n  LangGraph provides built-in utilities for visualizing your graph. Let's inspect our sequence. See [this guide](#visualize-your-graph) for detail on visualization.\n\n  ```typescript  theme={null}\n  import * as fs from \"node:fs/promises\";\n\n  const drawableGraph = await graph.getGraphAsync();\n  const image = await drawableGraph.drawMermaidPng();\n  const imageBuffer = new Uint8Array(await image.arrayBuffer());\n\n  await fs.writeFile(\"graph.png\", imageBuffer);\n  ```\n\n  Let's proceed with a simple invocation:\n\n  ```typescript  theme={null}\n  const result = await graph.invoke({ value1: \"c\" });\n  console.log(result);\n  ```\n\n  ```\n  { value1: 'a b', value2: 10 }\n  ```\n\n  Note that:\n\n  * We kicked off invocation by providing a value for a single state key. We must always provide a value for at least one key.\n  * The value we passed in was overwritten by the first node.\n  * The second node updated the value.\n  * The third node populated a different value.\n</Accordion>\n\n## Create branches\n\nParallel execution of nodes is essential to speed up overall graph operation. LangGraph offers native support for parallel execution of nodes, which can significantly enhance the performance of graph-based workflows. This parallelization is achieved through fan-out and fan-in mechanisms, utilizing both standard edges and [conditional\\_edges](https://langchain-ai.github.io/langgraph/reference/graphs.md#langgraph.graph.MessageGraph.add_conditional_edges). Below are some examples showing how to add create branching dataflows that work for you.\n\n### Run graph nodes in parallel\n\nIn this example, we fan out from `Node A` to `B and C` and then fan in to `D`. With our state, [we specify the reducer add operation](/oss/javascript/langgraph/graph-api#reducers). This will combine or accumulate values for the specific key in the State, rather than simply overwriting the existing value. For lists, this means concatenating the new list with the existing list. See the above section on [state reducers](#process-state-updates-with-reducers) for more detail on updating state with reducers.\n\n```typescript  theme={null}\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  // The reducer makes this append-only\n  aggregate: z.array(z.string()).register(registry, {\n    reducer: {\n      fn: (x, y) => x.concat(y),\n    },\n    default: () => [] as string[],\n  }),\n});\n\nconst nodeA = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"A\" to ${state.aggregate}`);\n  return { aggregate: [\"A\"] };\n};\n\nconst nodeB = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"B\" to ${state.aggregate}`);\n  return { aggregate: [\"B\"] };\n};\n\nconst nodeC = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"C\" to ${state.aggregate}`);\n  return { aggregate: [\"C\"] };\n};\n\nconst nodeD = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"D\" to ${state.aggregate}`);\n  return { aggregate: [\"D\"] };\n};\n\nconst graph = new StateGraph(State)\n  .addNode(\"a\", nodeA)\n  .addNode(\"b\", nodeB)\n  .addNode(\"c\", nodeC)\n  .addNode(\"d\", nodeD)\n  .addEdge(START, \"a\")\n  .addEdge(\"a\", \"b\")\n  .addEdge(\"a\", \"c\")\n  .addEdge(\"b\", \"d\")\n  .addEdge(\"c\", \"d\")\n  .addEdge(\"d\", END)\n  .compile();\n```\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\nWith the reducer, you can see that the values added in each node are accumulated.\n\n```typescript  theme={null}\nconst result = await graph.invoke({\n  aggregate: [],\n});\nconsole.log(result);\n```\n\n```\nAdding \"A\" to []\nAdding \"B\" to ['A']\nAdding \"C\" to ['A']\nAdding \"D\" to ['A', 'B', 'C']\n{ aggregate: ['A', 'B', 'C', 'D'] }\n```\n\n<Note>\n  In the above example, nodes `\"b\"` and `\"c\"` are executed concurrently in the same [superstep](/oss/javascript/langgraph/graph-api#graphs). Because they are in the same step, node `\"d\"` executes after both `\"b\"` and `\"c\"` are finished.\n\n  Importantly, updates from a parallel superstep may not be ordered consistently. If you need a consistent, predetermined ordering of updates from a parallel superstep, you should write the outputs to a separate field in the state together with a value with which to order them.\n</Note>\n\n<Accordion title=\"Exception handling?\">\n  LangGraph executes nodes within [supersteps](/oss/javascript/langgraph/graph-api#graphs), meaning that while parallel branches are executed in parallel, the entire superstep is **transactional**. If any of these branches raises an exception, **none** of the updates are applied to the state (the entire superstep errors).\n\n  Importantly, when using a [checkpointer](/oss/javascript/langgraph/persistence), results from successful nodes within a superstep are saved, and don't repeat when resumed.\n\n  If you have error-prone (perhaps want to handle flakey API calls), LangGraph provides two ways to address this:\n\n  1. You can write regular python code within your node to catch and handle exceptions.\n  2. You can set a **[retry\\_policy](https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.RetryPolicy)** to direct the graph to retry nodes that raise certain types of exceptions. Only failing branches are retried, so you needn't worry about performing redundant work.\n\n  Together, these let you perform parallel execution and fully control exception handling.\n</Accordion>\n\n<Tip>\n  **Set max concurrency**\n  You can control the maximum number of concurrent tasks by setting `max_concurrency` in the [configuration](https://reference.langchain.com/javascript/interfaces/_langchain_langgraph.index.LangGraphRunnableConfig.html) when invoking the graph.\n\n  ```typescript  theme={null}\n  const result = await graph.invoke({ value1: \"c\" }, {configurable: {max_concurrency: 10}});\n  ```\n</Tip>\n\n### Conditional branching\n\nIf your fan-out should vary at runtime based on the state, you can use [`addConditionalEdges`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.StateGraph.html#addconditionaledges) to select one or more paths using the graph state. See example below, where node `a` generates a state update that determines the following node.\n\n```typescript  theme={null}\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  aggregate: z.array(z.string()).register(registry, {\n    reducer: {\n      fn: (x, y) => x.concat(y),\n    },\n    default: () => [] as string[],\n  }),\n  // Add a key to the state. We will set this key to determine\n  // how we branch.\n  which: z.string().register(registry, {  // [!code highlight]\n    reducer: {\n      fn: (x, y) => y ?? x,\n    },\n  }),\n});\n\nconst nodeA = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"A\" to ${state.aggregate}`);\n  return { aggregate: [\"A\"], which: \"c\" };\n};\n\nconst nodeB = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"B\" to ${state.aggregate}`);\n  return { aggregate: [\"B\"] };\n};\n\nconst nodeC = (state: z.infer<typeof State>) => {\n  console.log(`Adding \"C\" to ${state.aggregate}`);\n  return { aggregate: [\"C\"] };  // [!code highlight]\n};\n\nconst conditionalEdge = (state: z.infer<typeof State>): \"b\" | \"c\" => {\n  // Fill in arbitrary logic here that uses the state\n  // to determine the next node\n  return state.which as \"b\" | \"c\";\n};\n\nconst graph = new StateGraph(State)\n  .addNode(\"a\", nodeA)\n  .addNode(\"b\", nodeB)\n  .addNode(\"c\", nodeC)\n  .addEdge(START, \"a\")\n  .addEdge(\"b\", END)\n  .addEdge(\"c\", END)\n  .addConditionalEdges(\"a\", conditionalEdge)\n  .compile();\n```\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\n```typescript  theme={null}\nconst result = await graph.invoke({ aggregate: [] });\nconsole.log(result);\n```\n\n```\nAdding \"A\" to []\nAdding \"C\" to ['A']\n{ aggregate: ['A', 'C'], which: 'c' }\n```\n\n<Tip>\n  Your conditional edges can route to multiple destination nodes. For example:\n\n  ```typescript  theme={null}\n  const routeBcOrCd = (state: z.infer<typeof State>): string[] => {\n  if (state.which === \"cd\") {\n  return [\"c\", \"d\"];\n  }\n  return [\"b\", \"c\"];\n  };\n  ```\n</Tip>\n\n## Map-Reduce and the Send API\n\nLangGraph supports map-reduce and other advanced branching patterns using the Send API. Here is an example of how to use it:\n\n```typescript  theme={null}\nimport { StateGraph, START, END, Send } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst OverallState = z.object({\n  topic: z.string(),\n  subjects: z.array(z.string()),\n  jokes: z.array(z.string()).register(registry, {\n    reducer: {\n      fn: (x, y) => x.concat(y),\n    },\n  }),\n  bestSelectedJoke: z.string(),\n});\n\nconst generateTopics = (state: z.infer<typeof OverallState>) => {\n  return { subjects: [\"lions\", \"elephants\", \"penguins\"] };\n};\n\nconst generateJoke = (state: { subject: string }) => {\n  const jokeMap: Record<string, string> = {\n    lions: \"Why don't lions like fast food? Because they can't catch it!\",\n    elephants: \"Why don't elephants use computers? They're afraid of the mouse!\",\n    penguins: \"Why don't penguins like talking to strangers at parties? Because they find it hard to break the ice.\"\n  };\n  return { jokes: [jokeMap[state.subject]] };\n};\n\nconst continueToJokes = (state: z.infer<typeof OverallState>) => {\n  return state.subjects.map((subject) => new Send(\"generateJoke\", { subject }));\n};\n\nconst bestJoke = (state: z.infer<typeof OverallState>) => {\n  return { bestSelectedJoke: \"penguins\" };\n};\n\nconst graph = new StateGraph(OverallState)\n  .addNode(\"generateTopics\", generateTopics)\n  .addNode(\"generateJoke\", generateJoke)\n  .addNode(\"bestJoke\", bestJoke)\n  .addEdge(START, \"generateTopics\")\n  .addConditionalEdges(\"generateTopics\", continueToJokes)\n  .addEdge(\"generateJoke\", \"bestJoke\")\n  .addEdge(\"bestJoke\", END)\n  .compile();\n```\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\n```typescript  theme={null}\n// Call the graph: here we call it to generate a list of jokes\nfor await (const step of await graph.stream({ topic: \"animals\" })) {\n  console.log(step);\n}\n```\n\n```\n{ generateTopics: { subjects: [ 'lions', 'elephants', 'penguins' ] } }\n{ generateJoke: { jokes: [ \"Why don't lions like fast food? Because they can't catch it!\" ] } }\n{ generateJoke: { jokes: [ \"Why don't elephants use computers? They're afraid of the mouse!\" ] } }\n{ generateJoke: { jokes: [ \"Why don't penguins like talking to strangers at parties? Because they find it hard to break the ice.\" ] } }\n{ bestJoke: { bestSelectedJoke: 'penguins' } }\n```\n\n## Create and control loops\n\nWhen creating a graph with a loop, we require a mechanism for terminating execution. This is most commonly done by adding a [conditional edge](/oss/javascript/langgraph/graph-api#conditional-edges) that routes to the [END](/oss/javascript/langgraph/graph-api#end-node) node once we reach some termination condition.\n\nYou can also set the graph recursion limit when invoking or streaming the graph. The recursion limit sets the number of [supersteps](/oss/javascript/langgraph/graph-api#graphs) that the graph is allowed to execute before it raises an error. Read more about the concept of recursion limits [here](/oss/javascript/langgraph/graph-api#recursion-limit).\n\nLet's consider a simple graph with a loop to better understand how these mechanisms work.\n\n<Tip>\n  To return the last value of your state instead of receiving a recursion limit error, see the [next section](#impose-a-recursion-limit).\n</Tip>\n\nWhen creating a loop, you can include a conditional edge that specifies a termination condition:\n\n```typescript  theme={null}\nconst graph = new StateGraph(State)\n  .addNode(\"a\", nodeA)\n  .addNode(\"b\", nodeB)\n  .addEdge(START, \"a\")\n  .addConditionalEdges(\"a\", route)\n  .addEdge(\"b\", \"a\")\n  .compile();\n\nconst route = (state: z.infer<typeof State>): \"b\" | typeof END => {\n  if (terminationCondition(state)) {\n    return END;\n  } else {\n    return \"b\";\n  }\n};\n```\n\nTo control the recursion limit, specify `\"recursionLimit\"` in the config. This will raise a `GraphRecursionError`, which you can catch and handle:\n\n```typescript  theme={null}\nimport { GraphRecursionError } from \"@langchain/langgraph\";\n\ntry {\n  await graph.invoke(inputs, { recursionLimit: 3 });\n} catch (error) {\n  if (error instanceof GraphRecursionError) {\n    console.log(\"Recursion Error\");\n  }\n}\n```\n\nLet's define a graph with a simple loop. Note that we use a conditional edge to implement a termination condition.\n\n```typescript  theme={null}\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  // The reducer makes this append-only\n  aggregate: z.array(z.string()).register(registry, {\n    reducer: {\n      fn: (x, y) => x.concat(y),\n    },\n    default: () => [] as string[],\n  }),\n});\n\nconst nodeA = (state: z.infer<typeof State>) => {\n  console.log(`Node A sees ${state.aggregate}`);\n  return { aggregate: [\"A\"] };\n};\n\nconst nodeB = (state: z.infer<typeof State>) => {\n  console.log(`Node B sees ${state.aggregate}`);\n  return { aggregate: [\"B\"] };\n};\n\n// Define edges\nconst route = (state: z.infer<typeof State>): \"b\" | typeof END => {\n  if (state.aggregate.length < 7) {\n    return \"b\";\n  } else {\n    return END;\n  }\n};\n\nconst graph = new StateGraph(State)\n  .addNode(\"a\", nodeA)\n  .addNode(\"b\", nodeB)\n  .addEdge(START, \"a\")\n  .addConditionalEdges(\"a\", route)\n  .addEdge(\"b\", \"a\")\n  .compile();\n```\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\nThis architecture is similar to a [ReAct agent](/oss/javascript/langgraph/workflows-agents) in which node `\"a\"` is a tool-calling model, and node `\"b\"` represents the tools.\n\nIn our `route` conditional edge, we specify that we should end after the `\"aggregate\"` list in the state passes a threshold length.\n\nInvoking the graph, we see that we alternate between nodes `\"a\"` and `\"b\"` before terminating once we reach the termination condition.\n\n```typescript  theme={null}\nconst result = await graph.invoke({ aggregate: [] });\nconsole.log(result);\n```\n\n```\nNode A sees []\nNode B sees ['A']\nNode A sees ['A', 'B']\nNode B sees ['A', 'B', 'A']\nNode A sees ['A', 'B', 'A', 'B']\nNode B sees ['A', 'B', 'A', 'B', 'A']\nNode A sees ['A', 'B', 'A', 'B', 'A', 'B']\n{ aggregate: ['A', 'B', 'A', 'B', 'A', 'B', 'A'] }\n```\n\n### Impose a recursion limit\n\nIn some applications, we may not have a guarantee that we will reach a given termination condition. In these cases, we can set the graph's [recursion limit](/oss/javascript/langgraph/graph-api#recursion-limit). This will raise a `GraphRecursionError` after a given number of [supersteps](/oss/javascript/langgraph/graph-api#graphs). We can then catch and handle this exception:\n\n```typescript  theme={null}\nimport { GraphRecursionError } from \"@langchain/langgraph\";\n\ntry {\n  await graph.invoke({ aggregate: [] }, { recursionLimit: 4 });\n} catch (error) {\n  if (error instanceof GraphRecursionError) {\n    console.log(\"Recursion Error\");\n  }\n}\n```\n\n```\nNode A sees []\nNode B sees ['A']\nNode A sees ['A', 'B']\nNode B sees ['A', 'B', 'A']\nNode A sees ['A', 'B', 'A', 'B']\nRecursion Error\n```\n\n## Combine control flow and state updates with `Command`\n\nIt can be useful to combine control flow (edges) and state updates (nodes). For example, you might want to BOTH perform state updates AND decide which node to go to next in the SAME node. LangGraph provides a way to do so by returning a [Command](https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.Command) object from node functions:\n\n```typescript  theme={null}\nimport { Command } from \"@langchain/langgraph\";\n\nconst myNode = (state: State): Command => {\n  return new Command({\n    // state update\n    update: { foo: \"bar\" },\n    // control flow\n    goto: \"myOtherNode\"\n  });\n};\n```\n\nWe show an end-to-end example below. Let's create a simple graph with 3 nodes: A, B and C. We will first execute node A, and then decide whether to go to Node B or Node C next based on the output of node A.\n\n```typescript  theme={null}\nimport { StateGraph, START, Command } from \"@langchain/langgraph\";\nimport * as z from \"zod\";\n\n// Define graph state\nconst State = z.object({\n  foo: z.string(),\n});\n\n// Define the nodes\n\nconst nodeA = (state: z.infer<typeof State>): Command => {\n  console.log(\"Called A\");\n  const value = Math.random() > 0.5 ? \"b\" : \"c\";\n  // this is a replacement for a conditional edge function\n  const goto = value === \"b\" ? \"nodeB\" : \"nodeC\";\n\n  // note how Command allows you to BOTH update the graph state AND route to the next node\n  return new Command({\n    // this is the state update\n    update: { foo: value },\n    // this is a replacement for an edge\n    goto,\n  });\n};\n\nconst nodeB = (state: z.infer<typeof State>) => {\n  console.log(\"Called B\");\n  return { foo: state.foo + \"b\" };\n};\n\nconst nodeC = (state: z.infer<typeof State>) => {\n  console.log(\"Called C\");\n  return { foo: state.foo + \"c\" };\n};\n```\n\nWe can now create the `StateGraph` with the above nodes. Notice that the graph doesn't have [conditional edges](/oss/javascript/langgraph/graph-api#conditional-edges) for routing! This is because control flow is defined with `Command` inside `nodeA`.\n\n```typescript  theme={null}\nconst graph = new StateGraph(State)\n  .addNode(\"nodeA\", nodeA, {\n    ends: [\"nodeB\", \"nodeC\"],\n  })\n  .addNode(\"nodeB\", nodeB)\n  .addNode(\"nodeC\", nodeC)\n  .addEdge(START, \"nodeA\")\n  .compile();\n```\n\n<Warning>\n  You might have noticed that we used `ends` to specify which nodes `nodeA` can navigate to. This is necessary for the graph rendering and tells LangGraph that `nodeA` can navigate to `nodeB` and `nodeC`.\n</Warning>\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\nIf we run the graph multiple times, we'd see it take different paths (A -> B or A -> C) based on the random choice in node A.\n\n```typescript  theme={null}\nconst result = await graph.invoke({ foo: \"\" });\nconsole.log(result);\n```\n\n```\nCalled A\nCalled C\n{ foo: 'cc' }\n```\n\n### Navigate to a node in a parent graph\n\nIf you are using [subgraphs](/oss/javascript/langgraph/use-subgraphs), you might want to navigate from a node within a subgraph to a different subgraph (i.e. a different node in the parent graph). To do so, you can specify `graph=Command.PARENT` in `Command`:\n\n```typescript  theme={null}\nconst myNode = (state: State): Command => {\n  return new Command({\n    update: { foo: \"bar\" },\n    goto: \"otherSubgraph\",  // where `otherSubgraph` is a node in the parent graph\n    graph: Command.PARENT\n  });\n};\n```\n\nLet's demonstrate this using the above example. We'll do so by changing `nodeA` in the above example into a single-node graph that we'll add as a subgraph to our parent graph.\n\n<Warning>\n  **State updates with `Command.PARENT`**\n  When you send updates from a subgraph node to a parent graph node for a key that's shared by both parent and subgraph [state schemas](/oss/javascript/langgraph/graph-api#schema), you **must** define a [reducer](/oss/javascript/langgraph/graph-api#reducers) for the key you're updating in the parent graph state. See the example below.\n</Warning>\n\n```typescript  theme={null}\nimport { StateGraph, START, Command } from \"@langchain/langgraph\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  // NOTE: we define a reducer here\n  foo: z.string().register(registry, {  // [!code highlight]\n    reducer: {\n      fn: (x, y) => x + y,\n    },\n  }),\n});\n\nconst nodeA = (state: z.infer<typeof State>) => {\n  console.log(\"Called A\");\n  const value = Math.random() > 0.5 ? \"nodeB\" : \"nodeC\";\n\n  // note how Command allows you to BOTH update the graph state AND route to the next node\n  return new Command({\n    update: { foo: \"a\" },  // [!code highlight]\n    goto: value,\n    // this tells LangGraph to navigate to nodeB or nodeC in the parent graph\n    // NOTE: this will navigate to the closest parent graph relative to the subgraph\n    graph: Command.PARENT,\n  });\n};\n\nconst subgraph = new StateGraph(State)\n  .addNode(\"nodeA\", nodeA, { ends: [\"nodeB\", \"nodeC\"] })\n  .addEdge(START, \"nodeA\")\n  .compile();\n\nconst nodeB = (state: z.infer<typeof State>) => {\n  console.log(\"Called B\");  // [!code highlight]\n  // NOTE: since we've defined a reducer, we don't need to manually append\n  // new characters to existing 'foo' value. instead, reducer will append these\n  // automatically\n  return { foo: \"b\" };\n};  // [!code highlight]\n\nconst nodeC = (state: z.infer<typeof State>) => {\n  console.log(\"Called C\");\n  return { foo: \"c\" };\n};\n\nconst graph = new StateGraph(State)\n  .addNode(\"subgraph\", subgraph, { ends: [\"nodeB\", \"nodeC\"] })\n  .addNode(\"nodeB\", nodeB)\n  .addNode(\"nodeC\", nodeC)\n  .addEdge(START, \"subgraph\")\n  .compile();\n```\n\n```typescript  theme={null}\nconst result = await graph.invoke({ foo: \"\" });\nconsole.log(result);\n```\n\n```\nCalled A\nCalled C\n{ foo: 'ac' }\n```\n\n### Use inside tools\n\nA common use case is updating graph state from inside a tool. For example, in a customer support application you might want to look up customer information based on their account number or ID in the beginning of the conversation. To update the graph state from the tool, you can return `Command(update={\"my_custom_key\": \"foo\", \"messages\": [...]})` from the tool:\n\n```typescript  theme={null}\nimport { tool } from \"@langchain/core/tools\";\nimport { Command } from \"@langchain/langgraph\";\nimport * as z from \"zod\";\n\nconst lookupUserInfo = tool(\n  async (input, config) => {\n    const userId = config.configurable?.userId;\n    const userInfo = getUserInfo(userId);\n    return new Command({\n      update: {\n        // update the state keys\n        userInfo: userInfo,\n        // update the message history\n        messages: [{\n          role: \"tool\",\n          content: \"Successfully looked up user information\",\n          tool_call_id: config.toolCall.id\n        }]\n      }\n    });\n  },\n  {\n    name: \"lookupUserInfo\",\n    description: \"Use this to look up user information to better assist them with their questions.\",\n    schema: z.object({}),\n  }\n);\n```\n\n<Warning>\n  You MUST include `messages` (or any state key used for the message history) in `Command.update` when returning [`Command`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.Command.html) from a tool and the list of messages in `messages` MUST contain a `ToolMessage`. This is necessary for the resulting message history to be valid (LLM providers require AI messages with tool calls to be followed by the tool result messages).\n</Warning>\n\nIf you are using tools that update state via [`Command`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.Command.html), we recommend using prebuilt [`ToolNode`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.prebuilt.ToolNode.html) which automatically handles tools returning [`Command`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.Command.html) objects and propagates them to the graph state. If you're writing a custom node that calls tools, you would need to manually propagate [`Command`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.Command.html) objects returned by the tools as the update from the node.\n\n## Visualize your graph\n\nHere we demonstrate how to visualize the graphs you create.\n\nYou can visualize any arbitrary [Graph](https://langchain-ai.github.io/langgraph/reference/graphs/), including [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph).\n\nLet's create a simple example graph to demonstrate visualization.\n\n```typescript  theme={null}\nimport { StateGraph, START, END, MessagesZodMeta } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { registry } from \"@langchain/langgraph/zod\";\nimport * as z from \"zod\";\n\nconst State = z.object({\n  messages: z\n    .array(z.custom<BaseMessage>())\n    .register(registry, MessagesZodMeta),\n  value: z.number().register(registry, {\n    reducer: {\n      fn: (x, y) => x + y,\n    },\n  }),\n});\n\nconst app = new StateGraph(State)\n  .addNode(\"node1\", (state) => {\n    return { value: state.value + 1 };\n  })\n  .addNode(\"node2\", (state) => {\n    return { value: state.value * 2 };\n  })\n  .addEdge(START, \"node1\")\n  .addConditionalEdges(\"node1\", (state) => {\n    if (state.value < 10) {\n      return \"node2\";\n    }\n    return END;\n  })\n  .addEdge(\"node2\", \"node1\")\n  .compile();\n```\n\n### Mermaid\n\nWe can also convert a graph class into Mermaid syntax.\n\n```typescript  theme={null}\nconst drawableGraph = await app.getGraphAsync();\nconsole.log(drawableGraph.drawMermaid());\n```\n\n```\n%%{init: {'flowchart': {'curve': 'linear'}}}%%\ngraph TD;\n    tart__([<p>__start__</p>]):::first\n    e1(node1)\n    e2(node2)\n    nd__([<p>__end__</p>]):::last\n    tart__ --> node1;\n    e1 -.-> node2;\n    e1 -.-> __end__;\n    e2 --> node1;\n    ssDef default fill:#f2f0ff,line-height:1.2\n    ssDef first fill-opacity:0\n    ssDef last fill:#bfb6fc\n```\n\n### PNG\n\nIf preferred, we could render the Graph into a `.png`. This uses the Mermaid.ink API to generate the diagram.\n\n```typescript  theme={null}\nimport * as fs from \"node:fs/promises\";\n\nconst drawableGraph = await app.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst imageBuffer = new Uint8Array(await image.arrayBuffer());\n\nawait fs.writeFile(\"graph.png\", imageBuffer);\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langgraph/use-graph-api.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 54081
}