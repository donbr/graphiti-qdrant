{
  "title": "Trace with Instructor",
  "source_url": "https://docs.langchain.com/langsmith/trace-with-instructor",
  "content": "LangSmith provides a convenient integration with [Instructor](https://python.useinstructor.com/), a popular open-source library for generating structured output with LLMs.\n\nIn order to use, you first need to set your LangSmith API key.\n\n```shell  theme={null}\nexport LANGSMITH_API_KEY=<your-api-key>\n# For LangSmith API keys linked to multiple workspaces, set the LANGSMITH_WORKSPACE_ID environment variable to specify which workspace to use.\nexport LANGSMITH_WORKSPACE_ID=<your-workspace-id>\n```\n\nNext, you will need to install the LangSmith SDK:\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install -U langsmith\n  ```\n\n  ```bash uv theme={null}\n  uv add langsmith\n  ```\n</CodeGroup>\n\nWrap your OpenAI client with `langsmith.wrappers.wrap_openai`\n\n```python  theme={null}\nfrom openai import OpenAI\nfrom langsmith import wrappers\n\nclient = wrappers.wrap_openai(OpenAI())\n```\n\nAfter this, you can patch the wrapped OpenAI client using `instructor`:\n\n```python  theme={null}\nimport instructor\n\nclient = instructor.patch(client)\n```\n\nNow, you can use `instructor` as you normally would, but now everything is logged to LangSmith!\n\n```python  theme={null}\nfrom pydantic import BaseModel\n\n\nclass UserDetail(BaseModel):\n    name: str\n    age: int\n\n\nuser = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=UserDetail,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n    ]\n)\n```\n\nOftentimes, you use `instructor` inside of other functions.\nYou can get nested traces by using this wrapped client and decorating those functions with `@traceable`.\nPlease see [this guide](./annotate-code) for more information on how to annotate your code for tracing with the `@traceable` decorator.\n\n```python {highlight={2}} theme={null}\n# You can customize the run name with the `name` keyword argument\n@traceable(name=\"Extract User Details\")\ndef my_function(text: str) -> UserDetail:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": f\"Extract {text}\"},\n        ]\n    )\n\nmy_function(\"Jason is 25 years old\")\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/trace-with-instructor.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 2533
}