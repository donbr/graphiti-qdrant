{
  "title": "Hugging Face",
  "source_url": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
  "content": "This page covers all LangChain integrations with [Hugging Face Hub](https://huggingface.co/) and libraries like [transformers](https://huggingface.co/docs/transformers/index), [sentence transformers](https://sbert.net/), and [datasets](https://huggingface.co/docs/datasets/index).\n\n## Chat models\n\n### ChatHuggingFace\n\nWe can use the `Hugging Face` LLM classes or directly use the `ChatHuggingFace` class.\n\nSee a [usage example](/oss/python/integrations/chat/huggingface).\n\n```python  theme={null}\nfrom langchain_huggingface import ChatHuggingFace\n```\n\n## LLMs\n\n### HuggingFaceEndpoint\n\nWe can use the `HuggingFaceEndpoint` class to run open source models via serverless [Inference Providers](https://huggingface.co/docs/inference-providers) or via dedicated [Inference Endpoints](https://huggingface.co/inference-endpoints/dedicated).\n\nSee a [usage example](/oss/python/integrations/llms/huggingface_endpoint).\n\n```python  theme={null}\nfrom langchain_huggingface import HuggingFaceEndpoint\n```\n\n### HuggingFacePipeline\n\nWe can use the `HuggingFacePipeline` class to run open source models locally.\n\nSee a [usage example](/oss/python/integrations/llms/huggingface_pipelines).\n\n```python  theme={null}\nfrom langchain_huggingface import HuggingFacePipeline\n```\n\n## Embedding Models\n\n### HuggingFaceEmbeddings\n\nWe can use the `HuggingFaceEmbeddings` class to run open source embedding models locally.\n\nSee a [usage example](/oss/python/integrations/text_embedding/huggingfacehub).\n\n```python  theme={null}\nfrom langchain_huggingface import HuggingFaceEmbeddings\n```\n\n### HuggingFaceEndpointEmbeddings\n\nWe can use the `HuggingFaceEndpointEmbeddings` class to run open source embedding models via a dedicated [Inference Endpoint](https://huggingface.co/inference-endpoints/dedicated).\n\nSee a [usage example](/oss/python/integrations/text_embedding/huggingfacehub).\n\n```python  theme={null}\nfrom langchain_huggingface import HuggingFaceEndpointEmbeddings\n```\n\n### HuggingFaceInferenceAPIEmbeddings\n\nWe can use the `HuggingFaceInferenceAPIEmbeddings` class to run open source embedding models via [Inference Providers](https://huggingface.co/docs/inference-providers).\n\nSee a [usage example](/oss/python/integrations/text_embedding/huggingfacehub).\n\n```python  theme={null}\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n```\n\n### HuggingFaceInstructEmbeddings\n\nWe can use the `HuggingFaceInstructEmbeddings` class to run open source embedding models locally.\n\nSee a [usage example](/oss/python/integrations/text_embedding/instruct_embeddings).\n\n```python  theme={null}\nfrom langchain_community.embeddings import HuggingFaceInstructEmbeddings\n```\n\n### HuggingFaceBgeEmbeddings\n\n> [BGE models on the HuggingFace](https://huggingface.co/BAAI/bge-large-en-v1.5) are one of [the best open-source embedding models](https://huggingface.co/spaces/mteb/leaderboard).\n> BGE model is created by the [Beijing Academy of Artificial Intelligence (BAAI)](https://en.wikipedia.org/wiki/Beijing_Academy_of_Artificial_Intelligence). `BAAI` is a private non-profit organization engaged in AI research and development.\n\nSee a [usage example](/oss/python/integrations/text_embedding/bge_huggingface).\n\n```python  theme={null}\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\n```\n\n## Document loaders\n\n### Hugging Face dataset\n\n> [Hugging Face Hub](https://huggingface.co/docs/hub/index) is home to over 75,000\n> [datasets](https://huggingface.co/docs/hub/index#datasets) in more than 100 languages\n> that can be used for a broad range of tasks across NLP, Computer Vision, and Audio.\n> They used for a diverse range of tasks such as translation, automatic speech\n> recognition, and image classification.\n\nWe need to install `datasets` python package.\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install datasets\n  ```\n\n  ```bash uv theme={null}\n  uv add datasets\n  ```\n</CodeGroup>\n\nSee a [usage example](/oss/python/integrations/document_loaders/hugging_face_dataset).\n\n```python  theme={null}\nfrom langchain_community.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader\n```\n\n### Hugging Face model loader\n\n> Load model information from `Hugging Face Hub`, including README content.\n>\n> This loader interfaces with the `Hugging Face Models API` to fetch\n> and load model metadata and README files.\n> The API allows you to search and filter models based on\n> specific criteria such as model tags, authors, and more.\n\n```python  theme={null}\nfrom langchain_community.document_loaders import HuggingFaceModelLoader\n```\n\n### Image captions\n\nIt uses the Hugging Face models to generate image captions.\n\nWe need to install several python packages.\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install transformers pillow\n  ```\n\n  ```bash uv theme={null}\n  uv add transformers pillow\n  ```\n</CodeGroup>\n\nSee a [usage example](/oss/python/integrations/document_loaders/image_captions).\n\n```python  theme={null}\nfrom langchain_community.document_loaders import ImageCaptionLoader\n```\n\n## Tools\n\n### Hugging Face Hub Tools\n\n> [Hugging Face Tools](https://huggingface.co/docs/transformers/v4.29.0/en/custom_tools)\n> support text I/O and are loaded using the `load_huggingface_tool` function.\n\nWe need to install several python packages.\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install transformers huggingface_hub\n  ```\n\n  ```bash uv theme={null}\n  uv add transformers huggingface_hub\n  ```\n</CodeGroup>\n\nSee a [usage example](/oss/python/integrations/tools/huggingface_tools).\n\n```python  theme={null}\nfrom langchain_community.agent_toolkits.load_tools import load_huggingface_tool\n```\n\n### Hugging Face Text-to-Speech Model Inference.\n\n> It is a wrapper around `OpenAI Text-to-Speech API`.\n\n```python  theme={null}\nfrom langchain_community.tools.audio import HuggingFaceTextToSpeechModelInference\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/huggingface.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 6218
}