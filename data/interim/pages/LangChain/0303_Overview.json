{
  "title": "Overview",
  "source_url": "https://docs.langchain.com/oss/javascript/integrations/providers/microsoft",
  "content": "All functionality related to `Microsoft Azure` and other `Microsoft` products.\n\n## Chat Models\n\n### Azure OpenAI\n\nSee a [usage example](/oss/javascript/integrations/chat/azure)\n\n```typescript  theme={null}\nimport { AzureChatOpenAI } from \"@langchain/openai\";\n\nconst model = new AzureChatOpenAI({\n  temperature: 0.9,\n  azureOpenAIApiKey: \"<your_key>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY\n  azureOpenAIApiInstanceName: \"<your_instance_name>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME\n  azureOpenAIApiDeploymentName: \"<your_deployment_name>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME\n  azureOpenAIApiVersion: \"<api_version>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION\n});\n```\n\n## LLM\n\n### Azure OpenAI\n\n> [Microsoft Azure](https://en.wikipedia.org/wiki/Microsoft_Azure), often referred to as `Azure` is a cloud computing platform run by `Microsoft`, which offers access, management, and development of applications and services through global data centers. It provides a range of capabilities, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). `Microsoft Azure` supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.\n\n> [Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service/) is a cloud service to help you quickly develop generative AI experiences with a diverse set of prebuilt and curated models from OpenAI, Meta and beyond.\n\nLangChain.js supports integration with [Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service/) using the new Azure integration in the [OpenAI SDK](https://github.com/openai/openai-node).\n\nYou can learn more about Azure OpenAI and its difference with the OpenAI API on [this page](https://learn.microsoft.com/azure/ai-services/openai/overview). If you don't have an Azure account, you can [create a free account](https://azure.microsoft.com/free/) to get started.\n\nYou'll need to have an Azure OpenAI instance deployed. You can deploy a version on Azure Portal following [this guide](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal).\n\nOnce you have your instance running, make sure you have the name of your instance and key. You can find the key in the Azure Portal, under the \"Keys and Endpoint\" section of your instance.\n\nIf you're using Node.js, you can define the following environment variables to use the service:\n\n```bash  theme={null}\nAZURE_OPENAI_API_INSTANCE_NAME=<YOUR_INSTANCE_NAME>\nAZURE_OPENAI_API_DEPLOYMENT_NAME=<YOUR_DEPLOYMENT_NAME>\nAZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=<YOUR_EMBEDDINGS_DEPLOYMENT_NAME>\nAZURE_OPENAI_API_KEY=<YOUR_KEY>\nAZURE_OPENAI_API_VERSION=\"2024-02-01\"\n```\n\n<Info>\n  **You can find the list of supported API versions in the [Azure OpenAI documentation](https://learn.microsoft.com/azure/ai-services/openai/reference).**\n</Info>\n\n<Tip>\n  See [this section for general instructions on installing LangChain packages](/oss/javascript/langchain/install).\n</Tip>\n\n```bash npm theme={null}\nnpm install @langchain/openai @langchain/core\n```\n\nSee a [usage example](/oss/javascript/integrations/llms/azure).\n\n```typescript  theme={null}\nimport { AzureOpenAI } from \"@langchain/openai\";\n\nconst model = new AzureOpenAI({\n  azureOpenAIApiKey: \"<your_key>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY\n  azureOpenAIApiInstanceName: \"<your_instance_name>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME\n  azureOpenAIApiDeploymentName: \"<your_deployment_name>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME\n  azureOpenAIApiVersion: \"<api_version>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION\n});\n```\n\n## Text Embedding Models\n\n### Azure OpenAI\n\nSee a [usage example](/oss/javascript/integrations/text_embedding/azure_openai)\n\n```typescript  theme={null}\nimport { AzureOpenAIEmbeddings } from \"@langchain/openai\";\n\nconst model = new AzureOpenAIEmbeddings({\n  azureOpenAIApiKey: \"<your_key>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY\n  azureOpenAIApiInstanceName: \"<your_instance_name>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME\n  azureOpenAIApiEmbeddingsDeploymentName: \"<your_embeddings_deployment_name>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME\n  azureOpenAIApiVersion: \"<api_version>\", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION\n});\n```\n\n## Vector stores\n\n### Azure AI Search\n\n> [Azure AI Search](https://azure.microsoft.com/products/ai-services/ai-search) (formerly known as Azure Search and Azure Cognitive Search) is a distributed, RESTful search engine optimized for speed and relevance on production-scale workloads on Azure. It supports also vector search using the [k-nearest neighbor](https://en.wikipedia.org/wiki/Nearest_neighbor_search) (kNN) algorithm and also [semantic search](https://learn.microsoft.com/azure/search/semantic-search-overview).\n\n```bash npm theme={null}\nnpm install -S @langchain/community @langchain/core @azure/search-documents\n```\n\nSee a [usage example](/oss/javascript/integrations/vectorstores/azure_aisearch).\n\n```typescript  theme={null}\nimport { AzureAISearchVectorStore } from \"@langchain/community/vectorstores/azure_aisearch\";\n```\n\n### Azure Cosmos DB for NoSQL\n\n> [Azure Cosmos DB for NoSQL](https://learn.microsoft.com/azure/cosmos-db/nosql/) provides support for querying items with flexible schemas and native support for JSON. It now offers vector indexing and search. This feature is designed to handle high-dimensional vectors, enabling efficient and accurate vector search at any scale. You can now store vectors directly in the documents alongside your data. Each document in your database can contain not only traditional schema-free data, but also high-dimensional vectors as other properties of the documents.\n\n```bash npm theme={null}\nnpm install @langchain/azure-cosmosdb @langchain/core\n```\n\nSee a [usage example](/oss/javascript/integrations/vectorstores/azure_cosmosdb_nosql).\n\n```typescript  theme={null}\nimport { AzureCosmosDBNoSQLVectorStore } from \"@langchain/azure-cosmosdb\";\n```\n\n### Azure Cosmos DB for MongoDB vCore\n\n> [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/) makes it easy to create a database with full native MongoDB support. You can apply your MongoDB experience and continue to use your favorite MongoDB drivers, SDKs, and tools by pointing your application to the API for MongoDB vCore account's connection string. Use vector search in Azure Cosmos DB for MongoDB vCore to seamlessly integrate your AI-based applications with your data that's stored in Azure Cosmos DB.\n\n```bash npm theme={null}\nnpm install @langchain/azure-cosmosdb @langchain/core\n```\n\nSee a [usage example](/oss/javascript/integrations/vectorstores/azure_cosmosdb_mongodb).\n\n```typescript  theme={null}\nimport { AzureCosmosDBMongoDBVectorStore } from \"@langchain/azure-cosmosdb\";\n```\n\n## Semantic Cache\n\n### Azure Cosmos DB NoSQL Semantic Cache\n\n> The Semantic Cache feature is supported with Azure Cosmos DB for NoSQL integration, enabling users to retrieve cached responses based on semantic similarity between the user input and previously cached results. It leverages [AzureCosmosDBNoSQLVectorStore](/oss/javascript/integrations/vectorstores/azure_cosmosdb_nosql), which stores vector embeddings of cached prompts. These embeddings enable similarity-based searches, allowing the system to retrieve relevant cached results.\n\n```bash npm theme={null}\nnpm install @langchain/azure-cosmosdb @langchain/core\n```\n\nSee a [usage example](/oss/javascript/integrations/llm_caching/azure_cosmosdb_nosql).\n\n```typescript  theme={null}\nimport { AzureCosmosDBNoSQLSemanticCache } from \"@langchain/azure-cosmosdb\";\n```\n\n## Document loaders\n\n### Azure Blob Storage\n\n> [Azure Blob Storage](https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction) is Microsoft's object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data.\n\n> [Azure Files](https://learn.microsoft.com/azure/storage/files/storage-files-introduction) offers fully managed\n> file shares in the cloud that are accessible via the industry standard Server Message Block (`SMB`) protocol,\n> Network File System (`NFS`) protocol, and `Azure Files REST API`. `Azure Files` are based on the `Azure Blob Storage`.\n\n`Azure Blob Storage` is designed for:\n\n* Serving images or documents directly to a browser.\n* Storing files for distributed access.\n* Streaming video and audio.\n* Writing to log files.\n* Storing data for backup and restore, disaster recovery, and archiving.\n* Storing data for analysis by an on-premises or Azure-hosted service.\n\n```bash npm theme={null}\nnpm install @langchain/community @langchain/core @azure/storage-blob\n```\n\nSee a [usage example for the Azure Blob Storage](/oss/javascript/integrations/document_loaders/web_loaders/azure_blob_storage_container).\n\n```typescript  theme={null}\nimport { AzureBlobStorageContainerLoader } from \"@langchain/community/document_loaders/web/azure_blob_storage_container\";\n```\n\nSee a [usage example for the Azure Files](/oss/javascript/integrations/document_loaders/web_loaders/azure_blob_storage_file).\n\n```typescript  theme={null}\nimport { AzureBlobStorageFileLoader } from \"@langchain/community/document_loaders/web/azure_blob_storage_file\";\n```\n\n## Tools\n\n### Azure Container Apps Dynamic Sessions\n\n> [Azure Container Apps dynamic sessions](https://learn.microsoft.com/azure/container-apps/sessions) provide fast access to secure sandboxed environments that are ideal for running code or applications that require strong isolation from other workloads.\n\n```bash npm theme={null}\nnpm install @langchain/azure-dynamic-sessions @langchain/core\n```\n\nSee a [usage example](/oss/javascript/integrations/tools/azure_dynamic_sessions).\n\n```typescript  theme={null}\nimport { SessionsPythonREPLTool } from \"@langchain/azure-dynamic-sessions\";\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/providers/microsoft.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 10692
}