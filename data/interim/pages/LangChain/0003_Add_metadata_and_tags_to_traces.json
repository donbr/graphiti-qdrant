{
  "title": "Add metadata and tags to traces",
  "source_url": "https://docs.langchain.com/langsmith/add-metadata-tags",
  "content": "LangSmith supports sending arbitrary metadata and tags along with traces.\n\nTags are strings that can be used to categorize or label a trace. Metadata is a dictionary of key-value pairs that can be used to store additional information about a trace.\n\nBoth are useful for associating additional information with a trace, such as the environment in which it was executed, the user who initiated it, or an internal correlation ID. For more information on tags and metadata, see the [Concepts](/langsmith/observability-concepts#tags) page. For information on how to query traces and runs by metadata and tags, see the [Filter traces in the application](/langsmith/filter-traces-in-application) page.\n\n<CodeGroup>\n  ```python Python theme={null}\n  import openai\n  import langsmith as ls\n  from langsmith.wrappers import wrap_openai\n\n  client = openai.Client()\n  messages = [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": \"Hello!\"}\n  ]\n\n      # You can set metadata & tags **statically** when decorating a function\n      # Use the @traceable decorator with tags and metadata\n      # Ensure that the LANGSMITH_TRACING environment variables are set for @traceable to work\n      @ls.traceable(\n          run_type=\"llm\",\n          name=\"OpenAI Call Decorator\",\n          tags=[\"my-tag\"],\n          metadata={\"my-key\": \"my-value\"}\n      )\n      def call_openai(\n          messages: list[dict], model: str = \"gpt-4o-mini\"\n      ) -> str:\n          # You can also dynamically set metadata on the parent run:\n          rt = ls.get_current_run_tree()\n          rt.metadata[\"some-conditional-key\"] = \"some-val\"\n          rt.tags.extend([\"another-tag\"])\n          return client.chat.completions.create(\n              model=model,\n              messages=messages,\n          ).choices[0].message.content\n\n      call_openai(\n          messages,\n          # To add at **invocation time**, when calling the function.\n          # via the langsmith_extra parameter\n          langsmith_extra={\"tags\": [\"my-other-tag\"], \"metadata\": {\"my-other-key\": \"my-value\"}}\n      )\n\n      # Alternatively, you can use the context manager\n      with ls.trace(\n          name=\"OpenAI Call Trace\",\n          run_type=\"llm\",\n          inputs={\"messages\": messages},\n          tags=[\"my-tag\"],\n          metadata={\"my-key\": \"my-value\"},\n      ) as rt:\n          chat_completion = client.chat.completions.create(\n              model=\"gpt-4o-mini\",\n              messages=messages,\n          )\n          rt.metadata[\"some-conditional-key\"] = \"some-val\"\n          rt.end(outputs={\"output\": chat_completion})\n\n  # You can use the same techniques with the wrapped client\n  patched_client = wrap_openai(\n      client, tracing_extra={\"metadata\": {\"my-key\": \"my-value\"}, \"tags\": [\"a-tag\"]}\n  )\n  chat_completion = patched_client.chat.completions.create(\n      model=\"gpt-4o-mini\",\n      messages=messages,\n      langsmith_extra={\n          \"tags\": [\"my-other-tag\"],\n          \"metadata\": {\"my-other-key\": \"my-value\"},\n      },\n  )\n  ```\n\n  ```typescript TypeScript theme={null}\n  import OpenAI from \"openai\";\n  import { traceable, getCurrentRunTree } from \"langsmith/traceable\";\n  import { wrapOpenAI } from \"langsmith/wrappers\";\n\n      const client = wrapOpenAI(new OpenAI());\n      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [\n          { role: \"system\", content: \"You are a helpful assistant.\" },\n          { role: \"user\", content: \"Hello!\" },\n      ];\n\n      const traceableCallOpenAI = traceable(\n          async (messages: OpenAI.Chat.ChatCompletionMessageParam[]) => {\n              const completion = await client.chat.completions.create({\n                  model: \"gpt-4o-mini\",\n                  messages,\n              });\n              const runTree = getCurrentRunTree();\n              runTree.extra.metadata = {\n                  ...runTree.extra.metadata,\n                  someKey: \"someValue\",\n              };\n              runTree.tags = [...(runTree.tags ?? []), \"runtime-tag\"];\n              return completion.choices[0].message.content;\n          },\n          {\n              run_type: \"llm\",\n              name: \"OpenAI Call Traceable\",\n              tags: [\"my-tag\"],\n              metadata: { \"my-key\": \"my-value\" },\n          }\n      );\n\n  // Call the traceable function\n  await traceableCallOpenAI(messages);\n  ```\n</CodeGroup>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/add-metadata-tags.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 4735
}