{
  "title": "Evaluate a complex agent",
  "source_url": "https://docs.langchain.com/langsmith/evaluate-complex-agent",
  "content": "<Info>\n  [Agent evaluation](/langsmith/evaluation-concepts#agents) | [Evaluators](/langsmith/evaluation-concepts#evaluators) | [LLM-as-judge evaluators](/langsmith/evaluation-concepts#llm-as-judge)\n</Info>\n\nIn this tutorial, we'll build a customer support bot that helps users navigate a digital music store. Then, we'll go through the three most effective types of evaluations to run on chat bots:\n\n* [Final response](/langsmith/evaluation-concepts#evaluating-an-agents-final-response): Evaluate the agent's final response.\n* [Trajectory](/langsmith/evaluation-concepts#evaluating-an-agents-trajectory): Evaluate whether the agent took the expected path (e.g., of tool calls) to arrive at the final answer.\n* [Single step](/langsmith/evaluation-concepts#evaluating-a-single-step-of-an-agent): Evaluate any agent step in isolation (e.g., whether it selects the appropriate first tool for a given step).\n\nWe'll build our agent using [LangGraph](https://github.com/langchain-ai/langgraph), but the techniques and LangSmith functionality shown here are framework-agnostic.\n\n## Setup\n\n### Configure the environment\n\nLet's install the required dependencies:\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install -U langgraph langchain[openai]\n  ```\n\n  ```bash uv theme={null}\n  uv add langgraph langchain[openai]\n  ```\n</CodeGroup>\n\nLet's set up environment variables for OpenAI and [LangSmith](https://smith.langchain.com):\n\n```python  theme={null}\nimport getpass\nimport os\n\ndef _set_env(var: str) -> None:\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"Set {var}: \")\n\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\n_set_env(\"LANGSMITH_API_KEY\")\n_set_env(\"OPENAI_API_KEY\")\n```\n\n### Download the database\n\nWe will create a SQLite database for this tutorial. SQLite is a lightweight database that is easy to set up and use. We will load the `chinook` database, which is a sample database that represents a digital media store. Find more information about the database [here](https://www.sqlitetutorial.net/sqlite-sample-database/).\n\nFor convenience, we have hosted the database in a public GCS bucket:\n\n```python  theme={null}\nimport requests\n\nurl = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\nresponse = requests.get(url)\n\nif response.status_code == 200:\n    # Open a local file in binary write mode\n    with open(\"chinook.db\", \"wb\") as file:\n        # Write the content of the response (the file) to the local file\n        file.write(response.content)\n    print(\"File downloaded and saved as Chinook.db\")\nelse:\n    print(f\"Failed to download the file. Status code: {response.status_code}\")\n```\n\nHere's a sample of the data in the db:\n\n```python  theme={null}\nimport sqlite3\n# ... database connection and query code\n```\n\n```\n[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n```\n\nAnd here's the database schema (image from [https://github.com/lerocha/chinook-database](https://github.com/lerocha/chinook-database)):\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=5da2a8dcca68f02dfcec11f9c472d341\" alt=\"Chinook DB\" data-og-width=\"1672\" width=\"1672\" data-og-height=\"1132\" height=\"1132\" data-path=\"langsmith/images/chinook-diagram.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?w=280&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=ea7b3a27e9780b556aa90f6914dcef30 280w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?w=560&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=d9cf3ddad46562213014ffb1a77b1e45 560w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?w=840&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=2c9e1e70e9be2cf07111b2211e1ef9b7 840w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?w=1100&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=970f7f48c80222219b493211331ee22f 1100w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?w=1650&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=3188acb57c4abc0156f8687fa9e229d8 1650w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/chinook-diagram.png?w=2500&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=86b9655b9fd1bc38fcf9e054b11833df 2500w\" />\n\n### Define the customer support agent\n\nWe'll create a [LangGraph](https://langchain-ai.github.io/langgraph/) agent with limited access to our database. For demo purposes, our agent will support two basic types of requests:\n\n* Lookup: The customer can look up song titles, artist names, and albums based on other identifying information. For example: \"What songs do you have by Jimi Hendrix?\"\n* Refund: The customer can request a refund on their past purchases. For example: \"My name is Claude Shannon and I'd like a refund on a purchase I made last week, could you help me?\"\n\nFor simplicity in this demo, we'll implement refunds by deleting the corresponding database records. We'll skip implementing user authentication and other production security measures.\n\nThe agent's logic will be structured as two separate subgraphs (one for lookups and one for refunds), with a parent graph that routes requests to the appropriate subgraph.\n\n#### Refund agent\n\nLet's build the refund processing agent. This agent needs to:\n\n1. Find the customer's purchase records in the database\n2. Delete the relevant Invoice and InvoiceLine records to process the refund\n\nWe'll create two SQL helper functions:\n\n1. A function to execute the refund by deleting records\n2. A function to look up a customer's purchase history\n\nTo make testing easier, we'll add a \"mock\" mode to these functions. When mock mode is enabled, the functions will simulate database operations without actually modifying any data.\n\n```python  theme={null}\nimport sqlite3\n\ndef _refund(invoice_id: int | None, invoice_line_ids: list[int] | None, mock: bool = False) -> float:\n    ...\n\ndef _lookup( ...\n```\n\nNow let's define our graph. We'll use a simple architecture with three main paths:\n\n1. Extract customer and purchase information from the conversation\n\n2. Route the request to one of three paths:\n\n   * Refund path: If we have sufficient purchase details (Invoice ID or Invoice Line IDs) to process a refund\n   * Lookup path: If we have enough customer information (name and phone) to search their purchase history\n   * Response path: If we need more information, respond to the user requesting the specific details needed\n\nThe graph's state will track:\n\n* The conversation history (messages between user and agent)\n* All customer and purchase information extracted from the conversation\n* The next message to send to the user (followup text)\n\n````python  theme={null}\nfrom typing import Literal\nimport json\n\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.runnables import RunnableConfig\nfrom langgraph.graph import END, StateGraph\nfrom langgraph.graph.message import AnyMessage, add_messages\nfrom langgraph.types import Command, interrupt\nfrom tabulate import tabulate\nfrom typing_extensions import Annotated, TypedDict\n\n# Graph state.\nclass State(TypedDict):\n    \"\"\"Agent state.\"\"\"\n    messages: Annotated[list[AnyMessage], add_messages]\n    followup: str | None\n\n    invoice_id: int | None\n    invoice_line_ids: list[int] | None\n    customer_first_name: str | None\n    customer_last_name: str | None\n    customer_phone: str | None\n    track_name: str | None\n    album_title: str | None\n    artist_name: str | None\n    purchase_date_iso_8601: str | None\n\n# Instructions for extracting the user/purchase info from the conversation.\ngather_info_instructions = \"\"\"You are managing an online music store that sells song tracks. \\\nCustomers can buy multiple tracks at a time and these purchases are recorded in a database as \\\nan Invoice per purchase and an associated set of Invoice Lines for each purchased track.\n\nYour task is to help customers who would like a refund for one or more of the tracks they've \\\npurchased. In order for you to be able refund them, the customer must specify the Invoice ID \\\nto get a refund on all the tracks they bought in a single transaction, or one or more Invoice \\\nLine IDs if they would like refunds on individual tracks.\n\nOften a user will not know the specific Invoice ID(s) or Invoice Line ID(s) for which they \\\nwould like a refund. In this case you can help them look up their invoices by asking them to \\\nspecify:\n- Required: Their first name, last name, and phone number.\n- Optionally: The track name, artist name, album name, or purchase date.\n\nIf the customer has not specified the required information (either Invoice/Invoice Line IDs \\\nor first name, last name, phone) then please ask them to specify it.\"\"\"\n\n# Extraction schema, mirrors the graph state.\nclass PurchaseInformation(TypedDict):\n    \"\"\"All of the known information about the invoice / invoice lines the customer would like refunded. Do not make up values, leave fields as null if you don't know their value.\"\"\"\n\n    invoice_id: int | None\n    invoice_line_ids: list[int] | None\n    customer_first_name: str | None\n    customer_last_name: str | None\n    customer_phone: str | None\n    track_name: str | None\n    album_title: str | None\n    artist_name: str | None\n    purchase_date_iso_8601: str | None\n    followup: Annotated[\n        str | None,\n        ...,\n        \"If the user hasn't enough identifying information, please tell them what the required information is and ask them to specify it.\",\n    ]\n\n# Model for performing extraction.\ninfo_llm = init_chat_model(\"gpt-4o-mini\").with_structured_output(\n    PurchaseInformation, method=\"json_schema\", include_raw=True\n)\n\n# Graph node for extracting user info and routing to lookup/refund/END.\nasync def gather_info(state: State) -> Command[Literal[\"lookup\", \"refund\", END]]:\n    info = await info_llm.ainvoke(\n        [\n            {\"role\": \"system\", \"content\": gather_info_instructions},\n            *state[\"messages\"],\n        ]\n    )\n    parsed = info[\"parsed\"]\n    if any(parsed[k] for k in (\"invoice_id\", \"invoice_line_ids\")):\n        goto = \"refund\"\n    elif all(\n        parsed[k]\n        for k in (\"customer_first_name\", \"customer_last_name\", \"customer_phone\")\n    ):\n        goto = \"lookup\"\n    else:\n        goto = END\n    update = {\"messages\": [info[\"raw\"]], **parsed}\n    return Command(update=update, goto=goto)\n\n# Graph node for executing the refund.\n# Note that here we inspect the runtime config for an \"env\" variable.\n# If \"env\" is set to \"test\", then we don't actually delete any rows from our database.\n# This will become important when we're running our evaluations.\ndef refund(state: State, config: RunnableConfig) -> dict:\n    # Whether to mock the deletion. True if the configurable var 'env' is set to 'test'.\n    mock = config.get(\"configurable\", {}).get(\"env\", \"prod\") == \"test\"\n    refunded = _refund(\n        invoice_id=state[\"invoice_id\"], invoice_line_ids=state[\"invoice_line_ids\"], mock=mock\n    )\n    response = f\"You have been refunded a total of: ${refunded:.2f}. Is there anything else I can help with?\"\n    return {\n        \"messages\": [{\"role\": \"assistant\", \"content\": response}],\n        \"followup\": response,\n    }\n\n# Graph node for looking up the users purchases\ndef lookup(state: State) -> dict:\n    args = (\n        state[k]\n        for k in (\n            \"customer_first_name\",\n            \"customer_last_name\",\n            \"customer_phone\",\n            \"track_name\",\n            \"album_title\",\n            \"artist_name\",\n            \"purchase_date_iso_8601\",\n        )\n    )\n    results = _lookup(*args)\n    if not results:\n        response = \"We did not find any purchases associated with the information you've provided. Are you sure you've entered all of your information correctly?\"\n        followup = response\n    else:\n        response = f\"Which of the following purchases would you like to be refunded for?\\n\\n```json{json.dumps(results, indent=2)}\\n```\"\n        followup = f\"Which of the following purchases would you like to be refunded for?\\n\\n{tabulate(results, headers='keys')}\"\n    return {\n        \"messages\": [{\"role\": \"assistant\", \"content\": response}],\n        \"followup\": followup,\n        \"invoice_line_ids\": [res[\"invoice_line_id\"] for res in results],\n    }\n\n# Building our graph\ngraph_builder = StateGraph(State)\n\ngraph_builder.add_node(gather_info)\ngraph_builder.add_node(refund)\ngraph_builder.add_node(lookup)\n\ngraph_builder.set_entry_point(\"gather_info\")\ngraph_builder.add_edge(\"lookup\", END)\ngraph_builder.add_edge(\"refund\", END)\n\nrefund_graph = graph_builder.compile()\n````\n\nWe can visualize our refund graph:\n\n```\n# Assumes you're in an interactive Python environmentfrom IPython.display import Image, display ...\n```\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=a65951850208fd3b03848629bdda8ae0\" alt=\"Refund graph\" data-og-width=\"256\" width=\"256\" data-og-height=\"333\" height=\"333\" data-path=\"langsmith/images/refund-graph.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?w=280&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=8817f44b37322ab9a51fd01ee7902181 280w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?w=560&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=753a20158640cbeeeb81498d5c5ae95d 560w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?w=840&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=8d38bcff07b53e1f5648b3dd45cffa66 840w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?w=1100&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=50a7f863cf45d9df7b59cc3614fdb4e9 1100w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?w=1650&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=cfbda86ec83a651bfe8e38235579302d 1650w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/refund-graph.png?w=2500&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=56745d2e7603dca7fa233e1fd5818008 2500w\" />\n\n#### Lookup agent\n\nFor the lookup (i.e. question-answering) agent, we'll use a simple ReACT architecture and give the agent tools for looking up track names, artist names, and album names based on various filters. For example, you can look up albums by a particular artist, artists who released songs with a specific name, etc.\n\n```python  theme={null}\nfrom langchain.embeddings import init_embeddings\nfrom langchain.tools import tool\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain.agents import create_agent\n\n\n# Our SQL queries will only work if we filter on the exact string values that are in the DB.\n# To ensure this, we'll create vectorstore indexes for all of the artists, tracks and albums\n# ahead of time and use those to disambiguate the user input. E.g. if a user searches for\n# songs by \"prince\" and our DB records the artist as \"Prince\", ideally when we query our\n# artist vectorstore for \"prince\" we'll get back the value \"Prince\", which we can then\n# use in our SQL queries.\ndef index_fields() -> tuple[InMemoryVectorStore, InMemoryVectorStore, InMemoryVectorStore]: ...\n\ntrack_store, artist_store, album_store = index_fields()\n\n# Agent tools\n@tool\ndef lookup_track( ...\n\n@tool\ndef lookup_album( ...\n\n@tool\ndef lookup_artist( ...\n\n# Agent model\nqa_llm = init_chat_model(\"claude-sonnet-4-5-20250929\")\n# The prebuilt ReACT agent only expects State to have a 'messages' key, so the\n# state we defined for the refund agent can also be passed to our lookup agent.\nqa_graph = create_agent(qa_llm, tools=[lookup_track, lookup_artist, lookup_album])\n```\n\n```\ndisplay(Image(qa_graph.get_graph(xray=True).draw_mermaid_png()))\n```\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=fa838edc78b2b29e8c29807d8c3dd7fd\" alt=\"QA Graph\" data-og-width=\"214\" width=\"214\" data-og-height=\"249\" height=\"249\" data-path=\"langsmith/images/qa-graph.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?w=280&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=920e82f376d6bbbcfe02c07ac7a45b80 280w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?w=560&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=938d3bd8c19abfe27ea5efd1c996494c 560w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?w=840&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=e46ece85318d4c376cd6bb632bf41ab4 840w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?w=1100&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=3e3c715ef37db24fd0cbf8eb4ca19190 1100w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?w=1650&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=e3270477acbc50eb9e4e9736a5ec6afc 1650w, https://mintcdn.com/langchain-5e9cc07a/Fr2lazPB4XVeEA7l/langsmith/images/qa-graph.png?w=2500&fit=max&auto=format&n=Fr2lazPB4XVeEA7l&q=85&s=667b26bb91f33aaacbeb0a2ea749825a 2500w\" />\n\n#### Parent agent\n\nNow let's define a parent agent that combines our two task-specific agents. The only job of the parent agent is to route to one of the sub-agents by classifying the user's current intent, and to compile the output into a followup message.\n\n```python  theme={null}\n# Schema for routing user intent.\n# We'll use structured output to enforce that the model returns only\n# the desired output.\nclass UserIntent(TypedDict):\n    \"\"\"The user's current intent in the conversation\"\"\"\n\n    intent: Literal[\"refund\", \"question_answering\"]\n\n# Routing model with structured output\nrouter_llm = init_chat_model(\"gpt-4o-mini\").with_structured_output(\n    UserIntent, method=\"json_schema\", strict=True\n)\n\n# Instructions for routing.\nroute_instructions = \"\"\"You are managing an online music store that sells song tracks. \\\nYou can help customers in two types of ways: (1) answering general questions about \\\ntracks sold at your store, (2) helping them get a refund on a purhcase they made at your store.\n\nBased on the following conversation, determine if the user is currently seeking general \\\ninformation about song tracks or if they are trying to refund a specific purchase.\n\nReturn 'refund' if they are trying to get a refund and 'question_answering' if they are \\\nasking a general music question. Do NOT return anything else. Do NOT try to respond to \\\nthe user.\n\"\"\"\n\n# Node for routing.\nasync def intent_classifier(\n    state: State,\n) -> Command[Literal[\"refund_agent\", \"question_answering_agent\"]]:\n    response = router_llm.invoke(\n        [{\"role\": \"system\", \"content\": route_instructions}, *state[\"messages\"]]\n    )\n    return Command(goto=response[\"intent\"] + \"_agent\")\n\n# Node for making sure the 'followup' key is set before our agent run completes.\ndef compile_followup(state: State) -> dict:\n    \"\"\"Set the followup to be the last message if it hasn't explicitly been set.\"\"\"\n    if not state.get(\"followup\"):\n        return {\"followup\": state[\"messages\"][-1].content}\n    return {}\n\n# Agent definition\ngraph_builder = StateGraph(State)\ngraph_builder.add_node(intent_classifier)\n# Since all of our subagents have compatible state,\n# we can add them as nodes directly.\ngraph_builder.add_node(\"refund_agent\", refund_graph)\ngraph_builder.add_node(\"question_answering_agent\", qa_graph)\ngraph_builder.add_node(compile_followup)\n\ngraph_builder.set_entry_point(\"intent_classifier\")\ngraph_builder.add_edge(\"refund_agent\", \"compile_followup\")\ngraph_builder.add_edge(\"question_answering_agent\", \"compile_followup\")\ngraph_builder.add_edge(\"compile_followup\", END)\n\ngraph = graph_builder.compile()\n```\n\nWe can visualize our compiled parent graph including all of its subgraphs:\n\n```python  theme={null}\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\n```\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=619f9b540ea69b1662b2a599ce78241b\" alt=\"graph\" data-og-width=\"646\" width=\"646\" data-og-height=\"680\" height=\"680\" data-path=\"langsmith/images/agent-tutorial-graph.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?w=280&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=227790d90780a4c56233650b957130df 280w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?w=560&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=30ae6a9b1bc367152a57d4a0c3e41af7 560w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?w=840&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=37f29b6e783cf2a80714c29ab0be3c5f 840w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?w=1100&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=423ad48e0266ac257b6d76962697b45d 1100w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?w=1650&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=581821d6b377b98108507712d6b08c51 1650w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/agent-tutorial-graph.png?w=2500&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=126ef194ff5042f691c8f52cf3a1cb75 2500w\" />\n\n#### Try it out\n\nLet's give our custom support agent a whirl!\n\n```python  theme={null}\nstate = await graph.ainvoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what james brown songs do you have\"}]}\n)\nprint(state[\"followup\"])\n```\n\n```\nI found 20 James Brown songs in the database, all from the album \"Sex Machine\". Here they are: ...\n```\n\n```python  theme={null}\nstate = await graph.ainvoke({\"messages\": [\n    {\n        \"role\": \"user\",\n        \"content\": \"my name is Aaron Mitchell and my number is +1 (204) 452-6452. I bought some songs by Led Zeppelin that i'd like refunded\",\n    }\n]})\nprint(state[\"followup\"])\n```\n\n```\nWhich of the following purchases would you like to be refunded for? ...\n```\n\n## Evaluations\n\nNow that we've got a testable version of our agent, let's run some evaluations. Agent evaluation can focus on at least 3 things:\n\n* [Final response](/langsmith/evaluation-concepts#evaluating-an-agents-final-response): The inputs are a prompt and an optional list of tools. The output is the final agent response.\n* [Trajectory](/langsmith/evaluation-concepts#evaluating-an-agents-trajectory): As before, the inputs are a prompt and an optional list of tools. The output is the list of tool calls\n* [Single step](/langsmith/evaluation-concepts#evaluating-a-single-step-of-an-agent): As before, the inputs are a prompt and an optional list of tools. The output is the tool call.\n\nLet's run each type of evaluation:\n\n### Final response evaluator\n\nFirst, let's create a [dataset](/langsmith/evaluation-concepts#datasets) that evaluates end-to-end performance of the agent. For simplicity we'll use the same dataset for final response and trajectory evaluation, so we'll add both ground-truth responses and trajectories for each example question. We'll cover the trajectories in the next section.\n\n```python  theme={null}\nfrom langsmith import Client\n\nclient = Client()\n\n# Create a dataset\nexamples = [\n    {\n        \"inputs\": {\n            \"question\": \"How many songs do you have by James Brown\",\n        },\n        \"outputs\": {\n            \"response\": \"We have 20 songs by James Brown\",\n            \"trajectory\": [\"question_answering_agent\", \"lookup_track\"]\n        }\n    },\n    {\n        \"inputs\": {\n            \"question\": \"My name is Aaron Mitchell and I'd like a refund.\",\n        },\n        \"outputs\": {\n            \"response\": \"I need some more information to help you with the refund. Please specify your phone number, the invoice ID, or the line item IDs for the purchase you'd like refunded.\",\n            \"trajectory\": [\"refund_agent\"],\n        }\n    },\n    {\n        \"inputs\": {\n            \"question\": \"My name is Aaron Mitchell and I'd like a refund on my Led Zeppelin purchases. My number is +1 (204) 452-6452\",\n        },\n        \"outputs\": {\n            \"response\": 'Which of the following purchases would you like to be refunded for?\\n\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99',\n            \"trajectory\": [\"refund_agent\", \"lookup\"],\n        },\n    },\n    {\n        \"inputs\": {\n            \"question\": \"Who recorded Wish You Were Here again? What other albums of there's do you have?\",\n        },\n        \"outputs\": {\n            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\n        },\n    },\n    {\n        \"inputs\": {\n            \"question\": \"I want a full refund for invoice 237\",\n        },\n        \"outputs\": {\n            \"response\": \"You have been refunded $0.99.\",\n            \"trajectory\": [\"refund_agent\", \"refund\"],\n        }\n    },\n]\n\ndataset_name = \"Chinook Customer Service Bot: E2E\"\n\nif not client.has_dataset(dataset_name=dataset_name):\n    dataset = client.create_dataset(dataset_name=dataset_name)\n    client.create_examples(\n        dataset_id=dataset.id,\n        examples=examples\n    )\n```\n\nWe'll create a custom [LLM-as-judge](/langsmith/evaluation-concepts#llm-as-judge) evaluator that uses another model to compare our agent's output on each example to the reference response, and judge if they're equivalent or not:\n\n```python  theme={null}\n# LLM-as-judge instructions\ngrader_instructions = \"\"\"You are a teacher grading a quiz.\n\nYou will be given a QUESTION, the GROUND TRUTH (correct) RESPONSE, and the STUDENT RESPONSE.\n\nHere is the grade criteria to follow:\n(1) Grade the student responses based ONLY on their factual accuracy relative to the ground truth answer.\n(2) Ensure that the student response does not contain any conflicting statements.\n(3) It is OK if the student response contains more information than the ground truth response, as long as it is factually accurate relative to the  ground truth response.\n\nCorrectness:\nTrue means that the student's response meets all of the criteria.\nFalse means that the student's response does not meet all of the criteria.\n\nExplain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n\n# LLM-as-judge output schema\nclass Grade(TypedDict):\n    \"\"\"Compare the expected and actual answers and grade the actual answer.\"\"\"\n    reasoning: Annotated[str, ..., \"Explain your reasoning for whether the actual response is correct or not.\"]\n    is_correct: Annotated[bool, ..., \"True if the student response is mostly or exactly correct, otherwise False.\"]\n\n# Judge LLM\ngrader_llm = init_chat_model(\"gpt-4o-mini\", temperature=0).with_structured_output(Grade, method=\"json_schema\", strict=True)\n\n# Evaluator function\nasync def final_answer_correct(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n    \"\"\"Evaluate if the final response is equivalent to reference response.\"\"\"\n\n    # Note that we assume the outputs has a 'response' dictionary. We'll need to make sure\n    # that the target function we define includes this key.\n    user = f\"\"\"QUESTION: {inputs['question']}\n    GROUND TRUTH RESPONSE: {reference_outputs['response']}\n    STUDENT RESPONSE: {outputs['response']}\"\"\"\n\n    grade = await grader_llm.ainvoke([{\"role\": \"system\", \"content\": grader_instructions}, {\"role\": \"user\", \"content\": user}])\n    return grade[\"is_correct\"]\n```\n\nNow we can run our evaluation. Our evaluator assumes that our target function returns a 'response' key, so lets define a target function that does so.\n\nAlso remember that in our refund graph we made the refund node configurable, so that if we specified `config={\"env\": \"test\"}`, we would mock out the refunds without actually updating the DB. We'll use this configurable variable in our target `run_graph` method when invoking our graph:\n\n```python  theme={null}\n# Target function\nasync def run_graph(inputs: dict) -> dict:\n    \"\"\"Run graph and track the trajectory it takes along with the final response.\"\"\"\n    result = await graph.ainvoke({\"messages\": [\n        { \"role\": \"user\", \"content\": inputs['question']},\n    ]}, config={\"env\": \"test\"})\n    return {\"response\": result[\"followup\"]}\n\n# Evaluation job and results\nexperiment_results = await client.aevaluate(\n    run_graph,\n    data=dataset_name,\n    evaluators=[final_answer_correct],\n    experiment_prefix=\"sql-agent-gpt4o-e2e\",\n    num_repetitions=1,\n    max_concurrency=4,\n)\nexperiment_results.to_pandas()\n```\n\nYou can see what these results look like here: [LangSmith link](https://smith.langchain.com/public/708d08f4-300e-4c75-9677-c6b71b0d28c9/d).\n\n### Trajectory evaluator\n\nAs agents become more complex, they have more potential points of failure. Rather than using simple pass/fail evaluations, it's often better to use evaluations that can give partial credit when an agent takes some correct steps, even if it doesn't reach the right final answer.\n\nThis is where trajectory evaluations come in. A trajectory evaluation:\n\n1. Compares the actual sequence of steps the agent took against an expected sequence\n2. Calculates a score based on how many of the expected steps were completed correctly\n\nFor this example, our end-to-end dataset contains an ordered list of steps that we expect the agent to take. Let's create an evaluator that checks the agent's actual trajectory against these expected steps and calculates what percentage were completed:\n\n```python  theme={null}\ndef trajectory_subsequence(outputs: dict, reference_outputs: dict) -> float:\n    \"\"\"Check how many of the desired steps the agent took.\"\"\"\n    if len(reference_outputs['trajectory']) > len(outputs['trajectory']):\n        return False\n\n    i = j = 0\n    while i < len(reference_outputs['trajectory']) and j < len(outputs['trajectory']):\n        if reference_outputs['trajectory'][i] == outputs['trajectory'][j]:\n            i += 1\n        j += 1\n\n    return i / len(reference_outputs['trajectory'])\n```\n\nNow we can run our evaluation. Our evaluator assumes that our target function returns a 'trajectory' key, so lets define a target function that does so. We'll need to usage [LangGraph's streaming capabilities](https://langchain-ai.github.io/langgra/langsmith/observability-concepts/streaming/) to record the trajectory.\n\nNote that we are reusing the same dataset as for our final response evaluation, so we could have run both evaluators together and defined a target function that returns both \"response\" and \"trajectory\". In practice it's often useful to have separate datasets for each type of evaluation, which is why we show them separately here:\n\n```python  theme={null}\nasync def run_graph(inputs: dict) -> dict:\n    \"\"\"Run graph and track the trajectory it takes along with the final response.\"\"\"\n    trajectory = []\n    # Set subgraph=True to stream events from subgraphs of the main graph: https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/\n    # Set stream_mode=\"debug\" to stream all possible events: https://langchain-ai.github.io/langgra/langsmith/observability-concepts/streaming\n    async for namespace, chunk in graph.astream({\"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": inputs['question'],\n            }\n        ]}, subgraphs=True, stream_mode=\"debug\"):\n        # Event type for entering a node\n        if chunk['type'] == 'task':\n            # Record the node name\n            trajectory.append(chunk['payload']['name'])\n            # Given how we defined our dataset, we also need to track when specific tools are\n            # called by our question answering ReACT agent. These tool calls can be found\n            # when the ToolsNode (named \"tools\") is invoked by looking at the AIMessage.tool_calls\n            # of the latest input message.\n            if chunk['payload']['name'] == 'tools' and chunk['type'] == 'task':\n                for tc in chunk['payload']['input']['messages'][-1].tool_calls:\n                    trajectory.append(tc['name'])\n    return {\"trajectory\": trajectory}\n\nexperiment_results = await client.aevaluate(\n    run_graph,\n    data=dataset_name,\n    evaluators=[trajectory_subsequence],\n    experiment_prefix=\"sql-agent-gpt4o-trajectory\",\n    num_repetitions=1,\n    max_concurrency=4,\n)\nexperiment_results.to_pandas()\n```\n\nYou can see what these results look like here: [LangSmith link](https://smith.langchain.com/public/708d08f4-300e-4c75-9677-c6b71b0d28c9/d).\n\n### Single step evaluators\n\nWhile end-to-end tests give you the most signal about your agents performance, for the sake of debugging and iterating on your agent it can be helpful to pinpoint specific steps that are difficult and evaluate them directly.\n\nIn our case, a crucial part of our agent is that it routes the user's intention correctly into either the \"refund\" path or the \"question answering\" path. Let's create a dataset and run some evaluations to directly stress test this one component.\n\n```python  theme={null}\n# Create dataset\nexamples = [\n    {\n        \"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"i bought some tracks recently and i dont like them\"}]},\n        \"outputs\": {\"route\": \"refund_agent\"},\n    },\n    {\n        \"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"I was thinking of purchasing some Rolling Stones tunes, any recommendations?\"}]},\n        \"outputs\": {\"route\": \"question_answering_agent\"},\n    },\n    {\n        \"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"i want a refund on purchase 237\"}, {\"role\": \"assistant\", \"content\": \"I've refunded you a total of $1.98. How else can I help you today?\"}, {\"role\": \"user\", \"content\": \"did prince release any albums in 2000?\"}]},\n        \"outputs\": {\"route\": \"question_answering_agent\"},\n    },\n    {\n        \"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"i purchased a cover of Yesterday recently but can't remember who it was by, which versions of it do you have?\"}]},\n        \"outputs\": {\"route\": \"question_answering_agent\"},\n    },\n]\n\ndataset_name = \"Chinook Customer Service Bot: Intent Classifier\"\nif not client.has_dataset(dataset_name=dataset_name):\n    dataset = client.create_dataset(dataset_name=dataset_name)\n    client.create_examples(\n        dataset_id=dataset.id,\n        examples=examples\n    )\n\n# Evaluator\ndef correct(outputs: dict, reference_outputs: dict) -> bool:\n    \"\"\"Check if the agent chose the correct route.\"\"\"\n    return outputs[\"route\"] == reference_outputs[\"route\"]\n\n# Target function for running the relevant step\nasync def run_intent_classifier(inputs: dict) -> dict:\n    # Note that we can access and run the intent_classifier node of our graph directly.\n    command = await graph.nodes['intent_classifier'].ainvoke(inputs)\n    return {\"route\": command.goto}\n\n# Run evaluation\nexperiment_results = await client.aevaluate(\n    run_intent_classifier,\n    data=dataset_name,\n    evaluators=[correct],\n    experiment_prefix=\"sql-agent-gpt4o-intent-classifier\",\n    max_concurrency=4,\n)\n```\n\nYou can see what these results look like here: [LangSmith link](https://smith.langchain.com/public/f133dae2-8a88-43a0-9bfd-ab45bfa3920b/d).\n\n## Reference code\n\nHere's a consolidated script with all the above code:\n\n<Accordion title=\"Reference code\">\n  ````python  theme={null}\n  import json\n  import sqlite3\n  from typing import Literal\n\n  from langchain.chat_models import init_chat_model\n  from langchain.embeddings import init_embeddings\n  from langchain_core.runnables import RunnableConfig\n  from langchain.tools import tool\n  from langchain_core.vectorstores import InMemoryVectorStore\n  from langgraph.graph import END, StateGraph\n  from langgraph.graph.message import AnyMessage, add_messages\n  from langchain.agents import create_agent\n  from langgraph.types import Command, interrupt\n  from langsmith import Client\n  import requests\n  from tabulate import tabulate\n  from typing_extensions import Annotated, TypedDict\n\n\n  url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n\n  response = requests.get(url)\n\n  if response.status_code == 200:\n      # Open a local file in binary write mode\n      with open(\"chinook.db\", \"wb\") as file:\n          # Write the content of the response (the file) to the local file\n          file.write(response.content)\n      print(\"File downloaded and saved as Chinook.db\")\n  else:\n      print(f\"Failed to download the file. Status code: {response.status_code}\")\n\n\n  def _refund(\n      invoice_id: int | None, invoice_line_ids: list[int] | None, mock: bool = False\n  ) -> float:\n      \"\"\"Given an Invoice ID and/or Invoice Line IDs, delete the relevant Invoice/InvoiceLine records in the Chinook DB.\n\n      Args:\n          invoice_id: The Invoice to delete.\n          invoice_line_ids: The Invoice Lines to delete.\n          mock: If True, do not actually delete the specified Invoice/Invoice Lines. Used for testing purposes.\n\n      Returns:\n          float: The total dollar amount that was deleted (or mock deleted).\n      \"\"\"\n\n      if invoice_id is None and invoice_line_ids is None:\n          return 0.0\n\n      # Connect to the Chinook database\n      conn = sqlite3.connect(\"chinook.db\")\n      cursor = conn.cursor()\n\n      total_refund = 0.0\n\n      try:\n          # If invoice_id is provided, delete entire invoice and its lines\n          if invoice_id is not None:\n              # First get the total amount for the invoice\n              cursor.execute(\n                  \"\"\"\n                  SELECT Total\n                  FROM Invoice\n                  WHERE InvoiceId = ?\n              \"\"\",\n                  (invoice_id,),\n              )\n\n              result = cursor.fetchone()\n              if result:\n                  total_refund += result[0]\n\n              # Delete invoice lines first (due to foreign key constraints)\n              if not mock:\n                  cursor.execute(\n                      \"\"\"\n                      DELETE FROM InvoiceLine\n                      WHERE InvoiceId = ?\n                  \"\"\",\n                      (invoice_id,),\n                  )\n\n                  # Then delete the invoice\n                  cursor.execute(\n                      \"\"\"\n                      DELETE FROM Invoice\n                      WHERE InvoiceId = ?\n                  \"\"\",\n                      (invoice_id,),\n                  )\n\n          # If specific invoice lines are provided\n          if invoice_line_ids is not None:\n              # Get the total amount for the specified invoice lines\n              placeholders = \",\".join([\"?\" for _ in invoice_line_ids])\n              cursor.execute(\n                  f\"\"\"\n                  SELECT SUM(UnitPrice * Quantity)\n                  FROM InvoiceLine\n                  WHERE InvoiceLineId IN ({placeholders})\n              \"\"\",\n                  invoice_line_ids,\n              )\n\n              result = cursor.fetchone()\n              if result and result[0]:\n                  total_refund += result[0]\n\n              if not mock:\n                  # Delete the specified invoice lines\n                  cursor.execute(\n                      f\"\"\"\n                      DELETE FROM InvoiceLine\n                      WHERE InvoiceLineId IN ({placeholders})\n                  \"\"\",\n                      invoice_line_ids,\n                  )\n\n          # Commit the changes\n          conn.commit()\n\n      except sqlite3.Error as e:\n          # Roll back in case of error\n          conn.rollback()\n          raise e\n\n      finally:\n          # Close the connection\n          conn.close()\n\n      return float(total_refund)\n\n\n  def _lookup(\n      customer_first_name: str,\n      customer_last_name: str,\n      customer_phone: str,\n      track_name: str | None,\n      album_title: str | None,\n      artist_name: str | None,\n      purchase_date_iso_8601: str | None,\n  ) -> list[dict]:\n      \"\"\"Find all of the Invoice Line IDs in the Chinook DB for the given filters.\n\n      Returns:\n          a list of dictionaries that contain keys: {\n              'invoice_line_id',\n              'track_name',\n              'artist_name',\n              'purchase_date',\n              'quantity_purchased',\n              'price_per_unit'\n          }\n      \"\"\"\n\n      # Connect to the database\n      conn = sqlite3.connect(\"chinook.db\")\n      cursor = conn.cursor()\n\n      # Base query joining all necessary tables\n      query = \"\"\"\n      SELECT\n          il.InvoiceLineId,\n          t.Name as track_name,\n          art.Name as artist_name,\n          i.InvoiceDate as purchase_date,\n          il.Quantity as quantity_purchased,\n          il.UnitPrice as price_per_unit\n      FROM InvoiceLine il\n      JOIN Invoice i ON il.InvoiceId = i.InvoiceId\n      JOIN Customer c ON i.CustomerId = c.CustomerId\n      JOIN Track t ON il.TrackId = t.TrackId\n      JOIN Album alb ON t.AlbumId = alb.AlbumId\n      JOIN Artist art ON alb.ArtistId = art.ArtistId\n      WHERE c.FirstName = ?\n      AND c.LastName = ?\n      AND c.Phone = ?\n      \"\"\"\n\n      # Parameters for the query\n      params = [customer_first_name, customer_last_name, customer_phone]\n\n      # Add optional filters\n      if track_name:\n          query += \" AND t.Name = ?\"\n          params.append(track_name)\n\n      if album_title:\n          query += \" AND alb.Title = ?\"\n          params.append(album_title)\n\n      if artist_name:\n          query += \" AND art.Name = ?\"\n          params.append(artist_name)\n\n      if purchase_date_iso_8601:\n          query += \" AND date(i.InvoiceDate) = date(?)\"\n          params.append(purchase_date_iso_8601)\n\n      # Execute query\n      cursor.execute(query, params)\n\n      # Fetch results\n      results = cursor.fetchall()\n\n      # Convert results to list of dictionaries\n      output = []\n      for row in results:\n          output.append(\n              {\n                  \"invoice_line_id\": row[0],\n                  \"track_name\": row[1],\n                  \"artist_name\": row[2],\n                  \"purchase_date\": row[3],\n                  \"quantity_purchased\": row[4],\n                  \"price_per_unit\": row[5],\n              }\n          )\n\n      # Close connection\n      conn.close()\n\n      return output\n\n\n  # Graph state.\n  class State(TypedDict):\n      \"\"\"Agent state.\"\"\"\n\n      messages: Annotated[list[AnyMessage], add_messages]\n      followup: str | None\n\n      invoice_id: int | None\n      invoice_line_ids: list[int] | None\n      customer_first_name: str | None\n      customer_last_name: str | None\n      customer_phone: str | None\n      track_name: str | None\n      album_title: str | None\n      artist_name: str | None\n      purchase_date_iso_8601: str | None\n\n\n  # Instructions for extracting the user/purchase info from the conversation.\n  gather_info_instructions = \"\"\"You are managing an online music store that sells song tracks. \\\n  Customers can buy multiple tracks at a time and these purchases are recorded in a database as \\\n  an Invoice per purchase and an associated set of Invoice Lines for each purchased track.\n\n  Your task is to help customers who would like a refund for one or more of the tracks they've \\\n  purchased. In order for you to be able refund them, the customer must specify the Invoice ID \\\n  to get a refund on all the tracks they bought in a single transaction, or one or more Invoice \\\n  Line IDs if they would like refunds on individual tracks.\n\n  Often a user will not know the specific Invoice ID(s) or Invoice Line ID(s) for which they \\\n  would like a refund. In this case you can help them look up their invoices by asking them to \\\n  specify:\n  - Required: Their first name, last name, and phone number.\n  - Optionally: The track name, artist name, album name, or purchase date.\n\n  If the customer has not specified the required information (either Invoice/Invoice Line IDs \\\n  or first name, last name, phone) then please ask them to specify it.\"\"\"\n\n\n  # Extraction schema, mirrors the graph state.\n  class PurchaseInformation(TypedDict):\n      \"\"\"All of the known information about the invoice / invoice lines the customer would like refunded. Do not make up values, leave fields as null if you don't know their value.\"\"\"\n\n      invoice_id: int | None\n      invoice_line_ids: list[int] | None\n      customer_first_name: str | None\n      customer_last_name: str | None\n      customer_phone: str | None\n      track_name: str | None\n      album_title: str | None\n      artist_name: str | None\n      purchase_date_iso_8601: str | None\n      followup: Annotated[\n          str | None,\n          ...,\n          \"If the user hasn't enough identifying information, please tell them what the required information is and ask them to specify it.\",\n      ]\n\n\n  # Model for performing extraction.\n  info_llm = init_chat_model(\"gpt-4o-mini\").with_structured_output(\n      PurchaseInformation, method=\"json_schema\", include_raw=True\n  )\n\n\n  # Graph node for extracting user info and routing to lookup/refund/END.\n  async def gather_info(state: State) -> Command[Literal[\"lookup\", \"refund\", END]]:\n      info = await info_llm.ainvoke(\n          [\n              {\"role\": \"system\", \"content\": gather_info_instructions},\n              *state[\"messages\"],\n          ]\n      )\n      parsed = info[\"parsed\"]\n      if any(parsed[k] for k in (\"invoice_id\", \"invoice_line_ids\")):\n          goto = \"refund\"\n      elif all(\n          parsed[k]\n          for k in (\"customer_first_name\", \"customer_last_name\", \"customer_phone\")\n      ):\n          goto = \"lookup\"\n      else:\n          goto = END\n      update = {\"messages\": [info[\"raw\"]], **parsed}\n      return Command(update=update, goto=goto)\n\n\n  # Graph node for executing the refund.\n  # Note that here we inspect the runtime config for an \"env\" variable.\n  # If \"env\" is set to \"test\", then we don't actually delete any rows from our database.\n  # This will become important when we're running our evaluations.\n  def refund(state: State, config: RunnableConfig) -> dict:\n      # Whether to mock the deletion. True if the configurable var 'env' is set to 'test'.\n      mock = config.get(\"configurable\", {}).get(\"env\", \"prod\") == \"test\"\n      refunded = _refund(\n          invoice_id=state[\"invoice_id\"],\n          invoice_line_ids=state[\"invoice_line_ids\"],\n          mock=mock,\n      )\n      response = f\"You have been refunded a total of: ${refunded:.2f}. Is there anything else I can help with?\"\n      return {\n          \"messages\": [{\"role\": \"assistant\", \"content\": response}],\n          \"followup\": response,\n      }\n\n\n  # Graph node for looking up the users purchases\n  def lookup(state: State) -> dict:\n      args = (\n          state[k]\n          for k in (\n              \"customer_first_name\",\n              \"customer_last_name\",\n              \"customer_phone\",\n              \"track_name\",\n              \"album_title\",\n              \"artist_name\",\n              \"purchase_date_iso_8601\",\n          )\n      )\n      results = _lookup(*args)\n      if not results:\n          response = \"We did not find any purchases associated with the information you've provided. Are you sure you've entered all of your information correctly?\"\n          followup = response\n      else:\n          response = f\"Which of the following purchases would you like to be refunded for?\\n\\n```json{json.dumps(results, indent=2)}\\n```\"\n          followup = f\"Which of the following purchases would you like to be refunded for?\\n\\n{tabulate(results, headers='keys')}\"\n      return {\n          \"messages\": [{\"role\": \"assistant\", \"content\": response}],\n          \"followup\": followup,\n          \"invoice_line_ids\": [res[\"invoice_line_id\"] for res in results],\n      }\n\n\n  # Building our graph\n  graph_builder = StateGraph(State)\n\n  graph_builder.add_node(gather_info)\n  graph_builder.add_node(refund)\n  graph_builder.add_node(lookup)\n\n  graph_builder.set_entry_point(\"gather_info\")\n  graph_builder.add_edge(\"lookup\", END)\n  graph_builder.add_edge(\"refund\", END)\n\n  refund_graph = graph_builder.compile()\n\n\n  # Our SQL queries will only work if we filter on the exact string values that are in the DB.\n  # To ensure this, we'll create vectorstore indexes for all of the artists, tracks and albums\n  # ahead of time and use those to disambiguate the user input. E.g. if a user searches for\n  # songs by \"prince\" and our DB records the artist as \"Prince\", ideally when we query our\n  # artist vectorstore for \"prince\" we'll get back the value \"Prince\", which we can then\n  # use in our SQL queries.\n  def index_fields() -> (\n      tuple[InMemoryVectorStore, InMemoryVectorStore, InMemoryVectorStore]\n  ):\n      \"\"\"Create an index for all artists, an index for all albums, and an index for all songs.\"\"\"\n      try:\n          # Connect to the chinook database\n          conn = sqlite3.connect(\"chinook.db\")\n          cursor = conn.cursor()\n\n          # Fetch all results\n          tracks = cursor.execute(\"SELECT Name FROM Track\").fetchall()\n          artists = cursor.execute(\"SELECT Name FROM Artist\").fetchall()\n          albums = cursor.execute(\"SELECT Title FROM Album\").fetchall()\n      finally:\n          # Close the connection\n          if conn:\n              conn.close()\n\n      embeddings = init_embeddings(\"openai:text-embedding-3-small\")\n\n      track_store = InMemoryVectorStore(embeddings)\n      artist_store = InMemoryVectorStore(embeddings)\n      album_store = InMemoryVectorStore(embeddings)\n\n      track_store.add_texts([t[0] for t in tracks])\n      artist_store.add_texts([a[0] for a in artists])\n      album_store.add_texts([a[0] for a in albums])\n      return track_store, artist_store, album_store\n\n\n  track_store, artist_store, album_store = index_fields()\n\n\n  # Agent tools\n  @tool\n  def lookup_track(\n      track_name: str | None = None,\n      album_title: str | None = None,\n      artist_name: str | None = None,\n  ) -> list[dict]:\n      \"\"\"Lookup a track in Chinook DB based on identifying information about.\n\n      Returns:\n          a list of dictionaries per matching track that contain keys {'track_name', 'artist_name', 'album_name'}\n      \"\"\"\n      conn = sqlite3.connect(\"chinook.db\")\n      cursor = conn.cursor()\n\n      query = \"\"\"\n      SELECT DISTINCT t.Name as track_name, ar.Name as artist_name, al.Title as album_name\n      FROM Track t\n      JOIN Album al ON t.AlbumId = al.AlbumId\n      JOIN Artist ar ON al.ArtistId = ar.ArtistId\n      WHERE 1=1\n      \"\"\"\n      params = []\n\n      if track_name:\n          track_name = track_store.similarity_search(track_name, k=1)[0].page_content\n          query += \" AND t.Name LIKE ?\"\n          params.append(f\"%{track_name}%\")\n      if album_title:\n          album_title = album_store.similarity_search(album_title, k=1)[0].page_content\n          query += \" AND al.Title LIKE ?\"\n          params.append(f\"%{album_title}%\")\n      if artist_name:\n          artist_name = artist_store.similarity_search(artist_name, k=1)[0].page_content\n          query += \" AND ar.Name LIKE ?\"\n          params.append(f\"%{artist_name}%\")\n\n      cursor.execute(query, params)\n      results = cursor.fetchall()\n\n      tracks = [\n          {\"track_name\": row[0], \"artist_name\": row[1], \"album_name\": row[2]}\n          for row in results\n      ]\n\n      conn.close()\n      return tracks\n\n\n  @tool\n  def lookup_album(\n      track_name: str | None = None,\n      album_title: str | None = None,\n      artist_name: str | None = None,\n  ) -> list[dict]:\n      \"\"\"Lookup an album in Chinook DB based on identifying information about.\n\n      Returns:\n          a list of dictionaries per matching album that contain keys {'album_name', 'artist_name'}\n      \"\"\"\n      conn = sqlite3.connect(\"chinook.db\")\n      cursor = conn.cursor()\n\n      query = \"\"\"\n      SELECT DISTINCT al.Title as album_name, ar.Name as artist_name\n      FROM Album al\n      JOIN Artist ar ON al.ArtistId = ar.ArtistId\n      LEFT JOIN Track t ON t.AlbumId = al.AlbumId\n      WHERE 1=1\n      \"\"\"\n      params = []\n\n      if track_name:\n          query += \" AND t.Name LIKE ?\"\n          params.append(f\"%{track_name}%\")\n      if album_title:\n          query += \" AND al.Title LIKE ?\"\n          params.append(f\"%{album_title}%\")\n      if artist_name:\n          query += \" AND ar.Name LIKE ?\"\n          params.append(f\"%{artist_name}%\")\n\n      cursor.execute(query, params)\n      results = cursor.fetchall()\n\n      albums = [{\"album_name\": row[0], \"artist_name\": row[1]} for row in results]\n\n      conn.close()\n      return albums\n\n\n  @tool\n  def lookup_artist(\n      track_name: str | None = None,\n      album_title: str | None = None,\n      artist_name: str | None = None,\n  ) -> list[str]:\n      \"\"\"Lookup an album in Chinook DB based on identifying information about.\n\n      Returns:\n          a list of matching artist names\n      \"\"\"\n      conn = sqlite3.connect(\"chinook.db\")\n      cursor = conn.cursor()\n\n      query = \"\"\"\n      SELECT DISTINCT ar.Name as artist_name\n      FROM Artist ar\n      LEFT JOIN Album al ON al.ArtistId = ar.ArtistId\n      LEFT JOIN Track t ON t.AlbumId = al.AlbumId\n      WHERE 1=1\n      \"\"\"\n      params = []\n\n      if track_name:\n          query += \" AND t.Name LIKE ?\"\n          params.append(f\"%{track_name}%\")\n      if album_title:\n          query += \" AND al.Title LIKE ?\"\n          params.append(f\"%{album_title}%\")\n      if artist_name:\n          query += \" AND ar.Name LIKE ?\"\n          params.append(f\"%{artist_name}%\")\n\n      cursor.execute(query, params)\n      results = cursor.fetchall()\n\n      artists = [row[0] for row in results]\n\n      conn.close()\n      return artists\n\n\n  # Agent model\n  qa_llm = init_chat_model(\"claude-sonnet-4-5-20250929\")\n  # The prebuilt ReACT agent only expects State to have a 'messages' key, so the\n  # state we defined for the refund agent can also be passed to our lookup agent.\n  qa_graph = create_agent(qa_llm, [lookup_track, lookup_artist, lookup_album])\n\n\n  # Schema for routing user intent.\n  # We'll use structured output to enforce that the model returns only\n  # the desired output.\n  class UserIntent(TypedDict):\n      \"\"\"The user's current intent in the conversation\"\"\"\n\n      intent: Literal[\"refund\", \"question_answering\"]\n\n\n  # Routing model with structured output\n  router_llm = init_chat_model(\"gpt-4o-mini\").with_structured_output(\n      UserIntent, method=\"json_schema\", strict=True\n  )\n\n  # Instructions for routing.\n  route_instructions = \"\"\"You are managing an online music store that sells song tracks. \\\n  You can help customers in two types of ways: (1) answering general questions about \\\n  tracks sold at your store, (2) helping them get a refund on a purhcase they made at your store.\n\n  Based on the following conversation, determine if the user is currently seeking general \\\n  information about song tracks or if they are trying to refund a specific purchase.\n\n  Return 'refund' if they are trying to get a refund and 'question_answering' if they are \\\n  asking a general music question. Do NOT return anything else. Do NOT try to respond to \\\n  the user.\n  \"\"\"\n\n\n  # Node for routing.\n  async def intent_classifier(\n      state: State,\n  ) -> Command[Literal[\"refund_agent\", \"question_answering_agent\"]]:\n      response = router_llm.invoke(\n          [{\"role\": \"system\", \"content\": route_instructions}, *state[\"messages\"]]\n      )\n      return Command(goto=response[\"intent\"] + \"_agent\")\n\n\n  # Node for making sure the 'followup' key is set before our agent run completes.\n  def compile_followup(state: State) -> dict:\n      \"\"\"Set the followup to be the last message if it hasn't explicitly been set.\"\"\"\n      if not state.get(\"followup\"):\n          return {\"followup\": state[\"messages\"][-1].content}\n      return {}\n\n\n  # Agent definition\n  graph_builder = StateGraph(State)\n  graph_builder.add_node(intent_classifier)\n  # Since all of our subagents have compatible state,\n  # we can add them as nodes directly.\n  graph_builder.add_node(\"refund_agent\", refund_graph)\n  graph_builder.add_node(\"question_answering_agent\", qa_graph)\n  graph_builder.add_node(compile_followup)\n\n  graph_builder.set_entry_point(\"intent_classifier\")\n  graph_builder.add_edge(\"refund_agent\", \"compile_followup\")\n  graph_builder.add_edge(\"question_answering_agent\", \"compile_followup\")\n  graph_builder.add_edge(\"compile_followup\", END)\n\n  graph = graph_builder.compile()\n\n\n  client = Client()\n\n  # Create a dataset\n  examples = [\n      {\n          \"inputs\": {\n              \"question\": \"How many songs do you have by James Brown\"\n          },\n          \"outputs\": {\n              \"response\": \"We have 20 songs by James Brown\",\n              \"trajectory\": [\"question_answering_agent\", \"lookup_tracks\"]\n          },\n      },\n      {\n          \"inputs\": {\n              \"question\": \"My name is Aaron Mitchell and I'd like a refund.\",\n          },\n          \"outputs\": {\n              \"response\": \"I need some more information to help you with the refund. Please specify your phone number, the invoice ID, or the line item IDs for the purchase you'd like refunded.\",\n              \"trajectory\": [\"refund_agent\"],\n          }\n      },\n      {\n          \"inputs\": {\n              \"question\": \"My name is Aaron Mitchell and I'd like a refund on my Led Zeppelin purchases. My number is +1 (204) 452-6452\",\n          },\n          \"outputs\": {\n              \"response\": \"Which of the following purchases would you like to be refunded for?\\n\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99\",\n              \"trajectory\": [\"refund_agent\", \"lookup\"],\n          },\n      },\n      {\n          \"inputs\": {\n              \"question\": \"Who recorded Wish You Were Here again? What other albums of there's do you have?\",\n          },\n          \"outputs\": {\n              \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n              \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\n          }\n      },\n      {\n          \"inputs\": {\n              \"question\": \"I want a full refund for invoice 237\",\n          },\n          \"outputs\": {\n              \"response\": \"You have been refunded $2.97.\",\n              \"trajectory\": [\"refund_agent\", \"refund\"],\n          },\n      },\n  ]\n\n  dataset_name = \"Chinook Customer Service Bot: E2E\"\n\n  if not client.has_dataset(dataset_name=dataset_name):\n      dataset = client.create_dataset(dataset_name=dataset_name)\n      client.create_examples(\n          dataset_id=dataset.id,\n          examples=examples\n      )\n\n  # LLM-as-judge instructions\n  grader_instructions = \"\"\"You are a teacher grading a quiz.\n\n  You will be given a QUESTION, the GROUND TRUTH (correct) RESPONSE, and the STUDENT RESPONSE.\n\n  Here is the grade criteria to follow:\n  (1) Grade the student responses based ONLY on their factual accuracy relative to the ground truth answer.\n  (2) Ensure that the student response does not contain any conflicting statements.\n  (3) It is OK if the student response contains more information than the ground truth response, as long as it is factually accurate relative to the  ground truth response.\n\n  Correctness:\n  True means that the student's response meets all of the criteria.\n  False means that the student's response does not meet all of the criteria.\n\n  Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n\n\n  # LLM-as-judge output schema\n  class Grade(TypedDict):\n      \"\"\"Compare the expected and actual answers and grade the actual answer.\"\"\"\n\n      reasoning: Annotated[\n          str,\n          ...,\n          \"Explain your reasoning for whether the actual response is correct or not.\",\n      ]\n      is_correct: Annotated[\n          bool,\n          ...,\n          \"True if the student response is mostly or exactly correct, otherwise False.\",\n      ]\n\n\n  # Judge LLM\n  grader_llm = init_chat_model(\"gpt-4o-mini\", temperature=0).with_structured_output(\n      Grade, method=\"json_schema\", strict=True\n  )\n\n\n  # Evaluator function\n  async def final_answer_correct(\n      inputs: dict, outputs: dict, reference_outputs: dict\n  ) -> bool:\n      \"\"\"Evaluate if the final response is equivalent to reference response.\"\"\"\n\n      # Note that we assume the outputs has a 'response' dictionary. We'll need to make sure\n      # that the target function we define includes this key.\n      user = f\"\"\"QUESTION: {inputs['question']}\n      GROUND TRUTH RESPONSE: {reference_outputs['response']}\n      STUDENT RESPONSE: {outputs['response']}\"\"\"\n\n      grade = await grader_llm.ainvoke(\n          [\n              {\"role\": \"system\", \"content\": grader_instructions},\n              {\"role\": \"user\", \"content\": user},\n          ]\n      )\n      return grade[\"is_correct\"]\n\n\n  # Target function\n  async def run_graph(inputs: dict) -> dict:\n      \"\"\"Run graph and track the trajectory it takes along with the final response.\"\"\"\n      result = await graph.ainvoke(\n          {\n              \"messages\": [\n                  {\"role\": \"user\", \"content\": inputs[\"question\"]},\n              ]\n          },\n          config={\"env\": \"test\"},\n      )\n      return {\"response\": result[\"followup\"]}\n\n\n  # Evaluation job and results\n  experiment_results = await client.aevaluate(\n      run_graph,\n      data=dataset_name,\n      evaluators=[final_answer_correct],\n      experiment_prefix=\"sql-agent-gpt4o-e2e\",\n      num_repetitions=1,\n      max_concurrency=4,\n  )\n  experiment_results.to_pandas()\n\n\n  def trajectory_subsequence(outputs: dict, reference_outputs: dict) -> float:\n      \"\"\"Check how many of the desired steps the agent took.\"\"\"\n      if len(reference_outputs[\"trajectory\"]) > len(outputs[\"trajectory\"]):\n          return False\n\n      i = j = 0\n      while i < len(reference_outputs[\"trajectory\"]) and j < len(outputs[\"trajectory\"]):\n          if reference_outputs[\"trajectory\"][i] == outputs[\"trajectory\"][j]:\n              i += 1\n          j += 1\n\n      return i / len(reference_outputs[\"trajectory\"])\n\n\n  async def run_graph(inputs: dict) -> dict:\n      \"\"\"Run graph and track the trajectory it takes along with the final response.\"\"\"\n      trajectory = []\n      # Set subgraph=True to stream events from subgraphs of the main graph: https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/\n      # Set stream_mode=\"debug\" to stream all possible events: https://langchain-ai.github.io/langgra/langsmith/observability-concepts/streaming\n      async for namespace, chunk in graph.astream(\n          {\n              \"messages\": [\n                  {\n                      \"role\": \"user\",\n                      \"content\": inputs[\"question\"],\n                  }\n              ]\n          },\n          subgraphs=True,\n          stream_mode=\"debug\",\n      ):\n          # Event type for entering a node\n          if chunk[\"type\"] == \"task\":\n              # Record the node name\n              trajectory.append(chunk[\"payload\"][\"name\"])\n              # Given how we defined our dataset, we also need to track when specific tools are\n              # called by our question answering ReACT agent. These tool calls can be found\n              # when the ToolsNode (named \"tools\") is invoked by looking at the AIMessage.tool_calls\n              # of the latest input message.\n              if chunk[\"payload\"][\"name\"] == \"tools\" and chunk[\"type\"] == \"task\":\n                  for tc in chunk[\"payload\"][\"input\"][\"messages\"][-1].tool_calls:\n                      trajectory.append(tc[\"name\"])\n\n      return {\"trajectory\": trajectory}\n\n\n  experiment_results = await client.aevaluate(\n      run_graph,\n      data=dataset_name,\n      evaluators=[trajectory_subsequence],\n      experiment_prefix=\"sql-agent-gpt4o-trajectory\",\n      num_repetitions=1,\n      max_concurrency=4,\n  )\n  experiment_results.to_pandas()\n\n  # Create dataset\n  examples = [\n      {\n          \"inputs\": {\n              \"messages\": [\n                  {\n                      \"role\": \"user\",\n                      \"content\": \"i bought some tracks recently and i dont like them\",\n                  }\n              ],\n          }\n          \"outputs\": {\"route\": \"refund_agent\"},\n      },\n      {\n          \"inputs\": {\n              \"messages\": [\n                  {\n                      \"role\": \"user\",\n                      \"content\": \"I was thinking of purchasing some Rolling Stones tunes, any recommendations?\",\n                  }\n              ],\n          },\n          \"outputs\": {\"route\": \"question_answering_agent\"},\n      },\n      {\n          \"inputs\": {\n              \"messages\": [\n                      {\"role\": \"user\", \"content\": \"i want a refund on purchase 237\"},\n                  {\n                      \"role\": \"assistant\",\n                      \"content\": \"I've refunded you a total of $1.98. How else can I help you today?\",\n                  },\n                  {\"role\": \"user\", \"content\": \"did prince release any albums in 2000?\"},\n              ],\n          },\n          \"outputs\": {\"route\": \"question_answering_agent\"},\n      },\n      {\n          \"inputs\": {\n              \"messages\": [\n                  {\n                      \"role\": \"user\",\n                      \"content\": \"i purchased a cover of Yesterday recently but can't remember who it was by, which versions of it do you have?\",\n                  }\n              ],\n          },\n          \"outputs\": {\"route\": \"question_answering_agent\"},\n      },\n  ]\n\n  dataset_name = \"Chinook Customer Service Bot: Intent Classifier\"\n  if not client.has_dataset(dataset_name=dataset_name):\n      dataset = client.create_dataset(dataset_name=dataset_name)\n      client.create_examples(\n          dataset_id=dataset.id,\n          examples=examples,\n      )\n\n\n  # Evaluator\n  def correct(outputs: dict, reference_outputs: dict) -> bool:\n      \"\"\"Check if the agent chose the correct route.\"\"\"\n      return outputs[\"route\"] == reference_outputs[\"route\"]\n\n\n  # Target function for running the relevant step\n  async def run_intent_classifier(inputs: dict) -> dict:\n      # Note that we can access and run the intent_classifier node of our graph directly.\n      command = await graph.nodes[\"intent_classifier\"].ainvoke(inputs)\n      return {\"route\": command.goto}\n\n\n  # Run evaluation\n  experiment_results = await client.aevaluate(\n      run_intent_classifier,\n      data=dataset_name,\n      evaluators=[correct],\n      experiment_prefix=\"sql-agent-gpt4o-intent-classifier\",\n      max_concurrency=4,\n  )\n  experiment_results.to_pandas()\n  ````\n</Accordion>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/evaluate-complex-agent.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 67926
}