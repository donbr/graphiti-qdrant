{
  "title": "Human-in-the-loop",
  "source_url": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
  "content": "The Human-in-the-Loop (HITL) [middleware](/oss/python/langchain/middleware/built-in#human-in-the-loop) lets you add human oversight to agent tool calls.\nWhen a model proposes an action that might require review — for example, writing to a file or executing SQL — the middleware can pause execution and wait for a decision.\n\nIt does this by checking each tool call against a configurable policy. If intervention is needed, the middleware issues an [interrupt](https://reference.langchain.com/python/langgraph/types/#langgraph.types.interrupt) that halts execution. The graph state is saved using LangGraph's [persistence layer](/oss/python/langgraph/persistence), so execution can pause safely and resume later.\n\nA human decision then determines what happens next: the action can be approved as-is (`approve`), modified before running (`edit`), or rejected with feedback (`reject`).\n\n## Interrupt decision types\n\nThe [middleware](/oss/python/langchain/middleware/built-in#human-in-the-loop) defines three built-in ways a human can respond to an interrupt:\n\n| Decision Type | Description                                                               | Example Use Case                                    |\n| ------------- | ------------------------------------------------------------------------- | --------------------------------------------------- |\n| ✅ `approve`   | The action is approved as-is and executed without changes.                | Send an email draft exactly as written              |\n| ✏️ `edit`     | The tool call is executed with modifications.                             | Change the recipient before sending an email        |\n| ❌ `reject`    | The tool call is rejected, with an explanation added to the conversation. | Reject an email draft and explain how to rewrite it |\n\nThe available decision types for each tool depend on the policy you configure in `interrupt_on`.\nWhen multiple tool calls are paused at the same time, each action requires a separate decision.\nDecisions must be provided in the same order as the actions appear in the interrupt request.\n\n<Tip>\n  When **editing** tool arguments, make changes conservatively. Significant modifications to the original arguments may cause the model to re-evaluate its approach and potentially execute the tool multiple times or take unexpected actions.\n</Tip>\n\n## Configuring interrupts\n\nTo use HITL, add the [middleware](/oss/python/langchain/middleware/built-in#human-in-the-loop) to the agent's `middleware` list when creating the agent.\n\nYou configure it with a mapping of tool actions to the decision types that are allowed for each action. The middleware will interrupt execution when a tool call matches an action in the mapping.\n\n```python  theme={null}\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware # [!code highlight]\nfrom langgraph.checkpoint.memory import InMemorySaver # [!code highlight]\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[write_file_tool, execute_sql_tool, read_data_tool],\n    middleware=[\n        HumanInTheLoopMiddleware( # [!code highlight]\n            interrupt_on={\n                \"write_file\": True,  # All decisions (approve, edit, reject) allowed\n                \"execute_sql\": {\"allowed_decisions\": [\"approve\", \"reject\"]},  # No editing allowed\n                # Safe operation, no approval needed\n                \"read_data\": False,\n            },\n            # Prefix for interrupt messages - combined with tool name and args to form the full message\n            # e.g., \"Tool execution pending approval: execute_sql with query='DELETE FROM...'\"\n            # Individual tools can override this by specifying a \"description\" in their interrupt config\n            description_prefix=\"Tool execution pending approval\",\n        ),\n    ],\n    # Human-in-the-loop requires checkpointing to handle interrupts.\n    # In production, use a persistent checkpointer like AsyncPostgresSaver.\n    checkpointer=InMemorySaver(),  # [!code highlight]\n)\n```\n\n<Info>\n  You must configure a checkpointer to persist the graph state across interrupts.\n  In production, use a persistent checkpointer like [`AsyncPostgresSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.postgres.aio.AsyncPostgresSaver). For testing or prototyping, use [`InMemorySaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.memory.InMemorySaver).\n\n  When invoking the agent, pass a `config` that includes the **thread ID** to associate execution with a conversation thread.\n  See the [LangGraph interrupts documentation](/oss/python/langgraph/interrupts) for details.\n</Info>\n\n<Accordion title=\"Configuration options\">\n  <ParamField body=\"interrupt_on\" type=\"dict\" required>\n    Mapping of tool names to approval configs. Values can be `True` (interrupt with default config), `False` (auto-approve), or an `InterruptOnConfig` object.\n  </ParamField>\n\n  <ParamField body=\"description_prefix\" type=\"string\" default=\"Tool execution requires approval\">\n    Prefix for action request descriptions\n  </ParamField>\n\n  **`InterruptOnConfig` options:**\n\n  <ParamField body=\"allowed_decisions\" type=\"list[string]\">\n    List of allowed decisions: `'approve'`, `'edit'`, or `'reject'`\n  </ParamField>\n\n  <ParamField body=\"description\" type=\"string | callable\">\n    Static string or callable function for custom description\n  </ParamField>\n</Accordion>\n\n## Responding to interrupts\n\nWhen you invoke the agent, it runs until it either completes or an interrupt is raised. An interrupt is triggered when a tool call matches the policy you configured in `interrupt_on`. In that case, the invocation result will include an `__interrupt__` field with the actions that require review. You can then present those actions to a reviewer and resume execution once decisions are provided.\n\n```python  theme={null}\nfrom langgraph.types import Command\n\n# Human-in-the-loop leverages LangGraph's persistence layer.\n# You must provide a thread ID to associate the execution with a conversation thread,\n# so the conversation can be paused and resumed (as is needed for human review).\nconfig = {\"configurable\": {\"thread_id\": \"some_id\"}} # [!code highlight]\n# Run the graph until the interrupt is hit.\nresult = agent.invoke(\n    {\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": \"Delete old records from the database\",\n            }\n        ]\n    },\n    config=config # [!code highlight]\n)\n\n# The interrupt contains the full HITL request with action_requests and review_configs\nprint(result['__interrupt__'])\n# > [\n# >    Interrupt(\n# >       value={\n# >          'action_requests': [\n# >             {\n# >                'name': 'execute_sql',\n# >                'arguments': {'query': 'DELETE FROM records WHERE created_at < NOW() - INTERVAL \\'30 days\\';'},\n# >                'description': 'Tool execution pending approval\\n\\nTool: execute_sql\\nArgs: {...}'\n# >             }\n# >          ],\n# >          'review_configs': [\n# >             {\n# >                'action_name': 'execute_sql',\n# >                'allowed_decisions': ['approve', 'reject']\n# >             }\n# >          ]\n# >       }\n# >    )\n# > ]\n\n\n# Resume with approval decision\nagent.invoke(\n    Command( # [!code highlight]\n        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"edit\", \"reject\" [!code highlight]\n    ), # [!code highlight]\n    config=config # Same thread ID to resume the paused conversation\n)\n```\n\n### Decision types\n\n<Tabs>\n  <Tab title=\"✅ approve\">\n    Use `approve` to approve the tool call as-is and execute it without changes.\n\n    ```python  theme={null}\n    agent.invoke(\n        Command(\n            # Decisions are provided as a list, one per action under review.\n            # The order of decisions must match the order of actions\n            # listed in the `__interrupt__` request.\n            resume={\n                \"decisions\": [\n                    {\n                        \"type\": \"approve\",\n                    }\n                ]\n            }\n        ),\n        config=config  # Same thread ID to resume the paused conversation\n    )\n    ```\n  </Tab>\n\n  <Tab title=\"✏️ edit\">\n    Use `edit` to modify the tool call before execution.\n    Provide the edited action with the new tool name and arguments.\n\n    ```python  theme={null}\n    agent.invoke(\n        Command(\n            # Decisions are provided as a list, one per action under review.\n            # The order of decisions must match the order of actions\n            # listed in the `__interrupt__` request.\n            resume={\n                \"decisions\": [\n                    {\n                        \"type\": \"edit\",\n                        # Edited action with tool name and args\n                        \"edited_action\": {\n                            # Tool name to call.\n                            # Will usually be the same as the original action.\n                            \"name\": \"new_tool_name\",\n                            # Arguments to pass to the tool.\n                            \"args\": {\"key1\": \"new_value\", \"key2\": \"original_value\"},\n                        }\n                    }\n                ]\n            }\n        ),\n        config=config  # Same thread ID to resume the paused conversation\n    )\n    ```\n\n    <Tip>\n      When **editing** tool arguments, make changes conservatively. Significant modifications to the original arguments may cause the model to re-evaluate its approach and potentially execute the tool multiple times or take unexpected actions.\n    </Tip>\n  </Tab>\n\n  <Tab title=\"❌ reject\">\n    Use `reject` to reject the tool call and provide feedback instead of execution.\n\n    ```python  theme={null}\n    agent.invoke(\n        Command(\n            # Decisions are provided as a list, one per action under review.\n            # The order of decisions must match the order of actions\n            # listed in the `__interrupt__` request.\n            resume={\n                \"decisions\": [\n                    {\n                        \"type\": \"reject\",\n                        # An explanation about why the action was rejected\n                        \"message\": \"No, this is wrong because ..., instead do this ...\",\n                    }\n                ]\n            }\n        ),\n        config=config  # Same thread ID to resume the paused conversation\n    )\n    ```\n\n    The `message` is added to the conversation as feedback to help the agent understand why the action was rejected and what it should do instead.\n\n    ***\n\n    ### Multiple decisions\n\n    When multiple actions are under review, provide a decision for each action in the same order as they appear in the interrupt:\n\n    ```python  theme={null}\n    {\n        \"decisions\": [\n            {\"type\": \"approve\"},\n            {\n                \"type\": \"edit\",\n                \"edited_action\": {\n                    \"name\": \"tool_name\",\n                    \"args\": {\"param\": \"new_value\"}\n                }\n            },\n            {\n                \"type\": \"reject\",\n                \"message\": \"This action is not allowed\"\n            }\n        ]\n    }\n    ```\n  </Tab>\n</Tabs>\n\n## Execution lifecycle\n\nThe middleware defines an `after_model` hook that runs after the model generates a response but before any tool calls are executed:\n\n1. The agent invokes the model to generate a response.\n2. The middleware inspects the response for tool calls.\n3. If any calls require human input, the middleware builds a `HITLRequest` with `action_requests` and `review_configs` and calls [interrupt](https://reference.langchain.com/python/langgraph/types/#langgraph.types.interrupt).\n4. The agent waits for human decisions.\n5. Based on the `HITLResponse` decisions, the middleware executes approved or edited calls, synthesizes [ToolMessage](https://reference.langchain.com/python/langchain/messages/#langchain.messages.ToolMessage)'s for rejected calls, and resumes execution.\n\n## Custom HITL logic\n\nFor more specialized workflows, you can build custom HITL logic directly using the [interrupt](https://reference.langchain.com/python/langgraph/types/#langgraph.types.interrupt) primitive and [middleware](/oss/python/langchain/middleware) abstraction.\n\nReview the [execution lifecycle](#execution-lifecycle) above to understand how to integrate interrupts into the agent's operation.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/human-in-the-loop.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 12756
}