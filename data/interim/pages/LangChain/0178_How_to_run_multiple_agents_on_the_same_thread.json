{
  "title": "How to run multiple agents on the same thread",
  "source_url": "https://docs.langchain.com/langsmith/same-thread",
  "content": "In LangSmith Deployment, a thread is not explicitly associated with a particular agent.\nThis means that you can run multiple agents on the same thread, which allows a different agent to continue from an initial agent's progress.\n\nIn this example, we will create two agents and then call them both on the same thread.\nYou'll see that the second agent will respond using information from the [checkpoint](/oss/python/langgraph/graph-api#checkpointer-state) generated in the thread by the first agent as context.\n\n## Setup\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    from langgraph_sdk import get_client\n\n    client = get_client(url=<DEPLOYMENT_URL>)\n\n    openai_assistant = await client.assistants.create(\n        graph_id=\"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n    )\n\n    # There should always be a default assistant with no configuration\n    assistants = await client.assistants.search()\n    default_assistant = [a for a in assistants if not a[\"config\"]][0]\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    import { Client } from \"@langchain/langgraph-sdk\";\n\n    const client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n\n    const openAIAssistant = await client.assistants.create(\n      { graphId: \"agent\", config: {\"configurable\": {\"model_name\": \"openai\"}}}\n    );\n\n    const assistants = await client.assistants.search();\n    const defaultAssistant = assistants.find(a => !a.config);\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request POST \\\n        --url <DEPLOYMENT_URL>/assistants \\\n        --header 'Content-Type: application/json' \\\n        --data '{\n            \"graph_id\": \"agent\",\n            \"config\": { \"configurable\": { \"model_name\": \"openai\" } }\n        }' && \\\n    curl --request POST \\\n        --url <DEPLOYMENT_URL>/assistants/search \\\n        --header 'Content-Type: application/json' \\\n        --data '{\n            \"limit\": 10,\n            \"offset\": 0\n        }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n    ```\n  </Tab>\n</Tabs>\n\nWe can see that these agents are different:\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    print(openai_assistant)\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    console.log(openAIAssistant);\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request GET \\\n        --url <DEPLOYMENT_URL>/assistants/<OPENAI_ASSISTANT_ID>\n    ```\n  </Tab>\n</Tabs>\n\nOutput:\n\n```\n{\n\"assistant_id\": \"db87f39d-b2b1-4da8-ac65-cf81beb3c766\",\n\"graph_id\": \"agent\",\n\"created_at\": \"2024-08-30T21:18:51.850581+00:00\",\n\"updated_at\": \"2024-08-30T21:18:51.850581+00:00\",\n\"config\": {\n\"configurable\": {\n\"model_name\": \"openai\"\n}\n},\n\"metadata\": {}\n}\n```\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    print(default_assistant)\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    console.log(defaultAssistant);\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request GET \\\n        --url <DEPLOYMENT_URL>/assistants/<DEFAULT_ASSISTANT_ID>\n    ```\n  </Tab>\n</Tabs>\n\nOutput:\n\n```\n{\n\"assistant_id\": \"fe096781-5601-53d2-b2f6-0d3403f7e9ca\",\n\"graph_id\": \"agent\",\n\"created_at\": \"2024-08-08T22:45:24.562906+00:00\",\n\"updated_at\": \"2024-08-08T22:45:24.562906+00:00\",\n\"config\": {},\n\"metadata\": {\n\"created_by\": \"system\"\n}\n}\n```\n\n## Run assistants on thread\n\n### Run OpenAI assistant\n\nWe can now run the OpenAI assistant on the thread first.\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    thread = await client.threads.create()\n    input = {\"messages\": [{\"role\": \"user\", \"content\": \"who made you?\"}]}\n    async for event in client.runs.stream(\n        thread[\"thread_id\"],\n        openai_assistant[\"assistant_id\"],\n        input=input,\n        stream_mode=\"updates\",\n    ):\n        print(f\"Receiving event of type: {event.event}\")\n        print(event.data)\n        print(\"\\n\\n\")\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    const thread = await client.threads.create();\n    let input =  {\"messages\": [{\"role\": \"user\", \"content\": \"who made you?\"}]}\n\n    const streamResponse = client.runs.stream(\n      thread[\"thread_id\"],\n      openAIAssistant[\"assistant_id\"],\n      {\n        input,\n        streamMode: \"updates\"\n      }\n    );\n    for await (const event of streamResponse) {\n      console.log(`Receiving event of type: ${event.event}`);\n      console.log(event.data);\n      console.log(\"\\n\\n\");\n    }\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    thread_id=$(curl --request POST \\\n        --url <DEPLOYMENT_URL>/threads \\\n        --header 'Content-Type: application/json' \\\n        --data '{}' | jq -r '.thread_id') && \\\n    curl --request POST \\\n        --url \"<DEPLOYMENT_URL>/threads/${thread_id}/runs/stream\" \\\n        --header 'Content-Type: application/json' \\\n        --data '{\n            \"assistant_id\": <OPENAI_ASSISTANT_ID>,\n            \"input\": {\n                \"messages\": [\n                    {\n                        \"role\": \"user\",\n                        \"content\": \"who made you?\"\n                    }\n                ]\n            },\n            \"stream_mode\": [\n                \"updates\"\n            ]\n        }' | \\\n        sed 's/\\r$//' | \\\n        awk '\n        /^event:/ {\n            if (data_content != \"\") {\n                print data_content \"\\n\"\n            }\n            sub(/^event: /, \"Receiving event of type: \", $0)\n            printf \"%s...\\n\", $0\n            data_content = \"\"\n        }\n        /^data:/ {\n            sub(/^data: /, \"\", $0)\n            data_content = $0\n        }\n        END {\n            if (data_content != \"\") {\n                print data_content \"\\n\\n\"\n            }\n        }\n    '\n    ```\n  </Tab>\n</Tabs>\n\nOutput:\n\n```\nReceiving event of type: metadata\n{'run_id': '1ef671c5-fb83-6e70-b698-44dba2d9213e'}\n\nReceiving event of type: updates\n{'agent': {'messages': [{'content': 'I was created by OpenAI, a research organization focused on developing and advancing artificial intelligence technology.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-f5735b86-b80d-4c71-8dc3-4782b5a9c7c8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]}}\n```\n\n### Run default assistant\n\nNow, we can run it on the default assistant and see that this second assistant is aware of the initial question, and can answer the question, \"and you?\":\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    input = {\"messages\": [{\"role\": \"user\", \"content\": \"and you?\"}]}\n    async for event in client.runs.stream(\n        thread[\"thread_id\"],\n        default_assistant[\"assistant_id\"],\n        input=input,\n        stream_mode=\"updates\",\n    ):\n        print(f\"Receiving event of type: {event.event}\")\n        print(event.data)\n        print(\"\\n\\n\")\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    let input =  {\"messages\": [{\"role\": \"user\", \"content\": \"and you?\"}]}\n\n    const streamResponse = client.runs.stream(\n      thread[\"thread_id\"],\n      defaultAssistant[\"assistant_id\"],\n      {\n        input,\n        streamMode: \"updates\"\n      }\n    );\n    for await (const event of streamResponse) {\n      console.log(`Receiving event of type: ${event.event}`);\n      console.log(event.data);\n      console.log(\"\\n\\n\");\n    }\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request POST \\\n        --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n        --header 'Content-Type: application/json' \\\n        --data '{\n            \"assistant_id\": <DEFAULT_ASSISTANT_ID>,\n            \"input\": {\n                \"messages\": [\n                    {\n                        \"role\": \"user\",\n                        \"content\": \"and you?\"\n                    }\n                ]\n            },\n            \"stream_mode\": [\n                \"updates\"\n            ]\n        }' | \\\n        sed 's/\\r$//' | \\\n        awk '\n        /^event:/ {\n            if (data_content != \"\") {\n                print data_content \"\\n\"\n            }\n            sub(/^event: /, \"Receiving event of type: \", $0)\n            printf \"%s...\\n\", $0\n            data_content = \"\"\n        }\n        /^data:/ {\n            sub(/^data: /, \"\", $0)\n            data_content = $0\n        }\n        END {\n            if (data_content != \"\") {\n                print data_content \"\\n\\n\"\n            }\n        }\n    '\n    ```\n  </Tab>\n</Tabs>\n\nOutput:\n\n```\nReceiving event of type: metadata\n{'run_id': '1ef6722d-80b3-6fbb-9324-253796b1cd13'}\n\nReceiving event of type: updates\n{'agent': {'messages': [{'content': [{'text': 'I am an artificial intelligence created by Anthropic, not by OpenAI. I should not have stated that OpenAI created me, as that is incorrect. Anthropic is the company that developed and trained me using advanced language models and AI technology. I will be more careful about providing accurate information regarding my origins in the future.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-ebaacf62-9dd9-4165-9535-db432e4793ec', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 302, 'output_tokens': 72, 'total_tokens': 374}}]}}\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/same-thread.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 9827
}