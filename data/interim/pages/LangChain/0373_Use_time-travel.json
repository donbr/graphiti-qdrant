{
  "title": "Use time-travel",
  "source_url": "https://docs.langchain.com/oss/javascript/langgraph/use-time-travel",
  "content": "When working with non-deterministic systems that make model-based decisions (e.g., agents powered by LLMs), it can be useful to examine their decision-making process in detail:\n\n1. <Icon icon=\"lightbulb\" size={16} /> **Understand reasoning**: Analyze the steps that led to a successful result.\n2. <Icon icon=\"bug\" size={16} /> **Debug mistakes**: Identify where and why errors occurred.\n3. <Icon icon=\"magnifying-glass\" size={16} /> **Explore alternatives**: Test different paths to uncover better solutions.\n\nLangGraph provides [time travel](/oss/javascript/langgraph/use-time-travel) functionality to support these use cases. Specifically, you can resume execution from a prior checkpoint — either replaying the same state or modifying it to explore alternatives. In all cases, resuming past execution produces a new fork in the history.\n\nTo use [time-travel](/oss/javascript/langgraph/use-time-travel) in LangGraph:\n\n1. [Run the graph](#1-run-the-graph) with initial inputs using [`invoke`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.CompiledStateGraph.html#invoke) or [`stream`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.CompiledStateGraph.html#stream) methods.\n2. [Identify a checkpoint in an existing thread](#2-identify-a-checkpoint): Use the [`getStateHistory`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.pregel.Pregel.html#getStateHistory) method to retrieve the execution history for a specific `thread_id` and locate the desired `checkpoint_id`.\n   Alternatively, set a [breakpoint](/oss/javascript/langgraph/interrupts) before the node(s) where you want execution to pause. You can then find the most recent checkpoint recorded up to that breakpoint.\n3. [Update the graph state (optional)](#3-update-the-state-optional): Use the [`updateState`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.pregel.Pregel.html#updateState) method to modify the graph's state at the checkpoint and resume execution from alternative state.\n4. [Resume execution from the checkpoint](#4-resume-execution-from-the-checkpoint): Use the `invoke` or `stream` methods with an input of `null` and a configuration containing the appropriate `thread_id` and `checkpoint_id`.\n\n<Tip>\n  For a conceptual overview of time-travel, see [Time travel](/oss/javascript/langgraph/use-time-travel).\n</Tip>\n\n## In a workflow\n\nThis example builds a simple LangGraph workflow that generates a joke topic and writes a joke using an LLM. It demonstrates how to run the graph, retrieve past execution checkpoints, optionally modify the state, and resume execution from a chosen checkpoint to explore alternate outcomes.\n\n### Setup\n\nFirst we need to install the packages required\n\n```bash  theme={null}\nnpm install @langchain/langgraph @langchain/anthropic\n```\n\nNext, we need to set API keys for Anthropic (the LLM we will use)\n\n```typescript  theme={null}\nprocess.env.ANTHROPIC_API_KEY = \"YOUR_API_KEY\";\n```\n\n<Tip>\n  Sign up for [LangSmith](https://smith.langchain.com) to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph.\n</Tip>\n\n```typescript  theme={null}\nimport { v4 as uuidv4 } from \"uuid\";\nimport * as z from \"zod\";\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst State = z.object({\n  topic: z.string().optional(),\n  joke: z.string().optional(),\n});\n\nconst model = new ChatAnthropic({\n  model: \"claude-sonnet-4-5-20250929\",\n  temperature: 0,\n});\n\n// Build workflow\nconst workflow = new StateGraph(State)\n  // Add nodes\n  .addNode(\"generateTopic\", async (state) => {\n    // LLM call to generate a topic for the joke\n    const msg = await model.invoke(\"Give me a funny topic for a joke\");\n    return { topic: msg.content };\n  })\n  .addNode(\"writeJoke\", async (state) => {\n    // LLM call to write a joke based on the topic\n    const msg = await model.invoke(`Write a short joke about ${state.topic}`);\n    return { joke: msg.content };\n  })\n  // Add edges to connect nodes\n  .addEdge(START, \"generateTopic\")\n  .addEdge(\"generateTopic\", \"writeJoke\")\n  .addEdge(\"writeJoke\", END);\n\n// Compile\nconst checkpointer = new MemorySaver();\nconst graph = workflow.compile({ checkpointer });\n```\n\n### 1. Run the graph\n\n```typescript  theme={null}\nconst config = {\n  configurable: {\n    thread_id: uuidv4(),\n  },\n};\n\nconst state = await graph.invoke({}, config);\n\nconsole.log(state.topic);\nconsole.log();\nconsole.log(state.joke);\n```\n\n**Output:**\n\n```\nHow about \"The Secret Life of Socks in the Dryer\"? You know, exploring the mysterious phenomenon of how socks go into the laundry as pairs but come out as singles. Where do they go? Are they starting new lives elsewhere? Is there a sock paradise we don't know about? There's a lot of comedic potential in the everyday mystery that unites us all!\n\n# The Secret Life of Socks in the Dryer\n\nI finally discovered where all my missing socks go after the dryer. Turns out they're not missing at all—they've just eloped with someone else's socks from the laundromat to start new lives together.\n\nMy blue argyle is now living in Bermuda with a red polka dot, posting vacation photos on Sockstagram and sending me lint as alimony.\n```\n\n### 2. Identify a checkpoint\n\n```typescript  theme={null}\n// The states are returned in reverse chronological order.\nconst states = [];\nfor await (const state of graph.getStateHistory(config)) {\n  states.push(state);\n}\n\nfor (const state of states) {\n  console.log(state.next);\n  console.log(state.config.configurable?.checkpoint_id);\n  console.log();\n}\n```\n\n**Output:**\n\n```\n[]\n1f02ac4a-ec9f-6524-8002-8f7b0bbeed0e\n\n['writeJoke']\n1f02ac4a-ce2a-6494-8001-cb2e2d651227\n\n['generateTopic']\n1f02ac4a-a4e0-630d-8000-b73c254ba748\n\n['__start__']\n1f02ac4a-a4dd-665e-bfff-e6c8c44315d9\n```\n\n```typescript  theme={null}\n// This is the state before last (states are listed in chronological order)\nconst selectedState = states[1];\nconsole.log(selectedState.next);\nconsole.log(selectedState.values);\n```\n\n**Output:**\n\n```\n['writeJoke']\n{'topic': 'How about \"The Secret Life of Socks in the Dryer\"? You know, exploring the mysterious phenomenon of how socks go into the laundry as pairs but come out as singles. Where do they go? Are they starting new lives elsewhere? Is there a sock paradise we don\\\\'t know about? There\\\\'s a lot of comedic potential in the everyday mystery that unites us all!'}\n```\n\n<a id=\"optional\" />\n\n### 3. Update the state\n\n`updateState` will create a new checkpoint. The new checkpoint will be associated with the same thread, but a new checkpoint ID.\n\n```typescript  theme={null}\nconst newConfig = await graph.updateState(selectedState.config, {\n  topic: \"chickens\",\n});\nconsole.log(newConfig);\n```\n\n**Output:**\n\n```\n{'configurable': {'thread_id': 'c62e2e03-c27b-4cb6-8cea-ea9bfedae006', 'checkpoint_ns': '', 'checkpoint_id': '1f02ac4a-ecee-600b-8002-a1d21df32e4c'}}\n```\n\n### 4. Resume execution from the checkpoint\n\n```typescript  theme={null}\nawait graph.invoke(null, newConfig);\n```\n\n**Output:**\n\n```typescript  theme={null}\n{\n  'topic': 'chickens',\n  'joke': 'Why did the chicken join a band?\\n\\nBecause it had excellent drumsticks!'\n}\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langgraph/use-time-travel.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 7733
}