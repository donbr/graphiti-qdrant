{
  "title": "Embedding models",
  "source_url": "https://docs.langchain.com/oss/javascript/integrations/text_embedding/index",
  "content": "## Overview\n\n<Note>\n  This overview covers **text-based embedding models**. LangChain does not currently support multimodal embeddings.\n</Note>\n\nEmbedding models transform raw text—such as a sentence, paragraph, or tweet—into a fixed-length vector of numbers that captures its **semantic meaning**. These vectors allow machines to compare and search text based on meaning rather than exact words.\n\nIn practice, this means that texts with similar ideas are placed close together in the vector space. For example, instead of matching only the phrase *\"machine learning\"*, embeddings can surface documents that discuss related concepts even when different wording is used.\n\n### How it works\n\n1. **Vectorization** — The model encodes each input string as a high-dimensional vector.\n2. **Similarity scoring** — Vectors are compared using mathematical metrics to measure how closely related the underlying texts are.\n\n### Similarity metrics\n\nSeveral metrics are commonly used to compare embeddings:\n\n* **Cosine similarity** — measures the angle between two vectors.\n* **Euclidean distance** — measures the straight-line distance between points.\n* **Dot product** — measures how much one vector projects onto another.\n\n## Interface\n\nLangChain provides a standard interface for text embedding models (e.g., OpenAI, Cohere, Hugging Face) via the [Embeddings](https://reference.langchain.com/javascript/classes/_langchain_core.embeddings.Embeddings.html) interface.\n\nTwo main methods are available:\n\n* `embedDocuments(documents: string[]) → number[][]`: Embeds a list of documents.\n* `embedQuery(text: string) → number[]`: Embeds a single query.\n\n<Note>\n  The interface allows queries and documents to be embedded with different strategies, though most providers handle them the same way in practice.\n</Note>\n\n## Install and use\n\n<AccordionGroup>\n  <Accordion title=\"OpenAI\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/openai\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/openai\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/openai\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    OPENAI_API_KEY=your-api-key\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { OpenAIEmbeddings } from \"@langchain/openai\";\n\n    const embeddings = new OpenAIEmbeddings({\n      model: \"text-embedding-3-large\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"Azure\">\n    Install dependencies\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/openai\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/openai\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/openai\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    AZURE_OPENAI_API_INSTANCE_NAME=<YOUR_INSTANCE_NAME>\n    AZURE_OPENAI_API_KEY=<YOUR_KEY>\n    AZURE_OPENAI_API_VERSION=\"2024-02-01\"\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { AzureOpenAIEmbeddings } from \"@langchain/openai\";\n\n    const embeddings = new AzureOpenAIEmbeddings({\n      azureOpenAIApiEmbeddingsDeploymentName: \"text-embedding-ada-002\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"AWS\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/aws\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/aws\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/aws\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    BEDROCK_AWS_REGION=your-region\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { BedrockEmbeddings } from \"@langchain/aws\";\n\n    const embeddings = new BedrockEmbeddings({\n      model: \"amazon.titan-embed-text-v1\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"Google Gemini\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/google-genai\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/google-genai\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/google-genai\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    GOOGLE_API_KEY=your-api-key\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { GoogleGenerativeAIEmbeddings } from \"@langchain/google-genai\";\n\n    const embeddings = new GoogleGenerativeAIEmbeddings({\n      model: \"text-embedding-004\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"Google Vertex\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/google-vertexai\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/google-vertexai\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/google-vertexai\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    GOOGLE_APPLICATION_CREDENTIALS=credentials.json\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { VertexAIEmbeddings } from \"@langchain/google-vertexai\";\n\n    const embeddings = new VertexAIEmbeddings({\n      model: \"gemini-embedding-001\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"MistralAI\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/mistralai\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/mistralai\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/mistralai\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    MISTRAL_API_KEY=your-api-key\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { MistralAIEmbeddings } from \"@langchain/mistralai\";\n\n    const embeddings = new MistralAIEmbeddings({\n      model: \"mistral-embed\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"Cohere\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/cohere\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/cohere\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/cohere\n      ```\n    </CodeGroup>\n\n    Add environment variables:\n\n    ```bash  theme={null}\n    COHERE_API_KEY=your-api-key\n    ```\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { CohereEmbeddings } from \"@langchain/cohere\";\n\n    const embeddings = new CohereEmbeddings({\n      model: \"embed-english-v3.0\"\n    });\n    ```\n  </Accordion>\n\n  <Accordion title=\"Ollama\">\n    Install dependencies:\n\n    <CodeGroup>\n      ```bash npm theme={null}\n      npm i @langchain/ollama\n      ```\n\n      ```bash yarn theme={null}\n      yarn add @langchain/ollama\n      ```\n\n      ```bash pnpm theme={null}\n      pnpm add @langchain/ollama\n      ```\n    </CodeGroup>\n\n    Instantiate the model:\n\n    ```typescript  theme={null}\n    import { OllamaEmbeddings } from \"@langchain/ollama\";\n\n    const embeddings = new OllamaEmbeddings({\n      model: \"llama2\",\n      baseUrl: \"http://localhost:11434\", // Default value\n    });\n    ```\n  </Accordion>\n</AccordionGroup>\n\n## Caching\n\nEmbeddings can be stored or temporarily cached to avoid needing to recompute them.\n\nCaching embeddings can be done using a `CacheBackedEmbeddings`. This wrapper stores embeddings in a key-value store, where the text is hashed and the hash is used as the key in the cache.\n\nThe main supported way to initialize a `CacheBackedEmbeddings` is `fromBytesStore`. It takes the following parameters:\n\n* **underlyingEmbeddings**: The embedder to use for embedding.\n* **documentEmbeddingStore**: Any [`BaseStore`](/oss/javascript/integrations/stores/) for caching document embeddings.\n* **options.namespace**: (optional, defaults to `\"\"`) The namespace to use for the document cache. Helps avoid collisions (e.g., set it to the embedding model name).\n\n<Important>\n  - Always set the `namespace` parameter to avoid collisions when using different embedding models.\n  - `CacheBackedEmbeddings` does not cache query embeddings by default. To enable this, specify a `query_embedding_store`.\n</Important>\n\n```typescript  theme={null}\nimport { CacheBackedEmbeddings } from \"@langchain/classic/embeddings/cache_backed\";\nimport { InMemoryStore } from \"@langchain/core/stores\";\n\nconst underlyingEmbeddings = new OpenAIEmbeddings();\n\nconst inMemoryStore = new InMemoryStore();\n\nconst cacheBackedEmbeddings = CacheBackedEmbeddings.fromBytesStore(\n  underlyingEmbeddings,\n  inMemoryStore,\n  {\n    namespace: underlyingEmbeddings.model,\n  }\n);\n\n// Example: caching a query embedding\nconst tic = Date.now();\nconst queryEmbedding = cacheBackedEmbeddings.embedQuery(\"Hello, world!\");\nconsole.log(`First call took: ${Date.now() - tic}ms`);\n\n// Example: caching a document embedding\nconst tic = Date.now();\nconst documentEmbedding = cacheBackedEmbeddings.embedDocuments([\"Hello, world!\"]);\nconsole.log(`Cached creation time: ${Date.now() - tic}ms`);\n```\n\nIn production, you would typically use a more robust persistent store, such as a database or cloud storage. Please see [stores integrations](/oss/javascript/integrations/stores/) for options.\n\n## All integrations\n\n<Columns cols={3}>\n  <Card title=\"Alibaba Tongyi\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/alibaba_tongyi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Azure OpenAI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/azure_openai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Baidu Qianfan\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/baidu_qianfan\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Amazon Bedrock\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/bedrock\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"ByteDance Doubao\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/bytedance_doubao\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Cloudflare Workers AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/cloudflare_ai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Cohere\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/cohere\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"DeepInfra\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/deepinfra\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Fireworks\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/fireworks\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Generative AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/google_generative_ai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Vertex AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/google_vertex_ai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Gradient AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/gradient_ai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"HuggingFace Inference\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/hugging_face_inference\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"IBM watsonx.ai\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/ibm\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Jina\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/jina\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Llama CPP\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/llama_cpp\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Minimax\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/minimax\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"MistralAI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/mistralai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Mixedbread AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/mixedbread_ai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Nomic\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/nomic\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Ollama\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/ollama\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"OpenAI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/openai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Pinecone\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/pinecone\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Prem AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/premai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tencent Hunyuan\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/tencent_hunyuan\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"TensorFlow\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/tensorflow\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"TogetherAI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/togetherai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"HuggingFace Transformers\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/transformers\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Voyage AI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/voyageai\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"ZhipuAI\" icon=\"link\" href=\"/oss/javascript/integrations/text_embedding/zhipuai\" arrow=\"true\" cta=\"View guide\" />\n</Columns>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/text_embedding/index.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 13800
}