{
  "title": "Multi-agent",
  "source_url": "https://docs.langchain.com/oss/python/langchain/multi-agent",
  "content": "**Multi-agent systems** break a complex application into multiple specialized agents that work together to solve problems.\nInstead of relying on a single agent to handle every step, **multi-agent architectures** allow you to compose smaller, focused agents into a coordinated workflow.\n\nMulti-agent systems are useful when:\n\n* A single agent has too many tools and makes poor decisions about which to use.\n* Context or memory grows too large for one agent to track effectively.\n* Tasks require **specialization** (e.g., a planner, researcher, math expert).\n\n## Multi-agent patterns\n\n| Pattern                           | How it works                                                                                                                                                     | Control flow                                               | Example use case                                 |\n| --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ------------------------------------------------ |\n| [**Tool Calling**](#tool-calling) | A **supervisor** agent calls other agents as *tools*. The “tool” agents don’t talk to the user directly — they just run their task and return results.           | Centralized: all routing passes through the calling agent. | Task orchestration, structured workflows.        |\n| [**Handoffs**](#handoffs)         | The current agent decides to **transfer control** to another agent. The active agent changes, and the user may continue interacting directly with the new agent. | Decentralized: agents can change who is active.            | Multi-domain conversations, specialist takeover. |\n\n<Card title=\"Tutorial: Build a supervisor agent\" icon=\"sitemap\" href=\"/oss/python/langchain/supervisor\" arrow cta=\"Learn more\">\n  Learn how to build a personal assistant using the supervisor pattern, where a central supervisor agent coordinates specialized worker agents.\n  This tutorial demonstrates:\n\n  * Creating specialized sub-agents for different domains (calendar and email)\n  * Wrapping sub-agents as tools for centralized orchestration\n  * Adding human-in-the-loop review for sensitive actions\n</Card>\n\n## Choosing a pattern\n\n| Question                                              | Tool Calling | Handoffs |\n| ----------------------------------------------------- | ------------ | -------- |\n| Need centralized control over workflow?               | ✅ Yes        | ❌ No     |\n| Want agents to interact directly with the user?       | ❌ No         | ✅ Yes    |\n| Complex, human-like conversation between specialists? | ❌ Limited    | ✅ Strong |\n\n<Tip>\n  You can mix both patterns — use **handoffs** for agent switching, and have each agent **call subagents as tools** for specialized tasks.\n</Tip>\n\n## Customizing agent context\n\nAt the heart of multi-agent design is **context engineering** - deciding what information each agent sees. LangChain gives you fine-grained control over:\n\n* Which parts of the conversation or state are passed to each agent.\n* Specialized prompts tailored to subagents.\n* Inclusion/exclusion of intermediate reasoning.\n* Customizing input/output formats per agent.\n\nThe quality of your system **heavily depends** on context engineering. The goal is to ensure that each agent has access to the correct data it needs to perform its task, whether it’s acting as a tool or as an active agent.\n\n## Tool calling\n\nIn **tool calling**, one agent (the “**controller**”) treats other agents as *tools* to be invoked when needed. The controller manages orchestration, while tool agents perform specific tasks and return results.\n\nFlow:\n\n1. The **controller** receives input and decides which tool (subagent) to call.\n2. The **tool agent** runs its task based on the controller’s instructions.\n3. The **tool agent** returns results to the controller.\n4. The **controller** decides the next step or finishes.\n\n```mermaid  theme={null}\ngraph LR\n    A[User] --> B[Controller Agent]\n    B --> C[Tool Agent 1]\n    B --> D[Tool Agent 2]\n    C --> B\n    D --> B\n    B --> E[User Response]\n```\n\n<Tip>\n  Agents used as tools are generally **not expected** to continue conversation with the user.\n  Their role is to perform a task and return results to the controller agent.\n  If you need subagents to be able to converse with the user, use **handoffs** instead.\n</Tip>\n\n### Implementation\n\nBelow is a minimal example where the main agent is given access to a single subagent via a tool definition:\n\n```python  theme={null}\nfrom langchain.tools import tool\nfrom langchain.agents import create_agent\n\n\nsubagent1 = create_agent(model=\"...\", tools=[...])\n\n@tool(\n    \"subagent1_name\",\n    description=\"subagent1_description\"\n)\ndef call_subagent1(query: str):\n    result = subagent1.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return result[\"messages\"][-1].content\n\nagent = create_agent(model=\"...\", tools=[call_subagent1])\n```\n\nIn this pattern:\n\n1. The main agent invokes `call_subagent1` when it decides the task matches the subagent’s description.\n2. The subagent runs independently and returns its result.\n3. The main agent receives the result and continues orchestration.\n\n### Where to customize\n\nThere are several points where you can control how context is passed between the main agent and its subagents:\n\n1. **Subagent name** (`\"subagent1_name\"`): This is how the main agent refers to the subagent. Since it influences prompting, choose it carefully.\n2. **Subagent description** (`\"subagent1_description\"`): This is what the main agent “knows” about the subagent. It directly shapes how the main agent decides when to call it.\n3. **Input to the subagent**: You can customize this input to better shape how the subagent interprets tasks. In the example above, we pass the agent-generated `query` directly.\n4. **Output from the subagent**: This is the **response** passed back to the main agent. You can adjust what is returned to control how the main agent interprets results. In the example above, we return the final message text, but you could return additional state or metadata.\n\n### Control the input to the subagent\n\nThere are two main levers to control the input that the main agent passes to a subagent:\n\n* **Modify the prompt** – Adjust the main agent's prompt or the tool metadata (i.e., sub-agent's name and description) to better guide when and how it calls the subagent.\n* **Context injection** – Add input that isn’t practical to capture in a static prompt (e.g., full message history, prior results, task metadata) by adjusting the tool call to pull from the agent’s state.\n\n```python  theme={null}\nfrom langchain.agents import AgentState\nfrom langchain.tools import tool, ToolRuntime\n\nclass CustomState(AgentState):\n    example_state_key: str\n\n@tool(\n    \"subagent1_name\",\n    description=\"subagent1_description\"\n)\ndef call_subagent1(query: str, runtime: ToolRuntime[None, CustomState]):\n    # Apply any logic needed to transform the messages into a suitable input\n    subagent_input = some_logic(query, runtime.state[\"messages\"])\n    result = subagent1.invoke({\n        \"messages\": subagent_input,\n        # You could also pass other state keys here as needed.\n        # Make sure to define these in both the main and subagent's\n        # state schemas.\n        \"example_state_key\": runtime.state[\"example_state_key\"]\n    })\n    return result[\"messages\"][-1].content\n```\n\n### Control the output from the subagent\n\nTwo common strategies for shaping what the main agent receives back from a subagent:\n\n* **Modify the prompt** – Refine the subagent’s prompt to specify exactly what should be returned.\n  * Useful when outputs are incomplete, too verbose, or missing key details.\n  * A common failure mode is that the subagent performs tool calls or reasoning but does **not include the results** in its final message. Remind it that the controller (and user) only see the final output, so all relevant info must be included there.\n* **Custom output formatting** – adjust or enrich the subagent's response in code before handing it back to the main agent.\n  * Example: pass specific state keys back to the main agent in addition to the final text.\n  * This requires wrapping the result in a [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) (or equivalent structure) so you can merge custom state with the subagent’s response.\n\n```python  theme={null}\nfrom typing import Annotated\nfrom langchain.agents import AgentState\nfrom langchain.tools import InjectedToolCallId\nfrom langgraph.types import Command\n\n\n@tool(\n    \"subagent1_name\",\n    description=\"subagent1_description\"\n)\n# We need to pass the `tool_call_id` to the sub agent so it can use it to respond with the tool call result\ndef call_subagent1(\n    query: str,\n    tool_call_id: Annotated[str, InjectedToolCallId],\n# You need to return a `Command` object to include more than just a final tool call\n) -> Command:\n    result = subagent1.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return Command(update={\n        # This is the example state key we are passing back\n        \"example_state_key\": result[\"example_state_key\"],\n        \"messages\": [\n            ToolMessage(\n                content=result[\"messages\"][-1].content,\n                # We need to include the tool call id so it matches up with the right tool call\n                tool_call_id=tool_call_id\n            )\n        ]\n    })\n```\n\n## Handoffs\n\nIn **handoffs**, agents can directly pass control to each other. The “active” agent changes, and the user interacts with whichever agent currently has control.\n\nFlow:\n\n1. The **current agent** decides it needs help from another agent.\n2. It passes control (and state) to the **next agent**.\n3. The **new agent** interacts directly with the user until it decides to hand off again or finish.\n\n```mermaid  theme={null}\ngraph LR\n    A[User] --> B[Agent A]\n    B --> C[Agent B]\n    C --> A\n```\n\n### Implementation (Coming soon)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/multi-agent.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 10532
}