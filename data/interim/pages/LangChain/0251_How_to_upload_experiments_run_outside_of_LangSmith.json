{
  "title": "How to upload experiments run outside of LangSmith with the REST API",
  "source_url": "https://docs.langchain.com/langsmith/upload-existing-experiments",
  "content": "Some users prefer to manage their datasets and run their experiments outside of LangSmith, but want to use the LangSmith UI to view the results. This is supported via our endpoint.\n\nThis guide will show you how to upload evals using the REST API, using the `requests` library in Python as an example. However, the same principles apply to any language.\n\n## Request body schema\n\nUploading an experiment requires specifying the relevant high-level information for your experiment and dataset, along with the individual data for your examples and runs within the experiment. Each object in the `results` represents a \"row\" in the experiment - a single dataset example, along with an associated run. Note that `dataset_id` and `dataset_name` refer to your dataset identifier in your external system and will be used to group external experiments together in a single dataset. They should not refer to an existing dataset in LangSmith (unless that dataset was created via this endpoint).\n\nYou may use the following schema to upload experiments to the `/datasets/upload-experiment` endpoint:\n\n```json  theme={null}\n{\n  \"experiment_name\": \"string (required)\",\n  \"experiment_description\": \"string (optional)\",\n  \"experiment_start_time\": \"datetime (required)\",\n  \"experiment_end_time\": \"datetime (required)\",\n  \"dataset_id\": \"uuid (optional - an external dataset id, used to group experiments together)\",\n  \"dataset_name\": \"string (optional - must provide either dataset_id or dataset_name)\",\n  \"dataset_description\": \"string (optional)\",\n  \"experiment_metadata\": { // Object (any shape - optional)\n    \"key\": \"value\"\n  },\n  \"summary_experiment_scores\": [ // List of summary feedback objects (optional)\n    {\n      \"key\": \"string (required)\",\n      \"score\": \"number (optional)\",\n      \"value\": \"string (optional)\",\n      \"comment\": \"string (optional)\",\n      \"feedback_source\": { // Object (optional)\n        \"type\": \"string (required)\"\n      },\n      \"feedback_config\": { // Object (optional)\n        \"type\": \"string enum: continuous, categorical, or freeform\",\n        \"min\": \"number (optional)\",\n        \"max\": \"number (optional)\",\n        \"categories\": [ // List of feedback category objects (optional)\n          {\n            \"value\": \"number (required)\",\n            \"label\": \"string (optional)\"\n          }\n        ]\n      },\n      \"created_at\": \"datetime (optional - defaults to now)\",\n      \"modified_at\": \"datetime (optional - defaults to now)\",\n      \"correction\": \"Object or string (optional)\"\n    }\n  ],\n  \"results\": [ // List of experiment row objects (required)\n    {\n      \"row_id\": \"uuid (required)\",\n      \"inputs\": { // Object (required - any shape). This will\n        \"key\": \"val\" // be the input to both the run and the dataset example.\n      },\n      \"expected_outputs\": { // Object (optional - any shape).\n        \"key\": \"val\" // These will be the outputs of the dataset examples.\n      },\n      \"actual_outputs\": { // Object (optional - any shape).\n        \"key\": \"val\" // These will be the outputs of the runs.\n      },\n      \"evaluation_scores\": [ // List of feedback objects for the run (optional)\n        {\n          \"key\": \"string (required)\",\n          \"score\": \"number (optional)\",\n          \"value\": \"string (optional)\",\n          \"comment\": \"string (optional)\",\n          \"feedback_source\": { // Object (optional)\n            \"type\": \"string (required)\"\n          },\n          \"feedback_config\": { // Object (optional)\n            \"type\": \"string enum: continuous, categorical, or freeform\",\n            \"min\": \"number (optional)\",\n            \"max\": \"number (optional)\",\n            \"categories\": [ // List of feedback category objects (optional)\n              {\n                \"value\": \"number (required)\",\n                \"label\": \"string (optional)\"\n              }\n            ]\n          },\n          \"created_at\": \"datetime (optional - defaults to now)\",\n          \"modified_at\": \"datetime (optional - defaults to now)\",\n          \"correction\": \"Object or string (optional)\"\n        }\n      ],\n      \"start_time\": \"datetime (required)\", // The start/end times for the runs will be used to\n      \"end_time\": \"datetime (required)\", // calculate latency. They must all fall between the\n      \"run_name\": \"string (optional)\", // start and end times for the experiment.\n      \"error\": \"string (optional)\",\n      \"run_metadata\": { // Object (any shape - optional)\n        \"key\": \"value\"\n      }\n    }\n  ]\n}\n```\n\nThe response JSON will be a dict with keys `experiment` and `dataset`, each of which is an object that contains relevant information about the experiment and dataset that was created.\n\n## Considerations\n\nYou may upload multiple experiments to the same dataset by providing the same dataset\\_id or dataset\\_name between multiple calls. Your experiments will be grouped together under a single dataset, and you will be able to [use the comparison view to compare results between experiments](/langsmith/compare-experiment-results).\n\nEnsure that the start and end times of your individual rows are all between the start and end time of your experiment.\n\nYou must provide either a dataset\\_id or a dataset\\_name. If you only provide an ID and the dataset does not yet exist, we will generate a name for you, and vice versa if you only provide a name.\n\nYou may not upload experiments to a dataset that was not created via this endpoint. Uploading experiments is only supported for externally-managed datasets.\n\n## Example request\n\nBelow is an example of a simple call to the `/datasets/upload-experiment`. This is a basic example that just uses the most important fields as an illustration.\n\n```python  theme={null}\nimport os\nimport requests\n\nbody = {\n    \"experiment_name\": \"My external experiment\",\n    \"experiment_description\": \"An experiment uploaded to LangSmith\",\n    \"dataset_name\": \"my-external-dataset\",\n    \"summary_experiment_scores\": [\n        {\n            \"key\": \"summary_accuracy\",\n            \"score\": 0.9,\n            \"comment\": \"Great job!\"\n        }\n    ],\n    \"results\": [\n        {\n            \"row_id\": \"<<uuid>>\",\n            \"inputs\": {\n                \"input\": \"Hello, what is the weather in San Francisco today?\"\n            },\n            \"expected_outputs\": {\n                \"output\": \"Sorry, I am unable to provide information about the current weather.\"\n            },\n            \"actual_outputs\": {\n                \"output\": \"The weather is partly cloudy with a high of 65.\"\n            },\n            \"evaluation_scores\": [\n                {\n                    \"key\": \"hallucination\",\n                    \"score\": 1,\n                    \"comment\": \"The chatbot made up the weather instead of identifying that \"\n                               \"they don't have enough info to answer the question. This is \"\n                               \"a hallucination.\"\n                }\n            ],\n            \"start_time\": \"2024-08-03T00:12:39\",\n            \"end_time\": \"2024-08-03T00:12:41\",\n            \"run_name\": \"Chatbot\"\n        },\n        {\n            \"row_id\": \"<<uuid>>\",\n            \"inputs\": {\n                \"input\": \"Hello, what is the square root of 49?\"\n            },\n            \"expected_outputs\": {\n                \"output\": \"The square root of 49 is 7.\"\n            },\n            \"actual_outputs\": {\n                \"output\": \"7.\"\n            },\n            \"evaluation_scores\": [\n                {\n                    \"key\": \"hallucination\",\n                    \"score\": 0,\n                    \"comment\": \"The chatbot correctly identified the answer. This is not a \"\n                               \"hallucination.\"\n                }\n            ],\n            \"start_time\": \"2024-08-03T00:12:40\",\n            \"end_time\": \"2024-08-03T00:12:42\",\n            \"run_name\": \"Chatbot\"\n        }\n    ],\n    \"experiment_start_time\": \"2024-08-03T00:12:38\",\n    \"experiment_end_time\": \"2024-08-03T00:12:43\"\n}\n\nresp = requests.post(\n    \"https://api.smith.langchain.com/api/v1/datasets/upload-experiment\", # Update appropriately for self-hosted installations or the EU region\n    json=body,\n    headers={\"x-api-key\": os.environ[\"LANGSMITH_API_KEY\"]}\n)\n\nprint(resp.json())\n```\n\nBelow is the response received:\n\n```json  theme={null}\n{\n  \"dataset\": {\n    \"name\": \"my-external-dataset\",\n    \"description\": null,\n    \"created_at\": \"2024-08-03T00:36:23.289730+00:00\",\n    \"data_type\": \"kv\",\n    \"inputs_schema_definition\": null,\n    \"outputs_schema_definition\": null,\n    \"externally_managed\": true,\n    \"id\": \"<<uuid>>\",\n    \"tenant_id\": \"<<uuid>>\",\n    \"example_count\": 0,\n    \"session_count\": 0,\n    \"modified_at\": \"2024-08-03T00:36:23.289730+00:00\",\n    \"last_session_start_time\": null\n  },\n  \"experiment\": {\n    \"start_time\": \"2024-08-03T00:12:38\",\n    \"end_time\": \"2024-08-03T00:12:43+00:00\",\n    \"extra\": null,\n    \"name\": \"My external experiment\",\n    \"description\": \"An experiment uploaded to LangSmith\",\n    \"default_dataset_id\": null,\n    \"reference_dataset_id\": \"<<uuid>>\",\n    \"trace_tier\": \"longlived\",\n    \"id\": \"<<uuid>>\",\n    \"run_count\": null,\n    \"latency_p50\": null,\n    \"latency_p99\": null,\n    \"first_token_p50\": null,\n    \"first_token_p99\": null,\n    \"total_tokens\": null,\n    \"prompt_tokens\": null,\n    \"completion_tokens\": null,\n    \"total_cost\": null,\n    \"prompt_cost\": null,\n    \"completion_cost\": null,\n    \"tenant_id\": \"<<uuid>>\",\n    \"last_run_start_time\": null,\n    \"last_run_start_time_live\": null,\n    \"feedback_stats\": null,\n    \"session_feedback_stats\": null,\n    \"run_facets\": null,\n    \"error_rate\": null,\n    \"streaming_rate\": null,\n    \"test_run_number\": 1\n  }\n}\n```\n\nNote that the latency and feedback stats in the experiment results are null because the runs haven't had a chance to be persisted yet, which may take a few seconds. If you save the experiment id and query again in a few seconds, you will see all the stats (although tokens/cost will still be null, because we don't ask for this information in the request body).\n\n## View the experiment in the UI\n\nNow, login to the UI and click on your newly-created dataset! You should see a single experiment: <img src=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=797dd62e7cd3f833cd13bafcedfa5607\" alt=\"Uploaded experiments table\" data-og-width=\"3454\" width=\"3454\" data-og-height=\"1914\" height=\"1914\" data-path=\"langsmith/images/uploaded-dataset.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?w=280&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=b1209e0ffca0c29ca3e0d7e42f0e8ac8 280w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?w=560&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=a0dc70688d773066f6844e49b0654c5d 560w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?w=840&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=abbe1374d734e276503394edb09aab40 840w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?w=1100&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=22595d2f890ce7918da47809c2ce18cd 1100w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?w=1650&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=303c085b3c5e8a5c9e49f5deb54852f0 1650w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset.png?w=2500&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=b5ee82414e1af652674022087d5dc131 2500w\" />\n\nYour examples will have been uploaded: <img src=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=093061568ece423d5a2c4cb2b5df2721\" alt=\"Uploaded examples\" data-og-width=\"3454\" width=\"3454\" data-og-height=\"1912\" height=\"1912\" data-path=\"langsmith/images/uploaded-dataset-examples.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?w=280&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=2112ea321eb2b791f29b2817e4ecfa70 280w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?w=560&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=8fa00a59f3ebe49c8dc413fcb8cdfff6 560w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?w=840&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=3a34d7d6ab89007cfb849b3b1e9fed6e 840w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?w=1100&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=4949985fdd2517513234cbec7fa70274 1100w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?w=1650&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=bdbc201e179f1ba78da86efe792837c9 1650w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-dataset-examples.png?w=2500&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=fafd5f13e4a508ecc26f370f85a143d2 2500w\" />\n\nClicking on your experiment will bring you to the comparison view: <img src=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=d66c9ea1cfbb1acf4f591b11f54a71da\" alt=\"Uploaded experiment comparison view\" data-og-width=\"3452\" width=\"3452\" data-og-height=\"1912\" height=\"1912\" data-path=\"langsmith/images/uploaded-experiment.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?w=280&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=9839c5164dffd92bb302b1858e6f36e5 280w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?w=560&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=a013685347c8915b42925027212052e5 560w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?w=840&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=513f29d729a87e70f1b1c0bc0f42c4b5 840w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?w=1100&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=eb4eda99fb12b2ebee2c1f4529fa63a8 1100w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?w=1650&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=b79aabcad20cca0bfc19cc363c6704d0 1650w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/uploaded-experiment.png?w=2500&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=b78901795d6b7886a0c251a9abba8d52 2500w\" />\n\nAs you upload more experiments to your dataset, you will be able to compare the results and easily identify regressions in the comparison view.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/upload-existing-experiments.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 15281
}