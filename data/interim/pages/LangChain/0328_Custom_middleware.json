{
  "title": "Custom middleware",
  "source_url": "https://docs.langchain.com/oss/javascript/langchain/middleware/custom",
  "content": "Build custom middleware by implementing hooks that run at specific points in the agent execution flow.\n\n## Hooks\n\nMiddleware provides two styles of hooks to intercept agent execution:\n\n<CardGroup cols={2}>\n  <Card title=\"Node-style hooks\" icon=\"share-nodes\" href=\"#node-style-hooks\">\n    Run sequentially at specific execution points.\n  </Card>\n\n  <Card title=\"Wrap-style hooks\" icon=\"container-storage\" href=\"#wrap-style-hooks\">\n    Run around each model or tool call.\n  </Card>\n</CardGroup>\n\n### Node-style hooks\n\nRun sequentially at specific execution points. Use for logging, validation, and state updates.\n\n**Available hooks:**\n\n* `beforeAgent` - Before agent starts (once per invocation)\n* `beforeModel` - Before each model call\n* `afterModel` - After each model response\n* `afterAgent` - After agent completes (once per invocation)\n\n**Example:**\n\n```typescript  theme={null}\nimport { createMiddleware, AIMessage } from \"langchain\";\n\nconst createMessageLimitMiddleware = (maxMessages: number = 50) => {\n  return createMiddleware({\n    name: \"MessageLimitMiddleware\",\n    beforeModel: (state) => {\n      if (state.messages.length === maxMessages) {\n        return {\n          messages: [new AIMessage(\"Conversation limit reached.\")],\n          jumpTo: \"end\",\n        };\n      }\n      return;\n    },\n    afterModel: (state) => {\n      const lastMessage = state.messages[state.messages.length - 1];\n      console.log(`Model returned: ${lastMessage.content}`);\n      return;\n    },\n  });\n};\n```\n\n### Wrap-style hooks\n\nIntercept execution and control when the handler is called. Use for retries, caching, and transformation.\n\nYou decide if the handler is called zero times (short-circuit), once (normal flow), or multiple times (retry logic).\n\n**Available hooks:**\n\n* `wrapModelCall` - Around each model call\n* `wrapToolCall` - Around each tool call\n\n**Example:**\n\n```typescript  theme={null}\nimport { createMiddleware } from \"langchain\";\n\nconst createRetryMiddleware = (maxRetries: number = 3) => {\n  return createMiddleware({\n    name: \"RetryMiddleware\",\n    wrapModelCall: (request, handler) => {\n      for (let attempt = 0; attempt < maxRetries; attempt++) {\n        try {\n          return handler(request);\n        } catch (e) {\n          if (attempt === maxRetries - 1) {\n            throw e;\n          }\n          console.log(`Retry ${attempt + 1}/${maxRetries} after error: ${e}`);\n        }\n      }\n      throw new Error(\"Unreachable\");\n    },\n  });\n};\n```\n\n## Create middleware\n\nUse the `createMiddleware` function to define custom middleware:\n\n```typescript  theme={null}\nimport { createMiddleware } from \"langchain\";\n\nconst loggingMiddleware = createMiddleware({\n  name: \"LoggingMiddleware\",\n  beforeModel: (state) => {\n    console.log(`About to call model with ${state.messages.length} messages`);\n    return;\n  },\n  afterModel: (state) => {\n    const lastMessage = state.messages[state.messages.length - 1];\n    console.log(`Model returned: ${lastMessage.content}`);\n    return;\n  },\n});\n```\n\n## Custom state schema\n\nMiddleware can extend the agent's state with custom properties.\n\n```typescript  theme={null}\nimport { createMiddleware, createAgent, HumanMessage } from \"langchain\";\nimport * as z from \"zod\";\n\nconst callCounterMiddleware = createMiddleware({\n  name: \"CallCounterMiddleware\",\n  stateSchema: z.object({\n    modelCallCount: z.number().default(0),\n    userId: z.string().optional(),\n  }),\n  beforeModel: (state) => {\n    if (state.modelCallCount > 10) {\n      return { jumpTo: \"end\" };\n    }\n    return;\n  },\n  afterModel: (state) => {\n    return { modelCallCount: state.modelCallCount + 1 };\n  },\n});\n\nconst agent = createAgent({\n  model: \"gpt-4o\",\n  tools: [...],\n  middleware: [callCounterMiddleware],\n});\n\nconst result = await agent.invoke({\n  messages: [new HumanMessage(\"Hello\")],\n  modelCallCount: 0,\n  userId: \"user-123\",\n});\n```\n\n## Execution order\n\nWhen using multiple middleware, understand how they execute:\n\n```typescript  theme={null}\nconst agent = createAgent({\n  model: \"gpt-4o\",\n  middleware: [middleware1, middleware2, middleware3],\n  tools: [...],\n});\n```\n\n<Accordion title=\"Execution flow\">\n  **Before hooks run in order:**\n\n  1. `middleware1.before_agent()`\n  2. `middleware2.before_agent()`\n  3. `middleware3.before_agent()`\n\n  **Agent loop starts**\n\n  4. `middleware1.before_model()`\n  5. `middleware2.before_model()`\n  6. `middleware3.before_model()`\n\n  **Wrap hooks nest like function calls:**\n\n  7. `middleware1.wrap_model_call()` → `middleware2.wrap_model_call()` → `middleware3.wrap_model_call()` → model\n\n  **After hooks run in reverse order:**\n\n  8. `middleware3.after_model()`\n  9. `middleware2.after_model()`\n  10. `middleware1.after_model()`\n\n  **Agent loop ends**\n\n  11. `middleware3.after_agent()`\n  12. `middleware2.after_agent()`\n  13. `middleware1.after_agent()`\n</Accordion>\n\n**Key rules:**\n\n* `before_*` hooks: First to last\n* `after_*` hooks: Last to first (reverse)\n* `wrap_*` hooks: Nested (first middleware wraps all others)\n\n## Agent jumps\n\nTo exit early from middleware, return a dictionary with `jump_to`:\n\n**Available jump targets:**\n\n* `'end'`: Jump to the end of the agent execution (or the first `after_agent` hook)\n* `'tools'`: Jump to the tools node\n* `'model'`: Jump to the model node (or the first `before_model` hook)\n\n```typescript  theme={null}\nimport { createMiddleware, AIMessage } from \"langchain\";\n\nconst blockedContentMiddleware = createMiddleware({\n  name: \"BlockedContentMiddleware\",\n  afterModel: (state) => {\n    const lastMessage = state.messages[state.messages.length - 1];\n    if (lastMessage.content.includes(\"BLOCKED\")) {\n      return {\n        messages: [new AIMessage(\"I cannot respond to that request.\")],\n        jumpTo: \"end\",\n      };\n    }\n    return;\n  },\n});\n```\n\n## Best practices\n\n1. Keep middleware focused - each should do one thing well\n2. Handle errors gracefully - don't let middleware errors crash the agent\n3. **Use appropriate hook types**:\n   * Node-style for sequential logic (logging, validation)\n   * Wrap-style for control flow (retry, fallback, caching)\n4. Clearly document any custom state properties\n5. Unit test middleware independently before integrating\n6. Consider execution order - place critical middleware first in the list\n7. Use built-in middleware when possible\n\n## Examples\n\n### Dynamic model selection\n\n```typescript  theme={null}\nimport { createMiddleware, initChatModel } from \"langchain\";\n\nconst dynamicModelMiddleware = createMiddleware({\n  name: \"DynamicModelMiddleware\",\n  wrapModelCall: (request, handler) => {\n    const modifiedRequest = { ...request };\n    if (request.messages.length > 10) {\n      modifiedRequest.model = initChatModel(\"gpt-4o\");\n    } else {\n      modifiedRequest.model = initChatModel(\"gpt-4o-mini\");\n    }\n    return handler(modifiedRequest);\n  },\n});\n```\n\n### Tool call monitoring\n\n```typescript  theme={null}\nimport { createMiddleware } from \"langchain\";\n\nconst toolMonitoringMiddleware = createMiddleware({\n  name: \"ToolMonitoringMiddleware\",\n  wrapToolCall: (request, handler) => {\n    console.log(`Executing tool: ${request.toolCall.name}`);\n    console.log(`Arguments: ${JSON.stringify(request.toolCall.args)}`);\n    try {\n      const result = handler(request);\n      console.log(\"Tool completed successfully\");\n      return result;\n    } catch (e) {\n      console.log(`Tool failed: ${e}`);\n      throw e;\n    }\n  },\n});\n```\n\n### Dynamically selecting tools\n\nSelect relevant tools at runtime to improve performance and accuracy.\n\n**Benefits:**\n\n* **Shorter prompts** - Reduce complexity by exposing only relevant tools\n* **Better accuracy** - Models choose correctly from fewer options\n* **Permission control** - Dynamically filter tools based on user access\n\n```typescript  theme={null}\nimport { createAgent, createMiddleware } from \"langchain\";\n\nconst toolSelectorMiddleware = createMiddleware({\n  name: \"ToolSelector\",\n  wrapModelCall: (request, handler) => {\n    // Select a small, relevant subset of tools based on state/context\n    const relevantTools = selectRelevantTools(request.state, request.runtime);\n    const modifiedRequest = { ...request, tools: relevantTools };\n    return handler(modifiedRequest);\n  },\n});\n\nconst agent = createAgent({\n  model: \"gpt-4o\",\n  tools: allTools,\n  middleware: [toolSelectorMiddleware],\n});\n```\n\n### Working with system messages\n\nModify system messages in middleware using the `systemMessage` field in `ModelRequest`. It contains a [`SystemMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.SystemMessage.html) object (even if the agent was created with a string [`systemPrompt`](https://reference.langchain.com/javascript/types/langchain.index.CreateAgentParams.html#systemprompt)).\n\n**Example: Chaining middleware** - Different middleware can use different approaches:\n\n```typescript  theme={null}\nimport { createMiddleware, SystemMessage, createAgent } from \"langchain\";\n\n// Middleware 1: Uses systemMessage with simple concatenation\nconst myMiddleware = createMiddleware({\n  name: \"MyMiddleware\",\n  wrapModelCall: async (request, handler) => {\n    return handler({\n      ...request,\n      systemMessage: request.systemMessage.concat(`Additional context.`),\n    });\n  },\n});\n\n// Middleware 2: Uses systemMessage with structured content (preserves structure)\nconst myOtherMiddleware = createMiddleware({\n  name: \"MyOtherMiddleware\",\n  wrapModelCall: async (request, handler) => {\n    return handler({\n      ...request,\n      systemMessage: request.systemMessage.concat(\n        new SystemMessage({\n          content: [\n            {\n              type: \"text\",\n              text: \" More additional context. This will be cached.\",\n              cache_control: { type: \"ephemeral\", ttl: \"5m\" },\n            },\n          ],\n        })\n      ),\n    });\n  },\n});\n\nconst agent = createAgent({\n  model: \"anthropic:claude-3-5-sonnet\",\n  systemPrompt: \"You are a helpful assistant.\",\n  middleware: [myMiddleware, myOtherMiddleware],\n});\n```\n\nThe resulting system message will be:\n\n```typescript  theme={null}\nnew SystemMessage({\n  content: [\n    { type: \"text\", text: \"You are a helpful assistant.\" },\n    { type: \"text\", text: \"Additional context.\" },\n    {\n        type: \"text\",\n        text: \" More additional context. This will be cached.\",\n        cache_control: { type: \"ephemeral\", ttl: \"5m\" },\n    },\n  ],\n});\n```\n\nUse [`SystemMessage.concat`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.SystemMessage.html#concat) to preserve cache control metadata or structured content blocks created by other middleware.\n\n## Additional resources\n\n* [Middleware API reference](https://reference.langchain.com/python/langchain/middleware/)\n* [Built-in middleware](/oss/javascript/langchain/middleware/built-in)\n* [Testing agents](/oss/javascript/langchain/test)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/middleware/custom.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 11199
}