{
  "title": "Frequently asked questions",
  "source_url": "https://docs.langchain.com/langsmith/faq",
  "content": "## Observability\n\n### *I can't create API keys or manage users in the UI, what's wrong?*\n\n* You have likely deployed LangSmith without setting up SSO. LangSmith requires SSO to manage users and API keys. You can find more information on setting up SSO in the [configuration section.](/langsmith/self-host-sso)\n\n### *How does load balancing/ingress work*?\n\n* You will need to expose the frontend container/service to your applications/users. This will handle routing to all downstream services.\n* You will need to terminate SSL at the ingress level. We recommend using a managed service like AWS ALB, GCP Load Balancer, or Nginx.\n\n### *How can we authenticate to the application?*\n\n* Currently, our self-hosted solution supports SSO with OAuth2.0 and OIDC as an authn solution. Note, we do offer a no-auth solution but highly recommend setting up oauth before moving into production.\n\nYou can find more information on setting up SSO in the [configuration section.](/langsmith/self-host-sso)\n\n### *Can I use external storage services?*\n\n* You can configure LangSmith to use external versions of all storage services. In a production setting, we strongly recommend using external storage services. Check out the [configuration section](/langsmith/self-hosted) for more information.\n\n### *Does my application need egress to function properly?*\n\nOur deployment only needs egress for a few things (most of which can reside within your VPC):\n\n* Fetching images (If mirroring your images, this may not be needed)\n\n* Talking to any LLM endpoints\n\n* Talking to any external storage services you may have configured\n\n* Fetching OAuth information\n\n* Subscription Metrics and Operational Metadata (if not running in offline mode)\n\n  * Requires egress to `https://beacon.langchain.com`\n  * See [Egress](/langsmith/self-host-egress) for more information\n\nYour VPC can set up rules to limit any other access. Note: We require the `X-Organization-Id` and `X-Tenant-Id` headers to be allowed to be passed through to the backend service. These are used to determine which organization and workspace (previously called \"tenant\") the request is for.\n\n### *Resource requirements for the application?*\n\n* In kubernetes, we recommend a minimum helm configuration which can be found in [here](https://github.com/langchain-ai/helm/blob/main/charts/langsmith/examples/medium_size.yaml). For docker, we recommend a minimum of 16GB of RAM and 4 CPUs.\n* For Postgres, we recommend a minimum of 8GB of RAM and 2 CPUs.\n* For Redis, we recommend 4GB of RAM and 2 CPUs.\n* For Clickhouse, we recommend 32GB of RAM and 8 CPUs.\n\n### SAML SSO FAQs\n\n#### *How do I change a SAML SSO user's email address?*\n\nSome identity providers retain the original `User ID` through an email change while others do not, so we recommend that you follow these steps to avoid duplicate users in LangSmith:\n\n1. Remove the user from the organization (see [here](/langsmith/set-up-a-workspace#manage-users))\n2. Change their email address in the IdP\n3. Have them login to LangSmith again via SAML SSO - this will trigger the usual [JIT provisioning](#just-in-time-jit-provisioning) flow with their new email address\n\n#### *How do I fix \"405 method not allowed\"?*\n\nEnsure you're using the correct ACS URL: [https://auth.langchain.com/auth/v1/sso/saml/acs](https://auth.langchain.com/auth/v1/sso/saml/acs)\n\n### SCIM FAQs\n\n#### *Can I use SCIM without SAML SSO?*\n\n* **Cloud**: No, SAML SSO is required for SCIM in cloud deployments\n* **Self-hosted**: Yes, SCIM works with OAuth with Client Secret authentication mode\n\n#### *What happens if I have both JIT provisioning and SCIM enabled?*\n\nJIT provisioning and SCIM can conflict with each other. We recommend disabling JIT provisioning before enabling SCIM to ensure consistent user provisioning behavior.\n\n#### *How do I change a user's role or workspace access?*\n\nUpdate the user's group membership in your IdP. The changes will be synchronized to LangSmith according to the [role precedence rules](#role-precedence).\n\n#### *What happens when a user is removed from all groups?*\n\nThe user will be deprovisioned from your LangSmith organization according to your IdP's deprovisioning settings.\n\n#### *Can I use custom group names?*\n\nYes. If your identity provider supports syncing alternate fields to the `displayName` group attribute, you may use an alternate attribute (like `description`) as the `displayName` in LangSmith and retain full customizability of the identity provider group name. Otherwise, groups must follow the specific naming convention described in the [Group Naming Convention](#group-naming-convention) section to properly map to LangSmith roles and workspaces.\n\n#### *Why is my Okta integration not working?*\n\nSee Okta's troubleshooting guide here: [https://help.okta.com/en-us/content/topics/users-groups-profiles/usgp-group-push-troubleshoot.htm](https://help.okta.com/en-us/content/topics/users-groups-profiles/usgp-group-push-troubleshoot.htm).\n\n## Deployment\n\n### Do I need to use LangChain to use LangGraph? What's the difference?\n\nNo. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents. LangChain provides a standard interface to interact with models and other components, useful for straight-forward chains and retrieval flows.\n\n### How is LangGraph different from other agent frameworks?\n\nOther agentic frameworks can work for simple, generic tasks but fall short for complex tasks bespoke to a company’s needs. LangGraph provides a more expressive framework to handle companies’ unique tasks without restricting users to a single black-box cognitive architecture.\n\n### Does LangGraph impact the performance of my app?\n\nLangGraph will not add any overhead to your code and is specifically designed with streaming workflows in mind.\n\n### Is LangGraph open source? Is it free?\n\nYes. LangGraph is an MIT-licensed open-source library and is free to use.\n\n### How are LangGraph and LangSmith different?\n\nLangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangSmith is a service for deploying and scaling agentic applications, with an opinionated API for building agent UXs, plus an integrated developer UI.\n\n| Features            | LangGraph (open source)                                   | LangSmith                                                                                              |\n| ------------------- | --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n| Description         | Stateful orchestration framework for agentic applications | Scalable infrastructure for deploying LangGraph applications                                           |\n| SDKs                | Python and JavaScript                                     | Python and JavaScript                                                                                  |\n| HTTP APIs           | None                                                      | Yes - useful for retrieving & updating state or long-term memory, or creating a configurable assistant |\n| Streaming           | Basic                                                     | Dedicated mode for token-by-token messages                                                             |\n| Checkpointer        | Community contributed                                     | Supported out-of-the-box                                                                               |\n| Persistence Layer   | Self-managed                                              | Managed Postgres with efficient storage                                                                |\n| Deployment          | Self-managed                                              | • Cloud <br /> • Free self-hosted <br /> • Enterprise (paid self-hosted)                               |\n| Scalability         | Self-managed                                              | Auto-scaling of task queues and servers                                                                |\n| Fault-tolerance     | Self-managed                                              | Automated retries                                                                                      |\n| Concurrency Control | Simple threading                                          | Supports double-texting                                                                                |\n| Scheduling          | None                                                      | Cron scheduling                                                                                        |\n| Monitoring          | None                                                      | Integrated with LangSmith for observability                                                            |\n| IDE integration     | Studio                                                    | Studio                                                                                                 |\n\n### Is LangSmith open source?\n\nNo. LangSmith is proprietary software.\n\nThere is a free, self-hosted version of LangSmith with access to basic features. The Cloud deployment option and the Self-Hosted deployment options are paid services. [Contact our sales team](https://www.langchain.com/contact-sales) to learn more.\n\nFor more information, see our [LangSmith pricing page](https://www.langchain.com/pricing).\n\n### Does LangGraph work with LLMs that don't support tool calling?\n\nYes! You can use LangGraph with any LLMs. The main reason we use LLMs that support tool calling is that this is often the most convenient way to have the LLM make its decision about what to do. If your LLM does not support tool calling, you can still use it - you just need to write a bit of logic to convert the raw LLM string response to a decision about what to do.\n\n### Does LangGraph work with OSS LLMs?\n\nYes! LangGraph is totally ambivalent to what LLMs are used under the hood. The main reason we use closed LLMs in most of the tutorials is that they seamlessly support tool calling, while OSS LLMs often don't. But tool calling is not necessary (see [this section](#does-langgraph-work-with-llms-that-dont-support-tool-calling)) so you can totally use LangGraph with OSS LLMs.\n\n### Can I use Studio without logging in to LangSmith?\n\nYes! You can use the [development version of Agent Server](/langsmith/local-server) to run the backend locally.\nThis will connect to the Studio frontend hosted as part of LangSmith.\nIf you set an environment variable of `LANGSMITH_TRACING=false`, then no traces will be sent to LangSmith.\n\n### What does \"nodes executed\" mean for LangSmith usage?\n\n**Nodes Executed** is the aggregate number of nodes in a LangGraph application that are called and completed successfully during an invocation of the application. If a node in the graph is not called during execution or ends in an error state, these nodes will not be counted. If a node is called and completes successfully multiple times, each occurrence will be counted.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/faq.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 11467
}