{
  "title": "Manage assistants",
  "source_url": "https://docs.langchain.com/langsmith/configuration-cloud",
  "content": "In this guide we will show how to create, configure, and manage an [assistant](/langsmith/assistants).\n\nFirst, as a brief refresher on the concept of context, consider the following simple `call_model` node and context schema.\nObserve that this node tries to read and use the `model_name` as defined by the `context` object's `model_name` field.\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    class ContextSchema(TypedDict):\n        model_name: str\n\n    builder = StateGraph(AgentState, context_schema=ContextSchema)\n\n    def call_model(state, runtime: Runtime[ContextSchema]):\n        messages = state[\"messages\"]\n        model = _get_model(runtime.context.get(\"model_name\", \"anthropic\"))\n        response = model.invoke(messages)\n        # We return a list, because this will get added to the existing list\n        return {\"messages\": [response]}\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    import { Annotation } from \"@langchain/langgraph\";\n\n    const ContextSchema = Annotation.Root({\n        model_name: Annotation<string>,\n        system_prompt:\n    });\n\n    const builder = new StateGraph(AgentState, ContextSchema)\n\n    function callModel(state: State, runtime: Runtime[ContextSchema]) {\n      const messages = state.messages;\n      const model = _getModel(runtime.context.model_name ?? \"anthropic\");\n      const response = model.invoke(messages);\n      // We return a list, because this will get added to the existing list\n      return { messages: [response] };\n    }\n    ```\n  </Tab>\n</Tabs>\n\nFor more information on configurations, [see here](/langsmith/configuration-cloud#configuration).\n\n## Create an assistant\n\n### LangGraph SDK\n\nTo create an assistant, use the [LangGraph SDK](/langsmith/sdk) `create` method. See the [Python](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.client.AssistantsClient.create) and [JS](https://reference.langchain.com/javascript/classes/_langchain_langgraph-sdk.client.AssistantsClient.html#create) SDK reference docs for more information.\n\nThis example uses the same context schema as above, and creates an assistant with `model_name` set to `openai`.\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    from langgraph_sdk import get_client\n\n    client = get_client(url=<DEPLOYMENT_URL>)\n    openai_assistant = await client.assistants.create(\n        # \"agent\" is the name of a graph we deployed\n        \"agent\", context={\"model_name\": \"openai\"}, name=\"Open AI Assistant\"\n    )\n\n    print(openai_assistant)\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    import { Client } from \"@langchain/langgraph-sdk\";\n\n    const client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n    const openAIAssistant = await client.assistants.create({\n        graphId: 'agent',\n        name: \"Open AI Assistant\",\n        context: { \"model_name\": \"openai\" },\n    });\n\n    console.log(openAIAssistant);\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request POST \\\n        --url <DEPLOYMENT_URL>/assistants \\\n        --header 'Content-Type: application/json' \\\n        --data '{\"graph_id\":\"agent\", \"context\":{\"model_name\":\"openai\"}, \"name\": \"Open AI Assistant\"}'\n    ```\n  </Tab>\n</Tabs>\n\nOutput:\n\n```\n{\n\"assistant_id\": \"62e209ca-9154-432a-b9e9-2d75c7a9219b\",\n\"graph_id\": \"agent\",\n\"name\": \"Open AI Assistant\"\n\"context\": {\n\"model_name\": \"openai\"\n}\n\"metadata\": {}\n\"created_at\": \"2024-08-31T03:09:10.230718+00:00\",\n\"updated_at\": \"2024-08-31T03:09:10.230718+00:00\",\n}\n```\n\n### LangSmith UI\n\nYou can also create assistants from the LangSmith UI.\n\nInside your deployment, select the \"Assistants\" tab. This will load a table of all of the assistants in your deployment, across all graphs.\n\nTo create a new assistant, select the \"+ New assistant\" button. This will open a form where you can specify the graph this assistant is for, as well as provide a name, description, and the desired configuration for the assistant based on the configuration schema for that graph.\n\nTo confirm, click \"Create assistant\". This will take you to [Studio](/langsmith/studio) where you can test the assistant. If you go back to the \"Assistants\" tab in the deployment, you will see the newly created assistant in the table.\n\n## Use an assistant\n\n### LangGraph SDK\n\nWe have now created an assistant called \"Open AI Assistant\" that has `model_name` defined as `openai`. We can now use this assistant with this configuration:\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    thread = await client.threads.create()\n    input = {\"messages\": [{\"role\": \"user\", \"content\": \"who made you?\"}]}\n    async for event in client.runs.stream(\n        thread[\"thread_id\"],\n        # this is where we specify the assistant id to use\n        openai_assistant[\"assistant_id\"],\n        input=input,\n        stream_mode=\"updates\",\n    ):\n        print(f\"Receiving event of type: {event.event}\")\n        print(event.data)\n        print(\"\\n\\n\")\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    const thread = await client.threads.create();\n    const input = { \"messages\": [{ \"role\": \"user\", \"content\": \"who made you?\" }] };\n\n    const streamResponse = client.runs.stream(\n      thread[\"thread_id\"],\n      // this is where we specify the assistant id to use\n      openAIAssistant[\"assistant_id\"],\n      {\n        input,\n        streamMode: \"updates\"\n      }\n    );\n\n    for await (const event of streamResponse) {\n      console.log(`Receiving event of type: ${event.event}`);\n      console.log(event.data);\n      console.log(\"\\n\\n\");\n    }\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    thread_id=$(curl --request POST \\\n        --url <DEPLOYMENT_URL>/threads \\\n        --header 'Content-Type: application/json' \\\n        --data '{}' | jq -r '.thread_id') && \\\n    curl --request POST \\\n        --url \"<DEPLOYMENT_URL>/threads/${thread_id}/runs/stream\" \\\n        --header 'Content-Type: application/json' \\\n        --data '{\n            \"assistant_id\": <OPENAI_ASSISTANT_ID>,\n            \"input\": {\n                \"messages\": [\n                    {\n                        \"role\": \"user\",\n                        \"content\": \"who made you?\"\n                    }\n                ]\n            },\n            \"stream_mode\": [\n                \"updates\"\n            ]\n        }' | \\\n        sed 's/\\r$//' | \\\n        awk '\n        /^event:/ {\n            if (data_content != \"\") {\n                print data_content \"\\n\"\n            }\n            sub(/^event: /, \"Receiving event of type: \", $0)\n            printf \"%s...\\n\", $0\n            data_content = \"\"\n        }\n        /^data:/ {\n            sub(/^data: /, \"\", $0)\n            data_content = $0\n        }\n        END {\n            if (data_content != \"\") {\n                print data_content \"\\n\\n\"\n            }\n        }\n    '\n    ```\n  </Tab>\n</Tabs>\n\nOutput:\n\n```\nReceiving event of type: metadata\n{'run_id': '1ef6746e-5893-67b1-978a-0f1cd4060e16'}\n\n\n\nReceiving event of type: updates\n{'agent': {'messages': [{'content': 'I was created by OpenAI, a research organization focused on developing and advancing artificial intelligence technology.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-e1a6b25c-8416-41f2-9981-f9cfe043f414', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]}}\n```\n\n### LangSmith UI\n\nInside your deployment, select the \"Assistants\" tab. For the assistant you would like to use, click the **Studio** button. This will open Studio with the selected assistant. When you submit an input (either in Graph or Chat mode), the selected assistant and its configuration will be used.\n\n## Create a new version for your assistant\n\n### LangGraph SDK\n\nTo edit the assistant, use the `update` method. This will create a new version of the assistant with the provided edits. See the [Python](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.client.AssistantsClient.update) and [JS](https://reference.langchain.com/javascript/classes/_langchain_langgraph-sdk.client.AssistantsClient.html#update) SDK reference docs for more information.\n\n<Note>\n  **Note**\n  You must pass in the ENTIRE context (and metadata if you are using it). The update endpoint creates new versions completely from scratch and does not rely on previous versions.\n</Note>\n\nFor example, to update your assistant's system prompt:\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    openai_assistant_v2 = await client.assistants.update(\n        openai_assistant[\"assistant_id\"],\n        context={\n              \"model_name\": \"openai\",\n              \"system_prompt\": \"You are an unhelpful assistant!\",\n        },\n    )\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    const openaiAssistantV2 = await client.assistants.update(\n        openai_assistant[\"assistant_id\"],\n        {\n            context: {\n                model_name: 'openai',\n                system_prompt: 'You are an unhelpful assistant!',\n            },\n        },\n    );\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request PATCH \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID> \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n    \"context\": {\"model_name\": \"openai\", \"system_prompt\": \"You are an unhelpful assistant!\"}\n    }'\n    ```\n  </Tab>\n</Tabs>\n\nThis will create a new version of the assistant with the updated parameters and set this as the active version of your assistant. If you now run your graph and pass in this assistant id, it will use this latest version.\n\n### LangSmith UI\n\nYou can also edit assistants from the LangSmith UI.\n\nInside your deployment, select the \"Assistants\" tab. This will load a table of all of the assistants in your deployment, across all graphs.\n\nTo edit an existing assistant, select the \"Edit\" button for the specified assistant. This will open a form where you can edit the assistant's name, description, and configuration.\n\nAdditionally, if using Studio, you can edit the assistants and create new versions via the \"Manage Assistants\" button.\n\n## Use a previous assistant version\n\n### LangGraph SDK\n\nYou can also change the active version of your assistant. To do so, use the `setLatest` method.\n\nIn the example above, to rollback to the first version of the assistant:\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    await client.assistants.set_latest(openai_assistant['assistant_id'], 1)\n    ```\n  </Tab>\n\n  <Tab title=\"Javascript\">\n    ```js  theme={null}\n    await client.assistants.setLatest(openaiAssistant['assistant_id'], 1);\n    ```\n  </Tab>\n\n  <Tab title=\"CURL\">\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/latest \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n    \"version\": 1\n    }'\n    ```\n  </Tab>\n</Tabs>\n\nIf you now run your graph and pass in this assistant id, it will use the first version of the assistant.\n\n### LangSmith UI\n\nIf using Studio, to set the active version of your assistant, click the \"Manage Assistants\" button and locate the assistant you would like to use. Select the assistant and the version, and then click the \"Active\" toggle. This will update the assistant to make the selected version active.\n\n<Warning>\n  **Deleting Assistants**\n  Deleting as assistant will delete ALL of its versions. There is currently no way to delete a single version, but by pointing your assistant to the correct version you can skip any versions that you don't wish to use.\n</Warning>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/configuration-cloud.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 12062
}