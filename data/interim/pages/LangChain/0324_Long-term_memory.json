{
  "title": "Long-term memory",
  "source_url": "https://docs.langchain.com/oss/javascript/langchain/long-term-memory",
  "content": "## Overview\n\nLangChain agents use [LangGraph persistence](/oss/javascript/langgraph/persistence#memory-store) to enable long-term memory. This is a more advanced topic and requires knowledge of LangGraph to use.\n\n## Memory storage\n\nLangGraph stores long-term memories as JSON documents in a [store](/oss/javascript/langgraph/persistence#memory-store).\n\nEach memory is organized under a custom `namespace` (similar to a folder) and a distinct `key` (like a file name). Namespaces often include user or org IDs or other labels that makes it easier to organize information.\n\nThis structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters.\n\n```typescript  theme={null}\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\nconst embed = (texts: string[]): number[][] => {\n    // Replace with an actual embedding function or LangChain embeddings object\n    return texts.map(() => [1.0, 2.0]);\n};\n\n// InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\nconst store = new InMemoryStore({ index: { embed, dims: 2 } }); // [!code highlight]\nconst userId = \"my-user\";\nconst applicationContext = \"chitchat\";\nconst namespace = [userId, applicationContext]; // [!code highlight]\n\nawait store.put( // [!code highlight]\n    namespace,\n    \"a-memory\",\n    {\n        rules: [\n            \"User likes short, direct language\",\n            \"User only speaks English & TypeScript\",\n        ],\n        \"my-key\": \"my-value\",\n    }\n);\n\n// get the \"memory\" by ID\nconst item = await store.get(namespace, \"a-memory\"); // [!code highlight]\n\n// search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\nconst items = await store.search( // [!code highlight]\n    namespace,\n    {\n        filter: { \"my-key\": \"my-value\" },\n        query: \"language preferences\"\n    }\n);\n```\n\nFor more information about the memory store, see the [Persistence](/oss/javascript/langgraph/persistence#memory-store) guide.\n\n## Read long-term memory in tools\n\n```typescript A tool the agent can use to look up user information theme={null}\nimport * as z from \"zod\";\nimport { createAgent, tool, type ToolRuntime } from \"langchain\";\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\n// InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\nconst store = new InMemoryStore(); // [!code highlight]\nconst contextSchema = z.object({\n  userId: z.string(),\n});\n\n// Write sample data to the store using the put method\nawait store.put( // [!code highlight]\n  [\"users\"], // Namespace to group related data together (users namespace for user data)\n  \"user_123\", // Key within the namespace (user ID as key)\n  {\n    name: \"John Smith\",\n    language: \"English\",\n  } // Data to store for the given user\n);\n\nconst getUserInfo = tool(\n  // Look up user info.\n  async (_, runtime: ToolRuntime<unknown, z.infer<typeof contextSchema>>) => {\n    // Access the store - same as that provided to `createAgent`\n    const userId = runtime.context.userId;\n    if (!userId) {\n      throw new Error(\"userId is required\");\n    }\n    // Retrieve data from store - returns StoreValue object with value and metadata\n    const userInfo = await runtime.store.get([\"users\"], userId);\n    return userInfo?.value ? JSON.stringify(userInfo.value) : \"Unknown user\";\n  },\n  {\n    name: \"getUserInfo\",\n    description: \"Look up user info by userId from the store.\",\n    schema: z.object({}),\n  }\n);\n\nconst agent = createAgent({\n  model: \"gpt-4o-mini\",\n  tools: [getUserInfo],\n  contextSchema,\n  // Pass store to agent - enables agent to access store when running tools\n  store, // [!code highlight]\n});\n\n// Run the agent\nconst result = await agent.invoke(\n  { messages: [{ role: \"user\", content: \"look up user information\" }] },\n  { context: { userId: \"user_123\" } } // [!code highlight]\n);\n\nconsole.log(result.messages.at(-1)?.content);\n\n/**\n * Outputs:\n * User Information:\n * - Name: John Smith\n * - Language: English\n */\n```\n\n<a id=\"write-long-term\" />\n\n## Write long-term memory from tools\n\n```typescript Example of a tool that updates user information theme={null}\nimport * as z from \"zod\";\nimport { tool, createAgent, type ToolRuntime } from \"langchain\";\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\n// InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\nconst store = new InMemoryStore(); // [!code highlight]\n\nconst contextSchema = z.object({\n  userId: z.string(),\n});\n\n// Schema defines the structure of user information for the LLM\nconst UserInfo = z.object({\n  name: z.string(),\n});\n\n// Tool that allows agent to update user information (useful for chat applications)\nconst saveUserInfo = tool(\n  async (\n    userInfo: z.infer<typeof UserInfo>,\n    runtime: ToolRuntime<unknown, z.infer<typeof contextSchema>>\n  ) => {\n    const userId = runtime.context.userId;\n    if (!userId) {\n      throw new Error(\"userId is required\");\n    }\n    // Store data in the store (namespace, key, data)\n    await runtime.store.put([\"users\"], userId, userInfo);\n    return \"Successfully saved user info.\";\n  },\n  {\n    name: \"save_user_info\",\n    description: \"Save user info\",\n    schema: UserInfo,\n  }\n);\n\nconst agent = createAgent({\n  model: \"gpt-4o-mini\",\n  tools: [saveUserInfo],\n  contextSchema,\n  store, // [!code highlight]\n});\n\n// Run the agent\nawait agent.invoke(\n  { messages: [{ role: \"user\", content: \"My name is John Smith\" }] },\n  // userId passed in context to identify whose information is being updated\n  { context: { userId: \"user_123\" } } // [!code highlight]\n);\n\n// You can access the store directly to get the value\nconst result = await store.get([\"users\"], \"user_123\");\nconsole.log(result?.value); // Output: { name: \"John Smith\" }\n\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/long-term-memory.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 6168
}