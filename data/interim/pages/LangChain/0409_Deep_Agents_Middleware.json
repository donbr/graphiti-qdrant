{
  "title": "Deep Agents Middleware",
  "source_url": "https://docs.langchain.com/oss/python/deepagents/middleware",
  "content": "Understand the middleware that powers deep agents\n\nDeep agents are built with a modular middleware architecture. Deep agents have access to:\n\n1. A planning tool\n2. A filesystem for storing context and long-term memories\n3. The ability to spawn subagents\n\nEach feature is implemented as separate middleware. When you create a deep agent with `create_deep_agent`, we automatically attach `TodoListMiddleware`, `FilesystemMiddleware`, and `SubAgentMiddleware` to your agent.\n\n```mermaid  theme={null}\ngraph LR\n    Agent[create_deep_agent] --> Todo[TodoList]\n    Agent --> FS[Filesystem]\n    Agent --> Sub[SubAgent]\n\n    Todo --> Tools[Agent Tools]\n    FS --> Tools\n    Sub --> Tools\n```\n\nMiddleware is composable—you can add as many or as few middleware to an agent as needed. You can use any middleware independently.\n\nThe following sections explain what each middleware provides.\n\n## To-do list middleware\n\nPlanning is integral to solving complex problems. If you've used Claude Code recently, you'll notice how it writes out a to-do list before tackling complex, multi-part tasks. You'll also notice how it can adapt and update this to-do list on the fly as more information comes in.\n\n`TodoListMiddleware` provides your agent with a tool specifically for updating this to-do list. Before and while it executes a multi-part task, the agent is prompted to use the `write_todos` tool to keep track of what it's doing and what still needs to be done.\n\n```python  theme={null}\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import TodoListMiddleware\n\n# TodoListMiddleware is included by default in create_deep_agent\n# You can customize it if building a custom agent\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    # Custom planning instructions can be added via middleware\n    middleware=[\n        TodoListMiddleware(\n            system_prompt=\"Use the write_todos tool to...\"  # Optional: Custom addition to the system prompt\n        ),\n    ],\n)\n```\n\n## Filesystem middleware\n\nContext engineering is a main challenge in building effective agents. This is particularly difficult when using tools that return variable-length results (for example, web\\_search and rag), as long tool results can quickly fill your context window.\n\n`FilesystemMiddleware` provides four tools for interacting with both short-term and long-term memory:\n\n* **ls**: List the files in the filesystem\n* **read\\_file**: Read an entire file or a certain number of lines from a file\n* **write\\_file**: Write a new file to the filesystem\n* **edit\\_file**: Edit an existing file in the filesystem\n\n```python  theme={null}\nfrom langchain.agents import create_agent\nfrom deepagents.middleware.filesystem import FilesystemMiddleware\n\n# FilesystemMiddleware is included by default in create_deep_agent\n# You can customize it if building a custom agent\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    middleware=[\n        FilesystemMiddleware(\n            backend=None,  # Optional: custom backend (defaults to StateBackend)\n            system_prompt=\"Write to the filesystem when...\",  # Optional custom addition to the system prompt\n            custom_tool_descriptions={\n                \"ls\": \"Use the ls tool when...\",\n                \"read_file\": \"Use the read_file tool to...\"\n            }  # Optional: Custom descriptions for filesystem tools\n        ),\n    ],\n)\n```\n\n### Short-term vs. long-term filesystem\n\nBy default, these tools write to a local \"filesystem\" in your graph state. To enable persistent storage across threads, configure a `CompositeBackend` that routes specific paths (like `/memories/`) to a `StoreBackend`.\n\n```python  theme={null}\nfrom langchain.agents import create_agent\nfrom deepagents.middleware import FilesystemMiddleware\nfrom deepagents.backends import CompositeBackend, StateBackend, StoreBackend\nfrom langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    store=store,\n    middleware=[\n        FilesystemMiddleware(\n            backend=lambda rt: CompositeBackend(\n                default=StateBackend(rt),\n                routes={\"/memories/\": StoreBackend(rt)}\n            ),\n            custom_tool_descriptions={\n                \"ls\": \"Use the ls tool when...\",\n                \"read_file\": \"Use the read_file tool to...\"\n            }  # Optional: Custom descriptions for filesystem tools\n        ),\n    ],\n)\n```\n\nWhen you configure a `CompositeBackend` with a `StoreBackend` for `/memories/`, any files prefixed with **/memories/** are saved to persistent storage and survive across different threads. Files without this prefix remain in ephemeral state storage.\n\n## Subagent middleware\n\nHanding off tasks to subagents isolates context, keeping the main (supervisor) agent's context window clean while still going deep on a task.\n\nThe subagents middleware allows you to supply subagents through a `task` tool.\n\n```python  theme={null}\nfrom langchain.tools import tool\nfrom langchain.agents import create_agent\nfrom deepagents.middleware.subagents import SubAgentMiddleware\n\n\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather in a city.\"\"\"\n    return f\"The weather in {city} is sunny.\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    middleware=[\n        SubAgentMiddleware(\n            default_model=\"claude-sonnet-4-5-20250929\",\n            default_tools=[],\n            subagents=[\n                {\n                    \"name\": \"weather\",\n                    \"description\": \"This subagent can get weather in cities.\",\n                    \"system_prompt\": \"Use the get_weather tool to get the weather in a city.\",\n                    \"tools\": [get_weather],\n                    \"model\": \"gpt-4o\",\n                    \"middleware\": [],\n                }\n            ],\n        )\n    ],\n)\n```\n\nA subagent is defined with a **name**, **description**, **system prompt**, and **tools**. You can also provide a subagent with a custom **model**, or with additional **middleware**. This can be particularly useful when you want to give the subagent an additional state key to share with the main agent.\n\nFor more complex use cases, you can also provide your own pre-built LangGraph graph as a subagent.\n\n```python  theme={null}\nfrom langchain.agents import create_agent\nfrom deepagents.middleware.subagents import SubAgentMiddleware\nfrom deepagents import CompiledSubAgent\nfrom langgraph.graph import StateGraph\n\n# Create a custom LangGraph graph\ndef create_weather_graph():\n    workflow = StateGraph(...)\n    # Build your custom graph\n    return workflow.compile()\n\nweather_graph = create_weather_graph()\n\n# Wrap it in a CompiledSubAgent\nweather_subagent = CompiledSubAgent(\n    name=\"weather\",\n    description=\"This subagent can get weather in cities.\",\n    runnable=weather_graph\n)\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    middleware=[\n        SubAgentMiddleware(\n            default_model=\"claude-sonnet-4-5-20250929\",\n            default_tools=[],\n            subagents=[weather_subagent],\n        )\n    ],\n)\n```\n\nIn addition to any user-defined subagents, the main agent has access to a `general-purpose` subagent at all times. This subagent has the same instructions as the main agent and all the tools it has access to. The primary purpose of the `general-purpose` subagent is context isolation—the main agent can delegate a complex task to this subagent and get a concise answer back without bloat from intermediate tool calls.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/deepagents/middleware.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 7895
}