{
  "title": "How to return multiple scores in one evaluator",
  "source_url": "https://docs.langchain.com/langsmith/multiple-scores",
  "content": "Sometimes it is useful for a custom evaluator or summary evaluator to return multiple metrics. For example, if you have multiple metrics being generated by an LLM judge, you can save time and money by making a single LLM call that generates multiple metrics instead of making multiple LLM calls.\n\nTo return multiple scores using the Python SDK, simply return a list of dictionaries/objects of the following form:\n\n```python  theme={null}\n[\n    # 'key' is the metric name\n    # 'score' is the value of a numerical metric\n    {\"key\": string, \"score\": number},\n    # 'value' is the value of a categorical metric\n    {\"key\": string, \"value\": string},\n    ... # You may log as many as you wish\n]\n```\n\nTo do so with the JS/TS SDK, return an object with a 'results' key and then a list of the above form\n\n```typescript  theme={null}\n{results: [{ key: string, score: number }, ...]};\n```\n\nEach of these dictionaries can contain any or all of the [feedback fields](/langsmith/feedback-data-format); check out the linked document for more information.\n\nExample:\n\n* Python: Requires `langsmith>=0.2.0`\n* TypeScript: Support for multiple scores is available in `langsmith@0.1.32` and higher\n\n<CodeGroup>\n  ```python Python theme={null}\n  def multiple_scores(outputs: dict, reference_outputs: dict) -> list[dict]:\n      # Replace with real evaluation logic.\n      precision = 0.8\n      recall = 0.9\n      f1 = 0.85\n      return [\n          {\"key\": \"precision\", \"score\": precision},\n          {\"key\": \"recall\", \"score\": recall},\n          {\"key\": \"f1\", \"score\": f1},\n      ]\n  ```\n\n  ```typescript TypeScript theme={null}\n  import type { Run, Example } from \"langsmith/schemas\";\n\n  function multipleScores(rootRun: Run, example: Example) {\n    // Your evaluation logic here\n    return {\n        results: [\n            { key: \"precision\", score: 0.8 },\n            { key: \"recall\", score: 0.9 },\n            { key: \"f1\", score: 0.85 },\n        ],\n    };\n  }\n  ```\n</CodeGroup>\n\nRows from the resulting experiment will display each of the scores.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=7f0a67189b7202a46d5e093cce9ea283\" alt=\"multiple_scores.png\" data-og-width=\"1622\" width=\"1622\" data-og-height=\"1020\" height=\"1020\" data-path=\"langsmith/images/multiple-scores.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?w=280&fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=cb2f322c66eadd3ef0eef99a5c11063f 280w, https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?w=560&fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=05a52f0d760f2e079c6701e83c48fb73 560w, https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?w=840&fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=147f1a6046e9dabac499f68ec6abf68f 840w, https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?w=1100&fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=0a807e000d2e2d7cd18b6af3e83e8a59 1100w, https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?w=1650&fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=f46442dafae69f9039fe1c9def5a1a01 1650w, https://mintcdn.com/langchain-5e9cc07a/4kN8yiLrZX_amfFn/langsmith/images/multiple-scores.png?w=2500&fit=max&auto=format&n=4kN8yiLrZX_amfFn&q=85&s=c182c52b39a42dbcab618fc8b2a0c525 2500w\" />\n\n## Related\n\n* [Return categorical vs numerical metrics](/langsmith/metric-type)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/multiple-scores.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 3953
}