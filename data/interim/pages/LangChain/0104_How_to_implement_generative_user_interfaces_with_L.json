{
  "title": "How to implement generative user interfaces with LangGraph",
  "source_url": "https://docs.langchain.com/langsmith/generative-ui-react",
  "content": "<Info>\n  **Prerequisites**\n\n  * [LangSmith](/langsmith/home)\n  * [Agent Server](/langsmith/agent-server)\n  * [`useStream()` React Hook](/langsmith/use-stream-react)\n</Info>\n\nGenerative user interfaces (Generative UI) allows agents to go beyond text and generate rich user interfaces. This enables creating more interactive and context-aware applications where the UI adapts based on the conversation flow and AI responses.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=105943c6c28853fad0a9bc3b4af3a999\" alt=\"Agent Chat showing a prompt about booking/lodging and a generated set of hotel listing cards (images, titles, prices, locations) rendered inline as UI components.\" data-og-width=\"1814\" width=\"1814\" data-og-height=\"898\" height=\"898\" data-path=\"langsmith/images/generative-ui-sample.jpg\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?w=280&fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=0fd526a7132d33ab6f72002d68a66dec 280w, https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?w=560&fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=0c9ffe86700a7b8404f1fdf51b906aa1 560w, https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?w=840&fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=50652e58566db8171ead4aef57d78fa6 840w, https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?w=1100&fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=a764d790719e8233313fabe4cee93958 1100w, https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?w=1650&fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=a02d8d6ecace7eee6df55e3a391c09e2 1650w, https://mintcdn.com/langchain-5e9cc07a/JOyLr_spVEW0t2KF/langsmith/images/generative-ui-sample.jpg?w=2500&fit=max&auto=format&n=JOyLr_spVEW0t2KF&q=85&s=b0709ca94bd9533f5ef5a80da1d60bf6 2500w\" />\n\nLangSmith supports colocating your React components with your graph code. This allows you to focus on building specific UI components for your graph while easily plugging into existing chat interfaces such as [Agent Chat](https://agentchat.vercel.app) and loading the code only when actually needed.\n\n## Tutorial\n\n### 1. Define and configure UI components\n\nFirst, create your first UI component. For each component you need to provide an unique identifier that will be used to reference the component in your graph code.\n\n```tsx title=\"src/agent/ui.tsx\" theme={null}\nconst WeatherComponent = (props: { city: string }) => {\n  return <div>Weather for {props.city}</div>;\n};\n\nexport default {\n  weather: WeatherComponent,\n};\n```\n\nNext, define your UI components in your `langgraph.json` configuration:\n\n```json  theme={null}\n{\n  \"node_version\": \"20\",\n  \"graphs\": {\n    \"agent\": \"./src/agent/index.ts:graph\"\n  },\n  \"ui\": {\n    \"agent\": \"./src/agent/ui.tsx\"\n  }\n}\n```\n\nThe `ui` section points to the UI components that will be used by graphs. By default, we recommend using the same key as the graph name, but you can split out the components however you like, see [Customise the namespace of UI components](#customise-the-namespace-of-ui-components) for more details.\n\nLangSmith will automatically bundle your UI components code and styles and serve them as external assets that can be loaded by the `LoadExternalComponent` component. Some dependencies such as `react` and `react-dom` will be automatically excluded from the bundle.\n\nCSS and Tailwind 4.x is also supported out of the box, so you can freely use Tailwind classes as well as `shadcn/ui` in your UI components.\n\n<Tabs>\n  <Tab title=\"src/agent/ui.tsx\">\n    ```tsx  theme={null}\n    import \"./styles.css\";\n\n    const WeatherComponent = (props: { city: string }) => {\n      return <div className=\"bg-red-500\">Weather for {props.city}</div>;\n    };\n\n    export default {\n      weather: WeatherComponent,\n    };\n    ```\n  </Tab>\n\n  <Tab title=\"src/agent/styles.css\">\n    ```css  theme={null}\n    @import \"tailwindcss\";\n    ```\n  </Tab>\n</Tabs>\n\n### 2. Send the UI components in your graph\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python title=\"src/agent.py\" theme={null}\n    import uuid\n    from typing import Annotated, Sequence, TypedDict\n\n    from langchain.messages import AIMessage\n    from langchain_core.messages import BaseMessage\n    from langchain_openai import ChatOpenAI\n    from langgraph.graph import StateGraph\n    from langgraph.graph.message import add_messages\n    from langgraph.graph.ui import AnyUIMessage, ui_message_reducer, push_ui_message\n\n\n    class AgentState(TypedDict):  # noqa: D101\n        messages: Annotated[Sequence[BaseMessage], add_messages]\n        ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\n\n\n    async def weather(state: AgentState):\n        class WeatherOutput(TypedDict):\n            city: str\n\n        weather: WeatherOutput = (\n            await ChatOpenAI(model=\"gpt-4o-mini\")\n            .with_structured_output(WeatherOutput)\n            .with_config({\"tags\": [\"nostream\"]})\n            .ainvoke(state[\"messages\"])\n        )\n\n        message = AIMessage(\n            id=str(uuid.uuid4()),\n            content=f\"Here's the weather for {weather['city']}\",\n        )\n\n        # Emit UI elements associated with the message\n        push_ui_message(\"weather\", weather, message=message)\n        return {\"messages\": [message]}\n\n\n    workflow = StateGraph(AgentState)\n    workflow.add_node(weather)\n    workflow.add_edge(\"__start__\", \"weather\")\n    graph = workflow.compile()\n    ```\n  </Tab>\n\n  <Tab title=\"JS\">\n    Use the `typedUi` utility to emit UI elements from your agent nodes:\n\n    ```typescript title=\"src/agent/index.ts\" theme={null}\n    import {\n      typedUi,\n      uiMessageReducer,\n    } from \"@langchain/langgraph-sdk/react-ui/server\";\n\n    import { ChatOpenAI } from \"@langchain/openai\";\n    import { v4 as uuidv4 } from \"uuid\";\n    import { z } from \"zod\";\n\n    import type ComponentMap from \"./ui.js\";\n\n    import {\n      Annotation,\n      MessagesAnnotation,\n      StateGraph,\n      type LangGraphRunnableConfig,\n    } from \"@langchain/langgraph\";\n\n    const AgentState = Annotation.Root({\n      ...MessagesAnnotation.spec,\n      ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\n    });\n\n    export const graph = new StateGraph(AgentState)\n      .addNode(\"weather\", async (state, config) => {\n        // Provide the type of the component map to ensure\n        // type safety of `ui.push()` calls as well as\n        // pushing the messages to the `ui` and sending a custom event as well.\n        const ui = typedUi<typeof ComponentMap>(config);\n\n        const weather = await new ChatOpenAI({ model: \"gpt-4o-mini\" })\n          .withStructuredOutput(z.object({ city: z.string() }))\n          .withConfig({ tags: [\"nostream\"] })\n          .invoke(state.messages);\n\n        const response = {\n          id: uuidv4(),\n          type: \"ai\",\n          content: `Here's the weather for ${weather.city}`,\n        };\n\n        // Emit UI elements associated with the AI message\n        ui.push({ name: \"weather\", props: weather }, { message: response });\n\n        return { messages: [response] };\n      })\n      .addEdge(\"__start__\", \"weather\")\n      .compile();\n    ```\n  </Tab>\n</Tabs>\n\n### 3. Handle UI elements in your React application\n\nOn the client side, you can use `useStream()` and `LoadExternalComponent` to display the UI elements.\n\n```tsx title=\"src/app/page.tsx\" theme={null}\n\"use client\";\n\nimport { useStream } from \"@langchain/langgraph-sdk/react\";\nimport { LoadExternalComponent } from \"@langchain/langgraph-sdk/react-ui\";\n\nexport default function Page() {\n  const { thread, values } = useStream({\n    apiUrl: \"http://localhost:2024\",\n    assistantId: \"agent\",\n  });\n\n  return (\n    <div>\n      {thread.messages.map((message) => (\n        <div key={message.id}>\n          {message.content}\n          {values.ui\n            ?.filter((ui) => ui.metadata?.message_id === message.id)\n            .map((ui) => (\n              <LoadExternalComponent key={ui.id} stream={thread} message={ui} />\n            ))}\n        </div>\n      ))}\n    </div>\n  );\n}\n```\n\nBehind the scenes, `LoadExternalComponent` will fetch the JS and CSS for the UI components from LangSmith and render them in a shadow DOM, thus ensuring style isolation from the rest of your application.\n\n## How-to guides\n\n### Provide custom components on the client side\n\nIf you already have the components loaded in your client application, you can provide a map of such components to be rendered directly without fetching the UI code from LangSmith.\n\n```tsx  theme={null}\nconst clientComponents = {\n  weather: WeatherComponent,\n};\n\n<LoadExternalComponent\n  stream={thread}\n  message={ui}\n  components={clientComponents}\n/>;\n```\n\n### Show loading UI when components are loading\n\nYou can provide a fallback UI to be rendered when the components are loading.\n\n```tsx  theme={null}\n<LoadExternalComponent\n  stream={thread}\n  message={ui}\n  fallback={<div>Loading...</div>}\n/>\n```\n\n### Customise the namespace of UI components.\n\nBy default `LoadExternalComponent` will use the `assistantId` from `useStream()` hook to fetch the code for UI components. You can customise this by providing a `namespace` prop to the `LoadExternalComponent` component.\n\n<Tabs>\n  <Tab title=\"src/app/page.tsx\">\n    ```tsx  theme={null}\n    <LoadExternalComponent\n      stream={thread}\n      message={ui}\n      namespace=\"custom-namespace\"\n    />\n    ```\n  </Tab>\n\n  <Tab title=\"langgraph.json\">\n    ```json  theme={null}\n    {\n      \"ui\": {\n        \"custom-namespace\": \"./src/agent/ui.tsx\"\n      }\n    }\n    ```\n  </Tab>\n</Tabs>\n\n### Access and interact with the thread state from the UI component\n\nYou can access the thread state inside the UI component by using the `useStreamContext` hook.\n\n```tsx  theme={null}\nimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";\n\nconst WeatherComponent = (props: { city: string }) => {\n  const { thread, submit } = useStreamContext();\n  return (\n    <>\n      <div>Weather for {props.city}</div>\n\n      <button\n        onClick={() => {\n          const newMessage = {\n            type: \"human\",\n            content: `What's the weather in ${props.city}?`,\n          };\n\n          submit({ messages: [newMessage] });\n        }}\n      >\n        Retry\n      </button>\n    </>\n  );\n};\n```\n\n### Pass additional context to the client components\n\nYou can pass additional context to the client components by providing a `meta` prop to the `LoadExternalComponent` component.\n\n```tsx  theme={null}\n<LoadExternalComponent stream={thread} message={ui} meta={{ userId: \"123\" }} />\n```\n\nThen, you can access the `meta` prop in the UI component by using the `useStreamContext` hook.\n\n```tsx  theme={null}\nimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";\n\nconst WeatherComponent = (props: { city: string }) => {\n  const { meta } = useStreamContext<\n    { city: string },\n    { MetaType: { userId?: string } }\n  >();\n\n  return (\n    <div>\n      Weather for {props.city} (user: {meta?.userId})\n    </div>\n  );\n};\n```\n\n### Streaming UI messages from the server\n\nYou can stream UI messages before the node execution is finished by using the `onCustomEvent` callback of the `useStream()` hook. This is especially useful when updating the UI component as the LLM is generating the response.\n\n```tsx  theme={null}\nimport { uiMessageReducer } from \"@langchain/langgraph-sdk/react-ui\";\n\nconst { thread, submit } = useStream({\n  apiUrl: \"http://localhost:2024\",\n  assistantId: \"agent\",\n  onCustomEvent: (event, options) => {\n    options.mutate((prev) => {\n      const ui = uiMessageReducer(prev.ui ?? [], event);\n      return { ...prev, ui };\n    });\n  },\n});\n```\n\nThen you can push updates to the UI component by calling `ui.push()` / `push_ui_message()` with the same ID as the UI message you wish to update.\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    from typing import Annotated, Sequence, TypedDict\n\n    from langchain_anthropic import ChatAnthropic\n    from langchain.messages import AIMessage, AIMessageChunk, BaseMessage\n    from langgraph.graph import StateGraph\n    from langgraph.graph.message import add_messages\n    from langgraph.graph.ui import AnyUIMessage, push_ui_message, ui_message_reducer\n\n\n    class AgentState(TypedDict):  # noqa: D101\n        messages: Annotated[Sequence[BaseMessage], add_messages]\n        ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\n\n\n    class CreateTextDocument(TypedDict):\n        \"\"\"Prepare a document heading for the user.\"\"\"\n\n        title: str\n\n\n    async def writer_node(state: AgentState):\n        model = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\n        message: AIMessage = await model.bind_tools(\n            tools=[CreateTextDocument],\n            tool_choice={\"type\": \"tool\", \"name\": \"CreateTextDocument\"},\n        ).ainvoke(state[\"messages\"])\n\n        tool_call = next(\n            (x[\"args\"] for x in message.tool_calls if x[\"name\"] == \"CreateTextDocument\"),\n            None,\n        )\n\n        if tool_call:\n            ui_message = push_ui_message(\"writer\", tool_call, message=message)\n            ui_message_id = ui_message[\"id\"]\n\n            # We're already streaming the LLM response to the client through UI messages\n            # so we don't need to stream it again to the `messages` stream mode.\n            content_stream = model.with_config({\"tags\": [\"nostream\"]}).astream(\n                f\"Create a document with the title: {tool_call['title']}\"\n            )\n\n            content: AIMessageChunk | None = None\n            async for chunk in content_stream:\n                content = content + chunk if content else chunk\n\n                push_ui_message(\n                    \"writer\",\n                    {\"content\": content.text()},\n                    id=ui_message_id,\n                    message=message,\n                    # Use `merge=rue` to merge props with the existing UI message\n                    merge=True,\n                )\n\n        return {\"messages\": [message]}\n    ```\n  </Tab>\n\n  <Tab title=\"JS\">\n    ```tsx  theme={null}\n    import {\n      Annotation,\n      MessagesAnnotation,\n      type LangGraphRunnableConfig,\n    } from \"@langchain/langgraph\";\n    import { z } from \"zod\";\n    import { ChatAnthropic } from \"@langchain/anthropic\";\n    import {\n      typedUi,\n      uiMessageReducer,\n    } from \"@langchain/langgraph-sdk/react-ui/server\";\n    import type { AIMessageChunk } from \"@langchain/core/messages\";\n\n    import type ComponentMap from \"./ui\";\n\n    const AgentState = Annotation.Root({\n      ...MessagesAnnotation.spec,\n      ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\n    });\n\n    async function writerNode(\n      state: typeof AgentState.State,\n      config: LangGraphRunnableConfig\n    ): Promise<typeof AgentState.Update> {\n      const ui = typedUi<typeof ComponentMap>(config);\n\n      const model = new ChatAnthropic({ model: \"claude-sonnet-4-5-20250929\" });\n      const message = await model\n        .bindTools(\n          [\n            {\n              name: \"create_text_document\",\n              description: \"Prepare a document heading for the user.\",\n              schema: z.object({ title: z.string() }),\n            },\n          ],\n          { tool_choice: { type: \"tool\", name: \"create_text_document\" } }\n        )\n        .invoke(state.messages);\n\n      type ToolCall = { name: \"create_text_document\"; args: { title: string } };\n      const toolCall = message.tool_calls?.find(\n        (tool): tool is ToolCall => tool.name === \"create_text_document\"\n      );\n\n      if (toolCall) {\n        const { id, name } = ui.push(\n          { name: \"writer\", props: { title: toolCall.args.title } },\n          { message }\n        );\n\n        const contentStream = await model\n          // We're already streaming the LLM response to the client through UI messages\n          // so we don't need to stream it again to the `messages` stream mode.\n          .withConfig({ tags: [\"nostream\"] })\n          .stream(`Create a short poem with the topic: ${message.text}`);\n\n        let content: AIMessageChunk | undefined;\n        for await (const chunk of contentStream) {\n          content = content?.concat(chunk) ?? chunk;\n\n          ui.push(\n            { id, name, props: { content: content?.text } },\n            // Use `merge: true` to merge props with the existing UI message\n            { message, merge: true }\n          );\n        }\n      }\n\n      return { messages: [message] };\n    }\n    ```\n  </Tab>\n\n  <Tab title=\"ui.tsx\">\n    ```tsx  theme={null}\n    function WriterComponent(props: { title: string; content?: string }) {\n      return (\n        <article>\n          <h2>{props.title}</h2>\n          <p style={{ whiteSpace: \"pre-wrap\" }}>{props.content}</p>\n        </article>\n      );\n    }\n\n    export default {\n      weather: WriterComponent,\n    };\n    ```\n  </Tab>\n</Tabs>\n\n### Remove UI messages from state\n\nSimilar to how messages can be removed from the state by appending a RemoveMessage you can remove an UI message from the state by calling `remove_ui_message` / `ui.delete` with the ID of the UI message.\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    from langgraph.graph.ui import push_ui_message, delete_ui_message\n\n    # push message\n    message = push_ui_message(\"weather\", {\"city\": \"London\"})\n\n    # remove said message\n    delete_ui_message(message[\"id\"])\n    ```\n  </Tab>\n\n  <Tab title=\"JS\">\n    ```tsx  theme={null}\n    // push message\n    const message = ui.push({ name: \"weather\", props: { city: \"London\" } });\n\n    // remove said message\n    ui.delete(message.id);\n    ```\n  </Tab>\n</Tabs>\n\n## Learn more\n\n* [JS/TS SDK Reference](https://langchain-ai.github.io/langgraphjs/reference/modules/sdk.html)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/generative-ui-react.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 18295
}