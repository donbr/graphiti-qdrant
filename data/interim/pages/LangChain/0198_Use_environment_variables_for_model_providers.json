{
  "title": "Use environment variables for model providers",
  "source_url": "https://docs.langchain.com/langsmith/self-host-playground-environment-settings",
  "content": "<Note>\n  This feature is only available on Helm chart versions 0.10.27 (application version 0.10.74) and later.\n</Note>\n\nMany model providers support setting credentials and other configuration options through environment variables. This is useful for self-hosted deployments where you want to avoid hardcoding sensitive information in your code or configuration files. In LangSmith, most model interactions are done through the `playground` service, which allows you to configure many of those environment variables directly on the pod itself. This can be useful to avoid having to set credentials in the UI.\n\n## Requirements\n\n* A self-hosted LangSmith instance with the `playground` service running.\n* The provider you want to configure must support environment variables for configuration. Check the provider's Chat Model [documentation](https://python.langchain.com/docs/integrations/providers/) for more information.\n* The secrets/roles you may want to attach to the `playground` service.\n  * Note that for IRSA you may need to grant the `langsmith-playground` service account the necessary permissions to access the secrets or roles in your cloud provider.\n\n## Configuration\n\nWith the parameters from above, you can configure your LangSmith instance to use environment variables for model providers. You can do this by modifying the `langsmith_config.yaml` file for your LangSmith Helm Chart installation or the `docker-compose.yaml` file for your Docker installation.\n\n<CodeGroup>\n  ```yaml Helm theme={null}\n  playground:\n    deployment:\n      extraEnv:\n        - name: OPENAI_BASE_URL\n          value: https://<my_proxy_url>\n        - name: OPENAI_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: <your_secret_name>\n              key: api_key\n    serviceAccount: # Can be useful if you want to use IRSA or workload identity\n      annotations:\n        eks.amazonaws.com/role-arn: <your_role_arn>\n  ```\n\n  ```yaml Docker theme={null}\n  # In your docker-compose.yaml file\n  langchain-playground:\n    environment:\n      .. # Other environment variables\n      - OPENAI_BASE_URL=https://<my_proxy_url>\n      - OPENAI_API_KEY=<your_key> # This will be set in the .env file\n  ```\n</CodeGroup>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/self-host-playground-environment-settings.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 2603
}