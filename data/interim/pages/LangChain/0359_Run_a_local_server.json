{
  "title": "Run a local server",
  "source_url": "https://docs.langchain.com/oss/javascript/langgraph/local-server",
  "content": "This guide shows you how to run a LangGraph application locally.\n\n## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n* An API key for [LangSmith](https://smith.langchain.com/settings) - free to sign up\n\n## 1. Install the LangGraph CLI\n\n```shell  theme={null}\nnpx @langchain/langgraph-cli\n```\n\n## 2. Create a LangGraph app ðŸŒ±\n\nCreate a new app from the [`new-langgraph-project-js` template](https://github.com/langchain-ai/new-langgraphjs-project). This template demonstrates a single-node application you can extend with your own logic.\n\n```shell  theme={null}\nnpm create langgraph\n```\n\n## 3. Install dependencies\n\nIn the root of your new LangGraph app, install the dependencies in `edit` mode so your local changes are used by the server:\n\n```shell  theme={null}\ncd path/to/your/app\nnpm install\n```\n\n## 4. Create a `.env` file\n\nYou will find a `.env.example` in the root of your new LangGraph app. Create a `.env` file in the root of your new LangGraph app and copy the contents of the `.env.example` file into it, filling in the necessary API keys:\n\n```bash  theme={null}\nLANGSMITH_API_KEY=lsv2...\n```\n\n## 5. Launch Agent server ðŸš€\n\nStart the LangGraph API server locally:\n\n```shell  theme={null}\nnpx @langchain/langgraph-cli dev\n```\n\nSample output:\n\n```\n>    Ready!\n>\n>    - API: [http://localhost:2024](http://localhost:2024/)\n>\n>    - Docs: http://localhost:2024/docs\n>\n>    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n```\n\nThe `langgraph dev` command starts Agent Server in an in-memory mode. This mode is suitable for development and testing purposes. For production use, deploy Agent Server with access to a persistent storage backend. For more information, see the [Platform setup overview](/langsmith/platform-setup).\n\n## 6. Test your application in Studio\n\n[Studio](/langsmith/studio) is a specialized UI that you can connect to LangGraph API server to visualize, interact with, and debug your application locally. Test your graph in Studio by visiting the URL provided in the output of the `langgraph dev` command:\n\n```\n>    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n```\n\nFor an Agent Server running on a custom host/port, update the baseURL parameter.\n\n<Accordion title=\"Safari compatibility\">\n  Use the `--tunnel` flag with your command to create a secure tunnel, as Safari has limitations when connecting to localhost servers:\n\n  ```shell  theme={null}\n  langgraph dev --tunnel\n  ```\n</Accordion>\n\n## 7. Test the API\n\n<Tabs>\n  <Tab title=\"Javascript SDK\">\n    1. Install the LangGraph JS SDK:\n\n    ```shell  theme={null}\n    npm install @langchain/langgraph-sdk\n    ```\n\n    2. Send a message to the assistant (threadless run):\n\n    ```js  theme={null}\n    const { Client } = await import(\"@langchain/langgraph-sdk\");\n\n    // only set the apiUrl if you changed the default port when calling langgraph dev\n    const client = new Client({ apiUrl: \"http://localhost:2024\"});\n\n    const streamResponse = client.runs.stream(\n        null, // Threadless run\n        \"agent\", // Assistant ID\n        {\n            input: {\n                \"messages\": [\n                    { \"role\": \"user\", \"content\": \"What is LangGraph?\"}\n                ]\n            },\n            streamMode: \"messages-tuple\",\n        }\n    );\n\n    for await (const chunk of streamResponse) {\n        console.log(`Receiving new event of type: ${chunk.event}...`);\n        console.log(JSON.stringify(chunk.data));\n        console.log(\"\\n\\n\");\n    }\n    ```\n  </Tab>\n\n  <Tab title=\"Rest API\">\n    ```bash  theme={null}\n    curl -s --request POST \\\n        --url \"http://localhost:2024/runs/stream\" \\\n        --header 'Content-Type: application/json' \\\n        --data \"{\n            \\\"assistant_id\\\": \\\"agent\\\",\n            \\\"input\\\": {\n                \\\"messages\\\": [\n                    {\n                        \\\"role\\\": \\\"human\\\",\n                        \\\"content\\\": \\\"What is LangGraph?\\\"\n                    }\n                ]\n            },\n            \\\"stream_mode\\\": \\\"messages-tuple\\\"\n        }\"\n    ```\n  </Tab>\n</Tabs>\n\n## Next steps\n\nNow that you have a LangGraph app running locally, take your journey further by exploring deployment and advanced features:\n\n* [Deployment quickstart](/langsmith/deployment-quickstart): Deploy your LangGraph app using LangSmith.\n\n* [LangSmith](/langsmith/home): Learn about foundational LangSmith concepts.\n\n* [JS/TS SDK Reference](https://reference.langchain.com/javascript/modules/_langchain_langgraph-sdk.html): Explore the JS/TS SDK API Reference.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langgraph/local-server.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 4953
}