{
  "title": "Context overview",
  "source_url": "https://docs.langchain.com/oss/javascript/concepts/context",
  "content": "**Context engineering** is the practice of building dynamic systems that provide the right information and tools, in the right format, so that an AI application can accomplish a task. Context can be characterized along two key dimensions:\n\n1. By **mutability**:\n\n* **Static context**: Immutable data that doesn't change during execution (e.g., user metadata, database connections, tools)\n* **Dynamic context**: Mutable data that evolves as the application runs (e.g., conversation history, intermediate results, tool call observations)\n\n2. By **lifetime**:\n\n* **Runtime context**: Data scoped to a single run or invocation\n* **Cross-conversation context**: Data that persists across multiple conversations or sessions\n\n<Tip>\n  Runtime context refers to local context: data and dependencies your code needs to run. It does **not** refer to:\n\n  * The LLM context, which is the data passed into the LLM's prompt.\n  * The \"context window\", which is the maximum number of tokens that can be passed to the LLM.\n\n  The runtime context is how you thread data through your agent. Rather than storing things in global state, you can attach values — like a database connection, user session, or configuration — to the context and access them inside tools and middleware. This keeps things stateless, testable, and reusable. For example, you can use user metadata in the runtime context to fetch user preferences and feed them into the context window.\n</Tip>\n\nLangGraph provides three ways to manage context, which combines the mutability and lifetime dimensions:\n\n| Context type                                                                                | Description                                   | Mutability | Lifetime           |\n| ------------------------------------------------------------------------------------------- | --------------------------------------------- | ---------- | ------------------ |\n| [**Config**](#config-static-context)                                                        | data passed at the start of a run             | Static     | Single run         |\n| [**Dynamic runtime context (state)**](#dynamic-runtime-context-state)                       | Mutable data that evolves during a single run | Dynamic    | Single run         |\n| [**Dynamic cross-conversation context (store)**](#dynamic-cross-conversation-context-store) | Persistent data shared across conversations   | Dynamic    | Cross-conversation |\n\n<a id=\"static-context\" />\n\n## Config\n\nConfig is for immutable data like user metadata or API keys. Use this when you have values that don't change mid-run.\n\nSpecify configuration using a key called **\"configurable\"** which is reserved for this purpose.\n\n```typescript  theme={null}\nawait graph.invoke(\n  { messages: [{ role: \"user\", content: \"hi!\" }] },\n  { configurable: { user_id: \"user_123\" } } // [!code highlight]\n);\n```\n\n<a id=\"state\" />\n\n## Dynamic runtime context\n\n**Dynamic runtime context** represents mutable data that can evolve during a single run and is managed through the LangGraph state object. This includes conversation history, intermediate results, and values derived from tools or LLM outputs. In LangGraph, the state object acts as [short-term memory](/oss/javascript/concepts/memory) during a run.\n\n<Tabs>\n  <Tab title=\"In an agent\">\n    Example shows how to incorporate state into an agent **prompt**.\n\n    State can also be accessed by the agent's **tools**, which can read or update the state as needed. See [tool calling guide](/oss/javascript/langchain/tools#short-term-memory) for details.\n\n    ```typescript  theme={null}\n    import { createAgent, createMiddleware } from \"langchain\";\n    import type { AgentState } from \"langchain\";\n    import * as z from \"zod\";\n\n    const CustomState = z.object({ // [!code highlight]\n      userName: z.string(),\n    });\n\n    const personalizedPrompt = createMiddleware({ // [!code highlight]\n      name: \"PersonalizedPrompt\",\n      stateSchema: CustomState,\n      wrapModelCall: (request, handler) => {\n        const userName = request.state.userName || \"User\";\n        const systemPrompt = `You are a helpful assistant. User's name is ${userName}`;\n        return handler({ ...request, systemPrompt });\n      },\n    });\n\n    const agent = createAgent({  // [!code highlight]\n      model: \"claude-sonnet-4-5-20250929\",\n      tools: [/* your tools here */],\n      middleware: [personalizedPrompt] as const, // [!code highlight]\n    });\n\n    await agent.invoke({\n      messages: [{ role: \"user\", content: \"hi!\" }],\n      userName: \"John Smith\",\n    });\n    ```\n  </Tab>\n\n  <Tab title=\"In a workflow\">\n    ```typescript  theme={null}\n    import type { BaseMessage } from \"@langchain/core/messages\";\n    import { StateGraph, MessagesZodMeta, START } from \"@langchain/langgraph\";\n    import { registry } from \"@langchain/langgraph/zod\";\n    import * as z from \"zod\";\n\n    const CustomState = z.object({  // [!code highlight]\n      messages: z\n        .array(z.custom<BaseMessage>())\n        .register(registry, MessagesZodMeta),\n      extraField: z.number(),\n    });\n\n    const builder = new StateGraph(CustomState)\n      .addNode(\"node\", async (state) => {  // [!code highlight]\n        const messages = state.messages;\n        // ...\n        return {  // [!code highlight]\n          extraField: state.extraField + 1,\n        };\n      })\n      .addEdge(START, \"node\");\n\n    const graph = builder.compile();\n    ```\n  </Tab>\n</Tabs>\n\n<Tip>\n  **Turning on memory**\n  Please see the [memory guide](/oss/javascript/langgraph/add-memory) for more details on how to enable memory. This is a powerful feature that allows you to persist the agent's state across multiple invocations. Otherwise, the state is scoped only to a single run.\n</Tip>\n\n<a id=\"store\" />\n\n## Dynamic cross-conversation context\n\n**Dynamic cross-conversation context** represents persistent, mutable data that spans across multiple conversations or sessions and is managed through the LangGraph store. This includes user profiles, preferences, and historical interactions. The LangGraph store acts as [long-term memory](/oss/javascript/concepts/memory#long-term-memory) across multiple runs. This can be used to read or update persistent facts (e.g., user profiles, preferences, prior interactions).\n\n## See also\n\n* [Memory conceptual overview](/oss/javascript/concepts/memory)\n* [Short-term memory in LangChain](/oss/javascript/langchain/short-term-memory)\n* [Long-term memory in LangChain](/oss/javascript/langchain/long-term-memory)\n* [Memory in LangGraph](/oss/javascript/langgraph/add-memory)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/concepts/context.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 6922
}