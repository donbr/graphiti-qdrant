{
  "title": "Configure your collector for LangSmith telemetry",
  "source_url": "https://docs.langchain.com/langsmith/langsmith-collector",
  "content": "The various services in a LangSmith deployment emit telemetry data in the form of logs, metrics, and traces. You may already have telemetry collectors set up in your Kubernetes cluster, or would like to deploy one to monitor your application.\n\nThis page describes how to configure an [OTel Collector](https://opentelemetry.io/docs/collector/configuration/) to gather telemetry data from LangSmith. Note that all of the concepts discussed below can be translated to other collectors such as [Fluentd](https://www.fluentd.org/) or [FluentBit](https://fluentbit.io/).\n\n<Warning>\n  **This section is only applicable for Kubernetes deployments.**\n</Warning>\n\n# Receivers\n\n## Logs\n\nThis is an example for a ***Sidecar*** collector to read logs from its own pod, excluding logs from non domain-specific containers. A Sidecar configuration is useful here because we require access to every container's filesystem. A DaemonSet can also be used.\n\n```yaml  theme={null}\nfilelog:\n  exclude:\n    - \"**/otc-container/*.log\"\n  include:\n    - /var/log/pods/${POD_NAMESPACE}_${POD_NAME}_${POD_UID}/*/*.log\n  include_file_name: false\n  include_file_path: true\n  operators:\n    - id: container-parser\n      type: container\n  retry_on_failure:\n    enabled: true\n  start_at: end\nenv:\n  - name: POD_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.name\n  - name: POD_NAMESPACE\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.namespace\n  - name: POD_UID\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.uid\nvolumes:\n  - name: varlogpods\n    hostPath:\n      path: /var/log/pods\nvolumeMounts:\n  - name: varlogpods\n    mountPath: /var/log/pods\n    readOnly: true\n```\n\n<Info>\n  **This configuration requires 'get', 'list', and 'watch' permissions on pods in the given namespace.**\n</Info>\n\n## Metrics\n\nMetrics can be scraped using the Prometheus endpoints. A single instance ***Gateway*** collector can be be used to avoid duplication of queries when fetching metrics. The following config scrapes all of the default named LangSmith services:\n\n```yaml  theme={null}\nprometheus:\n  config:\n    scrape_configs:\n      - job_name: langsmith-services\n        metrics_path: /metrics\n        scrape_interval: 15s\n        # Only scrape endpoints in the LangSmith namespace\n        kubernetes_sd_configs:\n          - role: endpoints\n            namespaces:\n              names: [<langsmith-namespace>]\n        relabel_configs:\n          # Only scrape services with the name langsmith-.*\n          - source_labels: [__meta_kubernetes_service_name]\n            regex: \"langsmith-.*\"\n            action: keep\n          # Only scrape ports with the following names\n          - source_labels: [__meta_kubernetes_endpoint_port_name]\n            regex: \"(backend|platform|playground|redis-metrics|postgres-metrics|metrics)\"\n            action: keep\n          # Promote useful metadata into regular labels\n          - source_labels: [__meta_kubernetes_service_name]\n            target_label: k8s_service\n          - source_labels: [__meta_kubernetes_pod_name]\n            target_label: k8s_pod\n          # Replace the default \"host:port\" as Prom's instance label\n          - source_labels: [__address__]\n            target_label: instance\n```\n\n<Info>\n  **This configuration requires 'get', 'list', and 'watch' permissions on pods, services and endpoints in the given namespace.**\n</Info>\n\n### Traces\n\nFor traces, you need to enable the OTLP receiver. The following configuration can be used to listen to HTTP traces on port 4318, and GRPC on port 4317:\n\n```yaml  theme={null}\notlp:\n  protocols:\n    grpc:\n      endpoint: 0.0.0.0:4317\n    http:\n      endpoint: 0.0.0.0:4318\n```\n\n## Processors\n\n### Recommended OTEL Processors\n\nThe following processors are recommended when using the OTel collector:\n\n* [Batch Processor](https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md): Groups the data into batches before sending to exporters.\n* [Memory Limiter](https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiterprocessor/README.md): Prevents the collector from using too much memory and crashing. When the soft limit is crossed, the collector stops accepting new data.\n* [Kubernetes Attributes Processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/k8sattributesprocessor): Adds Kubernetes metadata such as pod name into the telemetry data.\n\n## Exporters\n\nExporters just need to point to an external endpoint of your liking. The following configuration allows you to configure a separate endpoint for logs, metrics and traces:\n\n```yaml  theme={null}\notlphttp/logs:\n  endpoint: <your_logs_endpoint>\notlphttp/metrics:\n  endpoint: <your_metrics_endpoint>\notlphttp/traces:\n  endpoint: <your_traces_endpoint>\n```\n\n<Note>\n  **The OTel Collector also supports exporting directly to a [Datadog](https://docs.datadoghq.com/opentelemetry/setup/collector_exporter) endpoint.**\n</Note>\n\n# Example Collector Configuration: Logs Sidecar\n\n```yaml  theme={null}\nmode: sidecar\nimage: otel/opentelemetry-collector-contrib\nconfig:\n  receivers:\n    filelog:\n      exclude:\n        - \"**/otc-container/*.log\"\n      include:\n        - /var/log/pods/${POD_NAMESPACE}_${POD_NAME}_${POD_UID}/*/*.log\n      include_file_name: false\n      include_file_path: true\n      operators:\n        - id: container-parser\n          type: container\n      retry_on_failure:\n        enabled: true\n      start_at: end\n  processors:\n    batch:\n      send_batch_size: 8192\n      timeout: 10s\n    memory_limiter:\n      check_interval: 1m\n      limit_percentage: 90\n      spike_limit_percentage: 80\n  exporters:\n    otlphttp/logs:\n      endpoint: <your-endpoint>\n  service:\n    pipelines:\n      logs/langsmith:\n        receivers: [filelog]\n        processors: [batch, memory_limiter]\n        exporters: [otlphttp/logs]\nenv:\n  - name: POD_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.name\n  - name: POD_NAMESPACE\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.namespace\n  - name: POD_UID\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.uid\nvolumes:\n  - name: varlogpods\n    hostPath:\n      path: /var/log/pods\nvolumeMounts:\n  - name: varlogpods\n    mountPath: /var/log/pods\n    readOnly: true\n```\n\n# Example Collector Configuration: Metrics and Traces Gateway\n\n```yaml  theme={null}\nmode: deployment\nimage: otel/opentelemetry-collector-contrib\nconfig:\n  receivers:\n    prometheus:\n      config:\n        scrape_configs:\n          - job_name: langsmith-services\n            metrics_path: /metrics\n            scrape_interval: 15s\n            # Only scrape endpoints in the LangSmith namespace\n            kubernetes_sd_configs:\n              - role: endpoints\n                namespaces:\n                  names: [<langsmith-namespace>]\n            relabel_configs:\n              # Only scrape services with the name langsmith-.*\n              - source_labels: [__meta_kubernetes_service_name]\n                regex: \"langsmith-.*\"\n                action: keep\n              # Only scrape ports with the following names\n              - source_labels: [__meta_kubernetes_endpoint_port_name]\n                regex: \"(backend|platform|playground|redis-metrics|postgres-metrics|metrics)\"\n                action: keep\n              # Promote useful metadata into regular labels\n              - source_labels: [__meta_kubernetes_service_name]\n                target_label: k8s_service\n              - source_labels: [__meta_kubernetes_pod_name]\n                target_label: k8s_pod\n              # Replace the default \"host:port\" as Prom's instance label\n              - source_labels: [__address__]\n                target_label: instance\n    otlp:\n      protocols:\n        grpc:\n          endpoint: 0.0.0.0:4317\n        http:\n          endpoint: 0.0.0.0:4318\n  processors:\n    batch:\n      send_batch_size: 8192\n      timeout: 10s\n    memory_limiter:\n      check_interval: 1m\n      limit_percentage: 90\n      spike_limit_percentage: 80\n  exporters:\n    otlphttp/metrics:\n      endpoint: <metrics_endpoint>\n    otlphttp/traces:\n      endpoint: <traces_endpoint>\n  service:\n    pipelines:\n      metrics/langsmith:\n        receivers: [prometheus]\n        processors: [batch, memory_limiter]\n        exporters: [otlphttp/metrics]\n      traces/langsmith:\n        receivers: [otlp]\n        processors: [batch, memory_limiter]\n        exporters: [otlphttp/traces]\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/langsmith-collector.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 8825
}