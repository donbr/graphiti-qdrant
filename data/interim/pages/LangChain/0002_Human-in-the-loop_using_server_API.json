{
  "title": "Human-in-the-loop using server API",
  "source_url": "https://docs.langchain.com/langsmith/add-human-in-the-loop",
  "content": "To review, edit, and approve tool calls in an agent or workflow, use LangGraph's [human-in-the-loop](/oss/python/langgraph/interrupts) features.\n\n## Dynamic interrupts\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python {highlight={2,34}} theme={null}\n    from langgraph_sdk import get_client\n    from langgraph_sdk.schema import Command\n    client = get_client(url=<DEPLOYMENT_URL>)\n\n    # Using the graph deployed with the name \"agent\"\n    assistant_id = \"agent\"\n\n    # create a thread\n    thread = await client.threads.create()\n    thread_id = thread[\"thread_id\"]\n\n    # Run the graph until the interrupt is hit.\n    result = await client.runs.wait(\n        thread_id,\n        assistant_id,\n        input={\"some_text\": \"original text\"}   # (1)!\n    )\n\n    print(result['__interrupt__']) # (2)!\n    # > [\n    # >     {\n    # >         'value': {'text_to_revise': 'original text'},\n    # >         'resumable': True,\n    # >         'ns': ['human_node:fc722478-2f21-0578-c572-d9fc4dd07c3b'],\n    # >         'when': 'during'\n    # >     }\n    # > ]\n\n\n    # Resume the graph\n    print(await client.runs.wait(\n        thread_id,\n        assistant_id,\n        command=Command(resume=\"Edited text\")   # (3)!\n    ))\n    # > {'some_text': 'Edited text'}\n    ```\n\n    1. The graph is invoked with some initial state.\n    2. When the graph hits the interrupt, it returns an interrupt object with the payload and metadata.\n       3\\. The graph is resumed with a `Command(resume=...)`, injecting the human's input and continuing execution.\n  </Tab>\n\n  <Tab title=\"JavaScript\">\n    ```javascript {highlight={32}} theme={null}\n    import { Client } from \"@langchain/langgraph-sdk\";\n    const client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n\n    // Using the graph deployed with the name \"agent\"\n    const assistantID = \"agent\";\n\n    // create a thread\n    const thread = await client.threads.create();\n    const threadID = thread[\"thread_id\"];\n\n    // Run the graph until the interrupt is hit.\n    const result = await client.runs.wait(\n      threadID,\n      assistantID,\n      { input: { \"some_text\": \"original text\" } }   # (1)!\n    );\n\n    console.log(result['__interrupt__']); # (2)!\n    // > [\n    # >     {\n    # >         'value': {'text_to_revise': 'original text'},\n    # >         'resumable': True,\n    # >         'ns': ['human_node:fc722478-2f21-0578-c572-d9fc4dd07c3b'],\n    # >         'when': 'during'\n    # >     }\n    # > ]\n\n    // Resume the graph\n    console.log(await client.runs.wait(\n        threadID,\n        assistantID,\n        { command: { resume: \"Edited text\" }}   # (3)!\n    ));\n    # > {'some_text': 'Edited text'}\n    ```\n\n    1. The graph is invoked with some initial state.\n    2. When the graph hits the interrupt, it returns an interrupt object with the payload and metadata.\n    3. The graph is resumed with a `{ resume: ... }` command object, injecting the human's input and continuing execution.\n  </Tab>\n\n  <Tab title=\"cURL\">\n    Create a thread:\n\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads \\\n    --header 'Content-Type: application/json' \\\n    --data '{}'\n    ```\n\n    Run the graph until the interrupt is hit.:\n\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n    --header 'Content-Type: application/json' \\\n    --data \"{\n      \\\"assistant_id\\\": \\\"agent\\\",\n      \\\"input\\\": {\\\"some_text\\\": \\\"original text\\\"}\n    }\"\n    ```\n\n    Resume the graph:\n\n    ```bash  theme={null}\n    curl --request POST \\\n     --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n     --header 'Content-Type: application/json' \\\n     --data \"{\n       \\\"assistant_id\\\": \\\"agent\\\",\n       \\\"command\\\": {\n         \\\"resume\\\": \\\"Edited text\\\"\n       }\n     }\"\n    ```\n  </Tab>\n</Tabs>\n\n<Accordion title=\"Extended example: using `interrupt`\">\n  This is an example graph you can run in the Agent Server.\n  See [LangSmith quickstart](/langsmith/deployment-quickstart) for more details.\n\n  ```python {highlight={7,13}} theme={null}\n  from typing import TypedDict\n  import uuid\n\n  from langgraph.checkpoint.memory import InMemorySaver\n  from langgraph.constants import START\n  from langgraph.graph import StateGraph\n  from langgraph.types import interrupt, Command\n\n  class State(TypedDict):\n      some_text: str\n\n  def human_node(state: State):\n      value = interrupt( # (1)!\n          {\n              \"text_to_revise\": state[\"some_text\"] # (2)!\n          }\n      )\n      return {\n          \"some_text\": value # (3)!\n      }\n\n\n  # Build the graph\n  graph_builder = StateGraph(State)\n  graph_builder.add_node(\"human_node\", human_node)\n  graph_builder.add_edge(START, \"human_node\")\n\n  graph = graph_builder.compile()\n  ```\n\n  1. `interrupt(...)` pauses execution at `human_node`, surfacing the given payload to a human.\n  2. Any JSON serializable value can be passed to the [`interrupt`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.interrupt) function. Here, a dict containing the text to revise.\n  3. Once resumed, the return value of `interrupt(...)` is the human-provided input, which is used to update the state.\n\n  Once you have a running Agent Server, you can interact with it using\n  [LangGraph SDK](/langsmith/langgraph-python-sdk)\n\n  <Tabs>\n    <Tab title=\"Python\">\n      ```python {highlight={2,34}} theme={null}\n      from langgraph_sdk import get_client\n      from langgraph_sdk.schema import Command\n      client = get_client(url=<DEPLOYMENT_URL>)\n\n      # Using the graph deployed with the name \"agent\"\n      assistant_id = \"agent\"\n\n      # create a thread\n      thread = await client.threads.create()\n      thread_id = thread[\"thread_id\"]\n\n      # Run the graph until the interrupt is hit.\n      result = await client.runs.wait(\n          thread_id,\n          assistant_id,\n          input={\"some_text\": \"original text\"}   # (1)!\n      )\n\n      print(result['__interrupt__']) # (2)!\n      # > [\n      # >     {\n      # >         'value': {'text_to_revise': 'original text'},\n      # >         'resumable': True,\n      # >         'ns': ['human_node:fc722478-2f21-0578-c572-d9fc4dd07c3b'],\n      # >         'when': 'during'\n      # >     }\n      # > ]\n\n\n      # Resume the graph\n      print(await client.runs.wait(\n          thread_id,\n          assistant_id,\n          command=Command(resume=\"Edited text\")   # (3)!\n      ))\n      # > {'some_text': 'Edited text'}\n      ```\n\n      1. The graph is invoked with some initial state.\n      2. When the graph hits the interrupt, it returns an interrupt object with the payload and metadata.\n         3\\. The graph is resumed with a `Command(resume=...)`, injecting the human's input and continuing execution.\n    </Tab>\n\n    <Tab title=\"JavaScript\">\n      ```javascript {highlight={32}} theme={null}\n      import { Client } from \"@langchain/langgraph-sdk\";\n      const client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n\n      // Using the graph deployed with the name \"agent\"\n      const assistantID = \"agent\";\n\n      // create a thread\n      const thread = await client.threads.create();\n      const threadID = thread[\"thread_id\"];\n\n      // Run the graph until the interrupt is hit.\n      const result = await client.runs.wait(\n        threadID,\n        assistantID,\n        { input: { \"some_text\": \"original text\" } }   # (1)!\n      );\n\n      console.log(result['__interrupt__']); # (2)!\n      # > [\n      # >     {\n      # >         'value': {'text_to_revise': 'original text'},\n      # >         'resumable': True,\n      # >         'ns': ['human_node:fc722478-2f21-0578-c572-d9fc4dd07c3b'],\n      # >         'when': 'during'\n      # >     }\n      # > ]\n\n      // Resume the graph\n      console.log(await client.runs.wait(\n          threadID,\n          assistantID,\n          { command: { resume: \"Edited text\" }}   # (3)!\n      ));\n      # > {'some_text': 'Edited text'}\n      ```\n\n      1. The graph is invoked with some initial state.\n      2. When the graph hits the interrupt, it returns an interrupt object with the payload and metadata.\n      3. The graph is resumed with a `{ resume: ... }` command object, injecting the human's input and continuing execution.\n    </Tab>\n\n    <Tab title=\"cURL\">\n      Create a thread:\n\n      ```bash  theme={null}\n      curl --request POST \\\n      --url <DEPLOYMENT_URL>/threads \\\n      --header 'Content-Type: application/json' \\\n      --data '{}'\n      ```\n\n      Run the graph until the interrupt is hit:\n\n      ```bash  theme={null}\n      curl --request POST \\\n      --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n      --header 'Content-Type: application/json' \\\n      --data \"{\n        \\\"assistant_id\\\": \\\"agent\\\",\n        \\\"input\\\": {\\\"some_text\\\": \\\"original text\\\"}\n      }\"\n      ```\n\n      Resume the graph:\n\n      ```bash  theme={null}\n      curl --request POST \\\n      --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n      --header 'Content-Type: application/json' \\\n      --data \"{\n        \\\"assistant_id\\\": \\\"agent\\\",\n        \\\"command\\\": {\n          \\\"resume\\\": \\\"Edited text\\\"\n        }\n      }\"\n      ```\n    </Tab>\n  </Tabs>\n</Accordion>\n\n## Static interrupts\n\nStatic interrupts (also known as static breakpoints) are triggered either before or after a node executes.\n\n<Warning>\n  Static interrupts are **not** recommended for human-in-the-loop workflows. They are best used for debugging and testing.\n</Warning>\n\nYou can set static interrupts by specifying `interrupt_before` and `interrupt_after` at compile time:\n\n```python {highlight={1,2,3}} theme={null}\ngraph = graph_builder.compile( # (1)!\n    interrupt_before=[\"node_a\"], # (2)!\n    interrupt_after=[\"node_b\", \"node_c\"], # (3)!\n)\n```\n\n1. The breakpoints are set during `compile` time.\n2. `interrupt_before` specifies the nodes where execution should pause before the node is executed.\n3. `interrupt_after` specifies the nodes where execution should pause after the node is executed.\n\nAlternatively, you can set static interrupts at run time:\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python {highlight={1,5,6}} theme={null}\n    await client.runs.wait( # (1)!\n        thread_id,\n        assistant_id,\n        inputs=inputs,\n        interrupt_before=[\"node_a\"], # (2)!\n        interrupt_after=[\"node_b\", \"node_c\"] # (3)!\n    )\n    ```\n\n    1. `client.runs.wait` is called with the `interrupt_before` and `interrupt_after` parameters. This is a run-time configuration and can be changed for every invocation.\n    2. `interrupt_before` specifies the nodes where execution should pause before the node is executed.\n    3. `interrupt_after` specifies the nodes where execution should pause after the node is executed.\n  </Tab>\n\n  <Tab title=\"JavaScript\">\n    ```javascript {highlight={1,6,7}} theme={null}\n    await client.runs.wait( // (1)!\n        threadID,\n        assistantID,\n        {\n        input: input,\n        interruptBefore: [\"node_a\"], // (2)!\n        interruptAfter: [\"node_b\", \"node_c\"] // (3)!\n        }\n    )\n    ```\n\n    1. `client.runs.wait` is called with the `interruptBefore` and `interruptAfter` parameters. This is a run-time configuration and can be changed for every invocation.\n    2. `interruptBefore` specifies the nodes where execution should pause before the node is executed.\n    3. `interruptAfter` specifies the nodes where execution should pause after the node is executed.\n  </Tab>\n\n  <Tab title=\"cURL\">\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n    --header 'Content-Type: application/json' \\\n    --data \"{\n        \\\"assistant_id\\\": \\\"agent\\\",\n        \\\"interrupt_before\\\": [\\\"node_a\\\"],\n        \\\"interrupt_after\\\": [\\\"node_b\\\", \\\"node_c\\\"],\n        \\\"input\\\": <INPUT>\n    }\"\n    ```\n  </Tab>\n</Tabs>\n\nThe following example shows how to add static interrupts:\n\n<Tabs>\n  <Tab title=\"Python\">\n    ```python  theme={null}\n    from langgraph_sdk import get_client\n    client = get_client(url=<DEPLOYMENT_URL>)\n\n    # Using the graph deployed with the name \"agent\"\n    assistant_id = \"agent\"\n\n    # create a thread\n    thread = await client.threads.create()\n    thread_id = thread[\"thread_id\"]\n\n    # Run the graph until the breakpoint\n    result = await client.runs.wait(\n        thread_id,\n        assistant_id,\n        input=inputs   # (1)!\n    )\n\n    # Resume the graph\n    await client.runs.wait(\n        thread_id,\n        assistant_id,\n        input=None   # (2)!\n    )\n    ```\n\n    1. The graph is run until the first breakpoint is hit.\n    2. The graph is resumed by passing in `None` for the input. This will run the graph until the next breakpoint is hit.\n  </Tab>\n\n  <Tab title=\"JavaScript\">\n    ```js  theme={null}\n    import { Client } from \"@langchain/langgraph-sdk\";\n    const client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n\n    // Using the graph deployed with the name \"agent\"\n    const assistantID = \"agent\";\n\n    // create a thread\n    const thread = await client.threads.create();\n    const threadID = thread[\"thread_id\"];\n\n    // Run the graph until the breakpoint\n    const result = await client.runs.wait(\n      threadID,\n      assistantID,\n      { input: input }   # (1)!\n    );\n\n    // Resume the graph\n    await client.runs.wait(\n      threadID,\n      assistantID,\n      { input: null }   # (2)!\n    );\n    ```\n\n    1. The graph is run until the first breakpoint is hit.\n    2. The graph is resumed by passing in `null` for the input. This will run the graph until the next breakpoint is hit.\n  </Tab>\n\n  <Tab title=\"cURL\">\n    Create a thread:\n\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads \\\n    --header 'Content-Type: application/json' \\\n    --data '{}'\n    ```\n\n    Run the graph until the breakpoint:\n\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n    --header 'Content-Type: application/json' \\\n    --data \"{\n      \\\"assistant_id\\\": \\\"agent\\\",\n      \\\"input\\\": <INPUT>\n    }\"\n    ```\n\n    Resume the graph:\n\n    ```bash  theme={null}\n    curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/wait \\\n    --header 'Content-Type: application/json' \\\n    --data \"{\n      \\\"assistant_id\\\": \\\"agent\\\"\n    }\"\n    ```\n  </Tab>\n</Tabs>\n\n## Learn more\n\n* [Human-in-the-loop conceptual guide](/oss/python/langgraph/interrupts): learn more about LangGraph human-in-the-loop features.\n* [Common patterns](/oss/python/langgraph/interrupts#common-patterns): learn how to implement patterns like approving/rejecting actions, requesting user input, tool call review, and validating human input.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/add-human-in-the-loop.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "content_length": 14934
}